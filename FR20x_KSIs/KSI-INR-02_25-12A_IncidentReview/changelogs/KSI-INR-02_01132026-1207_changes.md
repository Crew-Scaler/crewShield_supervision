# Extracted Metadata and Statistics

Extracted on: 01132026-1207

**Data Source:** Synthesized from 160 research papers on AI-driven incident logging, analysis, and threat detection (2019-2025)
**Filtering Criteria:** Questions directly addressing AI-driven incident analysis capabilities, defenses against attacks targeting AI systems, compliance automation for AI logging, and agentic failure modes. Removed or moved: (1) generic incident response procedures not specific to AI systems; (2) infrastructure-heavy vector database performance/cost optimization questions (Q32-Q35 from Section 7, moved to logging/architecture and retention KSIs); (3) sponge attack and context window overflow questions (Q28-Q29 from Section 6, moved to resilience and access control KSIs); (4) API protection query rate limiting question (Q22 from Section 5, moved to API security KSI); (5) regulatory compliance mapping details duplicated across KSIs; (6) detailed standards citations (EU AI Act Articles moved to generic governance KSI).

**Question Reduction Summary:**
- Original: 40 questions across 8 sections
- Final: 30 questions across 8 sections
- Removed/Moved: 10 questions (Q22, Q25, Q28-Q35 from original numbering)
- Merged: Q11+Q13 (prompt injection risk and MTTD), Q14+Q15 (adversarial testing consolidated), Q37+Q39 (trust and feedback), Q38+Q40 (compliance and governance focused on incident analysis)

**Research Synthesis:** 160 papers synthesized into 10 thematic clusters emphasizing: Chain-of-Thought Tracing (25 papers) enabling 75% investigation time reduction with 10-100x storage overhead; AI-Powered Anomaly Detection (28 papers) achieving 60-80% alert compression with 3x threat discovery rate; Prompt Injection via Logs (18 papers) documenting 80-95% success rates against undefended systems; Log Poisoning (22 papers) showing 0.1-1% poisoned data causes 15-30% false negative increase; Model Inversion (15 papers) reducing extraction efficiency from 10,000+ queries to 500-1,000 queries; Agentic Incident Patterns (20 papers) documenting infinite loops ($10K-$50K cost), hallucination cascades (5-15 service impact); Accidental Secret Leakage (12 papers) with 3-8% of AI logs containing sensitive data vs 0.1-0.5% traditional; Semantic Log Analysis (16 papers) enabling 10-100x faster semantic search with performance validation; Explainability/Auditability (18 papers) improving analyst comprehension from 38% to >70%; Compliance/Regulatory (14 papers) covering minimum retention and audit trail requirements. Key finding: Organizations lack visibility into AI system degradation; 91% of ML systems exhibit measurable performance drift but 75% lack monitoring, creating blind windows where poisoned or degraded models operate undetected. Compliance mandates and adversarial threat evolution require continuous governance transformation from reactive incident response to proactive AI system resilience.