{
  "arxiv_id": "2404.03984v1",
  "title": "ROMA-iQSS: An Objective Alignment Approach via State-Based Value Learning and ROund-Robin Multi-Agent Scheduling",
  "authors": [
    "Chi-Hui Lin",
    "Joewie J. Koh",
    "Alessandro Roncone",
    "Lijun Chen"
  ],
  "published": "2024-04-05",
  "year": 2024,
  "relevance_score": 80,
  "arxiv_url": "https://arxiv.org/abs/2404.03984v1",
  "pdf_url": "https://arxiv.org/pdf/2404.03984v1.pdf",
  "cluster": "cluster-d",
  "abstract": "Effective multi-agent collaboration is imperative for solving complex, distributed problems. In this context, two key challenges must be addressed: first, autonomously identifying optimal objectives for collective outcomes; second, aligning these objectives among agents. Traditional frameworks, often reliant on centralized learning, struggle with scalability and efficiency in large multi-agent systems. To overcome these issues, we introduce a decentralized state-based value learning algorithm th",
  "metadata_generated": "2026-01-10T18:09:06.439696"
}