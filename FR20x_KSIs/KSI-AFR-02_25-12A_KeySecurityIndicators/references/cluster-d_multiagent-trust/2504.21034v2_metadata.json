{
  "arxiv_id": "2504.21034v2",
  "title": "SAGA: A Security Architecture for Governing AI Agentic Systems",
  "authors": [
    "Georgios Syros",
    "Anshuman Suri",
    "Jacob Ginesin",
    "Cristina Nita-Rotaru",
    "Alina Oprea"
  ],
  "published": "2025-04-27",
  "year": 2025,
  "relevance_score": 85,
  "arxiv_url": "https://arxiv.org/abs/2504.21034v2",
  "pdf_url": "https://arxiv.org/pdf/2504.21034v2.pdf",
  "cluster": "cluster-d",
  "abstract": "Large Language Model (LLM)-based agents increasingly interact, collaborate, and delegate tasks to one another autonomously with minimal human interaction. Industry guidelines for agentic system governance emphasize the need for users to maintain comprehensive control over their agents, mitigating potential damage from malicious agents. Several proposed agentic system designs address agent identity, authorization, and delegation, but remain purely theoretical, without concrete implementation and ",
  "metadata_generated": "2026-01-10T18:09:06.437332"
}