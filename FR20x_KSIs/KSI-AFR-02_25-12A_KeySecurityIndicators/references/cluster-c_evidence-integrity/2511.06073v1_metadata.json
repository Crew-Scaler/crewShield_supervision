{
  "arxiv_id": "2511.06073v1",
  "title": "Stemming Hallucination in Language Models Using a Licensing Oracle",
  "authors": [
    "Simeon Emanuilov",
    "Richard Ackermann"
  ],
  "published": "2025-11-08",
  "year": 2025,
  "relevance_score": 65,
  "arxiv_url": "https://arxiv.org/abs/2511.06073v1",
  "pdf_url": "https://arxiv.org/pdf/2511.06073v1.pdf",
  "cluster": "cluster-c",
  "abstract": "Language models exhibit remarkable natural language generation capabilities but remain prone to hallucinations, generating factually incorrect information despite producing syntactically coherent responses. This study introduces the Licensing Oracle, an architectural solution designed to stem hallucinations in LMs by enforcing truth constraints through formal validation against structured knowledge graphs. Unlike statistical approaches that rely on data scaling or fine-tuning, the Licensing Orac",
  "metadata_generated": "2026-01-10T18:09:06.433058"
}