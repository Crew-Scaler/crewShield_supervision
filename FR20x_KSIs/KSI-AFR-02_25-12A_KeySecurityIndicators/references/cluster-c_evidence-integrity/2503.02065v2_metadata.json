{
  "arxiv_id": "2503.02065v2",
  "title": "Too Much to Trust? Measuring the Security and Cognitive Impacts of Explainability in AI-Driven SOCs",
  "authors": [
    "Nidhi Rastogi",
    "Shirid Pant",
    "Devang Dhanuka",
    "Amulya Saxena",
    "Pranjal Mairal"
  ],
  "published": "2025-03-03",
  "year": 2025,
  "relevance_score": 65,
  "arxiv_url": "https://arxiv.org/abs/2503.02065v2",
  "pdf_url": "https://arxiv.org/pdf/2503.02065v2.pdf",
  "cluster": "cluster-c",
  "abstract": "Explainable AI (XAI) holds significant promise for enhancing the transparency and trustworthiness of AI-driven threat detection in Security Operations Centers (SOCs). However, identifying the appropriate level and format of explanation, particularly in environments that demand rapid decision-making under high-stakes conditions, remains a complex and underexplored challenge. To address this gap, we conducted a three-month mixed-methods study combining an online survey (N1=248) with in-depth inter",
  "metadata_generated": "2026-01-10T18:09:06.431544"
}