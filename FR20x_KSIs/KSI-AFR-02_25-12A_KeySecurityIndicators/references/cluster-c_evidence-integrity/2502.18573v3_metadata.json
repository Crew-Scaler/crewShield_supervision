{
  "arxiv_id": "2502.18573v3",
  "title": "FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models",
  "authors": [
    "Radu Marinescu",
    "Debarun Bhattacharjya",
    "Junkyu Lee",
    "Tigran Tchrakian",
    "Javier Carnerero Cano",
    "Yufang Hou",
    "Elizabeth Daly",
    "Alessandra Pascale"
  ],
  "published": "2025-02-25",
  "year": 2025,
  "relevance_score": 60,
  "arxiv_url": "https://arxiv.org/abs/2502.18573v3",
  "pdf_url": "https://arxiv.org/pdf/2502.18573v3.pdf",
  "cluster": "cluster-c",
  "abstract": "Large language models (LLMs) have achieved remarkable success in generative tasks, yet they often fall short in ensuring the factual accuracy of their outputs, thus limiting their reliability in real-world applications where correctness is critical. In this paper, we present FactReasoner, a novel neuro-symbolic based factuality assessment framework that employs probabilistic reasoning to evaluate the truthfulness of long-form generated responses. FactReasoner decomposes a response into atomic un",
  "metadata_generated": "2026-01-10T18:09:06.432789"
}