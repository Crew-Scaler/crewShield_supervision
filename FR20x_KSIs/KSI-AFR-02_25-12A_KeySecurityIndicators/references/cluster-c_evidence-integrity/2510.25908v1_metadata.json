{
  "arxiv_id": "2510.25908v1",
  "title": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications",
  "authors": [
    "Emily Herron",
    "Junqi Yin",
    "Feiyi Wang"
  ],
  "published": "2025-10-29",
  "year": 2025,
  "relevance_score": 65,
  "arxiv_url": "https://arxiv.org/abs/2510.25908v1",
  "pdf_url": "https://arxiv.org/pdf/2510.25908v1.pdf",
  "cluster": "cluster-c",
  "abstract": "Large language models (LLMs) have demonstrated transformative potential in scientific research, yet their deployment in high-stakes contexts raises significant trustworthiness concerns. Here, we introduce SciTrust 2.0, a comprehensive framework for evaluating LLM trustworthiness in scientific applications across four dimensions: truthfulness, adversarial robustness, scientific safety, and scientific ethics. Our framework incorporates novel, open-ended truthfulness benchmarks developed through a ",
  "metadata_generated": "2026-01-10T18:09:06.432702"
}