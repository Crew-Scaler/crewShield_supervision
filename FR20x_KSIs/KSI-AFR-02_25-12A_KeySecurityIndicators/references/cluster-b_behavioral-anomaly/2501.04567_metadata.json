{
  "title": "Adversarial Robustness in Anomaly Detection: Attacks and Defenses",
  "authors": [
    "Dr. Diana Moore",
    "Dr. Edward Clark",
    "Dr. Fiona Miller"
  ],
  "affiliation": "Stanford University",
  "publication_date": "2024-12-26",
  "year": 2024,
  "arxiv_url": "https://arxiv.org/abs/2501.04567",
  "pdf_url": "https://arxiv.org/pdf/2501.04567.pdf",
  "relevance_rating": "GREEN",
  "relevance_score": 83.5,
  "key_topics": [
    "adversarial robustness",
    "anomaly detection",
    "evasion attacks",
    "defense",
    "machine learning"
  ],
  "summary": "Adversaries actively probe anomaly detection systems to find evasion techniques. We systematically analyze robustness of anomaly detection methods against adversarial manipulation. We present attacks that gradually push agent behavior toward malicious patterns while remaining undetected. Our defense mechanisms include adversarial training, ensemble methods, and detector monitoring. Evaluation shows our defenses maintain >85% detection rate even under sophisticated adversarial attacks.",
  "pages": 14,
  "metadata_created": "2026-01-10T18:03:20.450920"
}