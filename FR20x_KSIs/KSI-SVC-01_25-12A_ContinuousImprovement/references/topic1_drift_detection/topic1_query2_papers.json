[
  {
    "id": "http://arxiv.org/abs/2512.19161v1",
    "arxiv_id": "2512.19161v1",
    "title": "From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs",
    "summary": "Subtitles are essential for video accessibility and audience engagement. Modern Automatic Speech Recognition (ASR) systems, built upon Encoder-Decoder neural network architectures and trained on massive amounts of data, have progressively reduced transcription errors on standard benchmark datasets. However, their performance in real-world production environments, particularly for non-English content like long-form Italian videos, remains largely unexplored. This paper presents a case study on developing a professional subtitling system for an Italian media company. To inform our system design, we evaluated four state-of-the-art ASR models (Whisper Large v2, AssemblyAI Universal, Parakeet TDT v3 0.6b, and WhisperX) on a 50-hour dataset of Italian television programs. The study highlights their strengths and limitations, benchmarking their performance against the work of professional human subtitlers. The findings indicate that, while current models cannot meet the media industry's accuracy needs for full autonomy, they can serve as highly effective tools for enhancing human productivity. We conclude that a human-in-the-loop (HITL) approach is crucial and present the production-grade, cloud-based infrastructure we designed to support this workflow.",
    "published": "2025-12-22T08:57:16Z",
    "updated": "2025-12-22T08:57:16Z",
    "authors": [
      "Alessandro Lucca",
      "Francesco Pierri"
    ],
    "affiliations": [],
    "first_author": "Alessandro Lucca",
    "pdf_url": "https://arxiv.org/pdf/2512.19161v1",
    "primary_category": "cs.CL",
    "relevance_score": 14.0
  },
  {
    "id": "http://arxiv.org/abs/2512.19842v1",
    "arxiv_id": "2512.19842v1",
    "title": "Holoscope: Open and Lightweight Distributed Telescope & Honeypot Platform",
    "summary": "The complexity and scale of Internet attacks call for distributed, cooperative observatories capable of monitoring malicious traffic across diverse networks. Holoscope is a lightweight, cloud-native platform designed to simplify the deployment and management of distributed telescope (passive) and honeypot (active) sensors, used to collect and analyse attack traffic by exposing or simulating vulnerable systems. Built upon K3s and WireGuard, Holoscope offers secure connectivity, automated node onboarding, and resilient operation even in resource-constrained environments. Through modular design and Infrastructure-as-Code principles, it supports dynamic sensor orchestration, automated recovery and processing. We build, deploy and operate Holoscope across multiple institutions and cloud networks in Europe and Brazil, enabling unified visibility into large-scale attack phenomena while maintaining ease of integration and security compliance.",
    "published": "2025-12-22T19:54:14Z",
    "updated": "2025-12-22T19:54:14Z",
    "authors": [
      "Andrea Sordello",
      "Marco Mellia",
      "Idilio Drago",
      "Rodolfo Valentim",
      "Francesco Musumeci",
      "Massimo Tornatore",
      "Federico Cerutti",
      "Martino Trevisan",
      "Alessio Botta",
      "Willen Borges Coelho"
    ],
    "affiliations": [],
    "first_author": "Andrea Sordello",
    "pdf_url": "https://arxiv.org/pdf/2512.19842v1",
    "primary_category": "cs.DC",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.19769v1",
    "arxiv_id": "2512.19769v1",
    "title": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
    "summary": "Building deployment-ready LLM agents requires complex orchestration of tools, data sources, and control flow logic, yet existing systems tightly couple agent logic to specific programming languages and deployment models. We present a declarative system that separates agent workflow specification from implementation, enabling the same pipeline definition to execute across multiple backend languages (Java, Python, Go) and deployment environments (cloud-native, on-premises).   Our key insight is that most agent workflows consist of common patterns -- data serialization, filtering, RAG retrieval, API orchestration -- that can be expressed through a unified DSL rather than imperative code. This approach transforms agent development from application programming to configuration, where adding new tools or fine-tuning agent behaviors requires only pipeline specification changes, not code deployment. Our system natively supports A/B testing of agent strategies, allowing multiple pipeline variants to run on the same backend infrastructure with automatic metric collection and comparison.   We evaluate our approach on real-world e-commerce workflows at PayPal, processing millions of daily interactions. Our results demonstrate 60% reduction in development time, and 3x improvement in deployment velocity compared to imperative implementations. The language's declarative approach enables non-engineers to modify agent behaviors safely, while maintaining sub-100ms orchestration overhead. We show that complex workflows involving product search, personalization, and cart management can be expressed in under 50 lines of DSL compared to 500+ lines of imperative code.",
    "published": "2025-12-22T05:03:37Z",
    "updated": "2025-12-22T05:03:37Z",
    "authors": [
      "Ivan Daunis"
    ],
    "affiliations": [],
    "first_author": "Ivan Daunis",
    "pdf_url": "https://arxiv.org/pdf/2512.19769v1",
    "primary_category": "cs.SE",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.19005v1",
    "arxiv_id": "2512.19005v1",
    "title": "Quantum-Resistant Cryptographic Models for Next-Gen Cybersecurity",
    "summary": "Another threat is the development of large quantum computers, which have a high likelihood of breaking the high popular security protocols because it can use both Shor and Grover algorithms. In order to fix this looming threat, quantum-resistant cryptographic systems, otherwise known as post-quantum cryptography (PQC), are being formulated to protect cybersecurity systems of the future. The current paper presents the state of the art in designing, realizing, and testing the security of robust quantum-resistant algorithms, paying attention to lattice-based, code-based, multivariate polynomial and hash-based cryptography. We discuss their resistance to classical and quantum attackers, distributed system scalability properties, and their deployment in practice (secure communications, blockchain, cloud computing infrastructures). Also, we study a hybrid cryptographic model that integrates the classical efficient cryptography scheme and a quantum-resilient cryptographic scheme to achieve a backward-compatible solution and simultaneously improving the forward security properties. With the experimental findings, it is evident that performance with reasonable computational footprint of the proposed framework succeeds to install amplified security fortitude which successfully harbours prolific cybersecurity systems of the future.",
    "published": "2025-12-22T03:47:06Z",
    "updated": "2025-12-22T03:47:06Z",
    "authors": [
      "Navin Chhibber",
      "Amber Rastogi",
      "Ankur Mahida",
      "Vatsal Gupta",
      "Piyush Ranjan"
    ],
    "affiliations": [],
    "first_author": "Navin Chhibber",
    "pdf_url": "https://arxiv.org/pdf/2512.19005v1",
    "primary_category": "cs.CR",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.18773v2",
    "arxiv_id": "2512.18773v2",
    "title": "Decentralized GNSS at Global Scale via Graph-Aware Diffusion Adaptation",
    "summary": "Network-based Global Navigation Satellite Systems (GNSS) underpin critical infrastructure and autonomous systems, yet typically rely on centralized processing hubs that limit scalability, resilience, and latency. Here we report a global-scale, decentralized GNSS architecture spanning hundreds of ground stations. By modeling the receiver network as a time-varying graph, we employ a deep linear neural network approach to learn topology-aware mixing schedules that optimize information exchange. This enables a gradient tracking diffusion strategy wherein stations execute local inference and exchange succinct messages to achieve two concurrent objectives: centimeter-level self-localization and network-wide consensus on satellite correction products. The consensus products are broadcast to user receivers as corrections, supporting precise point positioning (PPP) and precise point positioning-real-time kinematic (PPP-RTK). Numerical results demonstrate that our method matches the accuracy of centralized baselines while significantly outperforming existing decentralized methods in convergence speed and communication overhead. By reframing decentralized GNSS as a networked signal processing problem, our results pave the way for integrating decentralized optimization, consensus-based inference, and graph-aware learning as effective tools in operational satellite navigation.",
    "published": "2025-12-21T15:24:27Z",
    "updated": "2025-12-23T16:15:47Z",
    "authors": [
      "Xue Xian Zheng",
      "Xing Liu",
      "Tareq Y. Al-Naffouri"
    ],
    "affiliations": [],
    "first_author": "Xue Xian Zheng",
    "pdf_url": "https://arxiv.org/pdf/2512.18773v2",
    "primary_category": "eess.SP",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.17748v2",
    "arxiv_id": "2512.17748v2",
    "title": "Methods and Tools for Secure Quantum Clouds with a specific Case Study on Homomorphic Encryption",
    "summary": "The rise of quantum computing/technology potentially introduces significant security challenges to cloud computing, necessitating quantum-resistant encryption strategies as well as protection schemes and methods for cloud infrastructures offering quantum computing time and services (i.e. quantum clouds). This research explores various options for securing quantum clouds and ensuring privacy, especially focussing on the integration of homomorphic encryption (HE) into Eclipse Qrisp, a high-level quantum computing framework, to enhance the security of quantum cloud platforms. The study addresses the technical feasibility of integrating HE with Qrisp, evaluates performance trade-offs, and assesses the potential impact on future quantum cloud architectures. The successful implementation and Qrisp integration of three post-quantum cryptographic (PQC) algorithms demonstrates the feasibility of integrating HE with quantum computing frameworks. The findings indicate that while the Quantum One-Time Pad (QOTP) offers simplicity and low overhead, other algorithms like Chen and Gentry-Sahai-Waters (GSW) present performance trade-offs in terms of runtime and memory consumption. The study results in an overall set of recommendations for securing quantum clouds, e.g. implementing HE at data storage and processing levels, developing Quantum Key Distribution (QKD), and enforcing stringent access control and authentication mechanisms as well as participating in PQC standardization efforts.",
    "published": "2025-12-19T16:24:51Z",
    "updated": "2025-12-22T07:37:12Z",
    "authors": [
      "Aurelia Kusumastuti",
      "Nikolay Tcholtchev",
      "Philipp L\u00e4mmel",
      "Sebastian Bock",
      "Manfred Hauswirth"
    ],
    "affiliations": [],
    "first_author": "Aurelia Kusumastuti",
    "pdf_url": "https://arxiv.org/pdf/2512.17748v2",
    "primary_category": "cs.CR",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.17054v1",
    "arxiv_id": "2512.17054v1",
    "title": "When to compute in space",
    "summary": "Spacecraft increasingly rely on heterogeneous computing resources spanning onboard flight computers, orbital data centers, ground station edge nodes, and terrestrial cloud infrastructure. Selecting where a workload should execute is a nontrivial multi objective problem driven by latency, reliability, power, communication constraints, cost, and regulatory feasibility. This paper introduces a quantitative optimization framework that formalizes compute location selection through empirically measurable metrics, normalized scoring, feasibility constraints, and a unified utility function designed to operate under incomplete information. We evaluate the model on two representative workloads demonstrating how the framework compares compute tiers and identifies preferred deployment locations. The approach provides a structured, extensible method for mission designers to reason about compute placement in emerging space architectures.",
    "published": "2025-12-18T20:44:45Z",
    "updated": "2025-12-18T20:44:45Z",
    "authors": [
      "Rajiv Thummala",
      "Gregory Falco"
    ],
    "affiliations": [],
    "first_author": "Rajiv Thummala",
    "pdf_url": "https://arxiv.org/pdf/2512.17054v1",
    "primary_category": "cs.CE",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20589v1",
    "arxiv_id": "2512.20589v1",
    "title": "Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information",
    "summary": "As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME. To that end, this paper proposes an intelligent mission coordination methodology that integrates digital mission models with Reinforcement Learning (RL), that specifically addresses the need for adaptive task allocation and reconfiguration. More specifically, we are leveraging a Digital Engineering (DE) based infrastructure that is composed of a high-fidelity digital mission model and agent-based simulation; and then we formulate the mission tactics management problem as a Markov Decision Process (MDP), and employ an RL agent trained via Proximal Policy Optimization. By leveraging the simulation as a sandbox, we map the system states to actions, refining the policy based on realized mission outcomes. The utility of the RL-based intelligent mission coordinator is demonstrated through an aerial firefighting case study. Our findings indicate that the RL-based intelligent mission coordinator not only surpasses baseline performance but also significantly reduces the variability in mission performance. Thus, this study serves as a proof of concept demonstrating that DE-enabled mission simulations combined with advanced analytical tools offer a mission-agnostic framework for improving ME practice; which can be extended to more complicated fleet design and selection problems in the future from a mission-first perspective.",
    "published": "2025-12-23T18:36:07Z",
    "updated": "2025-12-23T18:36:07Z",
    "authors": [
      "\u0130brahim O\u011fuz \u00c7etinkaya",
      "Sajad Khodadadian",
      "Taylan G. Top\u00e7u"
    ],
    "affiliations": [],
    "first_author": "\u0130brahim O\u011fuz \u00c7etinkaya",
    "pdf_url": "https://arxiv.org/pdf/2512.20589v1",
    "primary_category": "cs.CY",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20469v1",
    "arxiv_id": "2512.20469v1",
    "title": "Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale",
    "summary": "AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \\emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.   However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.   We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \\emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.   We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.",
    "published": "2025-12-23T16:04:41Z",
    "updated": "2025-12-23T16:04:41Z",
    "authors": [
      "Linfeng Zhang",
      "Siheng Chen",
      "Yuzhu Cai",
      "Jingyi Chai",
      "Junhan Chang",
      "Kun Chen",
      "Zhi X. Chen",
      "Zhaohan Ding",
      "Yuwen Du",
      "Yuanpeng Gao",
      "Yuan Gao",
      "Jing Gao",
      "Zhifeng Gao",
      "Qiangqiang Gu",
      "Yanhui Hong",
      "Yuan Huang",
      "Xi Fang",
      "Xiaohong Ji",
      "Guolin Ke",
      "Zixing Lei",
      "Xinyu Li",
      "Yongge Li",
      "Ruoxue Liao",
      "Hang Lin",
      "Xiaolu Lin",
      "Yuxiang Liu",
      "Xinzijian Liu",
      "Zexi Liu",
      "Jintan Lu",
      "Tingjia Miao",
      "Haohui Que",
      "Weijie Sun",
      "Yanfeng Wang",
      "Bingyang Wu",
      "Tianju Xue",
      "Rui Ye",
      "Jinzhe Zeng",
      "Duo Zhang",
      "Jiahui Zhang",
      "Linfeng Zhang",
      "Tianhan Zhang",
      "Wenchang Zhang",
      "Yuzhi Zhang",
      "Zezhong Zhang",
      "Hang Zheng",
      "Hui Zhou",
      "Tong Zhu",
      "Xinyu Zhu",
      "Qingguo Zhou",
      "Weinan E"
    ],
    "affiliations": [],
    "first_author": "Linfeng Zhang",
    "pdf_url": "https://arxiv.org/pdf/2512.20469v1",
    "primary_category": "cs.AI",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20263v1",
    "arxiv_id": "2512.20263v1",
    "title": "Drug-like antibodies with low immunogenicity in human panels designed with Latent-X2",
    "summary": "Drug discovery has long sought computational systems capable of designing drug-like molecules directly: developable and non-immunogenic from the start. Here we introduce Latent-X2, a frontier generative model that achieves this goal through zero-shot design of antibodies with strong binding affinities, drug-like properties, and, for the first time for any de novo generated antibody, confirmed low immunogenicity in human donor panels. Latent-X2 is an all-atom model conditioned on target structure, epitope specification, and optional antibody framework, jointly generating sequences and structures while modelling the bound complex. Testing only 4 to 24 designs per target in each modality, we successfully generated VHH and scFv antibodies against 9 of 18 evaluated targets, achieving a 50% target-level success rate with picomolar to nanomolar binding affinities. Designed molecules exhibit developability profiles that match or exceed those of approved antibody therapeutics, including expression yield, aggregation propensity, polyreactivity, hydrophobicity, and thermal stability, without optimization, filtering, or selection. In the first immunogenicity assessment of any AI-generated antibody, representative de novo VHH binders targeting TNFL9 exhibit both potent target engagement and low immunogenicity across T-cell proliferation and cytokine release assays. The model generalizes beyond antibodies: against K-Ras, long considered undruggable, we generated macrocyclic peptide binders competitive with trillion-scale mRNA display screens. These properties emerge directly from the model, demonstrating the therapeutic viability of zero-shot molecular design, now available without AI infrastructure or coding expertise at https://platform.latentlabs.com.",
    "published": "2025-12-23T11:17:59Z",
    "updated": "2025-12-23T11:17:59Z",
    "authors": [
      " Latent Labs Team",
      "Henry Kenlay",
      "Daniella Pretorius",
      "Jonathan Crabb\u00e9",
      "Alex Bridgland",
      "Sebastian M. Schmon",
      "Agrin Hilmkil",
      "James Vuckovic",
      "Simon Mathis",
      "Tomas Matteson",
      "Rebecca Bartke-Croughan",
      "Amir Motmaen",
      "Robin Rombach",
      "M\u00e1ria Vlachynsk\u00e1",
      "Alexander W. R. Nelson",
      "David Yuan",
      "Annette Obika",
      "Simon A. A. Kohl"
    ],
    "affiliations": [],
    "first_author": " Latent Labs Team",
    "pdf_url": "https://arxiv.org/pdf/2512.20263v1",
    "primary_category": "q-bio.BM",
    "relevance_score": 10.0
  }
]