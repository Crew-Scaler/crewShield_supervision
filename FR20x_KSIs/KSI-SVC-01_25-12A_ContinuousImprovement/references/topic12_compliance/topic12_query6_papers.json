[
  {
    "id": "http://arxiv.org/abs/2512.20586v1",
    "arxiv_id": "2512.20586v1",
    "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
    "summary": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.",
    "published": "2025-12-23T18:32:17Z",
    "updated": "2025-12-23T18:32:17Z",
    "authors": [
      "Humza Nusrat",
      "Luke Francisco",
      "Bing Luo",
      "Hassan Bagher-Ebadian",
      "Joshua Kim",
      "Karen Chin-Snyder",
      "Salim Siddiqui",
      "Mira Shah",
      "Eric Mellon",
      "Mohammad Ghassemi",
      "Anthony Doemer",
      "Benjamin Movsas",
      "Kundan Thind"
    ],
    "affiliations": [],
    "first_author": "Humza Nusrat",
    "pdf_url": "https://arxiv.org/pdf/2512.20586v1",
    "primary_category": "cs.AI",
    "relevance_score": 14.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20344v1",
    "arxiv_id": "2512.20344v1",
    "title": "A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice",
    "summary": "A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P < 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.",
    "published": "2025-12-23T13:26:13Z",
    "updated": "2025-12-23T13:26:13Z",
    "authors": [
      "Yaowei Bai",
      "Ruiheng Zhang",
      "Yu Lei",
      "Xuhua Duan",
      "Jingfeng Yao",
      "Shuguang Ju",
      "Chaoyang Wang",
      "Wei Yao",
      "Yiwan Guo",
      "Guilin Zhang",
      "Chao Wan",
      "Qian Yuan",
      "Lei Chen",
      "Wenjuan Tang",
      "Biqiang Zhu",
      "Xinggang Wang",
      "Tao Sun",
      "Wei Zhou",
      "Dacheng Tao",
      "Yongchao Xu",
      "Chuansheng Zheng",
      "Huangxuan Zhao",
      "Bo Du"
    ],
    "affiliations": [],
    "first_author": "Yaowei Bai",
    "pdf_url": "https://arxiv.org/pdf/2512.20344v1",
    "primary_category": "cs.AI",
    "relevance_score": 14.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20610v1",
    "arxiv_id": "2512.20610v1",
    "title": "FedPOD: the deployable units of training for federated learning",
    "summary": "This paper proposes FedPOD (Proportionally Orchestrated Derivative) for optimizing learning efficiency and communication cost in federated learning among multiple clients. Inspired by FedPIDAvg, we define a round-wise task for FedPOD to enhance training efficiency. FedPIDAvg achieved performance improvement by incorporating the training loss reduction for prediction entropy as weights using differential terms. Furthermore, by modeling data distribution with a Poisson distribution and using a PID controller, it reduced communication costs even in skewed data distribution. However, excluding participants classified as outliers based on the Poisson distribution can limit data utilization. Additionally, PID controller requires the same participants to be maintained throughout the federated learning process as it uses previous rounds' learning information in the current round. In our approach, FedPOD addresses these issues by including participants excluded as outliers, eliminating dependency on previous rounds' learning information, and applying a method for calculating validation loss at each round. In this challenge, FedPOD presents comparable performance to FedPIDAvg in metrics of Dice score, 0.78, 0.71 and 0.72 for WT, ET and TC in average, and projected convergence score, 0.74 in average. Furthermore, the concept of FedPOD draws inspiration from Kubernetes' smallest computing unit, POD, designed to be compatible with Kubernetes auto-scaling. Extending round-wise tasks of FedPOD to POD units allows flexible design by applying scale-out similar to Kubernetes' auto-scaling. This work demonstrated the potentials of FedPOD to enhance federated learning by improving efficiency, flexibility, and performance in metrics.",
    "published": "2025-12-23T18:57:53Z",
    "updated": "2025-12-23T18:57:53Z",
    "authors": [
      "Daewoon Kim",
      "Si Young Yie",
      "Jae Sung Lee"
    ],
    "affiliations": [],
    "first_author": "Daewoon Kim",
    "pdf_url": "https://arxiv.org/pdf/2512.20610v1",
    "primary_category": "cs.CV",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20557v1",
    "arxiv_id": "2512.20557v1",
    "title": "Learning to Reason in 4D: Dynamic Spatial Understanding for Vision Language Models",
    "summary": "Vision-language models (VLM) excel at general understanding yet remain weak at dynamic spatial reasoning (DSR), i.e., reasoning about the evolvement of object geometry and relationship in 3D space over time, largely due to the scarcity of scalable 4D-aware training resources. To bridge this gap across aspects of dataset, benchmark and model, we introduce DSR Suite. First, we propose an automated pipeline that generates multiple-choice question-answer pairs from in-the-wild videos for DSR. By leveraging modern vision foundation models, the pipeline extracts rich geometric and motion information, including camera poses, local point clouds, object masks, orientations, and 3D trajectories. These geometric cues enable the construction of DSR-Train for learning and further human-refined DSR-Bench for evaluation. Compared with previous works, our data emphasize (i) in-the-wild video sources, (ii) object- and scene-level 3D requirements, (iii) viewpoint transformations, (iv) multi-object interactions, and (v) fine-grained, procedural answers. Beyond data, we propose a lightweight Geometry Selection Module (GSM) to seamlessly integrate geometric priors into VLMs, which condenses question semantics and extracts question-relevant knowledge from pretrained 4D reconstruction priors into a compact set of geometry tokens. This targeted extraction avoids overwhelming the model with irrelevant knowledge. Experiments show that integrating DSR-Train and GSM into Qwen2.5-VL-7B significantly enhances its dynamic spatial reasoning capability, while maintaining accuracy on general video understanding benchmarks.",
    "published": "2025-12-23T17:56:36Z",
    "updated": "2025-12-23T17:56:36Z",
    "authors": [
      "Shengchao Zhou",
      "Yuxin Chen",
      "Yuying Ge",
      "Wei Huang",
      "Jiehong Lin",
      "Ying Shan",
      "Xiaojuan Qi"
    ],
    "affiliations": [],
    "first_author": "Shengchao Zhou",
    "pdf_url": "https://arxiv.org/pdf/2512.20557v1",
    "primary_category": "cs.CV",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20549v1",
    "arxiv_id": "2512.20549v1",
    "title": "Global attractors for the Signorini problem with pointwise damping",
    "summary": "The existence of global attractors is investigated for the Signorini problem with pointwise dissipation. It is shown that both the semilinear Signorini problem and the elastic obstacle problem with normal compliance exhibit exponential decay to zero and admit compact global attractors. To establish these results, the original problem is approximated by a hybrid PDE-ODE system, which allows for a rigorous analysis of well-posedness and the long-time behavior of its solutions.",
    "published": "2025-12-23T17:44:01Z",
    "updated": "2025-12-23T17:44:01Z",
    "authors": [
      "Jaime E. Mu\u00f1oz Rivera",
      "Maria Grazia Naso"
    ],
    "affiliations": [],
    "first_author": "Jaime E. Mu\u00f1oz Rivera",
    "pdf_url": "https://arxiv.org/pdf/2512.20549v1",
    "primary_category": "math.AP",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20535v1",
    "arxiv_id": "2512.20535v1",
    "title": "ARBITER: AI-Driven Filtering for Role-Based Access Control",
    "summary": "Role-Based Access Control (RBAC) struggles to adapt to dynamic enterprise environments with documents that contain information that cannot be disclosed to specific user groups. As these documents are used by LLM-driven systems (e.g., in RAG) the problem is exacerbated as LLMs can leak sensitive data due to prompt truncation, classification errors, or loss of system context. We introduce \\our, a system designed to provide RBAC in RAG systems. \\our implements layered input/output validation, role-aware retrieval, and post-generation fact-checking. Unlike traditional RBAC approaches that rely on fine-tuned classifiers, \\our uses LLMs operating in few-shot settings with prompt-based steering for rapid deployment and role updates. We evaluate the approach on 389 queries using a synthetic dataset. Experimental results show 85\\% accuracy and 89\\% F1-score in query filtering, close to traditional RBAC solutions. Results suggest that practical RBAC deployment on RAG systems is approaching the maturity level needed for dynamic enterprise environments.",
    "published": "2025-12-23T17:25:51Z",
    "updated": "2025-12-23T17:25:51Z",
    "authors": [
      "Michele Lorenzo",
      "Idilio Drago",
      "Dario Salvadori",
      "Fabio Romolo Vayr"
    ],
    "affiliations": [],
    "first_author": "Michele Lorenzo",
    "pdf_url": "https://arxiv.org/pdf/2512.20535v1",
    "primary_category": "cs.CR",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20501v1",
    "arxiv_id": "2512.20501v1",
    "title": "Bridging Modalities and Transferring Knowledge: Enhanced Multimodal Understanding and Recognition",
    "summary": "This manuscript explores multimodal alignment, translation, fusion, and transference to enhance machine understanding of complex inputs. We organize the work into five chapters, each addressing unique challenges in multimodal machine learning.   Chapter 3 introduces Spatial-Reasoning Bert for translating text-based spatial relations into 2D arrangements between clip-arts. This enables effective decoding of spatial language into visual representations, paving the way for automated scene generation aligned with human spatial understanding.   Chapter 4 presents a method for translating medical texts into specific 3D locations within an anatomical atlas. We introduce a loss function leveraging spatial co-occurrences of medical terms to create interpretable mappings, significantly enhancing medical text navigability.   Chapter 5 tackles translating structured text into canonical facts within knowledge graphs. We develop a benchmark for linking natural language to entities and predicates, addressing ambiguities in text extraction to provide clearer, actionable insights.   Chapter 6 explores multimodal fusion methods for compositional action recognition. We propose a method fusing video frames and object detection representations, improving recognition robustness and accuracy.   Chapter 7 investigates multimodal knowledge transference for egocentric action recognition. We demonstrate how multimodal knowledge distillation enables RGB-only models to mimic multimodal fusion-based capabilities, reducing computational requirements while maintaining performance.   These contributions advance methodologies for spatial language understanding, medical text interpretation, knowledge graph enrichment, and action recognition, enhancing computational systems' ability to process complex, multimodal inputs across diverse applications.",
    "published": "2025-12-23T16:46:58Z",
    "updated": "2025-12-23T16:46:58Z",
    "authors": [
      "Gorjan Radevski"
    ],
    "affiliations": [],
    "first_author": "Gorjan Radevski",
    "pdf_url": "https://arxiv.org/pdf/2512.20501v1",
    "primary_category": "cs.CV",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20489v1",
    "arxiv_id": "2512.20489v1",
    "title": "A High-Dimensional Quantum Blockchain Protocol Based on Time- Entanglement",
    "summary": "Rapid advancements in quantum computing and machine learning threaten the long-term security of classical blockchain systems, whose protection mechanisms largely rely on computational difficulties. In this study, we propose a quantum blockchain protocol whose protection mechanism is directly derived from quantum mechanical principles. The protocol combines high-dimensional Bell states, time-entanglement, entanglement switching, and high-dimensional superdense coding. Encoding classical block information into time-delimited qudit states allows block identity and data verification to be implemented through the causal sequencing of quantum measurements instead of cryptographic hash functions. High-dimensional coding increases the information capacity per quantum carrier and improves noise resistance. Time-entanglement provides distributed authentication, non-repudiation, and tamper detection across the blockchain. Each block derives its own public-private key pair directly from the observed quantum correlations by performing high-dimensional Bell state measurements in successive time steps. Because these keys are dependent on the time ordering of measurements, attempts to alter block data or disrupt the protocol's timing structure inevitably affect the reconstructed correlations and are revealed during validation. Recent advances in the creation and detection of high-dimensional time-slice entanglement demonstrate that the necessary quantum resources are compatible with emerging quantum communication platforms. Taken together, these considerations suggest that the proposed framework can be evaluated as a viable and scalable candidate for quantum-secure blockchain architectures in future quantum network environments.",
    "published": "2025-12-23T16:31:12Z",
    "updated": "2025-12-23T16:31:12Z",
    "authors": [
      " Akta\u015f",
      " Arzu",
      " Y\u0131lmaz",
      " \u0130hsan"
    ],
    "affiliations": [],
    "first_author": " Akta\u015f",
    "pdf_url": "https://arxiv.org/pdf/2512.20489v1",
    "primary_category": "quant-ph",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20481v1",
    "arxiv_id": "2512.20481v1",
    "title": "Coherence in the brain unfolds across separable temporal regimes",
    "summary": "Coherence in language requires the brain to satisfy two competing temporal demands: gradual accumulation of meaning across extended context and rapid reconfiguration of representations at event boundaries. Despite their centrality to language and thought, how these processes are implemented in the human brain during naturalistic listening remains unclear. Here, we tested whether these two processes can be captured by annotation-free drift and shift signals and whether their neural expression dissociates across large-scale cortical systems. These signals were derived from a large language model (LLM) and formalized contextual drift and event shifts directly from the narrative input. To enable high-precision voxelwise encoding models with stable parameter estimates, we densely sampled one healthy adult across more than 7 hours of listening to thirteen crime stories while collecting ultra high-field (7T) BOLD data. We then modeled the feature-informed hemodynamic response using a regularized encoding framework validated on independent stories. Drift predictions were prevalent in default-mode network hubs, whereas shift predictions were evident bilaterally in the primary auditory cortex and language association cortex. Furthermore, activity in default-mode and parietal networks was best explained by a signal capturing how meaning accumulates and gradually fades over the course of the narrative. Together, these findings show that coherence during language comprehension is implemented through dissociable neural regimes of slow contextual integration and rapid event-driven reconfiguration, offering a mechanistic entry point for understanding disturbances of language coherence in psychiatric disorders.",
    "published": "2025-12-23T16:16:42Z",
    "updated": "2025-12-23T16:16:42Z",
    "authors": [
      "Davide Stauba",
      "Finn Rabe",
      "Akhil Misra",
      "Yves Pauli",
      "Roya H\u00fcppi",
      "Nils Lang",
      "Lars Michels",
      "Victoria Edkins",
      "Sascha Fr\u00fchholz",
      "Iris Sommer",
      "Wolfram Hinzen",
      "Philipp Homan"
    ],
    "affiliations": [],
    "first_author": "Davide Stauba",
    "pdf_url": "https://arxiv.org/pdf/2512.20481v1",
    "primary_category": "q-bio.NC",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20479v1",
    "arxiv_id": "2512.20479v1",
    "title": "UTDesign: A Unified Framework for Stylized Text Editing and Generation in Graphic Design Images",
    "summary": "AI-assisted graphic design has emerged as a powerful tool for automating the creation and editing of design elements such as posters, banners, and advertisements. While diffusion-based text-to-image models have demonstrated strong capabilities in visual content generation, their text rendering performance, particularly for small-scale typography and non-Latin scripts, remains limited. In this paper, we propose UTDesign, a unified framework for high-precision stylized text editing and conditional text generation in design images, supporting both English and Chinese scripts. Our framework introduces a novel DiT-based text style transfer model trained from scratch on a synthetic dataset, capable of generating transparent RGBA text foregrounds that preserve the style of reference glyphs. We further extend this model into a conditional text generation framework by training a multi-modal condition encoder on a curated dataset with detailed text annotations, enabling accurate, style-consistent text synthesis conditioned on background images, prompts, and layout specifications. Finally, we integrate our approach into a fully automated text-to-design (T2D) pipeline by incorporating pre-trained text-to-image (T2I) models and an MLLM-based layout planner. Extensive experiments demonstrate that UTDesign achieves state-of-the-art performance among open-source methods in terms of stylistic consistency and text accuracy, and also exhibits unique advantages compared to proprietary commercial approaches. Code and data for this paper are available at https://github.com/ZYM-PKU/UTDesign.",
    "published": "2025-12-23T16:13:55Z",
    "updated": "2025-12-23T16:13:55Z",
    "authors": [
      "Yiming Zhao",
      "Yuanpeng Gao",
      "Yuxuan Luo",
      "Jiwei Duan",
      "Shisong Lin",
      "Longfei Xiong",
      "Zhouhui Lian"
    ],
    "affiliations": [],
    "first_author": "Yiming Zhao",
    "pdf_url": "https://arxiv.org/pdf/2512.20479v1",
    "primary_category": "cs.CV",
    "relevance_score": 12.0
  }
]