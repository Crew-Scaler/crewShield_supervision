# Topic 7: Adversarial Evasion of ML-Based Configuration Detection Systems
## ArXiv Research Summary - Issue #64

**Research Date**: December 24, 2025
**Total Papers Downloaded**: 21 papers
**Total PDF Size**: ~64.1 MB
**Output Directory**: `/Users/tamnguyen/Documents/GitHub/ksi_watch/KSI-SVC-01_25-12A_ContinuousImprovement/references/topic7_adversarial_evasion/`

---

## Research Overview

This research collection focuses on adversarial evasion attacks against machine learning-based anomaly detection, intrusion detection, and configuration monitoring systems. The papers address critical vulnerabilities in ML-based security systems when exposed to adversarial perturbations, with emphasis on real-world deployment scenarios in networks, IoT systems, and infrastructure.

---

## Papers by Relevance Score

### Tier 1: Highest Relevance (Score 20.0)

#### 1. A Secured Intent-Based Networking (sIBN) with Data-Driven Time-Aware Intrusion Detection
- **ArXiv ID**: 2511.05133v1
- **Authors**: Urslla Uchechi Izuazu, Mounir Bensalem, Admela Jukan
- **Published**: November 7, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 20.0
- **Key Topics**: Intent tampering detection, configuration security, adversarial network manipulation, behavioral anomaly detection
- **Abstract**: Proposes secured IBN (sIBN) system with ML-based intrusion detection for network intent. Addresses Man-in-the-Middle attacks on network configuration intent, using time-aware features and behavioral metrics for anomaly detection. Directly relevant to detecting evasion of configuration detection systems.
- **PDF**: `2511.05133v1_A_Secured_Intent-Based_Networking_sIBN_with_Data-Driven_Time-Aware_Intrusion_Detection.pdf`

---

### Tier 2: Very High Relevance (Score 18.0)

#### 2. SoK: Systematic Analysis of Adversarial Threats Against Deep Learning Approaches for Autonomous Anomaly Detection Systems in SDN-IoT Networks
- **ArXiv ID**: 2509.26350v1
- **Authors**: Tharindu Lakshan Yasarathna, Nhien-An Le-Khac
- **Published**: September 30, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 18.0
- **Key Topics**: Adversarial threats, autonomous anomaly detection, evasion attacks, DL robustness, SDN-IoT security
- **Abstract**: Comprehensive systematization of knowledge (SoK) on adversarial threats to DL-based anomaly detection in SDN-IoT networks. Evaluates white/black/grey-box attack strategies, achieving up to 48.4% accuracy reduction. Proposes adversarial training countermeasures and explainable AI frameworks.
- **PDF**: `2509.26350v1_SoK_Systematic_analysis_of_adversarial_threats_against_deep_learning_approaches_for_autonomous_anoma.pdf`

#### 3. Robust Fine-Tuning from Non-Robust Pretrained Models: Mitigating Suboptimal Transfer With Adversarial Scheduling
- **ArXiv ID**: 2509.23325v1
- **Authors**: Jonas Ngnawé, Maxime Heuillet, Sabyasachi Sahoo, Yann Pequignot, Ola Ahmad, Audrey Durand, Frédéric Precioso, Christian Gagné
- **Published**: September 27, 2025
- **Category**: cs.LG (Computer Science - Machine Learning)
- **Relevance Score**: 18.0
- **Key Topics**: Adversarial robustness, fine-tuning, model configuration, robustness-accuracy tradeoff
- **Abstract**: Addresses challenges in robust fine-tuning of ML models. Proposes Epsilon-Scheduling to prevent suboptimal transfer when fine-tuning non-robust pretrained models with adversarial objectives. Introduces expected robustness metric for comprehensive evaluation.
- **PDF**: `2509.23325v1_Robust_Fine-Tuning_from_Non-Robust_Pretrained_Models_Mitigating_Suboptimal_Transfer_With_Adversarial.pdf`

#### 4. Enhancing Adversarial Robustness of IoT Intrusion Detection via SHAP-Based Attribution Fingerprinting
- **ArXiv ID**: 2511.06197v1
- **Authors**: Dilli Prasad Sharma, Liang Xue, Xiaowei Sun, Xiaodong Lin, Pulei Xiong
- **Published**: November 9, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 18.0
- **Key Topics**: Adversarial robustness, IoT IDS, evasion detection, SHAP fingerprinting, explainable AI
- **Abstract**: Proposes SHAP-based fingerprinting to enhance adversarial robustness of IoT intrusion detection systems. Uses attribution patterns to distinguish clean from adversarially perturbed inputs. Outperforms state-of-the-art methods in detecting adversarial attacks.
- **PDF**: `2511.06197v1_Enhancing_Adversarial_Robustness_of_IoT_Intrusion_Detection_via_SHAP-Based_Attribution_Fingerprintin.pdf`

#### 5. Budgeted Adversarial Attack against Graph-Based Anomaly Detection in Sensor Networks
- **ArXiv ID**: 2509.17987v1
- **Authors**: Sanju Xaviar, Omid Ardakanian
- **Published**: September 22, 2025
- **Category**: cs.LG (Computer Science - Machine Learning)
- **Relevance Score**: 18.0
- **Key Topics**: Evasion attacks, graph neural networks, anomaly detection, sensor network security, budget constraints
- **Abstract**: Introduces BETA, a grey-box evasion attack targeting GNN-based anomaly detectors in sensor networks. Reduces detection accuracy by 30.62-39.16% while respecting attacker budget constraints. Demonstrates practical evasion strategies.
- **PDF**: `2509.17987v1_Budgeted_Adversarial_Attack_against_Graph-Based_Anomaly_Detection_in_Sensor_Networks.pdf`

#### 6. A Novel and Practical Universal Adversarial Perturbations Against Deep Reinforcement Learning Based Intrusion Detection Systems
- **ArXiv ID**: 2511.18223v1
- **Authors**: H. Zhang, L. Zhang, G. Epiphaniou, C. Maple
- **Published**: November 22, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 18.0
- **Key Topics**: Universal adversarial perturbations, DRL-based IDS, evasion attacks, domain constraints
- **Abstract**: Proposes universal adversarial perturbations (UAPs) against DRL-based intrusion detection systems. First work on UAP generation for DRL-IDS under domain constraints. Outperforms FGSM, BIM, and UAP baselines.
- **PDF**: `2511.18223v1_A_Novel_and_Practical_Universal_Adversarial_Perturbations_against_Deep_Reinforcement_Learning_based_.pdf`

#### 7. Quantum Machine Learning for Cybersecurity: A Taxonomy and Future Directions
- **ArXiv ID**: 2512.15286v1
- **Authors**: Siva Sai, Ishika Goyal, Shubham Sharma, Sri Harshita Manuri, Vinay Chamola, Rajkumar Buyya
- **Published**: December 17, 2025
- **Category**: cs.LG (Computer Science - Machine Learning)
- **Relevance Score**: 18.0
- **Key Topics**: Quantum machine learning, cybersecurity, intrusion detection, anomaly detection, malware classification
- **Abstract**: Comprehensive survey of quantum machine learning techniques for cybersecurity. Maps QML methods across intrusion/anomaly detection, malware classification, and encrypted traffic analytics. Discusses limitations and future directions.
- **PDF**: `2512.15286v1_Quantum_Machine_Learning_for_Cybersecurity_A_Taxonomy_and_Future_Directions.pdf`

#### 8. HybridGuard: Enhancing Minority-Class Intrusion Detection in Dew-Enabled Edge-of-Things Networks
- **ArXiv ID**: 2511.07793v1
- **Authors**: Binayak Kara, Ujjwal Sahua, Ciza Thomas, Jyoti Prakash Sahoo
- **Published**: November 11, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 18.0
- **Key Topics**: Intrusion detection, class imbalance, adversarial robustness, edge networks, GAN-based enhancement
- **Abstract**: Presents HybridGuard framework integrating ML and DL for intrusion detection in EoT networks. Uses WCGAN-GP for class imbalance reduction and DualNetShield architecture for anomaly detection. Evaluated on multiple benchmark datasets.
- **PDF**: `2511.07793v1_HybridGuard_Enhancing_Minority-Class_Intrusion_Detection_in_Dew-Enabled_Edge-of-Things_Networks.pdf`

---

### Tier 3: High Relevance (Score 16.0)

#### 9. Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit
- **ArXiv ID**: 2512.20423v1
- **Authors**: Adam Elaoumari
- **Published**: December 23, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 16.0
- **Key Topics**: Evasion-resilient detection, adversarial scenarios, ML vs threshold-based detection, DoH exfiltration
- **Abstract**: Assesst defender effectiveness against DoH file exfiltration and attacker evasion strategies. Provides reproducible toolkit with containerized pipeline for generating configurable exfiltration scenarios. Compares ML classifiers against evasive DoH traffic.
- **PDF**: `2512.20423v1_Evasion-Resilient_Detection_of_DNS-over-HTTPS_Data_Exfiltration_A_Practical_Evaluation_and_Toolkit.pdf`

#### 10. GShield: Mitigating Poisoning Attacks in Federated Learning
- **ArXiv ID**: 2512.19286v1
- **Authors**: Sameera K. M., Serena Nicolazzo, Antonino Nocera, Vinod P., Rafidha Rehiman K. A
- **Published**: December 22, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 16.0
- **Key Topics**: Poisoning attacks, federated learning, adversarial robustness, non-IID data, gradient-based defense
- **Abstract**: Proposes GShield defense mechanism for federated learning against data poisoning. Uses clustering and Gaussian modeling to establish benign gradient profiles. Improves accuracy by 43-65% after detecting malicious clients.
- **PDF**: `2512.19286v1_GShield_Mitigating_Poisoning_Attacks_in_Federated_Learning.pdf`

#### 11. Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep Learning Model Robustness to Adversarial Attacks
- **ArXiv ID**: 2511.20456v1
- **Authors**: Shreevanth Krishnaa Gopalakrishnan, Stephen Hailes
- **Published**: November 25, 2025
- **Category**: cs.LG (Computer Science - Machine Learning)
- **Relevance Score**: 16.0
- **Key Topics**: Adversarial robustness, Wi-Fi sensing, CSI-based systems, threat models, adversarial training
- **Abstract**: Systematic evaluation of CSI deep learning model robustness under diverse threat models (white-box, black-box, universal perturbations). Confirms smaller models are less robust. Shows adversarial training improves mean robust accuracy.
- **PDF**: `2511.20456v1_Towards_Trustworthy_Wi-Fi_Sensing_Systematic_Evaluation_of_Deep_Learning_Model_Robustness_to_Adversa.pdf`

#### 12. Studying Various Activation Functions and Non-IID Data for Machine Learning Model Robustness
- **ArXiv ID**: 2512.04264v1
- **Authors**: Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Jing Lin
- **Published**: December 3, 2025
- **Category**: cs.LG (Computer Science - Machine Learning)
- **Relevance Score**: 16.0
- **Key Topics**: Adversarial training, model robustness, activation functions, federated learning, non-IID data
- **Abstract**: Studies ML model robustness using ten activation functions through adversarial training. Proposes advanced adversarial training approach incorporating model architecture changes and soft labeling. Evaluates in federated learning environments with non-IID data.
- **PDF**: `2512.04264v1_Studying_Various_Activation_Functions_and_Non-IID_Data_for_Machine_Learning_Model_Robustness.pdf`

#### 13. Efficient Adversarial Malware Defense via Trust-Based Raw Override and Confidence-Adaptive Bit-Depth Reduction
- **ArXiv ID**: 2511.12827v1
- **Authors**: Ayush Chaudhary, Sisir Doppalpudi
- **Published**: November 16, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 16.0
- **Key Topics**: Adversarial malware detection, robust defense, computational efficiency, production deployment
- **Abstract**: Proposes TRO-CABDR framework for adversarial malware detection. Achieves 1.76x computational overhead while maintaining 91% clean accuracy and reducing attack success rates to 31-37%. Optimizes efficiency-robustness tradeoff for production systems.
- **PDF**: `2511.12827v1_Efficient_Adversarial_Malware_Defense_via_Trust-Based_Raw_Override_and_Confidence-Adaptive_Bit-Depth.pdf`

#### 14. Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal Medical Retrieval-Augmented Generation
- **ArXiv ID**: 2511.19257v1
- **Authors**: Yingjia Shang, Yi Liu, Huimin Wang, Furong Li, Wenfang Sun, Wu Chengyu, Yefeng Zheng
- **Published**: November 24, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 16.0
- **Key Topics**: Cross-modal adversarial attacks, transferability, medical AI systems, black-box attacks
- **Abstract**: Proposes Medusa framework for crafting cross-modal transferable adversarial attacks on MMed-RAG systems. Achieves over 90% attack success rate while remaining robust against mainstream defenses. Highlights vulnerabilities in safety-critical systems.
- **PDF**: `2511.19257v1_Medusa_Cross-Modal_Transferable_Adversarial_Attacks_on_Multimodal_Medical_Retrieval-Augmented_Genera.pdf`

#### 15. Physics-Informed Machine Learning for Efficient Sim-to-Real Data Augmentation in Micro-Object Pose Estimation
- **ArXiv ID**: 2511.16494v1
- **Authors**: Zongcai Tan, Lan Wei, Dandan Zhang
- **Published**: November 20, 2025
- **Category**: cs.CV (Computer Vision)
- **Relevance Score**: 16.0
- **Key Topics**: Physics-informed ML, GANs, robustness, data augmentation, pose estimation
- **Abstract**: Integrates wave optics-based physical rendering into GAN for synthesizing high-fidelity microscope images. Improves SSIM by 35.6% compared to purely AI-driven methods. Demonstrates robustness to unseen poses.
- **PDF**: `2511.16494v1_Physics-Informed_Machine_Learning_for_Efficient_Sim-to-Real_Data_Augmentation_in_Micro-Object_Pose_E.pdf`

#### 16. MPD-SGR: Robust Spiking Neural Networks with Membrane Potential Distribution-Driven Surrogate Gradient Regularization
- **ArXiv ID**: 2511.12199v2
- **Authors**: Runhao Jiang, Chengzhi Jiang, Rui Yan, Huajin Tang
- **Published**: November 15, 2025
- **Category**: cs.LG (Computer Science - Machine Learning)
- **Relevance Score**: 16.0
- **Key Topics**: Spiking neural networks, adversarial robustness, gradient regularization, neural model hardening
- **Abstract**: Proposes MPD-SGR method for enhancing SNN robustness to adversarial perturbations. Analyzes relationship between membrane potential distribution and surrogate gradients. Shows strong generalizability across configurations.
- **PDF**: `2511.12199v2_MPD-SGR_Robust_Spiking_Neural_Networks_with_Membrane_Potential_Distribution-Driven_Surrogate_Gradien.pdf`

#### 17. Elevating Intrusion Detection and Security Fortification in Intelligent Networks through Cutting-Edge Machine Learning Paradigms
- **ArXiv ID**: 2512.19037v1
- **Authors**: Md Minhazul Islam Munna, Md Mahbubur Rahman, Jaroslav Frnda, Muhammad Shahid Anwar, Alpamis Kutlimuratov
- **Published**: December 22, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 16.0
- **Key Topics**: Intrusion detection, ensemble learning, feature selection, Wi-Fi security, configuration security
- **Abstract**: Proposes robust multiclass ML-based intrusion detection framework with advanced feature selection and stacked ensemble model. Achieves 98% accuracy on AWID3 dataset with only 2% false positive rate. Includes future adversarial resilience testing.
- **PDF**: `2512.19037v1_Elevating_Intrusion_Detection_and_Security_Fortification_in_Intelligent_Networks_through_Cutting-Edg.pdf`

#### 18. Bounty Hunter: Autonomous, Comprehensive Emulation of Multi-Faceted Adversaries
- **ArXiv ID**: 2512.15275v1
- **Authors**: Louis Hacklander-Jansen, Rafael Uetz, Martin Henze
- **Published**: December 17, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 16.0
- **Key Topics**: Adversary emulation, automated attacks, intrusion detection research, security assessment
- **Abstract**: Presents Bounty Hunter, automated adversary emulation plugin for Caldera platform. Enables autonomous emulation with diverse behavior and varying detectability levels. Facilitates realistic security assessments and intrusion detection research.
- **PDF**: `2512.15275v1_Bounty_Hunter_Autonomous_Comprehensive_Emulation_of_Multi-Faceted_Adversaries.pdf`

#### 19. PHANTOM: Progressive High-fidelity Adversarial Network for Threat Object Modeling
- **ArXiv ID**: 2512.15768v1
- **Authors**: Jamal Al-Karaki, Muhammad Al-Zafar Khan, Rand Derar Mohammad Al Athamneh
- **Published**: December 12, 2025
- **Category**: cs.CR (Computer Security)
- **Relevance Score**: 16.0
- **Key Topics**: Synthetic data generation, adversarial networks, intrusion detection training, class imbalance
- **Abstract**: Introduces PHANTOM framework for generating high-fidelity synthetic attack data using VAE-GAN architecture. Models trained on synthetic data achieve 98% accuracy on real attacks. Addresses rare attack type generation challenges.
- **PDF**: `2512.15768v1_PHANTOM_Progressive_High-fidelity_Adversarial_Network_for_Threat_Object_Modeling.pdf`

---

### Tier 4: Lower Relevance (Score 6.0)

#### 20. Attacking the Loop: Adversarial Attacks on Graph-based Loop Closure Detection
- **ArXiv ID**: 2312.06991v1
- **Authors**: Jonathan J. Y. Kim, Martin Urschler, Patricia J. Riddle, Jorg S. Wicker
- **Published**: December 12, 2023
- **Category**: cs.CV (Computer Vision)
- **Relevance Score**: 6.0
- **Key Topics**: Graph-based attacks, loop closure detection, evasion, SVM surrogate models
- **Abstract**: Presents Adversarial-LCD, a black-box evasion attack framework for graph-based loop closure detection in vSLAM. Uses eigencentrality-based perturbation with SVM-RBF surrogate model. Demonstrates effective graph perturbation attacks.
- **PDF**: `2312.06991v1_Attacking_the_Loop_Adversarial_Attacks_on_Graph-based_Loop_Closure_Detection.pdf`

---

### Secondary Papers (Lower Direct Relevance)

#### 21. An Intercomparison of Generative Machine Learning Methods for Downscaling Precipitation at Fine Spatial Scales
- **ArXiv ID**: 2512.13987v1
- **Authors**: Bryn Ward-Leikis, Neelesh Rampal, Yun Sing Koh, Peter B. Gibson, Hong-Yang Liu, Vassili Kitsios, Tristan Meyers, Jeff Adie, Yang Juntao, Steven C. Sherwood
- **Published**: December 16, 2025
- **Category**: physics.ao-ph (Physics - Atmospheric & Ocean Physics)
- **Relevance Score**: 16.0
- **Note**: Lower direct relevance to adversarial evasion of configuration detection, but relevant for understanding generative model robustness and distribution preservation under constraints
- **PDF**: `2512.13987v1_An_intercomparison_of_generative_machine_learning_methods_for_downscaling_precipitation_at_fine_spat.pdf`

---

## Key Research Themes

### 1. Adversarial Attack Methodologies
- Universal Adversarial Perturbations (UAPs) against IDS
- Grey-box and black-box evasion attacks
- Domain-constrained attacks under realistic constraints
- Graph-based and feature-level perturbations

### 2. Detection System Vulnerabilities
- Configuration tampering detection
- Intent-based network security
- IoT and sensor network anomaly detection
- Malware and intrusion detection robustness

### 3. Defense Mechanisms
- Adversarial training approaches
- SHAP-based attribution fingerprinting
- Gaussian modeling of benign gradients
- Ensemble learning with preprocessing

### 4. Robustness Evaluation
- White-box, black-box, and transfer attacks
- Model architecture impact on robustness
- Activation function effects
- Federated learning robustness in non-IID settings

### 5. Real-World Deployment Considerations
- Computational efficiency-robustness tradeoffs
- False positive rate minimization
- Scalability for enterprise environments
- Privacy-preserving detection mechanisms

---

## Research Recommendations

### For Configuration Detection System Hardening:
1. **Study papers 1-8** (Score 18-20) for comprehensive understanding of adversarial threats
2. **Implement detection** following approaches in papers 9-13 for production deployment
3. **Evaluate defenses** using methodologies in papers 5-7 for systematic threat modeling
4. **Consider GAN-based** synthetic data generation (PHANTOM, GShield) for robust model training

### For ML Model Configuration:
- Apply Epsilon-Scheduling (paper 3) for robust fine-tuning
- Use SHAP fingerprinting (paper 4) for anomaly detection robustness
- Study activation function effects (paper 12) on adversarial robustness
- Implement gradient regularization (paper 16) for neural network hardening

### For Intrusion/Anomaly Detection:
- Deploy HybridGuard's dual-phase architecture (paper 8) for class-imbalanced environments
- Use quantum ML approaches (paper 7) for future-proofing
- Implement ensemble methods (paper 17) with adversarial resilience testing
- Leverage autonomous emulation (paper 18) for detection system evaluation

---

## Statistical Summary

- **2025 Papers**: 20
- **2024 Papers**: 0
- **2023 Papers**: 1
- **Computer Science (cs.*)**: 20
- **Other Domains**: 1
- **Average Relevance Score**: 16.5
- **Papers with Score >= 18**: 8
- **Papers with Score >= 16**: 19
- **Total Download Size**: ~64.1 MB
- **Download Success Rate**: 100% (21/21)

---

## File Organization

All papers are organized in the directory:
`/Users/tamnguyen/Documents/GitHub/ksi_watch/KSI-SVC-01_25-12A_ContinuousImprovement/references/topic7_adversarial_evasion/`

Naming convention: `{arxiv_id}_{truncated_title}.pdf`

Metadata files:
- `topic7_query1_papers.json` - Query 1 results (1 paper)
- `topic7_query3_papers.json` - Query 3 results (10 papers)
- `topic7_query4_papers.json` - Query 4 results (10 papers)

---

## Future Research Directions

1. **Adaptive Adversarial Defenses**: Develop detection systems that adapt to evolving evasion techniques
2. **Configuration Drift Detection**: Apply ensemble methods to detect configuration changes as evasion
3. **Explainable Anomaly Detection**: Extend SHAP-based approaches for configuration-specific anomalies
4. **Federated Configuration Detection**: Distribute detection across organizations with privacy preservation
5. **Quantum-Enhanced Robustness**: Explore quantum ML for configuration detection (paper 7)

---

Generated: December 24, 2025
Research Query: Issue #64, Topic 7 - Adversarial Evasion of ML-Based Configuration Detection Systems
