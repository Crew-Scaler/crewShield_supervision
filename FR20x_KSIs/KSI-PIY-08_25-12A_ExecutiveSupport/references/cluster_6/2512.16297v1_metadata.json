{
  "arxiv_id": "2512.16297v1",
  "title": "Feature-Selective Representation Misdirection for Machine Unlearning",
  "authors": [
    "Taozhao Chen",
    "Linghan Huang",
    "Kim-Kwang Raymond Choo",
    "Huaming Chen"
  ],
  "published": "2025-12-18T08:31:50Z",
  "summary": "As large language models (LLMs) are increasingly adopted in safety-critical and regulated sectors, the retention of sensitive or prohibited knowledge introduces escalating risks, ranging from privacy leakage to regulatory non-compliance to to potential misuse, and so on. Recent studies suggest that machine unlearning can help ensure deployed models comply with evolving legal, safety, and governance requirements. However, current unlearning techniques assume clean separation between forget and re",
  "cluster": "cluster_6",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.197515"
}