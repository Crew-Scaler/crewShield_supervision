{
  "arxiv_id": "2512.15249v2",
  "title": "Intersectional Fairness in Vision-Language Models for Medical Image Disease Classification",
  "authors": [
    "Yupeng Zhang",
    "Adam G. Dunn",
    "Usman Naseem",
    "Jinman Kim"
  ],
  "published": "2025-12-17T09:47:29Z",
  "summary": "Medical artificial intelligence (AI) systems, particularly multimodal vision-language models (VLM), often exhibit intersectional biases where models are systematically less confident in diagnosing marginalised patient subgroups. Such bias can lead to higher rates of inaccurate and missed diagnoses due to demographically skewed data and divergent distributions of diagnostic certainty. Current fairness interventions frequently fail to address these gaps or compromise overall diagnostic performance",
  "cluster": "cluster_6",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.193276"
}