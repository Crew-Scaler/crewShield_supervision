{
  "arxiv_id": "2512.18567v1",
  "title": "AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software",
  "authors": [
    "Bin Wang",
    "Wenjie Yu",
    "Yilu Zhong",
    "Hao Yu",
    "Keke Lian",
    "Chaohua Lu",
    "Hongfang Zheng",
    "Dong Zhang",
    "Hui Li"
  ],
  "published": "2025-12-21T02:26:29Z",
  "summary": "Large language models (LLMs) for code generation are becoming integral to modern software development, but their real-world prevalence and security impact remain poorly understood.\n  We present the first large-scale empirical study of AI-generated code (AIGCode) in the wild. We build a high-precision detection pipeline and a representative benchmark to distinguish AIGCode from human-written code, and apply them to (i) development commits from the top 1,000 GitHub repositories (2022-2025) and (ii",
  "cluster": "cluster_6",
  "classification": "GREEN",
  "relevance_score": 85,
  "screened_at": "2026-01-11T11:46:04.198277"
}