{
  "arxiv_id": "2511.22788v1",
  "title": "PRISM: Privacy-Aware Routing for Adaptive Cloud-Edge LLM Inference via Semantic Sketch Collaboration",
  "authors": [
    "Junfei Zhan",
    "Haoxun Shen",
    "Zheng Lin",
    "Tengjiao He"
  ],
  "published": "2025-11-27T22:32:33Z",
  "summary": "Large Language Models (LLMs) demonstrate impressive capabilities in natural language understanding and generation, but incur high communication overhead and privacy risks in cloud deployments, while facing compute and memory constraints when confined to edge devices. Cloud-edge inference has emerged as a promising paradigm for improving privacy in LLM services by retaining sensitive computations on local devices. However, existing cloud-edge inference approaches apply uniform privacy protection ",
  "cluster": "cluster_6",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.196265"
}