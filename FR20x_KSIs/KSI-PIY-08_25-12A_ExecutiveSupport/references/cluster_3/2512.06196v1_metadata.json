{
  "arxiv_id": "2512.06196v1",
  "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment",
  "authors": [
    "Charlie Masters",
    "Marta Grze\u015bkiewicz",
    "Stefano V. Albrecht"
  ],
  "published": "2025-12-05T22:39:54Z",
  "summary": "As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that fram",
  "cluster": "cluster_3",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.174834"
}