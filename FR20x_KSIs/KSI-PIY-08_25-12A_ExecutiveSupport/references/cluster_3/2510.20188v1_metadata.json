{
  "arxiv_id": "2510.20188v1",
  "title": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning",
  "authors": [
    "Morris Yu-Chao Huang",
    "Zhen Tan",
    "Mohan Zhang",
    "Pingzhi Li",
    "Zhuo Zhang",
    "Tianlong Chen"
  ],
  "published": "2025-10-23T04:16:44Z",
  "summary": "Large Language Models generate complex reasoning chains that reveal their decision-making, yet verifying the faithfulness and harmlessness of these intermediate steps remains a critical unsolved problem. Existing auditing methods are centralized, opaque, and hard to scale, creating significant risks for deploying proprietary models in high-stakes domains. We identify four core challenges: (1) Robustness: Centralized auditors are single points of failure, prone to bias or attacks. (2) Scalability",
  "cluster": "cluster_3",
  "classification": "GREEN",
  "relevance_score": 90,
  "screened_at": "2026-01-11T11:46:04.171918"
}