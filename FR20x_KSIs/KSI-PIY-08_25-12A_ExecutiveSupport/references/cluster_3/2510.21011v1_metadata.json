{
  "arxiv_id": "2510.21011v1",
  "title": "Race and Gender in LLM-Generated Personas: A Large-Scale Audit of 41 Occupations",
  "authors": [
    "Ilona van der Linden",
    "Sahana Kumar",
    "Arnav Dixit",
    "Aadi Sudan",
    "Smruthi Danda",
    "David C. Anastasiu",
    "Kai Lukoff"
  ],
  "published": "2025-10-23T21:43:08Z",
  "summary": "Generative AI tools are increasingly used to create portrayals of people in occupations, raising concerns about how race and gender are represented. We conducted a large-scale audit of over 1.5 million occupational personas across 41 U.S. occupations, generated by four large language models with different AI safety commitments and countries of origin (U.S., China, France). Compared with Bureau of Labor Statistics data, we find two recurring patterns: systematic shifts, where some groups are cons",
  "cluster": "cluster_3",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.171900"
}