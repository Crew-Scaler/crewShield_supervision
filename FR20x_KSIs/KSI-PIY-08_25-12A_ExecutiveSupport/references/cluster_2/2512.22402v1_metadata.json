{
  "arxiv_id": "2512.22402v1",
  "title": "Efficient Multi-Model Orchestration for Self-Hosted Large Language Models",
  "authors": [
    "Bhanu Prakash Vangala",
    "Tanu Malik"
  ],
  "published": "2025-12-26T22:42:40Z",
  "summary": "Self-hosting large language models (LLMs) is increasingly appealing for organizations seeking privacy, cost control, and customization. Yet deploying and maintaining in-house models poses challenges in GPU utilization, workload routing, and reliability. We introduce Pick and Spin, a practical framework that makes self-hosted LLM orchestration scalable and economical. Built on Kubernetes, it integrates a unified Helm-based deployment system, adaptive scale-to-zero automation, and a hybrid routing",
  "cluster": "cluster_2",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.164800"
}