{
  "arxiv_id": "2512.23453v1",
  "title": "CoFi-Dec: Hallucination-Resistant Decoding via Coarse-to-Fine Generative Feedback in Large Vision-Language Models",
  "authors": [
    "Zongsheng Cao",
    "Yangfan He",
    "Anran Liu",
    "Jun Xie",
    "Feng Chen",
    "Zepeng Wang"
  ],
  "published": "2025-12-29T13:23:20Z",
  "summary": "Large Vision-Language Models (LVLMs) have achieved impressive progress in multi-modal understanding and generation. However, they still tend to produce hallucinated content that is inconsistent with the visual input, which limits their reliability in real-world applications. We propose \\textbf{CoFi-Dec}, a training-free decoding framework that mitigates hallucinations by integrating generative self-feedback with coarse-to-fine visual conditioning. Inspired by the human visual process from global",
  "cluster": "cluster_2",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.169703"
}