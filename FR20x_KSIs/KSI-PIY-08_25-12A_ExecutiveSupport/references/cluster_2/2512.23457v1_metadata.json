{
  "arxiv_id": "2512.23457v1",
  "title": "Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following",
  "authors": [
    "Kongcheng Zhang",
    "Qi Yao",
    "Shunyu Liu",
    "Wenjian Zhang",
    "Min Cen",
    "Yang Zhou",
    "Wenkai Fang",
    "Yiru Zhao",
    "Baisheng Lai",
    "Mingli Song"
  ],
  "published": "2025-12-29T13:31:08Z",
  "summary": "Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (",
  "cluster": "cluster_2",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.169683"
}