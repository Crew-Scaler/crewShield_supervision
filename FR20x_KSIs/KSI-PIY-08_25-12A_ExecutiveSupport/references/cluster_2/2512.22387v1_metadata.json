{
  "arxiv_id": "2512.22387v1",
  "title": "AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents",
  "authors": [
    "Bhanu Prakash Vangala",
    "Ali Adibifar",
    "Tanu Malik",
    "Ashish Gehani"
  ],
  "published": "2025-12-26T21:17:22Z",
  "summary": "The rise of Large Language Models (LLMs) as coding agents promises to accelerate software development, but their impact on generated code reproducibility remains largely unexplored. This paper presents an empirical study investigating whether LLM-generated code can be executed successfully in a clean environment with only OS packages and using only the dependencies that the model specifies. We evaluate three state-of-the-art LLM coding agents (Claude Code, OpenAI Codex, and Gemini) across 300 pr",
  "cluster": "cluster_2",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.168070"
}