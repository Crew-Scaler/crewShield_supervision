{
  "arxiv_id": "2512.23236v2",
  "title": "KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta",
  "authors": [
    "Gang Liao",
    "Hongsen Qin",
    "Ying Wang",
    "Alicia Golden",
    "Michael Kuchnik",
    "Yavuz Yetim",
    "Jia Jiunn Ang",
    "Chunli Fu",
    "Yihan He",
    "Samuel Hsia",
    "Zewei Jiang",
    "Dianshi Li",
    "Uladzimir Pashkevich",
    "Varna Puvvada",
    "Feng Shi",
    "Matt Steiner",
    "Ruichao Xiao",
    "Nathan Yan",
    "Xiayu Yu",
    "Zhou Fang",
    "Abdul Zainul-Abedin",
    "Ketan Singh",
    "Hongtao Yu",
    "Wenyuan Chi",
    "Barney Huang",
    "Sean Zhang",
    "Noah Weller",
    "Zach Marine",
    "Wyatt Cook",
    "Carole-Jean Wu",
    "Gaoxiang Liu"
  ],
  "published": "2025-12-29T06:31:55Z",
  "summary": "Making deep learning recommendation model (DLRM) training and inference fast and efficient is important. However, this presents three key system challenges - model architecture diversity, kernel primitive diversity, and hardware generation and architecture heterogeneity. This paper presents KernelEvolve-an agentic kernel coding framework-to tackle heterogeneity at-scale for DLRM. KernelEvolve is designed to take kernel specifications as input and automate the process of kernel generation and opt",
  "cluster": "cluster_2",
  "classification": "GREEN",
  "relevance_score": 85,
  "screened_at": "2026-01-11T11:46:04.167852"
}