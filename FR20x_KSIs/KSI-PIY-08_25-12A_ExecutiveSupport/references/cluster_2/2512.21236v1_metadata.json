{
  "arxiv_id": "2512.21236v1",
  "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking",
  "authors": [
    "Yifan Huang",
    "Xiaojun Jia",
    "Wenbo Guo",
    "Yuqiang Sun",
    "Yihao Huang",
    "Chong Wang",
    "Yang Liu"
  ],
  "published": "2025-12-24T15:25:31Z",
  "summary": "Large language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generate harmful software. Existing jailbreaking research primarily focuses on general attack scenarios against LLMs, with limited exploration of malicious code generation as a jailbreak target. To address t",
  "cluster": "cluster_2",
  "classification": "GREEN",
  "relevance_score": 85,
  "screened_at": "2026-01-11T11:46:04.170239"
}