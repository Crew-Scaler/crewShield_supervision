{
  "arxiv_id": "2512.09048v1",
  "title": "Monitoring Deployed AI Systems in Health Care",
  "authors": [
    "Timothy Keyes",
    "Alison Callahan",
    "Abby S. Pandya",
    "Nerissa Ambers",
    "Juan M. Banda",
    "Miguel Fuentes",
    "Carlene Lugtu",
    "Pranav Masariya",
    "Srikar Nallan",
    "Connor O'Brien",
    "Thomas Wang",
    "Emily Alsentzer",
    "Jonathan H. Chen",
    "Dev Dash",
    "Matthew A. Eisenberg",
    "Patricia Garcia",
    "Nikesh Kotecha",
    "Anurang Revri",
    "Michael A. Pfeffer",
    "Nigam H. Shah",
    "Sneha S. Jain"
  ],
  "published": "2025-12-09T19:06:48Z",
  "summary": "Post-deployment monitoring of artificial intelligence (AI) systems in health care is essential to ensure their safety, quality, and sustained benefit-and to support governance decisions about which systems to update, modify, or decommission. Motivated by these needs, we developed a framework for monitoring deployed AI systems grounded in the mandate to take specific actions when they fail to behave as intended. This framework, which is now actively used at Stanford Health Care, is organized arou",
  "cluster": "cluster_7",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.202619"
}