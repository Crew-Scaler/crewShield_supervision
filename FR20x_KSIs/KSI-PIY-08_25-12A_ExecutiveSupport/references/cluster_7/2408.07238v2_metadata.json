{
  "arxiv_id": "2408.07238v2",
  "title": "Can Advanced LLMs Coach Smaller LLMs? Knowledge Distillation for Goal-Oriented Dialogs",
  "authors": [
    "Tong Wang",
    "K. Sudhir",
    "Dat Hong"
  ],
  "published": "2024-08-13T23:59:36Z",
  "summary": "Enterprises deploying LLMs for goal-oriented dialogs, such as customer service, face a critical trade-off between performance, control, and cost. Proprietary models like GPT-4 offer strong performance but are costly and cannot be self-hosted, raising security and privacy concerns. Open-source alternatives offer flexibility and lower token costs but lag in performance. We introduce Guidance Elicitation and Retrieval (GER), a prompt-based knowledge distillation framework where a high-performance t",
  "cluster": "cluster_7",
  "classification": "GREEN",
  "relevance_score": 85,
  "screened_at": "2026-01-11T11:46:04.202300"
}