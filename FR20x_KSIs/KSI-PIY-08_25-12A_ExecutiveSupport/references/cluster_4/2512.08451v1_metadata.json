{
  "arxiv_id": "2512.08451v1",
  "title": "Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models II: Benchmark Generation Process",
  "authors": [
    "Gary Ackerman",
    "Zachary Kallenborn",
    "Anna Wetzel",
    "Hayley Peterson",
    "Jenna LaTourette",
    "Olivia Shoemaker",
    "Brandon Behlendorf",
    "Sheriff Almakki",
    "Doug Clifford",
    "Noah Sheinbaum"
  ],
  "published": "2025-12-09T10:24:25Z",
  "summary": "The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper, the second in ",
  "cluster": "cluster_4",
  "classification": "GREEN",
  "relevance_score": 85,
  "screened_at": "2026-01-11T11:46:04.185133"
}