{
  "arxiv_id": "2512.14600v1",
  "title": "PerProb: Indirectly Evaluating Memorization in Large Language Models",
  "authors": [
    "Yihan Liao",
    "Jacky Keung",
    "Xiaoxue Ma",
    "Jingyu Zhang",
    "Yicheng Sun"
  ],
  "published": "2025-12-16T17:10:01Z",
  "summary": "The rapid advancement of Large Language Models (LLMs) has been driven by extensive datasets that may contain sensitive information, raising serious privacy concerns. One notable threat is the Membership Inference Attack (MIA), where adversaries infer whether a specific sample was used in model training. However, the true impact of MIA on LLMs remains unclear due to inconsistent findings and the lack of standardized evaluation methods, further complicated by the undisclosed nature of many LLM tra",
  "cluster": "cluster_4",
  "classification": "GREEN",
  "relevance_score": 90,
  "screened_at": "2026-01-11T11:46:04.184847"
}