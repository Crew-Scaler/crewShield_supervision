{
  "arxiv_id": "2512.21008v2",
  "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
  "authors": [
    "Lichao Wu",
    "Sasha Behrouzi",
    "Mohamadreza Rostami",
    "Stjepan Picek",
    "Ahmad-Reza Sadeghi"
  ],
  "published": "2025-12-24T07:13:24Z",
  "summary": "Mixture-of-Experts (MoE) architectures have advanced the scaling of Large Language Models (LLMs) by activating only a sparse subset of parameters per input, enabling state-of-the-art performance with reduced computational cost. As these models are increasingly deployed in critical domains, understanding and strengthening their alignment mechanisms is essential to prevent harmful outputs. However, existing LLM safety research has focused almost exclusively on dense architectures, leaving the uniq",
  "cluster": "cluster_4",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.181283"
}