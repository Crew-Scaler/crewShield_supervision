{
  "arxiv_id": "2512.17254v1",
  "title": "Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning",
  "authors": [
    "Baolei Zhang",
    "Minghong Fang",
    "Zhuqing Liu",
    "Biao Yi",
    "Peizhao Zhou",
    "Yuan Wang",
    "Tong Li",
    "Zheli Liu"
  ],
  "published": "2025-12-19T05:52:35Z",
  "summary": "Federated Learning (FL) allows multiple clients to collaboratively train a model without sharing their private data. However, FL is vulnerable to Byzantine attacks, where adversaries manipulate client models to compromise the federated model, and privacy inference attacks, where adversaries exploit client models to infer private data. Existing defenses against both backdoor and privacy inference attacks introduce significant computational and communication overhead, creating a gap between theory",
  "cluster": "cluster_4",
  "classification": "GREEN",
  "relevance_score": 80,
  "screened_at": "2026-01-11T11:46:04.179453"
}