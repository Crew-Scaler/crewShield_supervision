{
  "arxiv_id": "2512.19016v1",
  "title": "DREAM: Dynamic Red-teaming across Environments for AI Models",
  "authors": [
    "Liming Lu",
    "Xiang Gu",
    "Junyu Huang",
    "Jiawei Du",
    "Yunhuai Liu",
    "Yongbin Zhou",
    "Shuchao Pang"
  ],
  "published": "2025-12-22T04:11:57Z",
  "summary": "Large Language Models (LLMs) are increasingly used in agentic systems, where their interactions with diverse tools and environments create complex, multi-stage safety challenges. However, existing benchmarks mostly rely on static, single-turn assessments that miss vulnerabilities from adaptive, long-chain attacks. To fill this gap, we introduce DREAM, a framework for systematic evaluation of LLM agents against dynamic, multi-stage attacks. At its core, DREAM uses a Cross-Environment Adversarial ",
  "cluster": "cluster_4",
  "classification": "GREEN",
  "relevance_score": 90,
  "screened_at": "2026-01-11T11:46:04.183237"
}