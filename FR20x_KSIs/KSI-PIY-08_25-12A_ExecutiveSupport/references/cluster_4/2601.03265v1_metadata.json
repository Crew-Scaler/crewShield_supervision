{
  "arxiv_id": "2601.03265v1",
  "title": "Jailbreak-Zero: A Path to Pareto Optimal Red Teaming for Large Language Models",
  "authors": [
    "Kai Hu",
    "Abhinav Aggarwal",
    "Mehran Khodabandeh",
    "David Zhang",
    "Eric Hsin",
    "Li Chen",
    "Ankit Jain",
    "Matt Fredrikson",
    "Akash Bharadwaj"
  ],
  "published": "2025-12-18T16:26:09Z",
  "summary": "This paper introduces Jailbreak-Zero, a novel red teaming methodology that shifts the paradigm of Large Language Model (LLM) safety evaluation from a constrained example-based approach to a more expansive and effective policy-based framework. By leveraging an attack LLM to generate a high volume of diverse adversarial prompts and then fine-tuning this attack model with a preference dataset, Jailbreak-Zero achieves Pareto optimality across the crucial objectives of policy coverage, attack strateg",
  "cluster": "cluster_4",
  "classification": "GREEN",
  "relevance_score": 85,
  "screened_at": "2026-01-11T11:46:04.178390"
}