[
  {
    "idx": 1,
    "title": "LaMoSys3.5D: Enabling 3.5D-IC-Based Large Language Model Inference Serving Systems via Hardware/Software Co-Design",
    "arxiv_id": "2512.08731v1",
    "published": "2025-12-09",
    "year": 2025,
    "authors": "Qipan Wang, Zhe Zhang, Shuangchen Li",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "The success of large language models LLMs amplifies the need for highthroughput energyefficient inference at scale. 3DDRAMbased accelerators provide high memory bandwidth and therefore an opportunity to accelerate the bandwidthbound decode phase. However, how to adequately balance compute density for prefill with bandwidthcapacity for decode remains open. Moreover, most prior designs do not target...",
    "pdf_url": "https://arxiv.org/pdf/2512.08731v1"
  },
  {
    "idx": 2,
    "title": "Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging",
    "arxiv_id": "2512.08365v1",
    "published": "2025-12-09",
    "year": 2025,
    "authors": "Yi Pan, Wenbo Qian, Dedong Xie",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "The training and deployment of machine learning (ML) models have become extremely energy-intensive. While existing optimization efforts focus primarily on hardware energy efficiency, a significant but overlooked source of inefficiency is software energy waste caused by poor software design. This often includes redundant or poorly designed operations that consume more energy without improving perfo...",
    "pdf_url": "https://arxiv.org/pdf/2512.08365v1"
  },
  {
    "idx": 3,
    "title": "An Empirical Framework for Evaluating Semantic Preservation Using Hugging Face",
    "arxiv_id": "2512.07983v1",
    "published": "2025-12-08",
    "year": 2025,
    "authors": "Nan Jia, Anita Raja, Raffi Khatchadourian",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "As machine learning (ML) becomes an integral part of high-autonomy systems, it is critical to ensure the trustworthiness of learning-enabled software systems (LESS). Yet, the nondeterministic and run-time-defined semantics of ML complicate traditional software refactoring. We define semantic preservation in LESS as the property that optimizations of intelligent components do not alter the system's...",
    "pdf_url": "https://arxiv.org/pdf/2512.07983v1"
  },
  {
    "idx": 4,
    "title": "Predictive Modeling of I/O Performance for Machine Learning Training Pipelines: A Data-Driven Approach to Storage Optimization",
    "arxiv_id": "2512.06699v1",
    "published": "2025-12-07",
    "year": 2025,
    "authors": "Karthik Prabhakar",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Modern machine learning training is increasingly bottlenecked by data I/O rather than compute. GPUs often sit idle at below 50% utilization waiting for data. This paper presents a machine learning approach to predict I/O performance and recommend optimal storage configurations for ML training pipelines. We collected 141 observations through systematic benchmarking across different storage backends...",
    "pdf_url": "https://arxiv.org/pdf/2512.06699v1"
  },
  {
    "idx": 5,
    "title": "Quantization Blindspots: How Model Compression Breaks Backdoor Defenses",
    "arxiv_id": "2512.06243v1",
    "published": "2025-12-06",
    "year": 2025,
    "authors": "Rohan Pandey, Eric Ye",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Backdoor attacks embed input-dependent malicious behavior into neural networks while preserving high clean accuracy, making them a persistent threat for deployed ML systems. At the same time, real-world deployments almost never serve full-precision models: post-training quantization to INT8 or lower precision is now standard practice for reducing memory and latency. This work asks a simple questio...",
    "pdf_url": "https://arxiv.org/pdf/2512.06243v1"
  },
  {
    "idx": 6,
    "title": "Compass: Mapping Space Exploration for Multi-Chiplet Accelerators Targeting LLM Inference Serving Workloads",
    "arxiv_id": "2512.06093v1",
    "published": "2025-12-05",
    "year": 2025,
    "authors": "Boyu Li, Zongwei Zhu, Yi Xiong",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "Large Language Models (LLMs) impose massive computational demands, driving the need for scalable multi-chiplet accelerators. However, existing mapping space exploration efforts for such accelerators primarily focus on traditional CNN/Transformer workloads and fail to adequately support the dynamic behaviors of mixed request types and variable sequence lengths in real-world LLM inference serving. T...",
    "pdf_url": "https://arxiv.org/pdf/2512.06093v1"
  },
  {
    "idx": 7,
    "title": "Model Gateway: Model Management Platform for Model-Driven Drug Discovery",
    "arxiv_id": "2512.05462v1",
    "published": "2025-12-05",
    "year": 2025,
    "authors": "Yan-Shiun Wu, Nathan A. Morin",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregate...",
    "pdf_url": "https://arxiv.org/pdf/2512.05462v1"
  },
  {
    "idx": 8,
    "title": "CryptoTensors: A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution",
    "arxiv_id": "2512.04580v2",
    "published": "2025-12-04",
    "year": 2025,
    "authors": "Huifeng Zhu, Shijie Li, Qinfeng Li",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "To enhance the performance of large language models (LLMs) in various domain-specific applications, sensitive data such as healthcare, law, and finance are being used to privately customize or fine-tune these models. Such privately adapted LLMs are regarded as either personal privacy assets or corporate intellectual property. Therefore, protecting model weights and maintaining strict confidentiali...",
    "pdf_url": "https://arxiv.org/pdf/2512.04580v2"
  },
  {
    "idx": 9,
    "title": "A Conceptual Model for AI Adoption in Financial Decision-Making: Addressing the Unique Challenges of Small and Medium-Sized Enterprises",
    "arxiv_id": "2512.04339v1",
    "published": "2025-12-03",
    "year": 2025,
    "authors": "Manh Chien Vu, Thang Le Dinh, Manh Chien Vu",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "The adoption of artificial intelligence (AI) offers transformative potential for small and medium-sized enterprises (SMEs), particularly in enhancing financial decision-making processes. However, SMEs often face significant barriers to implementing AI technologies, including limited resources, technical expertise, and data management capabilities. This paper presents a conceptual model for the ado...",
    "pdf_url": "https://arxiv.org/pdf/2512.04339v1"
  },
  {
    "idx": 10,
    "title": "AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving",
    "arxiv_id": "2512.04013v1",
    "published": "2025-12-03",
    "year": 2025,
    "authors": "Ying Wang, Zhen Jin, Jiexiong Xu",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. How...",
    "pdf_url": "https://arxiv.org/pdf/2512.04013v1"
  },
  {
    "idx": 11,
    "title": "UniQL: Unified Quantization and Low-rank Compression for Adaptive Edge LLMs",
    "arxiv_id": "2512.03383v2",
    "published": "2025-12-03",
    "year": 2025,
    "authors": "Hung-Yueh Chiang, Chi-Chih Chang, Yu-Chen Lu",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Deploying large language models (LLMs) on mobile platforms faces significant challenges due to the limited memory and shared computational resources of the device. Resource availability may be an issue as it is directly impacted by the current device workload, adding to the uncertainty of model deployment. We introduce UniQL, a unified post-training quantization and low-rank compression framework ...",
    "pdf_url": "https://arxiv.org/pdf/2512.03383v2"
  },
  {
    "idx": 12,
    "title": "TRoVe: Discovering Error-Inducing Static Feature Biases in Temporal Vision-Language Models",
    "arxiv_id": "2512.01048v1",
    "published": "2025-11-30",
    "year": 2025,
    "authors": "Maya Varma, Jean-Benoit Delbrouck, Sophie Ostmeier",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Vision-language models (VLMs) have made great strides in addressing temporal understanding tasks, which involve characterizing visual changes across a sequence of images. However, recent works have suggested that when making predictions, VLMs may rely on static feature biases, such as background or object features, rather than dynamic visual changes. Static feature biases are a type of shortcut an...",
    "pdf_url": "https://arxiv.org/pdf/2512.01048v1"
  },
  {
    "idx": 13,
    "title": "Subgroup Validity in Machine Learning for Echocardiogram Data",
    "arxiv_id": "2512.00976v1",
    "published": "2025-11-30",
    "year": 2025,
    "authors": "Cynthia Feeney, Shane Williams, Benjamin S. Wessler",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Echocardiogram datasets enable training deep learning models to automate interpretation of cardiac ultrasound, thereby expanding access to accurate readings of diagnostically-useful images. However, the gender, sex, race, and ethnicity of the patients in these datasets are underreported and subgroup-specific predictive performance is unevaluated. These reporting deficiencies raise concerns about s...",
    "pdf_url": "https://arxiv.org/pdf/2512.00976v1"
  },
  {
    "idx": 14,
    "title": "PRISM: Privacy-Aware Routing for Adaptive Cloud-Edge LLM Inference via Semantic Sketch Collaboration",
    "arxiv_id": "2511.22788v1",
    "published": "2025-11-27",
    "year": 2025,
    "authors": "Junfei Zhan, Haoxun Shen, Zheng Lin",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Large Language Models (LLMs) demonstrate impressive capabilities in natural language understanding and generation, but incur high communication overhead and privacy risks in cloud deployments, while facing compute and memory constraints when confined to edge devices. Cloud-edge inference has emerged as a promising paradigm for improving privacy in LLM services by retaining sensitive computations o...",
    "pdf_url": "https://arxiv.org/pdf/2511.22788v1"
  },
  {
    "idx": 15,
    "title": "AutoTailor: Automatic and Efficient Adaptive Model Deployment for Diverse Edge Devices",
    "arxiv_id": "2511.22355v1",
    "published": "2025-11-27",
    "year": 2025,
    "authors": "Mengyang Liu, Chenyu Lu, Haodong Tian",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "On-device machine learning (ML) has become a fundamental component of emerging mobile applications. Adaptive model deployment delivers efficient inference for heterogeneous device capabilities and performance requirements through customizing neural architectures. SuperNet-based approaches offer a promising solution by generating a large number of model variants from a pre-trained ML model. However...",
    "pdf_url": "https://arxiv.org/pdf/2511.22355v1"
  },
  {
    "idx": 16,
    "title": "What AI Speaks for Your Community: Polling AI Agents for Public Opinion on Data Center Projects",
    "arxiv_id": "2511.22037v2",
    "published": "2025-11-27",
    "year": 2025,
    "authors": "Zhifeng Wu, Yuelin Han, Shaolei Ren",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "The intense computational demands of AI, especially large foundation models, are driving a global boom in data centers. These facilities bring both tangible benefits and potential environmental burdens to local communities. However, the planning processes for data centers often fail to proactively integrate local public opinion in advance, largely because traditional polling is expensive or is con...",
    "pdf_url": "https://arxiv.org/pdf/2511.22037v2"
  },
  {
    "idx": 17,
    "title": "A Unified Metric Architecture for AI Infrastructure: A Cross-Layer Taxonomy Integrating Performance, Efficiency, and Cost",
    "arxiv_id": "2511.21772v1",
    "published": "2025-11-26",
    "year": 2025,
    "authors": "Qi He",
    "us_affiliation": false,
    "relevance_score": 6,
    "summary": "The growth of large-scale AI systems is increasingly constrained by infrastructure limits: power availability, thermal and water constraints, interconnect scaling, memory pressure, data-pipeline throughput, and rapidly escalating lifecycle cost. Across hyperscale clusters, these constraints interact, yet the main metrics remain fragmented. Existing metrics, ranging from facility measures (PUE) and...",
    "pdf_url": "https://arxiv.org/pdf/2511.21772v1"
  },
  {
    "idx": 18,
    "title": "Are Neuro-Inspired Multi-Modal Vision-Language Models Resilient to Membership Inference Privacy Leakage?",
    "arxiv_id": "2511.20710v1",
    "published": "2025-11-24",
    "year": 2025,
    "authors": "David Amebley, Sayanton Dibbo",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "In the age of agentic AI, the growing deployment of multi-modal models (MMs) has introduced new attack vectors that can leak sensitive training data in MMs, causing privacy leakage. This paper investigates a black-box privacy attack, i.e., membership inference attack (MIA) on multi-modal vision-language models (VLMs). State-of-the-art research analyzes privacy attacks primarily to unimodal AI-ML s...",
    "pdf_url": "https://arxiv.org/pdf/2511.20710v1"
  },
  {
    "idx": 19,
    "title": "Crash-Consistent Checkpointing for AI Training on macOS/APFS",
    "arxiv_id": "2511.18323v1",
    "published": "2025-11-23",
    "year": 2025,
    "authors": "Juha Jeon",
    "us_affiliation": false,
    "relevance_score": 4,
    "summary": "Deep learning training relies on periodic checkpoints to recover from failures, but unsafe checkpoint installation can leave corrupted files on disk. This paper presents an experimental study of checkpoint installation protocols and integrity validation for AI training on macOS/APFS. We implement three write modes with increasing durability guarantees: unsafe (baseline, no fsync), atomic_nodirsync...",
    "pdf_url": "https://arxiv.org/pdf/2511.18323v1"
  },
  {
    "idx": 20,
    "title": "Towards a future space-based, highly scalable AI infrastructure system design",
    "arxiv_id": "2511.19468v1",
    "published": "2025-11-22",
    "year": 2025,
    "authors": "Blaise Ag\u00fcera y Arcas, Travis Beals, Maria Biggs",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "If AI is a foundational general-purpose technology, we should anticipate that demand for AI compute -- and energy -- will continue to grow. The Sun is by far the largest energy source in our solar system, and thus it warrants consideration how future AI infrastructure could most efficiently tap into that power. This work explores a scalable compute system for machine learning in space, using fleet...",
    "pdf_url": "https://arxiv.org/pdf/2511.19468v1"
  },
  {
    "idx": 21,
    "title": "Datacenters in the Desert: Feasibility and Sustainability of LLM Inference in the Middle East",
    "arxiv_id": "2511.17683v1",
    "published": "2025-11-21",
    "year": 2025,
    "authors": "Lara Hassan, Mohamed ElZeftawy, Abdulrahman Mahmoud",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "As the Middle East emerges as a strategic hub for artificial intelligence (AI) infrastructure, the feasibility of deploying sustainable datacenters in desert environments has become a topic of growing relevance. This paper presents an empirical study analyzing the energy consumption and carbon footprint of large language model (LLM) inference across four countries: the United Arab Emirates, Icelan...",
    "pdf_url": "https://arxiv.org/pdf/2511.17683v1"
  },
  {
    "idx": 22,
    "title": "Green Distributed AI Training: Orchestrating Compute Across Renewable-Powered Micro Datacenters",
    "arxiv_id": "2511.16182v1",
    "published": "2025-11-20",
    "year": 2025,
    "authors": "Giuseppe Tomei, Andrea Mayer, Giuseppe Alcini",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "The accelerating expansion of AI workloads is colliding with an energy landscape increasingly dominated by intermittent renewable generation. While vast quantities of zero-carbon energy are routinely curtailed, today's centralized datacenter architectures remain poorly matched to this reality in both energy proportionality and geographic flexibility. This work envisions a shift toward a distribute...",
    "pdf_url": "https://arxiv.org/pdf/2511.16182v1"
  },
  {
    "idx": 23,
    "title": "The Loss of Control Playbook: Degrees, Dynamics, and Preparedness",
    "arxiv_id": "2511.15846v5",
    "published": "2025-11-19",
    "year": 2025,
    "authors": "Charlotte Stix, Annika Hallensleben, Alejandro Ortega",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "This research report addresses the absence of an actionable definition for Loss of Control (LoC) in AI systems by developing a novel taxonomy and preparedness framework. Despite increasing policy and research attention, existing LoC definitions vary significantly in scope and timeline, hindering effective LoC assessment and mitigation. To address this issue, we draw from an extensive literature re...",
    "pdf_url": "https://arxiv.org/pdf/2511.15846v5"
  },
  {
    "idx": 24,
    "title": "From Machine Learning Documentation to Requirements: Bridging Processes with Requirements Languages",
    "arxiv_id": "2511.15340v1",
    "published": "2025-11-19",
    "year": 2025,
    "authors": "Yi Peng, Hans-Martin Heyn, Jennifer Horkoff",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "In software engineering processes for machine learning (ML)-enabled systems, integrating and verifying ML components is a major challenge. A prerequisite is the specification of ML component requirements, including models and data, an area where traditional requirements engineering (RE) processes face new obstacles. An underexplored source of RE-relevant information in this context is ML documenta...",
    "pdf_url": "https://arxiv.org/pdf/2511.15340v1"
  },
  {
    "idx": 25,
    "title": "Smart Manufacturing: MLOps-Enabled Event-Driven Architecture for Enhanced Control in Steel Production",
    "arxiv_id": "2511.17632v1",
    "published": "2025-11-19",
    "year": 2025,
    "authors": "Bestoun S. Ahmed, Tommaso Azzalin, Andreas Kassler",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "We explore a Digital Twin-Based Approach for Smart Manufacturing to improve Sustainability, Efficiency, and Cost-Effectiveness for a steel production plant. Our system is based on a micro-service edge-compute platform that ingests real-time sensor data from the process into a digital twin over a converged network infrastructure. We implement agile machine learning-based control loops in the digita...",
    "pdf_url": "https://arxiv.org/pdf/2511.17632v1"
  },
  {
    "idx": 26,
    "title": "Intermediate N-Gramming: Deterministic and Fast N-Grams For Large N and Large Datasets",
    "arxiv_id": "2511.14955v1",
    "published": "2025-11-18",
    "year": 2025,
    "authors": "Ryan R. Curtin, Fred Lu, Edward Raff",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "The number of n-gram features grows exponentially in n, making it computationally demanding to compute the most frequent n-grams even for n as small as 3. Motivated by our production machine learning system built on n-gram features, we ask: is it possible to accurately, deterministically, and quickly recover the top-k most frequent n-grams? We devise a multi-pass algorithm called Intergrams that c...",
    "pdf_url": "https://arxiv.org/pdf/2511.14955v1"
  },
  {
    "idx": 27,
    "title": "Dynamic Template Selection for Output Token Generation Optimization: MLP-Based and Transformer Approaches",
    "arxiv_id": "2511.20683v1",
    "published": "2025-11-17",
    "year": 2025,
    "authors": "Bharadwaj Yadavalli",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Contemporary large language model deployments typically employ uniform prompting strategies across diverse query types, applying verbose response patterns to both complex analytical tasks and straightforward factual questions. This one-size-fits-all methodology leads to substantial token inefficiency, a concern amplified by the significant cost differential between input and output tokens--the lat...",
    "pdf_url": "https://arxiv.org/pdf/2511.20683v1"
  },
  {
    "idx": 28,
    "title": "Comparative Analysis of Large Language Model Inference Serving Systems: A Performance Study of vLLM and HuggingFace TGI",
    "arxiv_id": "2511.17593v1",
    "published": "2025-11-17",
    "year": 2025,
    "authors": "Saicharan Kolluru",
    "us_affiliation": false,
    "relevance_score": 4,
    "summary": "The deployment of Large Language Models (LLMs) in production environments requires efficient inference serving systems that balance throughput, latency, and resource utilization. This paper presents a comprehensive empirical evaluation of two prominent open-source LLM serving frameworks: vLLM and HuggingFace Text Generation Inference (TGI). We benchmark these systems across multiple dimensions inc...",
    "pdf_url": "https://arxiv.org/pdf/2511.17593v1"
  },
  {
    "idx": 29,
    "title": "FengHuang: Next-Generation Memory Orchestration for AI Inferencing",
    "arxiv_id": "2511.10753v1",
    "published": "2025-11-13",
    "year": 2025,
    "authors": "Jiamin Li, Lei Qu, Tao Zhang",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "This document presents a vision for a novel AI infrastructure design that has been initially validated through inference simulations on state-of-the-art large language models. Advancements in deep learning and specialized hardware have driven the rapid growth of large language models (LLMs) and generative AI systems. However, traditional GPU-centric architectures face scalability challenges for in...",
    "pdf_url": "https://arxiv.org/pdf/2511.10753v1"
  },
  {
    "idx": 30,
    "title": "Deploying Rapid Damage Assessments from sUAS Imagery for Disaster Response",
    "arxiv_id": "2511.03132v2",
    "published": "2025-11-05",
    "year": 2025,
    "authors": "Thomas Manzini, Priyankari Perali, Robin R. Murphy",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "This paper presents the first AI/ML system for automating building damage assessment in uncrewed aerial systems (sUAS) imagery to be deployed operationally during federally declared disasters (Hurricanes Debby and Helene). In response to major disasters, sUAS teams are dispatched to collect imagery of the affected areas to assess damage; however, at recent disasters, teams collectively delivered b...",
    "pdf_url": "https://arxiv.org/pdf/2511.03132v2"
  },
  {
    "idx": 31,
    "title": "Zero-shot data citation function classification using transformer-based large language models (LLMs)",
    "arxiv_id": "2511.02936v1",
    "published": "2025-11-04",
    "year": 2025,
    "authors": "Neil Byers, Ali Zaidi, Valerie Skye",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Efforts have increased in recent years to identify associations between specific datasets and the scientific literature that incorporates them. Knowing that a given publication cites a given dataset, the next logical step is to explore how or why that data was used. Advances in recent years with pretrained, transformer-based large language models (LLMs) offer potential means for scaling the descri...",
    "pdf_url": "https://arxiv.org/pdf/2511.02936v1"
  },
  {
    "idx": 32,
    "title": "From Code Changes to Quality Gains: An Empirical Study in Python ML Systems with PyQu",
    "arxiv_id": "2511.02827v1",
    "published": "2025-11-04",
    "year": 2025,
    "authors": "Mohamed Almukhtar, Anwar Ghammam, Marouane Kessentini",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "In an era shaped by Generative Artificial Intelligence for code generation and the rising adoption of Python-based Machine Learning systems (MLS), software quality has emerged as a major concern. As these systems grow in complexity and importance, a key obstacle lies in understanding exactly how specific code changes affect overall quality-a shortfall aggravated by the lack of quality assessment t...",
    "pdf_url": "https://arxiv.org/pdf/2511.02827v1"
  },
  {
    "idx": 33,
    "title": "SmartMLOps Studio: Design of an LLM-Integrated IDE with Automated MLOps Pipelines for Model Development and Monitoring",
    "arxiv_id": "2511.01850v1",
    "published": "2025-11-03",
    "year": 2025,
    "authors": "Jiawei Jin, Yingxin Su, Xiaotong Zhu",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "The rapid expansion of artificial intelligence and machine learning (ML) applications has intensified the demand for integrated environments that unify model development, deployment, and monitoring. Traditional Integrated Development Environments (IDEs) focus primarily on code authoring, lacking intelligent support for the full ML lifecycle, while existing MLOps platforms remain detached from the ...",
    "pdf_url": "https://arxiv.org/pdf/2511.01850v1"
  },
  {
    "idx": 34,
    "title": "From Pre-labeling to Production: Engineering Lessons from a Machine Learning Pipeline in the Public Sector",
    "arxiv_id": "2511.01545v1",
    "published": "2025-11-03",
    "year": 2025,
    "authors": "Ronivaldo Ferreira, Guilherme da Silva, Carla Rocha",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Machine learning is increasingly being embedded into government digital platforms, but public-sector constraints make it difficult to build ML systems that are accurate, auditable, and operationally sustainable. In practice, teams face not only technical issues like extreme class imbalance and data drift, but also organizational barriers such as bureaucratic data access, lack of versioned datasets...",
    "pdf_url": "https://arxiv.org/pdf/2511.01545v1"
  },
  {
    "idx": 35,
    "title": "Seed-Induced Uniqueness in Transformer Models: Subspace Alignment Governs Subliminal Transfer",
    "arxiv_id": "2511.01023v1",
    "published": "2025-11-02",
    "year": 2025,
    "authors": "Ay\u015fe Selin Okatan, Mustafa \u0130lhan Akba\u015f, Laxima Niure Kandel",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "We analyze subliminal transfer in Transformer models, where a teacher embeds hidden traits that can be linearly decoded by a student without degrading main-task performance. Prior work often attributes transferability to global representational similarity, typically quantified with Centered Kernel Alignment (CKA). Using synthetic corpora with disentangled public and private labels, we distill stud...",
    "pdf_url": "https://arxiv.org/pdf/2511.01023v1"
  },
  {
    "idx": 36,
    "title": "Identifying Slug Formation in Oil Well Pipelines: A Use Case from Industrial Analytics",
    "arxiv_id": "2511.00851v1",
    "published": "2025-11-02",
    "year": 2025,
    "authors": "Abhishek Patange, Sharat Chidambaran, Prabhat Shankar",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Slug formation in oil and gas pipelines poses significant challenges to operational safety and efficiency, yet existing detection approaches are often offline, require domain expertise, and lack real-time interpretability. We present an interactive application that enables end-to-end data-driven slug detection through a compact and user-friendly interface. The system integrates data exploration an...",
    "pdf_url": "https://arxiv.org/pdf/2511.00851v1"
  },
  {
    "idx": 37,
    "title": "\"Show Me You Comply... Without Showing Me Anything\": Zero-Knowledge Software Auditing for AI-Enabled Systems",
    "arxiv_id": "2510.26576v1",
    "published": "2025-10-30",
    "year": 2025,
    "authors": "Filippo Scaramuzza, Renato Cordeiro Ferreira, Tomaz Maia Suller",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "The increasing exploitation of Artificial Intelligence (AI) enabled systems in critical domains has made trustworthiness concerns a paramount showstopper, requiring verifiable accountability, often by regulation (e.g., the EU AI Act). Classical software verification and validation techniques, such as procedural audits, formal methods, or model documentation, are the mechanisms used to achieve this...",
    "pdf_url": "https://arxiv.org/pdf/2510.26576v1"
  },
  {
    "idx": 38,
    "title": "Beyond Benchmarks: The Economics of AI Inference",
    "arxiv_id": "2510.26136v1",
    "published": "2025-10-30",
    "year": 2025,
    "authors": "Boqin Zhuang, Jiacheng Qiao, Mingqian Liu",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "The inference cost of Large Language Models (LLMs) has become a critical factor in determining their commercial viability and widespread adoption. This paper introduces a quantitative ``economics of inference'' framework, treating the LLM inference process as a compute-driven intelligent production activity. We analyze its marginal cost, economies of scale, and quality of output under various perf...",
    "pdf_url": "https://arxiv.org/pdf/2510.26136v1"
  },
  {
    "idx": 39,
    "title": "Filtering instances and rejecting predictions to obtain reliable models in healthcare",
    "arxiv_id": "2510.24368v1",
    "published": "2025-10-28",
    "year": 2025,
    "authors": "Maria Gabriela Valeriano, David Kohan Marzag\u00e3o, Alfredo Montelongo",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Machine Learning (ML) models are widely used in high-stakes domains such as healthcare, where the reliability of predictions is critical. However, these models often fail to account for uncertainty, providing predictions even with low confidence. This work proposes a novel two-step data-centric approach to enhance the performance of ML models by improving data quality and filtering low-confidence ...",
    "pdf_url": "https://arxiv.org/pdf/2510.24368v1"
  },
  {
    "idx": 40,
    "title": "Monitoring and Observability of Machine Learning Systems: Current Practices and Gaps",
    "arxiv_id": "2510.24142v1",
    "published": "2025-10-28",
    "year": 2025,
    "authors": "Joran Leest, Ilias Gerostathopoulos, Patricia Lago",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Production machine learning (ML) systems fail silently -- not with crashes, but through wrong decisions. While observability is recognized as critical for ML operations, there is a lack empirical evidence of what practitioners actually capture. This study presents empirical results on ML observability in practice through seven focus group sessions in several domains. We catalog the information pra...",
    "pdf_url": "https://arxiv.org/pdf/2510.24142v1"
  },
  {
    "idx": 41,
    "title": "On the Societal Impact of Machine Learning",
    "arxiv_id": "2510.23693v1",
    "published": "2025-10-27",
    "year": 2025,
    "authors": "Joachim Baumann",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "This PhD thesis investigates the societal impact of machine learning (ML). ML increasingly informs consequential decisions and recommendations, significantly affecting many aspects of our lives. As these data-driven systems are often developed without explicit fairness considerations, they carry the risk of discriminatory effects. The contributions in this thesis enable more appropriate measuremen...",
    "pdf_url": "https://arxiv.org/pdf/2510.23693v1"
  },
  {
    "idx": 42,
    "title": "Tracing Distribution Shifts with Causal System Maps",
    "arxiv_id": "2510.23528v1",
    "published": "2025-10-27",
    "year": 2025,
    "authors": "Joran Leest, Ilias Gerostathopoulos, Patricia Lago",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Monitoring machine learning (ML) systems is hard, with standard practice focusing on detecting distribution shifts rather than their causes. Root-cause analysis often relies on manual tracing to determine whether a shift is caused by software faults, data-quality issues, or natural change. We propose ML System Maps -- causal maps that, through layered views, make explicit the propagation paths bet...",
    "pdf_url": "https://arxiv.org/pdf/2510.23528v1"
  },
  {
    "idx": 43,
    "title": "Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and Learning Paradigms for Sustainable Intelligence",
    "arxiv_id": "2510.23524v1",
    "published": "2025-10-27",
    "year": 2025,
    "authors": "KC Santosh, Rodrigue Rizk, Longwei Wang",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "The rapid advancement of Artificial Intelligence (AI) has led to unprecedented computational demands, raising significant environmental and ethical concerns. This paper critiques the prevailing reliance on large-scale, static datasets and monolithic training paradigms, advocating for a shift toward human-inspired, sustainable AI solutions. We introduce a novel framework, Human AI (HAI), which emph...",
    "pdf_url": "https://arxiv.org/pdf/2510.23524v1"
  },
  {
    "idx": 44,
    "title": "Reciprocity Deficits: Observing AI in the street with everyday publics",
    "arxiv_id": "2510.23342v2",
    "published": "2025-10-27",
    "year": 2025,
    "authors": "Alex S. Taylor, Noortje Marres, Mercedes Bunz",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "The street has emerged as a primary site where everyday publics are confronted with AI as an infrastructural phenomenon, as machine learning-based systems are now commonly deployed in this setting in the form of automated cars, facial recognition, smart billboards and the like. While these deployments of AI in the street have attracted significant media attention and public controversy in recent y...",
    "pdf_url": "https://arxiv.org/pdf/2510.23342v2"
  },
  {
    "idx": 45,
    "title": "Bias Begins with Data: The FairGround Corpus for Robust and Reproducible Research on Algorithmic Fairness",
    "arxiv_id": "2510.22363v1",
    "published": "2025-10-25",
    "year": 2025,
    "authors": "Jan Simson, Alessandro Fabris, Cosima Fr\u00f6hner",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "As machine learning (ML) systems are increasingly adopted in high-stakes decision-making domains, ensuring fairness in their outputs has become a central challenge. At the core of fair ML research are the datasets used to investigate bias and develop mitigation strategies. Yet, much of the existing work relies on a narrow selection of datasets--often arbitrarily chosen, inconsistently processed, a...",
    "pdf_url": "https://arxiv.org/pdf/2510.22363v1"
  },
  {
    "idx": 46,
    "title": "Efficient semantic uncertainty quantification in language models via diversity-steered sampling",
    "arxiv_id": "2510.21310v1",
    "published": "2025-10-24",
    "year": 2025,
    "authors": "Ji Won Park, Kyunghyun Cho",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Accurately estimating semantic aleatoric and epistemic uncertainties in large language models (LLMs) is particularly challenging in free-form question answering (QA), where obtaining stable estimates often requires many expensive generations. We introduce a diversity-steered sampler that discourages semantically redundant outputs during decoding, covers both autoregressive and masked diffusion par...",
    "pdf_url": "https://arxiv.org/pdf/2510.21310v1"
  },
  {
    "idx": 47,
    "title": "JSTprove: Pioneering Verifiable AI for a Trustless Future",
    "arxiv_id": "2510.21024v1",
    "published": "2025-10-23",
    "year": 2025,
    "authors": "Jonathan Gold, Tristan Freiberg, Haruna Isah",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "The integration of machine learning (ML) systems into critical industries such as healthcare, finance, and cybersecurity has transformed decision-making processes, but it also brings new challenges around trust, security, and accountability. As AI systems become more ubiquitous, ensuring the transparency and correctness of AI-driven decisions is crucial, especially when they have direct consequenc...",
    "pdf_url": "https://arxiv.org/pdf/2510.21024v1"
  },
  {
    "idx": 48,
    "title": "Embedding the MLOps Lifecycle into OT Reference Models",
    "arxiv_id": "2510.20590v1",
    "published": "2025-10-23",
    "year": 2025,
    "authors": "Simon Schindler, Christoph Binder, Lukas L\u00fcrzer",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "Machine Learning Operations (MLOps) practices are increas- ingly adopted in industrial settings, yet their integration with Opera- tional Technology (OT) systems presents significant challenges. This pa- per analyzes the fundamental obstacles in combining MLOps with OT en- vironments and proposes a systematic approach to embed MLOps prac- tices into established OT reference models. We evaluate the...",
    "pdf_url": "https://arxiv.org/pdf/2510.20590v1"
  },
  {
    "idx": 49,
    "title": "Exploring the Effect of DNN Depth on Adversarial Attacks in Network Intrusion Detection Systems",
    "arxiv_id": "2510.19761v1",
    "published": "2025-10-22",
    "year": 2025,
    "authors": "Mohamed ElShehaby, Ashraf Matrawy",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Adversarial attacks pose significant challenges to Machine Learning (ML) systems and especially Deep Neural Networks (DNNs) by subtly manipulating inputs to induce incorrect predictions. This paper investigates whether increasing the layer depth of deep neural networks affects their robustness against adversarial attacks in the Network Intrusion Detection System (NIDS) domain. We compare the adver...",
    "pdf_url": "https://arxiv.org/pdf/2510.19761v1"
  },
  {
    "idx": 50,
    "title": "CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation",
    "arxiv_id": "2510.19670v3",
    "published": "2025-10-22",
    "year": 2025,
    "authors": "Hasan Akgul, Mari Eplik, Javier Rojas",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "We present CoSense-LLM, an edge-first framework that turns continuous multimodal sensor streams (for example Wi-Fi CSI, IMU, audio, RFID, and lightweight vision) into compact, verifiable semantic tokens and coordinates with large language models under explicit latency, energy, bandwidth, and privacy constraints. CoSense-LLM has four parts: (i) SenseFusion, a lightweight encoder that aligns sensor ...",
    "pdf_url": "https://arxiv.org/pdf/2510.19670v3"
  },
  {
    "idx": 51,
    "title": "Reasoning Language Model Inference Serving Unveiled: An Empirical Study",
    "arxiv_id": "2510.18672v1",
    "published": "2025-10-21",
    "year": 2025,
    "authors": "Qi Li, Junpan Wu, Xiang Liu",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "The reasoning large language model (RLLM) has been proven competitive in solving complex reasoning tasks such as mathematics, coding, compared to general LLM. However, the serving performance and behavior of RLLM remains unexplored, which may undermine the deployment and utilization of RLLM in real-world scenario. To close this gap, in this paper, we conduct a comprehensive study of RLLM service. ...",
    "pdf_url": "https://arxiv.org/pdf/2510.18672v1"
  },
  {
    "idx": 52,
    "title": "Ensuring Robustness in ML-enabled Software Systems: A User Survey",
    "arxiv_id": "2510.18292v1",
    "published": "2025-10-21",
    "year": 2025,
    "authors": "Hala Abdelkader, Mohamed Abdelrazek, Priya Rani",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Ensuring robustness in ML-enabled software systems requires addressing critical challenges, such as silent failures, out-of-distribution (OOD) data, and adversarial attacks. Traditional software engineering practices, which rely on predefined logic, are insufficient for ML components that depend on data and probabilistic decision-making. To address these challenges, we propose the ML-On-Rails prot...",
    "pdf_url": "https://arxiv.org/pdf/2510.18292v1"
  },
  {
    "idx": 53,
    "title": "Learning After Model Deployment",
    "arxiv_id": "2510.17160v1",
    "published": "2025-10-20",
    "year": 2025,
    "authors": "Derda Kaymak, Gyuhak Kim, Tomoya Kaichi",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "In classic supervised learning, once a model is deployed in an application, it is fixed. No updates will be made to it during the application. This is inappropriate for many dynamic and open environments, where unexpected samples from unseen classes may appear. In such an environment, the model should be able to detect these novel samples from unseen classes and learn them after they are labeled. ...",
    "pdf_url": "https://arxiv.org/pdf/2510.17160v1"
  },
  {
    "idx": 54,
    "title": "Hephaestus: Mixture Generative Modeling with Energy Guidance for Large-scale QoS Degradation",
    "arxiv_id": "2510.17036v1",
    "published": "2025-10-19",
    "year": 2025,
    "authors": "Nguyen Do, Bach Ngo, Youval Kashuv",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "We study the Quality of Service Degradation (QoSD) problem, in which an adversary perturbs edge weights to degrade network performance. This setting arises in both network infrastructures and distributed ML systems, where communication quality, not just connectivity, determines functionality. While classical methods rely on combinatorial optimization, and recent ML approaches address only restrict...",
    "pdf_url": "https://arxiv.org/pdf/2510.17036v1"
  },
  {
    "idx": 55,
    "title": "Detecting Adversarial Fine-tuning with Auditing Agents",
    "arxiv_id": "2510.16255v1",
    "published": "2025-10-17",
    "year": 2025,
    "authors": "Sarah Egler, John Schulman, Nicholas Carlini",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Large Language Model (LLM) providers expose fine-tuning APIs that let end users fine-tune their frontier LLMs. Unfortunately, it has been shown that an adversary with fine-tuning access to an LLM can bypass safeguards. Particularly concerning, such attacks may avoid detection with datasets that are only implicitly harmful. Our work studies robust detection mechanisms for adversarial use of fine-tu...",
    "pdf_url": "https://arxiv.org/pdf/2510.16255v1"
  },
  {
    "idx": 56,
    "title": "BanaServe: Unified KV Cache and Dynamic Module Migration for Balancing Disaggregated LLM Serving in AI Infrastructure",
    "arxiv_id": "2510.13223v1",
    "published": "2025-10-15",
    "year": 2025,
    "authors": "Yiyuan He, Minxian Xu, Jingfeng Wu",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Large language models (LLMs) are increasingly deployed in AI infrastructure, driving the need for high throughput, resource efficient serving systems. Disaggregated LLM serving, which separates prompt prefill from auto-regressive decode, has emerged as a promising architecture by isolating their heterogeneous compute and memory demands. However, current disaggregated systems face three key limitat...",
    "pdf_url": "https://arxiv.org/pdf/2510.13223v1"
  },
  {
    "idx": 57,
    "title": "Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning",
    "arxiv_id": "2510.15996v1",
    "published": "2025-10-14",
    "year": 2025,
    "authors": "Ozan K. Tonguz, Federico Taschin",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "One of the major problems in Machine Learning (ML) and Artificial Intelligence (AI) is the fact that the probability distribution of the test data in the real world could deviate substantially from the probability distribution of the training data set. When this happens, the predictions of an ML system or an AI agent could involve large errors which is very troublesome and undesirable. While this ...",
    "pdf_url": "https://arxiv.org/pdf/2510.15996v1"
  },
  {
    "idx": 58,
    "title": "Robust ML-based Detection of Conventional, LLM-Generated, and Adversarial Phishing Emails Using Advanced Text Preprocessing",
    "arxiv_id": "2510.11915v1",
    "published": "2025-10-13",
    "year": 2025,
    "authors": "Deeksha Hareesha Kulal, Chidozie Princewill Arannonu, Afsah Anwar",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Phishing remains a critical cybersecurity threat, especially with the advent of large language models (LLMs) capable of generating highly convincing malicious content. Unlike earlier phishing attempts which are identifiable by grammatical errors, misspellings, incorrect phrasing, and inconsistent formatting, LLM generated emails are grammatically sound, contextually relevant, and linguistically na...",
    "pdf_url": "https://arxiv.org/pdf/2510.11915v1"
  },
  {
    "idx": 59,
    "title": "MC#: Mixture Compressor for Mixture-of-Experts Large Models",
    "arxiv_id": "2510.10962v1",
    "published": "2025-10-13",
    "year": 2025,
    "authors": "Wei Huang, Yue Liao, Yukang Chen",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Mixture-of-Experts (MoE) effectively scales large language models (LLMs) and vision-language models (VLMs) by increasing capacity through sparse activation. However, preloading all experts into memory and activating multiple experts per input introduces significant computational and memory overhead, making the expert module a major contributor to model size and inference cost. To address this, we ...",
    "pdf_url": "https://arxiv.org/pdf/2510.10962v1"
  },
  {
    "idx": 60,
    "title": "Bhasha-Rupantarika: Algorithm-Hardware Co-design approach for Multilingual Neural Machine Translation",
    "arxiv_id": "2510.10676v1",
    "published": "2025-10-12",
    "year": 2025,
    "authors": "Mukul Lokhande, Tanushree Dewangan, Mohd Sharik Mansoori",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "This paper introduces Bhasha-Rupantarika, a light and efficient multilingual translation system tailored through algorithm-hardware codesign for resource-limited settings. The method investigates model deployment at sub-octet precision levels (FP8, INT8, INT4, and FP4), with experimental results indicating a 4.1x reduction in model size (FP4) and a 4.2x speedup in inference speed, which correlates...",
    "pdf_url": "https://arxiv.org/pdf/2510.10676v1"
  },
  {
    "idx": 61,
    "title": "Operationalizing AI: Empirical Evidence on MLOps Practices, User Satisfaction, and Organizational Context",
    "arxiv_id": "2510.09968v1",
    "published": "2025-10-11",
    "year": 2025,
    "authors": "Stefan Pasch",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Organizational efforts to utilize and operationalize artificial intelligence (AI) are often accompanied by substantial challenges, including scalability, maintenance, and coordination across teams. In response, the concept of Machine Learning Operations (MLOps) has emerged as a set of best practices that integrate software engineering principles with the unique demands of managing the ML lifecycle...",
    "pdf_url": "https://arxiv.org/pdf/2510.09968v1"
  },
  {
    "idx": 62,
    "title": "Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study",
    "arxiv_id": "2510.09187v1",
    "published": "2025-10-10",
    "year": 2025,
    "authors": "Sungwoo Kang",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Cricket shot classification from video sequences remains a challenging problem in sports video analysis, requiring effective modeling of both spatial and temporal features. This paper presents the first comprehensive baseline study comparing seven different deep learning approaches across four distinct research paradigms for cricket shot classification. We implement and systematically evaluate tra...",
    "pdf_url": "https://arxiv.org/pdf/2510.09187v1"
  },
  {
    "idx": 63,
    "title": "Mozart: A Chiplet Ecosystem-Accelerator Codesign Framework for Composable Bespoke Application Specific Integrated Circuits",
    "arxiv_id": "2510.08873v1",
    "published": "2025-10-10",
    "year": 2025,
    "authors": "Haoran Jin, Jirong Yang, Yunpeng Liu",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Modern AI acceleration faces a fundamental challenge: conventional assumptions about memory requirements, batching effectiveness, and latency-throughput tradeoffs are systemwide generalizations that ignore the heterogeneous computational patterns of individual neural network operators. However, going towards network-level customization and operator-level heterogeneity incur substantial Non-Recurri...",
    "pdf_url": "https://arxiv.org/pdf/2510.08873v1"
  },
  {
    "idx": 64,
    "title": "Enabling Responsible, Secure and Sustainable Healthcare AI - A Strategic Framework for Clinical and Operational Impact",
    "arxiv_id": "2510.15943v1",
    "published": "2025-10-09",
    "year": 2025,
    "authors": "Jimmy Joseph",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "We offer a pragmatic model to operationalize responsible, secure, and sustainable healthcare AI, aligning world-class technical excellence with organizational readiness. The framework includes five key pillars - Leadership & Strategy, MLOps & Technical Infrastructure, Governance & Ethics, Education & Workforce Development, and Change Management & Adoption - and is intended to operationalize 'compl...",
    "pdf_url": "https://arxiv.org/pdf/2510.15943v1"
  },
  {
    "idx": 65,
    "title": "InstaGeo: Compute-Efficient Geospatial Machine Learning from Data to Deployment",
    "arxiv_id": "2510.05617v1",
    "published": "2025-10-07",
    "year": 2025,
    "authors": "Ibrahim Salihu Yusuf, Iffanice Houndayi, Rym Oualha",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Open-access multispectral imagery from missions like Landsat 8-9 and Sentinel-2 has fueled the development of geospatial foundation models (GFMs) for humanitarian and environmental applications. Yet, their deployment remains limited by (i) the absence of automated geospatial data pipelines and (ii) the large size of fine-tuned models. Existing GFMs lack workflows for processing raw satellite image...",
    "pdf_url": "https://arxiv.org/pdf/2510.05617v1"
  },
  {
    "idx": 66,
    "title": "Draft, Verify, and Improve: Toward Training-Aware Speculative Decoding",
    "arxiv_id": "2510.05421v1",
    "published": "2025-10-06",
    "year": 2025,
    "authors": "Shrenik Bhansali, Larry Heck",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Autoregressive (AR) decoding is a major latency bottleneck for large language models. Speculative decoding (SD) accelerates AR by letting a drafter propose multi-token blocks that a verifier accepts or rejects. However, many SD systems require heavy offline training or extra components. These choices raise data/compute cost and can yield brittle drafters under distribution drift. We introduce \\emp...",
    "pdf_url": "https://arxiv.org/pdf/2510.05421v1"
  },
  {
    "idx": 67,
    "title": "From Noisy Traces to Stable Gradients: Bias-Variance Optimized Preference Optimization for Aligning Large Reasoning Models",
    "arxiv_id": "2510.05095v1",
    "published": "2025-10-06",
    "year": 2025,
    "authors": "Mingkang Zhu, Xi Chen, Bei Yu",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Large reasoning models (LRMs) generate intermediate reasoning traces before producing final answers, yielding strong gains on multi-step and mathematical tasks. Yet aligning LRMs with human preferences, a crucial prerequisite for model deployment, remains underexplored. The statistically correct objective for preference alignment requires marginalizing over reasoning traces, but this computation i...",
    "pdf_url": "https://arxiv.org/pdf/2510.05095v1"
  },
  {
    "idx": 68,
    "title": "NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation",
    "arxiv_id": "2510.03895v1",
    "published": "2025-10-04",
    "year": 2025,
    "authors": "Zheng Huang, Mingyu Liu, Xiaoyi Lin",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Vision-Language-Action (VLA) models represent a pivotal advance in embodied intelligence, yet they confront critical barriers to real-world deployment, most notably catastrophic forgetting. This issue stems from their overreliance on continuous action sequences or action chunks, which inadvertently create isolated data silos that disrupt knowledge retention across tasks. To tackle these challenges...",
    "pdf_url": "https://arxiv.org/pdf/2510.03895v1"
  },
  {
    "idx": 69,
    "title": "GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis",
    "arxiv_id": "2510.03555v1",
    "published": "2025-10-03",
    "year": 2025,
    "authors": "Peiran Quan, Zifan Gu, Zhuo Zhao",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Foundation models (FMs) have transformed computational pathology by providing powerful, general-purpose feature extractors. However, adapting and benchmarking individual FMs for specific diagnostic tasks is often time-consuming and resource-intensive, especially given their scale and diversity. To address this challenge, we introduce Group-Aggregative Selection Multi-Instance Learning (GAS-MIL), a...",
    "pdf_url": "https://arxiv.org/pdf/2510.03555v1"
  },
  {
    "idx": 70,
    "title": "Agentic AI meets Neural Architecture Search: Proactive Traffic Prediction for AI-RAN",
    "arxiv_id": "2510.00851v1",
    "published": "2025-10-01",
    "year": 2025,
    "authors": "Abdelaziz Salama, Mohammed M. H. Qazzaz, Zeinab Nezami",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Next-generation wireless networks require intelligent traffic prediction to enable autonomous resource management and handle diverse, dynamic service demands. The Open Radio Access Network (O-RAN) framework provides a promising foundation for embedding machine learning intelligence through its disaggregated architecture and programmable interfaces. This work applies a Neural Architecture Search (N...",
    "pdf_url": "https://arxiv.org/pdf/2510.00851v1"
  },
  {
    "idx": 71,
    "title": "PolyLink: A Blockchain Based Decentralized Edge AI Platform for LLM Inference",
    "arxiv_id": "2510.02395v1",
    "published": "2025-10-01",
    "year": 2025,
    "authors": "Hongbo Liu, Jiannong Cao, Bo Yang",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "The rapid advancement of large language models (LLMs) in recent years has revolutionized the AI landscape. However, the deployment model and usage of LLM services remain highly centralized, creating significant trust issues and costs for end users and developers. To address these issues, we propose PolyLink, a blockchain-based decentralized AI platform that decentralizes LLM development and infere...",
    "pdf_url": "https://arxiv.org/pdf/2510.02395v1"
  },
  {
    "idx": 72,
    "title": "TVS Sidekick: Challenges and Practical Insights from Deploying Large Language Models in the Enterprise",
    "arxiv_id": "2509.26482v1",
    "published": "2025-09-30",
    "year": 2025,
    "authors": "Paula Reyero Lobo, Kevin Johnson, Bill Buchanan",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Many enterprises are increasingly adopting Artificial Intelligence (AI) to make internal processes more competitive and efficient. In response to public concern and new regulations for the ethical and responsible use of AI, implementing AI governance frameworks could help to integrate AI within organisations and mitigate associated risks. However, the rapid technological advances and lack of share...",
    "pdf_url": "https://arxiv.org/pdf/2509.26482v1"
  },
  {
    "idx": 73,
    "title": "Interpret, prune and distill Donut : towards lightweight VLMs for VQA on document",
    "arxiv_id": "2509.26235v1",
    "published": "2025-09-30",
    "year": 2025,
    "authors": "Adnan Ben Mansour, Ayoub Karine, David Naccache",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Recent advances in Visually-rich Document Understanding rely on large Vision-Language Models like Donut, which perform document-level Visual Question Answering without Optical Character Recognition. Despite their effectiveness, these models are too costly for real-time or resource-constrained applications. We investigate model compression through knowledge distillation, training compact student mo...",
    "pdf_url": "https://arxiv.org/pdf/2509.26235v1"
  },
  {
    "idx": 74,
    "title": "Towards a Framework for Supporting the Ethical and Regulatory Certification of AI Systems",
    "arxiv_id": "2510.00084v1",
    "published": "2025-09-30",
    "year": 2025,
    "authors": "Fabian Kovac, Sebastian Neumaier, Timea Pahi",
    "us_affiliation": true,
    "relevance_score": 0,
    "summary": "Artificial Intelligence has rapidly become a cornerstone technology, significantly influencing Europe's societal and economic landscapes. However, the proliferation of AI also raises critical ethical, legal, and regulatory challenges. The CERTAIN (Certification for Ethical and Regulatory Transparency in Artificial Intelligence) project addresses these issues by developing a comprehensive framework...",
    "pdf_url": "https://arxiv.org/pdf/2510.00084v1"
  },
  {
    "idx": 75,
    "title": "Scalable Disk-Based Approximate Nearest Neighbor Search with Page-Aligned Graph",
    "arxiv_id": "2509.25487v2",
    "published": "2025-09-29",
    "year": 2025,
    "authors": "Dingyi Kang, Dongming Jiang, Hanshen Yang",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Approximate Nearest Neighbor Search (ANNS), as the core of vector databases (VectorDBs), has become widely used in modern AI and ML systems, powering applications from information retrieval to bio-informatics. While graph-based ANNS methods achieve high query efficiency, their scalability is constrained by the available host memory. Recent disk-based ANNS approaches mitigate memory usage by offloa...",
    "pdf_url": "https://arxiv.org/pdf/2509.25487v2"
  },
  {
    "idx": 76,
    "title": "Uncertainty-Guided Expert-AI Collaboration for Efficient Soil Horizon Annotation",
    "arxiv_id": "2509.24873v1",
    "published": "2025-09-29",
    "year": 2025,
    "authors": "Teodor Chiaburu, Vipin Singh, Frank Hau\u00dfer",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Uncertainty quantification is essential in human-machine collaboration, as human agents tend to adjust their decisions based on the confidence of the machine counterpart. Reliably calibrated model uncertainties, hence, enable more effective collaboration, targeted expert intervention and more responsible usage of Machine Learning (ML) systems. Conformal prediction has become a well established mod...",
    "pdf_url": "https://arxiv.org/pdf/2509.24873v1"
  },
  {
    "idx": 77,
    "title": "Drift-Adapter: A Practical Approach to Near Zero-Downtime Embedding Model Upgrades in Vector Databases",
    "arxiv_id": "2509.23471v1",
    "published": "2025-09-27",
    "year": 2025,
    "authors": "Harshil Vejendla",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Upgrading embedding models in production vector databases typically requires re-encoding the entire corpus and rebuilding the Approximate Nearest Neighbor (ANN) index, leading to significant operational disruption and computational cost. This paper presents Drift-Adapter, a lightweight, learnable transformation layer designed to bridge embedding spaces between model versions. By mapping new querie...",
    "pdf_url": "https://arxiv.org/pdf/2509.23471v1"
  },
  {
    "idx": 78,
    "title": "A Predictive and Synergistic Two-Layer Scheduling Framework for LLM Serving",
    "arxiv_id": "2509.23384v3",
    "published": "2025-09-27",
    "year": 2025,
    "authors": "Yue Zhang, Yuansheng Chen, Xuan Mo",
    "us_affiliation": false,
    "relevance_score": 4,
    "summary": "LLM inference serving typically scales out with a two-tier architecture: a cluster router distributes requests to multiple inference engines, each of which then in turn performs its own internal scheduling. However, this commonly used paradigm suffers from critical, systemic inefficiency caused by the information gaps across two layers. At the cluster-layer, the router mainly relies on lagging, co...",
    "pdf_url": "https://arxiv.org/pdf/2509.23384v3"
  },
  {
    "idx": 79,
    "title": "DRIFT: Learning from Abundant User Dissatisfaction in Real-World Preference Learning",
    "arxiv_id": "2510.02341v1",
    "published": "2025-09-27",
    "year": 2025,
    "authors": "Yifan Wang, Bolian Li, Junlin Wu",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Real-world large language model deployments (e.g., conversational AI systems, code generation assistants) naturally generate abundant implicit user dissatisfaction (DSAT) signals, as users iterate toward better answers through refinements, corrections, and expressed preferences, while explicit satisfaction (SAT) feedback is scarce. Existing preference learning approaches are poorly aligned with th...",
    "pdf_url": "https://arxiv.org/pdf/2510.02341v1"
  },
  {
    "idx": 80,
    "title": "Towards a more realistic evaluation of machine learning models for bearing fault diagnosis",
    "arxiv_id": "2509.22267v1",
    "published": "2025-09-26",
    "year": 2025,
    "authors": "Jo\u00e3o Paulo Vieira, Victor Afonso Bauler, Rodrigo Kobashikawa Rosa",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Reliable detection of bearing faults is essential for maintaining the safety and operational efficiency of rotating machinery. While recent advances in machine learning (ML), particularly deep learning, have shown strong performance in controlled settings, many studies fail to generalize to real-world applications due to methodological flaws, most notably data leakage. This paper investigates the ...",
    "pdf_url": "https://arxiv.org/pdf/2509.22267v1"
  },
  {
    "idx": 81,
    "title": "SPRINT: Stochastic Performative Prediction With Variance Reduction",
    "arxiv_id": "2509.17304v2",
    "published": "2025-09-22",
    "year": 2025,
    "authors": "Tian Xie, Ding Zhu, Jia Liu",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Performative prediction (PP) is an algorithmic framework for optimizing machine learning (ML) models where the model's deployment affects the distribution of the data it is trained on. Compared to traditional ML with fixed data, designing algorithms in PP converging to a stable point -- known as a stationary performative stable (SPS) solution -- is more challenging than the counterpart in conventi...",
    "pdf_url": "https://arxiv.org/pdf/2509.17304v2"
  },
  {
    "idx": 82,
    "title": "GPU Temperature Simulation-Based Testing for In-Vehicle Deep Learning Frameworks",
    "arxiv_id": "2509.15815v2",
    "published": "2025-09-19",
    "year": 2025,
    "authors": "Yinglong Zou, Juan Zhai, Chunrong Fang",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Deep learning models play a vital role in autonomous driving systems, supporting critical functions such as environmental perception. To accelerate model inference, these deep learning models' deployment relies on automotive deep learning frameworks, for example, PaddleInference in Apollo and TensorRT in AutoWare. However, unlike deploying deep learning models on the cloud, vehicular environments ...",
    "pdf_url": "https://arxiv.org/pdf/2509.15815v2"
  },
  {
    "idx": 83,
    "title": "Qianfan-VL: Domain-Enhanced Universal Vision-Language Models",
    "arxiv_id": "2509.18189v1",
    "published": "2025-09-19",
    "year": 2025,
    "authors": "Daxiang Dong, Mingming Zheng, Dong Xu",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "We present Qianfan-VL, a series of multimodal large language models ranging from 3B to 70B parameters, achieving state-of-the-art performance through innovative domain enhancement techniques. Our approach employs multi-stage progressive training and high-precision data synthesis pipelines, which prove to be critical technologies for enhancing domain-specific capabilities while maintaining strong g...",
    "pdf_url": "https://arxiv.org/pdf/2509.18189v1"
  },
  {
    "idx": 84,
    "title": "Optimization techniques for SQL+ML queries: A performance analysis of real-time feature computation in OpenMLDB",
    "arxiv_id": "2509.15529v1",
    "published": "2025-09-19",
    "year": 2025,
    "authors": "Mashkhal A. Sidiq, Aras A. Salih, Samrand M. Hassan",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "In this study, we optimize SQL+ML queries on top of OpenMLDB, an open-source database that seamlessly integrates offline and online feature computations. The work used feature-rich synthetic dataset experiments in Docker, which acted like production environments that processed 100 to 500 records per batch and 6 to 12 requests per batch in parallel. Efforts have been concentrated in the areas of be...",
    "pdf_url": "https://arxiv.org/pdf/2509.15529v1"
  },
  {
    "idx": 85,
    "title": "Monitoring Machine Learning Systems: A Multivocal Literature Review",
    "arxiv_id": "2509.14294v1",
    "published": "2025-09-17",
    "year": 2025,
    "authors": "Hira Naveed, Scott Barnett, Chetan Arora",
    "us_affiliation": false,
    "relevance_score": 3,
    "summary": "Context: Dynamic production environments make it challenging to maintain reliable machine learning (ML) systems. Runtime issues, such as changes in data patterns or operating contexts, that degrade model performance are a common occurrence in production settings. Monitoring enables early detection and mitigation of these runtime issues, helping maintain users' trust and prevent unwanted consequenc...",
    "pdf_url": "https://arxiv.org/pdf/2509.14294v1"
  },
  {
    "idx": 86,
    "title": "DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform",
    "arxiv_id": "2509.13506v1",
    "published": "2025-09-16",
    "year": 2025,
    "authors": "Xingzi Xu, Qi Li, Shuwen Qiu",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Diffusion models enable high-quality virtual try-on (VTO) with their established image synthesis abilities. Despite the extensive end-to-end training of large pre-trained models involved in current VTO methods, real-world applications often prioritize limited training and inference, serving, and deployment budgets for VTO. To solve this obstacle, we apply Doob's h-transform efficient fine-tuning (...",
    "pdf_url": "https://arxiv.org/pdf/2509.13506v1"
  },
  {
    "idx": 87,
    "title": "Sy-FAR: Symmetry-based Fair Adversarial Robustness",
    "arxiv_id": "2509.12939v1",
    "published": "2025-09-16",
    "year": 2025,
    "authors": "Haneen Najjar, Eyal Ronen, Mahmood Sharif",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "Security-critical machine-learning (ML) systems, such as face-recognition systems, are susceptible to adversarial examples, including real-world physically realizable attacks. Various means to boost ML's adversarial robustness have been proposed; however, they typically induce unfair robustness: It is often easier to attack from certain classes or groups than from others. Several techniques have b...",
    "pdf_url": "https://arxiv.org/pdf/2509.12939v1"
  },
  {
    "idx": 88,
    "title": "AI Asset Management for Manufacturing (AIM4M): Development of a Process Model for Operationalization",
    "arxiv_id": "2509.11691v1",
    "published": "2025-09-15",
    "year": 2025,
    "authors": "Lukas Rauh, Mel-Rick S\u00fcner, Daniel Schel",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "The benefits of adopting artificial intelligence (AI) in manufacturing are undeniable. However, operationalizing AI beyond the prototype, especially when involved with cyber-physical production systems (CPPS), remains a significant challenge due to the technical system complexity, a lack of implementation standards and fragmented organizational processes. To this end, this paper proposes a new pro...",
    "pdf_url": "https://arxiv.org/pdf/2509.11691v1"
  },
  {
    "idx": 89,
    "title": "When the Code Autopilot Breaks: Why LLMs Falter in Embedded Machine Learning",
    "arxiv_id": "2509.10946v1",
    "published": "2025-09-13",
    "year": 2025,
    "authors": "Roberto Morabito, Guanghan Wu",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Large Language Models (LLMs) are increasingly used to automate software generation in embedded machine learning workflows, yet their outputs often fail silently or behave unpredictably. This article presents an empirical investigation of failure modes in LLM-powered ML pipelines, based on an autopilot framework that orchestrates data preprocessing, model conversion, and on-device inference code ge...",
    "pdf_url": "https://arxiv.org/pdf/2509.10946v1"
  },
  {
    "idx": 90,
    "title": "Verifying Computational Graphs in Production-Grade Distributed Machine Learning Frameworks",
    "arxiv_id": "2509.10694v1",
    "published": "2025-09-12",
    "year": 2025,
    "authors": "Kahfi S. Zulkifli, Wenbo Qian, Shaowei Zhu",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "Modern machine learning frameworks support very large models by incorporating parallelism and optimization techniques. Yet, these very techniques add new layers of complexity, introducing silent errors that severely degrade model performance. Existing solutions are either ad hoc or too costly for production.\n  We present Scalify, a lightweight framework that exposes silent errors by verifying sema...",
    "pdf_url": "https://arxiv.org/pdf/2509.10694v1"
  },
  {
    "idx": 91,
    "title": "Machine Unlearning for Responsible and Adaptive AI in Education",
    "arxiv_id": "2509.10590v2",
    "published": "2025-09-12",
    "year": 2025,
    "authors": "Betty Mayeku, Sandra Hummel, Parisa Memarmoshrefi",
    "us_affiliation": false,
    "relevance_score": 0,
    "summary": "Machine Unlearning (MU) has emerged as a promising approach to addressing persistent challenges in Machine Learning (ML) systems. By enabling the selective removal of learned data, MU introduces protective, corrective, and adaptive capabilities that are central to advancing Responsible and Adaptive AI. However, despite its growing prominence in other domains, MU remains underexplored within educat...",
    "pdf_url": "https://arxiv.org/pdf/2509.10590v2"
  },
  {
    "idx": 92,
    "title": "SynergAI: Edge-to-Cloud Synergy for Architecture-Driven High-Performance Orchestration for AI Inference",
    "arxiv_id": "2509.12252v1",
    "published": "2025-09-12",
    "year": 2025,
    "authors": "Foteini Stathopoulou, Aggelos Ferikoglou, Manolis Katsaragakis",
    "us_affiliation": true,
    "relevance_score": 3,
    "summary": "The rapid evolution of Artificial Intelligence (AI) and Machine Learning (ML) has significantly heightened computational demands, particularly for inference-serving workloads. While traditional cloud-based deployments offer scalability, they face challenges such as network congestion, high energy consumption, and privacy concerns. In contrast, edge computing provides low-latency and sustainable al...",
    "pdf_url": "https://arxiv.org/pdf/2509.12252v1"
  },
  {
    "idx": 93,
    "title": "Towards Data Drift Monitoring for Speech Deepfake Detection in the context of MLOps",
    "arxiv_id": "2509.10086v1",
    "published": "2025-09-12",
    "year": 2025,
    "authors": "Xin Wang, Wanying Ge, Junichi Yamagishi",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "When being delivered in applications or services on the cloud, static speech deepfake detectors that are not updated will become vulnerable to newly created speech deepfake attacks. From the perspective of machine learning operations (MLOps), this paper tries to answer whether we can monitor new and unseen speech deepfake data that drifts away from a seen reference data set. We further ask, if dri...",
    "pdf_url": "https://arxiv.org/pdf/2509.10086v1"
  },
  {
    "idx": 94,
    "title": "Combating the Memory Walls: Optimization Pathways for Long-Context Agentic LLM Inference",
    "arxiv_id": "2509.09505v2",
    "published": "2025-09-11",
    "year": 2025,
    "authors": "Haoran Wu, Can Xiao, Jiayi Nie",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "LLMs now form the backbone of AI agents for a diverse array of applications, including tool use, command-line agents, and web or computer use agents. These agentic LLM inference tasks are fundamentally different from chatbot-focused inference -- they often have much larger context lengths to capture complex, prolonged inputs, such as entire webpage DOMs or complicated tool call trajectories. This,...",
    "pdf_url": "https://arxiv.org/pdf/2509.09505v2"
  },
  {
    "idx": 95,
    "title": "Position: AI Safety Must Embrace an Antifragile Perspective",
    "arxiv_id": "2509.13339v1",
    "published": "2025-09-11",
    "year": 2025,
    "authors": "Ming Jin, Hyunin Lee",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "This position paper contends that modern AI research must adopt an antifragile perspective on safety -- one in which the system's capacity to guarantee long-term AI safety such as handling rare or out-of-distribution (OOD) events expands over time. Conventional static benchmarks and single-shot robustness tests overlook the reality that environments evolve and that models, if left unchallenged, ca...",
    "pdf_url": "https://arxiv.org/pdf/2509.13339v1"
  },
  {
    "idx": 96,
    "title": "Agents of Discovery",
    "arxiv_id": "2509.08535v1",
    "published": "2025-09-10",
    "year": 2025,
    "authors": "Sascha Diefenbacher, Anna Hallin, Gregor Kasieczka",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "The substantial data volumes encountered in modern particle physics and other domains of fundamental physics research allow (and require) the use of increasingly complex data analysis tools and workflows. While the use of machine learning (ML) tools for data analysis has recently proliferated, these tools are typically special-purpose algorithms that rely, for example, on encoded physics knowledge...",
    "pdf_url": "https://arxiv.org/pdf/2509.08535v1"
  },
  {
    "idx": 97,
    "title": "Ubiquitous Intelligence Via Wireless Network-Driven LLMs Evolution",
    "arxiv_id": "2509.08400v1",
    "published": "2025-09-10",
    "year": 2025,
    "authors": "Xingkun Yin, Feiran You, Hongyang Du",
    "us_affiliation": false,
    "relevance_score": 1,
    "summary": "We introduce ubiquitous intelligence as a paradigm where Large Language Models (LLMs) evolve within wireless network-driven ecosystems. Unlike static model deployments, this approach enables scalable and continuous intelligence ascension through coordination between networks and LLMs. Wireless networks support system-orchestrated lifelong learning, while LLMs drive the next-generation network deve...",
    "pdf_url": "https://arxiv.org/pdf/2509.08400v1"
  },
  {
    "idx": 98,
    "title": "DuoServe-MoE: Dual-Phase Expert Prefetch and Cache Scheduling for Efficient MoE LLM Inference",
    "arxiv_id": "2509.07379v1",
    "published": "2025-09-09",
    "year": 2025,
    "authors": "Yuning Zhang, Grant Pinkert, Nan Yang",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Large Language Models (LLMs) have demonstrated impressive performance across a wide range of deep learning tasks. Mixture of Experts (MoE) further enhances their capabilities by increasing model width through sparsely activated expert branches, which keeps inference computation efficient. However, the large number of expert weights introduces significant GPU memory pressure, especially in resource...",
    "pdf_url": "https://arxiv.org/pdf/2509.07379v1"
  },
  {
    "idx": 99,
    "title": "FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving",
    "arxiv_id": "2509.06261v2",
    "published": "2025-09-08",
    "year": 2025,
    "authors": "Kyungmin Bin, Seungbeom Choi, Jimyoung Son",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "Recent advances in Post-Training Quantization (PTQ) techniques have significantly increased demand for serving quantized large language models (LLMs), enabling higher throughput and substantially reduced memory usage with minimal accuracy loss. Quantized models address memory constraints in LLMs and enhance GPU resource utilization through efficient GPU sharing. However, quantized models have smal...",
    "pdf_url": "https://arxiv.org/pdf/2509.06261v2"
  },
  {
    "idx": 100,
    "title": "Ratio1 -- AI meta-OS",
    "arxiv_id": "2509.12223v1",
    "published": "2025-09-05",
    "year": 2025,
    "authors": "Andrei Damian, Petrica Butusina, Alessandro De Franceschi",
    "us_affiliation": false,
    "relevance_score": 2,
    "summary": "We propose the Ratio1 AI meta-operating system (meta-OS), a decentralized MLOps protocol that unifies AI model development, deployment, and inference across heterogeneous edge devices. Its key innovation is an integrated blockchain-based framework that transforms idle computing resources (laptops, smartphones, cloud VMs) into a trustless global supercomputer. The architecture includes novel compon...",
    "pdf_url": "https://arxiv.org/pdf/2509.12223v1"
  }
]