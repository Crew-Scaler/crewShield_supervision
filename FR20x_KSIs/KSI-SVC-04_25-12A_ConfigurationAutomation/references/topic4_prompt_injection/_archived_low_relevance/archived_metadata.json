{
  "total_archived_papers": 84,
  "archive_reason": "Lower relevance scores compared to top 10 selected papers",
  "papers": [
    {
      "rank": 11,
      "arxiv_id": "2511.00447v2",
      "title": "DRIP: Defending Prompt Injection via Token-wise Representation Editing and Residual Instruction Fusion",
      "authors": [
        "Ruofan Liu",
        "Yun Lin",
        "Zhiyong Huang",
        "Jin Song Dong"
      ],
      "published_date": "2025-11-01",
      "year": 2025,
      "relevance_score": 137,
      "arxiv_url": "https://arxiv.org/abs/2511.00447v2",
      "pdf_url": "https://arxiv.org/pdf/2511.00447v2"
    },
    {
      "rank": 12,
      "arxiv_id": "2506.23576v1",
      "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models",
      "authors": [
        "Maria Carolina Cornelia Wit",
        "Jun Pang"
      ],
      "published_date": "2025-06-30",
      "year": 2025,
      "relevance_score": 135,
      "arxiv_url": "https://arxiv.org/abs/2506.23576v1",
      "pdf_url": "https://arxiv.org/pdf/2506.23576v1"
    },
    {
      "rank": 13,
      "arxiv_id": "2502.05206v5",
      "title": "Safety at Scale: A Comprehensive Survey of Large Model and Agent Safety",
      "authors": [
        "Xingjun Ma",
        "Yifeng Gao",
        "Yixu Wang",
        "Ruofan Wang",
        "Xin Wang"
      ],
      "published_date": "2025-02-02",
      "year": 2025,
      "relevance_score": 135,
      "arxiv_url": "https://arxiv.org/abs/2502.05206v5",
      "pdf_url": "https://arxiv.org/pdf/2502.05206v5"
    },
    {
      "rank": 14,
      "arxiv_id": "2509.13597v1",
      "title": "Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents",
      "authors": [
        "Abhishek Goswami"
      ],
      "published_date": "2025-09-16",
      "year": 2025,
      "relevance_score": 134,
      "arxiv_url": "https://arxiv.org/abs/2509.13597v1",
      "pdf_url": "https://arxiv.org/pdf/2509.13597v1"
    },
    {
      "rank": 15,
      "arxiv_id": "2510.19844v1",
      "title": "CourtGuard: A Local, Multiagent Prompt Injection Classifier",
      "authors": [
        "Isaac Wu",
        "Michael Maslowski"
      ],
      "published_date": "2025-10-20",
      "year": 2025,
      "relevance_score": 132,
      "arxiv_url": "https://arxiv.org/abs/2510.19844v1",
      "pdf_url": "https://arxiv.org/pdf/2510.19844v1"
    },
    {
      "rank": 16,
      "arxiv_id": "2503.12188v2",
      "title": "Multi-Agent Systems Execute Arbitrary Malicious Code",
      "authors": [
        "Harold Triedman",
        "Rishi Jha",
        "Vitaly Shmatikov"
      ],
      "published_date": "2025-03-15",
      "year": 2025,
      "relevance_score": 131,
      "arxiv_url": "https://arxiv.org/abs/2503.12188v2",
      "pdf_url": "https://arxiv.org/pdf/2503.12188v2"
    },
    {
      "rank": 17,
      "arxiv_id": "2505.21936v3",
      "title": "RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments",
      "authors": [
        "Zeyi Liao",
        "Jaylen Jones",
        "Linxi Jiang",
        "Yuting Ning",
        "Eric Fosler-Lussier"
      ],
      "published_date": "2025-05-28",
      "year": 2025,
      "relevance_score": 130,
      "arxiv_url": "https://arxiv.org/abs/2505.21936v3",
      "pdf_url": "https://arxiv.org/pdf/2505.21936v3"
    },
    {
      "rank": 18,
      "arxiv_id": "2508.17155v1",
      "title": "Mind the Gap: Time-of-Check to Time-of-Use Vulnerabilities in LLM-Enabled Agents",
      "authors": [
        "Derek Lilienthal",
        "Sanghyun Hong"
      ],
      "published_date": "2025-08-23",
      "year": 2025,
      "relevance_score": 129,
      "arxiv_url": "https://arxiv.org/abs/2508.17155v1",
      "pdf_url": "https://arxiv.org/pdf/2508.17155v1"
    },
    {
      "rank": 19,
      "arxiv_id": "2511.03434v1",
      "title": "Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof, Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2, ERC-8004, and Beyond",
      "authors": [
        "Botao 'Amber' Hu",
        "Helena Rong"
      ],
      "published_date": "2025-11-05",
      "year": 2025,
      "relevance_score": 129,
      "arxiv_url": "https://arxiv.org/abs/2511.03434v1",
      "pdf_url": "https://arxiv.org/pdf/2511.03434v1"
    },
    {
      "rank": 20,
      "arxiv_id": "2510.19207v1",
      "title": "Defending Against Prompt Injection with DataFilter",
      "authors": [
        "Yizhu Wang",
        "Sizhe Chen",
        "Raghad Alkhudair",
        "Basel Alomair",
        "David Wagner"
      ],
      "published_date": "2025-10-22",
      "year": 2025,
      "relevance_score": 129,
      "arxiv_url": "https://arxiv.org/abs/2510.19207v1",
      "pdf_url": "https://arxiv.org/pdf/2510.19207v1"
    },
    {
      "rank": 21,
      "arxiv_id": "2510.14312v1",
      "title": "Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies",
      "authors": [
        "Mason Nakamura",
        "Abhinav Kumar",
        "Saaduddin Mahmud",
        "Sahar Abdelnabi",
        "Shlomo Zilberstein"
      ],
      "published_date": "2025-10-16",
      "year": 2025,
      "relevance_score": 129,
      "arxiv_url": "https://arxiv.org/abs/2510.14312v1",
      "pdf_url": "https://arxiv.org/pdf/2510.14312v1"
    },
    {
      "rank": 22,
      "arxiv_id": "2512.16962v1",
      "title": "MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval",
      "authors": [
        "Saksham Sahai Srivastava",
        "Haoyu He"
      ],
      "published_date": "2025-12-18",
      "year": 2025,
      "relevance_score": 126,
      "arxiv_url": "https://arxiv.org/abs/2512.16962v1",
      "pdf_url": "https://arxiv.org/pdf/2512.16962v1"
    },
    {
      "rank": 23,
      "arxiv_id": "2512.09321v3",
      "title": "ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data",
      "authors": [
        "Reachal Wang",
        "Yuqi Jia",
        "Neil Zhenqiang Gong"
      ],
      "published_date": "2025-12-10",
      "year": 2025,
      "relevance_score": 126,
      "arxiv_url": "https://arxiv.org/abs/2512.09321v3",
      "pdf_url": "https://arxiv.org/pdf/2512.09321v3"
    },
    {
      "rank": 24,
      "arxiv_id": "2512.19011v1",
      "title": "Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline",
      "authors": [
        "Akshaj Prashanth Rao",
        "Advait Singh",
        "Saumya Kumaar Saksena",
        "Dhruv Kumar"
      ],
      "published_date": "2025-12-22",
      "year": 2025,
      "relevance_score": 125,
      "arxiv_url": "https://arxiv.org/abs/2512.19011v1",
      "pdf_url": "https://arxiv.org/pdf/2512.19011v1"
    },
    {
      "rank": 25,
      "arxiv_id": "2510.16381v1",
      "title": "ATA: A Neuro-Symbolic Approach to Implement Autonomous and Trustworthy Agents",
      "authors": [
        "David Peer",
        "Sebastian Stabinger"
      ],
      "published_date": "2025-10-18",
      "year": 2025,
      "relevance_score": 124,
      "arxiv_url": "https://arxiv.org/abs/2510.16381v1",
      "pdf_url": "https://arxiv.org/pdf/2510.16381v1"
    },
    {
      "rank": 26,
      "arxiv_id": "2512.01326v1",
      "title": "Securing Large Language Models (LLMs) from Prompt Injection Attacks",
      "authors": [
        "Omar Farooq Khan Suri",
        "John McCrae"
      ],
      "published_date": "2025-12-01",
      "year": 2025,
      "relevance_score": 122,
      "arxiv_url": "https://arxiv.org/abs/2512.01326v1",
      "pdf_url": "https://arxiv.org/pdf/2512.01326v1"
    },
    {
      "rank": 27,
      "arxiv_id": "2512.12583v1",
      "title": "Detecting Prompt Injection Attacks Against Application Using Classifiers",
      "authors": [
        "Safwan Shaheer",
        "G. M. Refatul Islam",
        "Mohammad Rafid Hamid",
        "Md. Abrar Faiaz Khan",
        "Md. Omar Faruk"
      ],
      "published_date": "2025-12-14",
      "year": 2025,
      "relevance_score": 121,
      "arxiv_url": "https://arxiv.org/abs/2512.12583v1",
      "pdf_url": "https://arxiv.org/pdf/2512.12583v1"
    },
    {
      "rank": 28,
      "arxiv_id": "2511.15203v1",
      "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks",
      "authors": [
        "Zimo Ji",
        "Xunguang Wang",
        "Zongjie Li",
        "Pingchuan Ma",
        "Yudong Gao"
      ],
      "published_date": "2025-11-19",
      "year": 2025,
      "relevance_score": 120,
      "arxiv_url": "https://arxiv.org/abs/2511.15203v1",
      "pdf_url": "https://arxiv.org/pdf/2511.15203v1"
    },
    {
      "rank": 29,
      "arxiv_id": "2506.10171v3",
      "title": "Beyond Jailbreaking: Auditing Contextual Privacy in LLM Agents",
      "authors": [
        "Saswat Das",
        "Jameson Sandler",
        "Ferdinando Fioretto"
      ],
      "published_date": "2025-06-11",
      "year": 2025,
      "relevance_score": 120,
      "arxiv_url": "https://arxiv.org/abs/2506.10171v3",
      "pdf_url": "https://arxiv.org/pdf/2506.10171v3"
    },
    {
      "rank": 30,
      "arxiv_id": "2505.13862v3",
      "title": "PandaGuard: Systematic Evaluation of LLM Safety against Jailbreaking Attacks",
      "authors": [
        "Guobin Shen",
        "Dongcheng Zhao",
        "Linghao Feng",
        "Xiang He",
        "Jihang Wang"
      ],
      "published_date": "2025-05-20",
      "year": 2025,
      "relevance_score": 120,
      "arxiv_url": "https://arxiv.org/abs/2505.13862v3",
      "pdf_url": "https://arxiv.org/pdf/2505.13862v3"
    },
    {
      "rank": 31,
      "arxiv_id": "2512.04785v1",
      "title": "ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications",
      "authors": [
        "Eranga Bandara",
        "Amin Hass",
        "Ross Gore",
        "Sachin Shetty",
        "Ravi Mukkamala"
      ],
      "published_date": "2025-12-04",
      "year": 2025,
      "relevance_score": 114,
      "arxiv_url": "https://arxiv.org/abs/2512.04785v1",
      "pdf_url": "https://arxiv.org/pdf/2512.04785v1"
    },
    {
      "rank": 32,
      "arxiv_id": "2510.15994v1",
      "title": "MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents",
      "authors": [
        "Dongsen Zhang",
        "Zekun Li",
        "Xu Luo",
        "Xuannan Liu",
        "Peipei Li"
      ],
      "published_date": "2025-10-14",
      "year": 2025,
      "relevance_score": 113,
      "arxiv_url": "https://arxiv.org/abs/2510.15994v1",
      "pdf_url": "https://arxiv.org/pdf/2510.15994v1"
    },
    {
      "rank": 33,
      "arxiv_id": "2512.00742v1",
      "title": "On the Regulatory Potential of User Interfaces for AI Agent Governance",
      "authors": [
        "K. J. Kevin Feng",
        "Tae Soo Kim",
        "Rock Yuren Pang",
        "Faria Huq",
        "Tal August"
      ],
      "published_date": "2025-11-30",
      "year": 2025,
      "relevance_score": 112,
      "arxiv_url": "https://arxiv.org/abs/2512.00742v1",
      "pdf_url": "https://arxiv.org/pdf/2512.00742v1"
    },
    {
      "rank": 34,
      "arxiv_id": "2510.09462v1",
      "title": "Adaptive Attacks on Trusted Monitors Subvert AI Control Protocols",
      "authors": [
        "Mikhail Terekhov",
        "Alexander Panfilov",
        "Daniil Dzenhaliou",
        "Caglar Gulcehre",
        "Maksym Andriushchenko"
      ],
      "published_date": "2025-10-10",
      "year": 2025,
      "relevance_score": 112,
      "arxiv_url": "https://arxiv.org/abs/2510.09462v1",
      "pdf_url": "https://arxiv.org/pdf/2510.09462v1"
    },
    {
      "rank": 35,
      "arxiv_id": "2508.02736v2",
      "title": "AgentSight: System-Level Observability for AI Agents Using eBPF",
      "authors": [
        "Yusheng Zheng",
        "Yanpeng Hu",
        "Tong Yu",
        "Andi Quinn"
      ],
      "published_date": "2025-08-02",
      "year": 2025,
      "relevance_score": 111,
      "arxiv_url": "https://arxiv.org/abs/2508.02736v2",
      "pdf_url": "https://arxiv.org/pdf/2508.02736v2"
    },
    {
      "rank": 36,
      "arxiv_id": "2506.22183v1",
      "title": "A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety",
      "authors": [
        "Camille Fran\u00e7ois",
        "Ludovic P\u00e9ran",
        "Ayah Bdeir",
        "Nouha Dziri",
        "Will Hawkins"
      ],
      "published_date": "2025-06-27",
      "year": 2025,
      "relevance_score": 111,
      "arxiv_url": "https://arxiv.org/abs/2506.22183v1",
      "pdf_url": "https://arxiv.org/pdf/2506.22183v1"
    },
    {
      "rank": 37,
      "arxiv_id": "2510.22628v1",
      "title": "Sentra-Guard: A Multilingual Human-AI Framework for Real-Time Defense Against Adversarial LLM Jailbreaks",
      "authors": [
        "Md. Mehedi Hasan",
        "Ziaur Rahman",
        "Rafid Mostafiz",
        "Md. Abir Hossain"
      ],
      "published_date": "2025-10-26",
      "year": 2025,
      "relevance_score": 111,
      "arxiv_url": "https://arxiv.org/abs/2510.22628v1",
      "pdf_url": "https://arxiv.org/pdf/2510.22628v1"
    },
    {
      "rank": 38,
      "arxiv_id": "2507.01020v2",
      "title": "AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models",
      "authors": [
        "Aashray Reddy",
        "Andrew Zagula",
        "Nicholas Saban"
      ],
      "published_date": "2025-04-18",
      "year": 2025,
      "relevance_score": 111,
      "arxiv_url": "https://arxiv.org/abs/2507.01020v2",
      "pdf_url": "https://arxiv.org/pdf/2507.01020v2"
    },
    {
      "rank": 39,
      "arxiv_id": "2511.02894v3",
      "title": "Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models",
      "authors": [
        "W. K. M Mithsara",
        "Ning Yang",
        "Ahmed Imteaj",
        "Hussein Zangoti",
        "Abdur R. Shahid"
      ],
      "published_date": "2025-11-04",
      "year": 2025,
      "relevance_score": 111,
      "arxiv_url": "https://arxiv.org/abs/2511.02894v3",
      "pdf_url": "https://arxiv.org/pdf/2511.02894v3"
    },
    {
      "rank": 40,
      "arxiv_id": "2511.01634v2",
      "title": "Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models",
      "authors": [
        "Daniyal Ganiuly",
        "Assel Smaiyl"
      ],
      "published_date": "2025-11-03",
      "year": 2025,
      "relevance_score": 110,
      "arxiv_url": "https://arxiv.org/abs/2511.01634v2",
      "pdf_url": "https://arxiv.org/pdf/2511.01634v2"
    },
    {
      "rank": 41,
      "arxiv_id": "2511.19477v1",
      "title": "Building Browser Agents: Architecture, Security, and Practical Solutions",
      "authors": [
        "Aram Vardanyan"
      ],
      "published_date": "2025-11-22",
      "year": 2025,
      "relevance_score": 109,
      "arxiv_url": "https://arxiv.org/abs/2511.19477v1",
      "pdf_url": "https://arxiv.org/pdf/2511.19477v1"
    },
    {
      "rank": 42,
      "arxiv_id": "2511.05797v1",
      "title": "When AI Meets the Web: Prompt Injection Risks in Third-Party AI Chatbot Plugins",
      "authors": [
        "Yigitcan Kaya",
        "Anton Landerer",
        "Stijn Pletinckx",
        "Michelle Zimmermann",
        "Christopher Kruegel"
      ],
      "published_date": "2025-11-08",
      "year": 2025,
      "relevance_score": 108,
      "arxiv_url": "https://arxiv.org/abs/2511.05797v1",
      "pdf_url": "https://arxiv.org/pdf/2511.05797v1"
    },
    {
      "rank": 43,
      "arxiv_id": "2511.12295v1",
      "title": "Privacy-Preserving Prompt Injection Detection for LLMs Using Federated Learning and Embedding-Based NLP Classification",
      "authors": [
        "Hasini Jayathilaka"
      ],
      "published_date": "2025-11-15",
      "year": 2025,
      "relevance_score": 107,
      "arxiv_url": "https://arxiv.org/abs/2511.12295v1",
      "pdf_url": "https://arxiv.org/pdf/2511.12295v1"
    },
    {
      "rank": 44,
      "arxiv_id": "2512.16307v1",
      "title": "Beyond the Benchmark: Innovative Defenses Against Prompt Injection Attacks",
      "authors": [
        "Safwan Shaheer",
        "G. M. Refatul Islam",
        "Mohammad Rafid Hamid",
        "Tahsin Zaman Jilan"
      ],
      "published_date": "2025-12-18",
      "year": 2025,
      "relevance_score": 106,
      "arxiv_url": "https://arxiv.org/abs/2512.16307v1",
      "pdf_url": "https://arxiv.org/pdf/2512.16307v1"
    },
    {
      "rank": 45,
      "arxiv_id": "2512.12921v1",
      "title": "Cisco Integrated AI Security and Safety Framework Report",
      "authors": [
        "Amy Chang",
        "Tiffany Saade",
        "Sanket Mendapara",
        "Adam Swanda",
        "Ankit Garg"
      ],
      "published_date": "2025-12-15",
      "year": 2025,
      "relevance_score": 105,
      "arxiv_url": "https://arxiv.org/abs/2512.12921v1",
      "pdf_url": "https://arxiv.org/pdf/2512.12921v1"
    },
    {
      "rank": 46,
      "arxiv_id": "2512.15081v1",
      "title": "Quantifying Return on Security Controls in LLM Systems",
      "authors": [
        "Richard Helder Moulton",
        "Austin O'Brien",
        "John D. Hastings"
      ],
      "published_date": "2025-12-17",
      "year": 2025,
      "relevance_score": 105,
      "arxiv_url": "https://arxiv.org/abs/2512.15081v1",
      "pdf_url": "https://arxiv.org/pdf/2512.15081v1"
    },
    {
      "rank": 47,
      "arxiv_id": "2510.19169v2",
      "title": "OpenGuardrails: A Configurable, Unified, and Scalable Guardrails Platform for Large Language Models",
      "authors": [
        "Thomas Wang",
        "Haowen Li"
      ],
      "published_date": "2025-10-22",
      "year": 2025,
      "relevance_score": 104,
      "arxiv_url": "https://arxiv.org/abs/2510.19169v2",
      "pdf_url": "https://arxiv.org/pdf/2510.19169v2"
    },
    {
      "rank": 48,
      "arxiv_id": "2510.13893v1",
      "title": "Guarding the Guardrails: A Taxonomy-Driven Approach to Jailbreak Detection",
      "authors": [
        "Olga E. Sorokoletova",
        "Francesco Giarrusso",
        "Vincenzo Suriani",
        "Daniele Nardi"
      ],
      "published_date": "2025-10-14",
      "year": 2025,
      "relevance_score": 104,
      "arxiv_url": "https://arxiv.org/abs/2510.13893v1",
      "pdf_url": "https://arxiv.org/pdf/2510.13893v1"
    },
    {
      "rank": 49,
      "arxiv_id": "2510.14005v2",
      "title": "PIShield: Detecting Prompt Injection Attacks via Intrinsic LLM Features",
      "authors": [
        "Wei Zou",
        "Yupei Liu",
        "Yanting Wang",
        "Ying Chen",
        "Neil Gong"
      ],
      "published_date": "2025-10-15",
      "year": 2025,
      "relevance_score": 102,
      "arxiv_url": "https://arxiv.org/abs/2510.14005v2",
      "pdf_url": "https://arxiv.org/pdf/2510.14005v2"
    },
    {
      "rank": 50,
      "arxiv_id": "2511.23174v1",
      "title": "Are LLMs Good Safety Agents or a Propaganda Engine?",
      "authors": [
        "Neemesh Yadav",
        "Francesco Ortu",
        "Jiarui Liu",
        "Joeun Yook",
        "Bernhard Sch\u00f6lkopf"
      ],
      "published_date": "2025-11-28",
      "year": 2025,
      "relevance_score": 101,
      "arxiv_url": "https://arxiv.org/abs/2511.23174v1",
      "pdf_url": "https://arxiv.org/pdf/2511.23174v1"
    },
    {
      "rank": 51,
      "arxiv_id": "2511.21752v1",
      "title": "Semantics as a Shield: Label Disguise Defense (LDD) against Prompt Injection in LLM Sentiment Classification",
      "authors": [
        "Yanxi Li",
        "Ruocheng Shan"
      ],
      "published_date": "2025-11-23",
      "year": 2025,
      "relevance_score": 101,
      "arxiv_url": "https://arxiv.org/abs/2511.21752v1",
      "pdf_url": "https://arxiv.org/pdf/2511.21752v1"
    },
    {
      "rank": 52,
      "arxiv_id": "2511.10720v1",
      "title": "PISanitizer: Preventing Prompt Injection to Long-Context LLMs via Prompt Sanitization",
      "authors": [
        "Runpeng Geng",
        "Yanting Wang",
        "Chenlong Yin",
        "Minhao Cheng",
        "Ying Chen"
      ],
      "published_date": "2025-11-13",
      "year": 2025,
      "relevance_score": 101,
      "arxiv_url": "https://arxiv.org/abs/2511.10720v1",
      "pdf_url": "https://arxiv.org/pdf/2511.10720v1"
    },
    {
      "rank": 53,
      "arxiv_id": "2510.16794v1",
      "title": "Black-box Optimization of LLM Outputs by Asking for Directions",
      "authors": [
        "Jie Zhang",
        "Meng Ding",
        "Yang Liu",
        "Jue Hong",
        "Florian Tram\u00e8r"
      ],
      "published_date": "2025-10-19",
      "year": 2025,
      "relevance_score": 100,
      "arxiv_url": "https://arxiv.org/abs/2510.16794v1",
      "pdf_url": "https://arxiv.org/pdf/2510.16794v1"
    },
    {
      "rank": 54,
      "arxiv_id": "2507.02850v2",
      "title": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users",
      "authors": [
        "Almog Hilel",
        "Idan Shenfeld",
        "Jacob Andreas",
        "Leshem Choshen"
      ],
      "published_date": "2025-07-03",
      "year": 2025,
      "relevance_score": 100,
      "arxiv_url": "https://arxiv.org/abs/2507.02850v2",
      "pdf_url": "https://arxiv.org/pdf/2507.02850v2"
    },
    {
      "rank": 55,
      "arxiv_id": "2508.01741v2",
      "title": "Simulated Ensemble Attack: Transferring Jailbreaks Across Fine-tuned Vision-Language Models",
      "authors": [
        "Ruofan Wang",
        "Xin Wang",
        "Yang Yao",
        "Xuan Tong",
        "Xingjun Ma"
      ],
      "published_date": "2025-08-03",
      "year": 2025,
      "relevance_score": 99,
      "arxiv_url": "https://arxiv.org/abs/2508.01741v2",
      "pdf_url": "https://arxiv.org/pdf/2508.01741v2"
    },
    {
      "rank": 56,
      "arxiv_id": "2510.11837v1",
      "title": "Countermind: A Multi-Layered Security Architecture for Large Language Models",
      "authors": [
        "Dominik Schwarz"
      ],
      "published_date": "2025-10-13",
      "year": 2025,
      "relevance_score": 98,
      "arxiv_url": "https://arxiv.org/abs/2510.11837v1",
      "pdf_url": "https://arxiv.org/pdf/2510.11837v1"
    },
    {
      "rank": 57,
      "arxiv_id": "2509.20324v1",
      "title": "RAG Security and Privacy: Formalizing the Threat Model and Attack Surface",
      "authors": [
        "Atousa Arzanipour",
        "Rouzbeh Behnia",
        "Reza Ebrahimi",
        "Kaushik Dutta"
      ],
      "published_date": "2025-09-24",
      "year": 2025,
      "relevance_score": 97,
      "arxiv_url": "https://arxiv.org/abs/2509.20324v1",
      "pdf_url": "https://arxiv.org/pdf/2509.20324v1"
    },
    {
      "rank": 58,
      "arxiv_id": "2512.06556v1",
      "title": "Securing the Model Context Protocol: Defending LLMs Against Tool Poisoning and Adversarial Attacks",
      "authors": [
        "Saeid Jamshidi",
        "Kawser Wazed Nafi",
        "Arghavan Moradi Dakhel",
        "Negar Shahabi",
        "Foutse Khomh"
      ],
      "published_date": "2025-12-06",
      "year": 2025,
      "relevance_score": 95,
      "arxiv_url": "https://arxiv.org/abs/2512.06556v1",
      "pdf_url": "https://arxiv.org/pdf/2512.06556v1"
    },
    {
      "rank": 59,
      "arxiv_id": "2402.14857v2",
      "title": "Is the System Message Really Important to Jailbreaks in Large Language Models?",
      "authors": [
        "Xiaotian Zou",
        "Yongkang Chen",
        "Ke Li"
      ],
      "published_date": "2024-02-20",
      "year": 2024,
      "relevance_score": 95,
      "arxiv_url": "https://arxiv.org/abs/2402.14857v2",
      "pdf_url": "https://arxiv.org/pdf/2402.14857v2"
    },
    {
      "rank": 60,
      "arxiv_id": "2512.20405v1",
      "title": "ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected",
      "authors": [
        "Kanchon Gharami",
        "Sanjiv Kumar Sarkar",
        "Yongxin Liu",
        "Shafika Showkat Moni"
      ],
      "published_date": "2025-12-23",
      "year": 2025,
      "relevance_score": 94,
      "arxiv_url": "https://arxiv.org/abs/2512.20405v1",
      "pdf_url": "https://arxiv.org/pdf/2512.20405v1"
    },
    {
      "rank": 61,
      "arxiv_id": "2508.02312v1",
      "title": "A Survey on Data Security in Large Language Models",
      "authors": [
        "Kang Chen",
        "Xiuze Zhou",
        "Yuanguo Lin",
        "Jinhe Su",
        "Yuanhui Yu"
      ],
      "published_date": "2025-08-04",
      "year": 2025,
      "relevance_score": 93,
      "arxiv_url": "https://arxiv.org/abs/2508.02312v1",
      "pdf_url": "https://arxiv.org/pdf/2508.02312v1"
    },
    {
      "rank": 62,
      "arxiv_id": "2506.14913v1",
      "title": "Winter Soldier: Backdooring Language Models at Pre-Training with Indirect Data Poisoning",
      "authors": [
        "Wassim Bouaziz",
        "Mathurin Videau",
        "Nicolas Usunier",
        "El-Mahdi El-Mhamdi"
      ],
      "published_date": "2025-06-17",
      "year": 2025,
      "relevance_score": 93,
      "arxiv_url": "https://arxiv.org/abs/2506.14913v1",
      "pdf_url": "https://arxiv.org/pdf/2506.14913v1"
    },
    {
      "rank": 63,
      "arxiv_id": "2511.06212v1",
      "title": "RAG-targeted Adversarial Attack on LLM-based Threat Detection and Mitigation Framework",
      "authors": [
        "Seif Ikbarieh",
        "Kshitiz Aryal",
        "Maanak Gupta"
      ],
      "published_date": "2025-11-09",
      "year": 2025,
      "relevance_score": 91,
      "arxiv_url": "https://arxiv.org/abs/2511.06212v1",
      "pdf_url": "https://arxiv.org/pdf/2511.06212v1"
    },
    {
      "rank": 64,
      "arxiv_id": "2504.09593v2",
      "title": "ControlNET: A Firewall for RAG-based LLM System",
      "authors": [
        "Hongwei Yao",
        "Haoran Shi",
        "Yidou Chen",
        "Yixin Jiang",
        "Cong Wang"
      ],
      "published_date": "2025-04-13",
      "year": 2025,
      "relevance_score": 91,
      "arxiv_url": "https://arxiv.org/abs/2504.09593v2",
      "pdf_url": "https://arxiv.org/pdf/2504.09593v2"
    },
    {
      "rank": 65,
      "arxiv_id": "2406.11007v1",
      "title": "Threat Modelling and Risk Analysis for Large Language Model (LLM)-Powered Applications",
      "authors": [
        "Stephen Burabari Tete"
      ],
      "published_date": "2024-06-16",
      "year": 2024,
      "relevance_score": 91,
      "arxiv_url": "https://arxiv.org/abs/2406.11007v1",
      "pdf_url": "https://arxiv.org/pdf/2406.11007v1"
    },
    {
      "rank": 66,
      "arxiv_id": "2406.00240v1",
      "title": "Exploring Vulnerabilities and Protections in Large Language Models: A Survey",
      "authors": [
        "Frank Weizhen Liu",
        "Chenhui Hu"
      ],
      "published_date": "2024-06-01",
      "year": 2024,
      "relevance_score": 91,
      "arxiv_url": "https://arxiv.org/abs/2406.00240v1",
      "pdf_url": "https://arxiv.org/pdf/2406.00240v1"
    },
    {
      "rank": 67,
      "arxiv_id": "2507.19195v2",
      "title": "Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?",
      "authors": [
        "Chaymaa Abbas",
        "Mariette Awad",
        "Razane Tajeddine"
      ],
      "published_date": "2025-07-25",
      "year": 2025,
      "relevance_score": 90,
      "arxiv_url": "https://arxiv.org/abs/2507.19195v2",
      "pdf_url": "https://arxiv.org/pdf/2507.19195v2"
    },
    {
      "rank": 68,
      "arxiv_id": "2511.21718v1",
      "title": "When Harmless Words Harm: A New Threat to LLM Safety via Conceptual Triggers",
      "authors": [
        "Zhaoxin Zhang",
        "Borui Chen",
        "Yiming Hu",
        "Youyang Qu",
        "Tianqing Zhu"
      ],
      "published_date": "2025-11-19",
      "year": 2025,
      "relevance_score": 88,
      "arxiv_url": "https://arxiv.org/abs/2511.21718v1",
      "pdf_url": "https://arxiv.org/pdf/2511.21718v1"
    },
    {
      "rank": 69,
      "arxiv_id": "2407.07403v2",
      "title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
      "authors": [
        "Daizong Liu",
        "Mingyu Yang",
        "Xiaoye Qu",
        "Pan Zhou",
        "Yu Cheng"
      ],
      "published_date": "2024-07-10",
      "year": 2024,
      "relevance_score": 88,
      "arxiv_url": "https://arxiv.org/abs/2407.07403v2",
      "pdf_url": "https://arxiv.org/pdf/2407.07403v2"
    },
    {
      "rank": 70,
      "arxiv_id": "2405.12750v2",
      "title": "Generative AI in Cybersecurity: A Comprehensive Review of LLM Applications and Vulnerabilities",
      "authors": [
        "Mohamed Amine Ferrag",
        "Fatima Alwahedi",
        "Ammar Battah",
        "Bilel Cherif",
        "Abdechakour Mechri"
      ],
      "published_date": "2024-05-21",
      "year": 2024,
      "relevance_score": 87,
      "arxiv_url": "https://arxiv.org/abs/2405.12750v2",
      "pdf_url": "https://arxiv.org/pdf/2405.12750v2"
    },
    {
      "rank": 71,
      "arxiv_id": "2511.03247v1",
      "title": "Death by a Thousand Prompts: Open Model Vulnerability Analysis",
      "authors": [
        "Amy Chang",
        "Nicholas Conley",
        "Harish Santhanalakshmi Ganesan",
        "Adam Swanda"
      ],
      "published_date": "2025-11-05",
      "year": 2025,
      "relevance_score": 85,
      "arxiv_url": "https://arxiv.org/abs/2511.03247v1",
      "pdf_url": "https://arxiv.org/pdf/2511.03247v1"
    },
    {
      "rank": 72,
      "arxiv_id": "2509.26584v1",
      "title": "Fairness Testing in Retrieval-Augmented Generation: How Small Perturbations Reveal Bias in Small Language Models",
      "authors": [
        "Matheus Vinicius da Silva de Oliveira",
        "Jonathan de Andrade Silva",
        "Awdren de Lima Fontao"
      ],
      "published_date": "2025-09-30",
      "year": 2025,
      "relevance_score": 85,
      "arxiv_url": "https://arxiv.org/abs/2509.26584v1",
      "pdf_url": "https://arxiv.org/pdf/2509.26584v1"
    },
    {
      "rank": 73,
      "arxiv_id": "2511.05919v2",
      "title": "Injecting Falsehoods: Adversarial Man-in-the-Middle Attacks Undermining Factual Recall in LLMs",
      "authors": [
        "Alina Fastowski",
        "Bardh Prenkaj",
        "Yuxiao Li",
        "Gjergji Kasneci"
      ],
      "published_date": "2025-11-08",
      "year": 2025,
      "relevance_score": 84,
      "arxiv_url": "https://arxiv.org/abs/2511.05919v2",
      "pdf_url": "https://arxiv.org/pdf/2511.05919v2"
    },
    {
      "rank": 74,
      "arxiv_id": "2511.19727v1",
      "title": "Prompt Fencing: A Cryptographic Approach to Establishing Security Boundaries in Large Language Model Prompts",
      "authors": [
        "Steven Peh"
      ],
      "published_date": "2025-11-24",
      "year": 2025,
      "relevance_score": 83,
      "arxiv_url": "https://arxiv.org/abs/2511.19727v1",
      "pdf_url": "https://arxiv.org/pdf/2511.19727v1"
    },
    {
      "rank": 75,
      "arxiv_id": "2509.08729v3",
      "title": "X-Teaming Evolutionary M2S: Automated Discovery of Multi-turn to Single-turn Jailbreak Templates",
      "authors": [
        "Hyunjun Kim",
        "Junwoo Ha",
        "Sangyoon Yu",
        "Haon Park"
      ],
      "published_date": "2025-09-10",
      "year": 2025,
      "relevance_score": 83,
      "arxiv_url": "https://arxiv.org/abs/2509.08729v3",
      "pdf_url": "https://arxiv.org/pdf/2509.08729v3"
    },
    {
      "rank": 76,
      "arxiv_id": "2511.05867v2",
      "title": "MCP-RiskCue: Can LLM Infer Risk Information From MCP Server System Logs?",
      "authors": [
        "Jiayi Fu",
        "Qiyao Sun"
      ],
      "published_date": "2025-11-08",
      "year": 2025,
      "relevance_score": 82,
      "arxiv_url": "https://arxiv.org/abs/2511.05867v2",
      "pdf_url": "https://arxiv.org/pdf/2511.05867v2"
    },
    {
      "rank": 77,
      "arxiv_id": "2511.04694v3",
      "title": "Reasoning Up the Instruction Ladder for Controllable Language Models",
      "authors": [
        "Zishuo Zheng",
        "Vidhisha Balachandran",
        "Chan Young Park",
        "Faeze Brahman",
        "Sachin Kumar"
      ],
      "published_date": "2025-10-30",
      "year": 2025,
      "relevance_score": 80,
      "arxiv_url": "https://arxiv.org/abs/2511.04694v3",
      "pdf_url": "https://arxiv.org/pdf/2511.04694v3"
    },
    {
      "rank": 78,
      "arxiv_id": "2512.15782v1",
      "title": "Auto-Tuning Safety Guardrails for Black-Box Large Language Models",
      "authors": [
        "Perry Abdulkadir"
      ],
      "published_date": "2025-12-14",
      "year": 2025,
      "relevance_score": 80,
      "arxiv_url": "https://arxiv.org/abs/2512.15782v1",
      "pdf_url": "https://arxiv.org/pdf/2512.15782v1"
    },
    {
      "rank": 79,
      "arxiv_id": "2504.02193v3",
      "title": "More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment",
      "authors": [
        "Yifan Wang",
        "Runjin Chen",
        "Bolian Li",
        "David Cho",
        "Yihe Deng"
      ],
      "published_date": "2025-04-03",
      "year": 2025,
      "relevance_score": 80,
      "arxiv_url": "https://arxiv.org/abs/2504.02193v3",
      "pdf_url": "https://arxiv.org/pdf/2504.02193v3"
    },
    {
      "rank": 80,
      "arxiv_id": "2502.00306v2",
      "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation",
      "authors": [
        "Ali Naseh",
        "Yuefeng Peng",
        "Anshuman Suri",
        "Harsh Chaudhari",
        "Alina Oprea"
      ],
      "published_date": "2025-02-01",
      "year": 2025,
      "relevance_score": 80,
      "arxiv_url": "https://arxiv.org/abs/2502.00306v2",
      "pdf_url": "https://arxiv.org/pdf/2502.00306v2"
    },
    {
      "rank": 81,
      "arxiv_id": "2506.00281v1",
      "title": "Adversarial Threat Vectors and Risk Mitigation for Retrieval-Augmented Generation Systems",
      "authors": [
        "Chris M. Ward",
        "Josh Harguess"
      ],
      "published_date": "2025-05-30",
      "year": 2025,
      "relevance_score": 80,
      "arxiv_url": "https://arxiv.org/abs/2506.00281v1",
      "pdf_url": "https://arxiv.org/pdf/2506.00281v1"
    },
    {
      "rank": 82,
      "arxiv_id": "2412.06788v1",
      "title": "Poison Attacks and Adversarial Prompts Against an Informed University Virtual Assistant",
      "authors": [
        "Ivan A. Fernandez",
        "Subash Neupane",
        "Sudip Mittal",
        "Shahram Rahimi"
      ],
      "published_date": "2024-11-03",
      "year": 2024,
      "relevance_score": 80,
      "arxiv_url": "https://arxiv.org/abs/2412.06788v1",
      "pdf_url": "https://arxiv.org/pdf/2412.06788v1"
    },
    {
      "rank": 83,
      "arxiv_id": "2404.18567v2",
      "title": "Double Backdoored: Converting Code Large Language Model Backdoors to Traditional Malware via Adversarial Instruction Tuning Attacks",
      "authors": [
        "Md Imran Hossen",
        "Sai Venkatesh Chilukoti",
        "Liqun Shan",
        "Sheng Chen",
        "Yinzhi Cao"
      ],
      "published_date": "2024-04-29",
      "year": 2024,
      "relevance_score": 78,
      "arxiv_url": "https://arxiv.org/abs/2404.18567v2",
      "pdf_url": "https://arxiv.org/pdf/2404.18567v2"
    },
    {
      "rank": 84,
      "arxiv_id": "2508.20333v1",
      "title": "Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs",
      "authors": [
        "Md Abdullah Al Mamun",
        "Ihsen Alouani",
        "Nael Abu-Ghazaleh"
      ],
      "published_date": "2025-08-28",
      "year": 2025,
      "relevance_score": 76,
      "arxiv_url": "https://arxiv.org/abs/2508.20333v1",
      "pdf_url": "https://arxiv.org/pdf/2508.20333v1"
    },
    {
      "rank": 85,
      "arxiv_id": "2512.10104v2",
      "title": "Phishing Email Detection Using Large Language Models",
      "authors": [
        "Najmul Hasan",
        "Prashanth BusiReddyGari",
        "Haitao Zhao",
        "Yihao Ren",
        "Jinsheng Xu"
      ],
      "published_date": "2025-12-10",
      "year": 2025,
      "relevance_score": 75,
      "arxiv_url": "https://arxiv.org/abs/2512.10104v2",
      "pdf_url": "https://arxiv.org/pdf/2512.10104v2"
    },
    {
      "rank": 86,
      "arxiv_id": "2511.04508v1",
      "title": "Large Language Models for Cyber Security",
      "authors": [
        "Raunak Somani",
        "Aswani Kumar Cherukuri"
      ],
      "published_date": "2025-11-06",
      "year": 2025,
      "relevance_score": 75,
      "arxiv_url": "https://arxiv.org/abs/2511.04508v1",
      "pdf_url": "https://arxiv.org/pdf/2511.04508v1"
    },
    {
      "rank": 87,
      "arxiv_id": "2510.04503v2",
      "title": "P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs",
      "authors": [
        "Shuai Zhao",
        "Xinyi Wu",
        "Shiqian Zhao",
        "Xiaobao Wu",
        "Zhongliang Guo"
      ],
      "published_date": "2025-10-06",
      "year": 2025,
      "relevance_score": 73,
      "arxiv_url": "https://arxiv.org/abs/2510.04503v2",
      "pdf_url": "https://arxiv.org/pdf/2510.04503v2"
    },
    {
      "rank": 88,
      "arxiv_id": "2511.12423v1",
      "title": "GRAPHTEXTACK: A Realistic Black-Box Node Injection Attack on LLM-Enhanced GNNs",
      "authors": [
        "Jiaji Ma",
        "Puja Trivedi",
        "Danai Koutra"
      ],
      "published_date": "2025-11-16",
      "year": 2025,
      "relevance_score": 70,
      "arxiv_url": "https://arxiv.org/abs/2511.12423v1",
      "pdf_url": "https://arxiv.org/pdf/2511.12423v1"
    },
    {
      "rank": 89,
      "arxiv_id": "2509.05739v1",
      "title": "Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated",
      "authors": [
        "Hanna Foerster",
        "Ilia Shumailov",
        "Yiren Zhao",
        "Harsh Chaudhari",
        "Jamie Hayes"
      ],
      "published_date": "2025-09-06",
      "year": 2025,
      "relevance_score": 70,
      "arxiv_url": "https://arxiv.org/abs/2509.05739v1",
      "pdf_url": "https://arxiv.org/pdf/2509.05739v1"
    },
    {
      "rank": 90,
      "arxiv_id": "2508.19277v1",
      "title": "POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization",
      "authors": [
        "Xinyu Li",
        "Tianjin Huang",
        "Ronghui Mu",
        "Xiaowei Huang",
        "Gaojie Jin"
      ],
      "published_date": "2025-08-23",
      "year": 2025,
      "relevance_score": 70,
      "arxiv_url": "https://arxiv.org/abs/2508.19277v1",
      "pdf_url": "https://arxiv.org/pdf/2508.19277v1"
    },
    {
      "rank": 91,
      "arxiv_id": "2407.20181v2",
      "title": "Blockchain for Large Language Model Security and Safety: A Holistic Survey",
      "authors": [
        "Caleb Geren",
        "Amanda Board",
        "Gaby G. Dagher",
        "Tim Andersen",
        "Jun Zhuang"
      ],
      "published_date": "2024-07-26",
      "year": 2024,
      "relevance_score": 70,
      "arxiv_url": "https://arxiv.org/abs/2407.20181v2",
      "pdf_url": "https://arxiv.org/pdf/2407.20181v2"
    },
    {
      "rank": 92,
      "arxiv_id": "2410.10526v1",
      "title": "Generalized Adversarial Code-Suggestions: Exploiting Contexts of LLM-based Code-Completion",
      "authors": [
        "Karl Rubel",
        "Maximilian Noppel",
        "Christian Wressnegger"
      ],
      "published_date": "2024-10-14",
      "year": 2024,
      "relevance_score": 66,
      "arxiv_url": "https://arxiv.org/abs/2410.10526v1",
      "pdf_url": "https://arxiv.org/pdf/2410.10526v1"
    },
    {
      "rank": 93,
      "arxiv_id": "2505.14200v1",
      "title": "Capturing the Effects of Quantization on Trojans in Code LLMs",
      "authors": [
        "Aftab Hussain",
        "Sadegh AlMahdi Kazemi Zarkouei",
        "Md Rafiqul Islam Rabin",
        "Mohammad Amin Alipour",
        "Sen Lin"
      ],
      "published_date": "2025-05-20",
      "year": 2025,
      "relevance_score": 65,
      "arxiv_url": "https://arxiv.org/abs/2505.14200v1",
      "pdf_url": "https://arxiv.org/pdf/2505.14200v1"
    },
    {
      "rank": 94,
      "arxiv_id": "2412.15004v3",
      "title": "From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security",
      "authors": [
        "Enna Basic",
        "Alberto Giaretta"
      ],
      "published_date": "2024-12-19",
      "year": 2024,
      "relevance_score": 65,
      "arxiv_url": "https://arxiv.org/abs/2412.15004v3",
      "pdf_url": "https://arxiv.org/pdf/2412.15004v3"
    }
  ]
}