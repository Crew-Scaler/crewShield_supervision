{
  "total_archived_papers": 309,
  "reason": "Lower relevance scores compared to top 10 papers",
  "papers": [
    {
      "arxiv_id": "2404.16887v1",
      "title": "Anomaly Detection for Incident Response at Scale",
      "authors": [
        "Hanzhang Wang",
        "Gowtham Kumar Tangirala",
        "Gilkara Pranav Naidu",
        "Charles Mayville",
        "Arighna Roy",
        "Joanne Sun",
        "Ramesh Babu Mandava"
      ],
      "abstract": "We present a machine learning-based anomaly detection product, AI Detect and Respond (AIDR), that monitors Walmart's business and system health in real-time. During the validation over 3 months, the product served predictions from over 3000 models to more than 25 application, platform, and operation teams, covering 63\\% of major incidents and reducing the mean-time-to-detect (MTTD) by more than 7 minutes. Unlike previous anomaly detection methods, our solution leverages statistical, ML and deep learning models while continuing to incorporate rule-based static thresholds to incorporate domain-specific knowledge. Both univariate and multivariate ML models are deployed and maintained through distributed services for scalability and high availability. AIDR has a feedback loop that assesses model quality with a combination of drift detection algorithms and customer feedback. It also offers self-onboarding capabilities and customizability. AIDR has achieved success with various internal teams with lower time to detection and fewer false positives than previous methods. As we move forward, we aim to expand incident coverage and prevention, reduce noise, and integrate further with root cause recommendation (RCR) to enable an end-to-end AIDR experience.",
      "published": "2024-04-24",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2404.16887v1",
      "relevance_score": 59
    },
    {
      "arxiv_id": "2512.08277v1",
      "title": "FedLAD: A Modular and Adaptive Testbed for Federated Log Anomaly Detection",
      "authors": [
        "Yihan Liao",
        "Jacky Keung",
        "Zhenyu Mao",
        "Jingyu Zhang",
        "Jialong Li"
      ],
      "abstract": "Log-based anomaly detection (LAD) is critical for ensuring the reliability of large-scale distributed systems. However, most existing LAD approaches assume centralized training, which is often impractical due to privacy constraints and the decentralized nature of system logs. While federated learning (FL) offers a promising alternative, there is a lack of dedicated testbeds tailored to the needs of LAD in federated settings. To address this, we present FedLAD, a unified platform for training and evaluating LAD models under FL constraints. FedLAD supports plug-and-play integration of diverse LAD models, benchmark datasets, and aggregation strategies, while offering runtime support for validation logging (self-monitoring), parameter tuning (self-configuration), and adaptive strategy control (self-adaptation). By enabling reproducible and scalable experimentation, FedLAD bridges the gap between FL frameworks and LAD requirements, providing a solid foundation for future research. Project code is publicly available at: https://github.com/AA-cityu/FedLAD.",
      "published": "2025-12-09",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.08277v1",
      "relevance_score": 58
    },
    {
      "arxiv_id": "2509.12982v1",
      "title": "Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins",
      "authors": [
        "Erblin Isaku",
        "Hassan Sartaj",
        "Shaukat Ali",
        "Beatriz Sanguino",
        "Tongtong Wang",
        "Guoyuan Li",
        "Houxiang Zhang",
        "Thomas Peyrucain"
      ],
      "abstract": "Self-adaptive robots (SARs) in complex, uncertain environments must proactively detect and address abnormal behaviors, including out-of-distribution (OOD) cases. To this end, digital twins offer a valuable solution for OOD detection. Thus, we present a digital twin-based approach for OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to forecast SAR states and employs reconstruction error and Monte Carlo dropout for uncertainty quantification. By combining reconstruction error with predictive variance, the digital twin effectively detects OOD behaviors, even in previously unseen conditions. The digital twin also includes an explainability layer that links potential OOD to specific SAR states, offering insights for self-adaptation. We evaluated ODiSAR by creating digital twins of two industrial robots: one navigating an office environment, and another performing maritime ship navigation. In both cases, ODiSAR forecasts SAR behaviors (i.e., robot trajectories and vessel motion) and proactively detects OOD events. Our results showed that ODiSAR achieved high detection performance -- up to 98\\% AUROC, 96\\% TNR@TPR95, and 95\\% F1-score -- while providing interpretable insights to support self-adaptation.",
      "published": "2025-09-16",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.12982v1",
      "relevance_score": 58
    },
    {
      "arxiv_id": "2511.19644v1",
      "title": "IRSDA: An Agent-Orchestrated Framework for Enterprise Intrusion Response",
      "authors": [
        "Damodar Panigrahi",
        "Raj Patel",
        "Shaswata Mitra",
        "Sudip Mittal",
        "Shahram Rahimi"
      ],
      "abstract": "Modern enterprise systems face escalating cyber threats that are increasingly dynamic, distributed, and multi-stage in nature. Traditional intrusion detection and response systems often rely on static rules and manual workflows, which limit their ability to respond with the speed and precision required in high-stakes environments. To address these challenges, we present the Intrusion Response System Digital Assistant (IRSDA), an agent-based framework designed to deliver autonomous and policy-compliant cyber defense. IRSDA combines Self-Adaptive Autonomic Computing Systems (SA-ACS) with the Knowledge guided Monitor, Analyze, Plan, and Execute (MAPE-K) loop to support real-time, partition-aware decision-making across enterprise infrastructure.   IRSDA incorporates a knowledge-driven architecture that integrates contextual information with AI-based reasoning to support system-guided intrusion response. The framework leverages retrieval mechanisms and structured representations to inform decision-making while maintaining alignment with operational policies. We assess the system using a representative real-world microservices application, demonstrating its ability to automate containment, enforce compliance, and provide traceable outputs for security analyst interpretation. This work outlines a modular and agent-driven approach to cyber defense that emphasizes explainability, system-state awareness, and operational control in intrusion response.",
      "published": "2025-11-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.19644v1",
      "relevance_score": 58
    },
    {
      "arxiv_id": "2512.06396v1",
      "title": "AgenticCyber: A GenAI-Powered Multi-Agent System for Multimodal Threat Detection and Adaptive Response in Cybersecurity",
      "authors": [
        "Shovan Roy"
      ],
      "abstract": "The increasing complexity of cyber threats in distributed environments demands advanced frameworks for real-time detection and response across multimodal data streams. This paper introduces AgenticCyber, a generative AI powered multi-agent system that orchestrates specialized agents to monitor cloud logs, surveillance videos, and environmental audio concurrently. The solution achieves 96.2% F1-score in threat detection, reduces response latency to 420 ms, and enables adaptive security posture management using multimodal language models like Google's Gemini coupled with LangChain for agent orchestration. Benchmark datasets, such as AWS CloudTrail logs, UCF-Crime video frames, and UrbanSound8K audio clips, show greater performance over standard intrusion detection systems, reducing mean time to respond (MTTR) by 65% and improving situational awareness. This work introduces a scalable, modular proactive cybersecurity architecture for enterprise networks and IoT ecosystems that overcomes siloed security technologies with cross-modal reasoning and automated remediation.",
      "published": "2025-12-06",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.06396v1",
      "relevance_score": 54
    },
    {
      "arxiv_id": "2507.08164v1",
      "title": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence",
      "authors": [
        "Yun Tang",
        "Mengbang Zou",
        "Zeinab Nezami",
        "Syed Ali Raza Zaidi",
        "Weisi Guo"
      ],
      "abstract": "The emergence of large language models (LLMs) and agentic systems is enabling autonomous 6G networks with advanced intelligence, including self-configuration, self-optimization, and self-healing. However, the current implementation of individual intelligence tasks necessitates isolated knowledge retrieval pipelines, resulting in redundant data flows and inconsistent interpretations. Inspired by the service model unification effort in Open-RAN (to support interoperability and vendor diversity), we propose KP-A: a unified Network Knowledge Plane specifically designed for Agentic network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, KP-A streamlines development and reduces maintenance complexity for intelligence engineers. By offering an intuitive and consistent knowledge interface, KP-A also enhances interoperability for the network intelligence agents. We demonstrate KP-A in two representative intelligence tasks: live network knowledge Q&A and edge AI service orchestration. All implementation artifacts have been open-sourced to support reproducibility and future standardization efforts.",
      "published": "2025-07-10",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.08164v1",
      "relevance_score": 51
    },
    {
      "arxiv_id": "2505.01365v1",
      "title": "Hacktive Matter: data-driven discovery through hackathon-based cross-disciplinary coding",
      "authors": [
        "Megan T. Valentine",
        "Rae M. Robertson-Anderson"
      ],
      "abstract": "The past decade has seen unprecedented growth in active matter and autonomous biomaterials research, yielding diverse classes of materials that promise revolutionary applications such as self-healing infrastructure and self-sensing tissue implants. However, inconsistencies in metrics, definitions, and analysis algorithms across research groups, as well as the high-dimension data streams, has hindered identification of performance intersections. Progress in this arena demands multi-disciplinary team approaches to discovery with scaffolded training and cross-pollination of ideas, and requires new learning and collaboration methods. To address this challenge, we have developed a hackathon platform to train future scientists and engineers in big data, interdisciplinary collaboration, and community coding; and to design and beta-test high-throughput (HTP) biomaterials analysis software and workflows. We enforce a flat hierarchy, pairing participants ranging from high school students to faculty with varied experiences and skills to collectively contribute to data acquisition and processing, ideation, coding, testing and dissemination. With clearly-defined goals and deliverables, participants achieve success through a series of tutorials, small group coding sessions, facilitated breakouts, and large group report-outs and discussions. These modules facilitate efficient iterative algorithm development and optimization; strengthen community and collaboration skills; and establish teams, benchmarks, and community standards for continued productive work. Our hackathons provide a powerful model for the soft matter community to educate and train students and collaborators in cutting edge data-driven analysis, which is critical for future innovation in complex materials research.",
      "published": "2025-05-02",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.01365v1",
      "relevance_score": 51
    },
    {
      "arxiv_id": "2504.05071v1",
      "title": "AI-Driven Tactical Communications and Networking for Defense: A Survey and Emerging Trends",
      "authors": [
        "Victor Monzon Baeza",
        "Ra\u00fal Parada",
        "Laura Concha Salor",
        "Carlos Monzo"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) in military communications and networking is reshaping modern defense strategies, enhancing secure data exchange, real-time situational awareness, and autonomous decision-making. This survey explores how AI-driven technologies improve tactical communication networks, radar-based data transmission, UAV-assisted relay systems, and electronic warfare resilience. The study highlights AI applications in adaptive signal processing, multi-agent coordination for network optimization, radar-assisted target tracking, and AI-driven electronic countermeasures. Our work introduces a novel three-criteria evaluation methodology. It systematically assesses AI applications based on general system objectives, communications constraints in the military domain, and critical tactical environmental factors. We analyze key AI techniques for different types of learning applied to multi-domain network interoperability and distributed data information fusion in military operations. We also address challenges such as adversarial AI threats, the real-time adaptability of autonomous communication networks, and the limitations of current AI models under battlefield conditions. Finally, we discuss emerging trends in self-healing networks, AI-augmented decision support systems, and intelligent spectrum allocation. We provide a structured roadmap for future AI-driven defense communications and networking research.",
      "published": "2025-04-07",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.05071v1",
      "relevance_score": 51
    },
    {
      "arxiv_id": "2512.21133v1",
      "title": "SparScene: Efficient Traffic Scene Representation via Sparse Graph Learning for Large-Scale Trajectory Generation",
      "authors": [
        "Xiaoyu Mo",
        "Jintian Ge",
        "Zifan Wang",
        "Chen Lv",
        "Karl Henrik Johansson"
      ],
      "abstract": "Multi-agent trajectory generation is a core problem for autonomous driving and intelligent transportation systems. However, efficiently modeling the dynamic interactions between numerous road users and infrastructures in complex scenes remains an open problem. Existing methods typically employ distance-based or fully connected dense graph structures to capture interaction information, which not only introduces a large number of redundant edges but also requires complex and heavily parameterized networks for encoding, thereby resulting in low training and inference efficiency, limiting scalability to large and complex traffic scenes. To overcome the limitations of existing methods, we propose SparScene, a sparse graph learning framework designed for efficient and scalable traffic scene representation. Instead of relying on distance thresholds, SparScene leverages the lane graph topology to construct structure-aware sparse connections between agents and lanes, enabling efficient yet informative scene graph representation. SparScene adopts a lightweight graph encoder that efficiently aggregates agent-map and agent-agent interactions, yielding compact scene representations with substantially improved efficiency and scalability. On the motion prediction benchmark of the Waymo Open Motion Dataset (WOMD), SparScene achieves competitive performance with remarkable efficiency. It generates trajectories for more than 200 agents in a scene within 5 ms and scales to more than 5,000 agents and 17,000 lanes with merely 54 ms of inference time with a GPU memory of 2.9 GB, highlighting its superior scalability for large-scale traffic scenes.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21133v1",
      "relevance_score": 51
    },
    {
      "arxiv_id": "2512.20275v1",
      "title": "Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks",
      "authors": [
        "Divya Vijay",
        "Vignesh Ethiraj"
      ],
      "abstract": "As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20275v1",
      "relevance_score": 51
    },
    {
      "arxiv_id": "2512.18733v1",
      "title": "Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection",
      "authors": [
        "Junjun Pan",
        "Yixin Liu",
        "Rui Miao",
        "Kaize Ding",
        "Yu Zheng",
        "Quoc Viet Hung Nguyen",
        "Alan Wee-Chung Liew",
        "Shirui Pan"
      ],
      "abstract": "Large language model (LLM)-based multi-agent systems (MAS) have shown strong capabilities in solving complex tasks. As MAS become increasingly autonomous in various safety-critical tasks, detecting malicious agents has become a critical security concern. Although existing graph anomaly detection (GAD)-based defenses can identify anomalous agents, they mainly rely on coarse sentence-level information and overlook fine-grained lexical cues, leading to suboptimal performance. Moreover, the lack of interpretability in these methods limits their reliability and real-world applicability. To address these limitations, we propose XG-Guard, an explainable and fine-grained safeguarding framework for detecting malicious agents in MAS. To incorporate both coarse and fine-grained textual information for anomalous agent identification, we utilize a bi-level agent encoder to jointly model the sentence- and token-level representations of each agent. A theme-based anomaly detector further captures the evolving discussion focus in MAS dialogues, while a bi-level score fusion mechanism quantifies token-level contributions for explanation. Extensive experiments across diverse MAS topologies and attack scenarios demonstrate robust detection performance and strong interpretability of XG-Guard.",
      "published": "2025-12-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18733v1",
      "relevance_score": 51
    },
    {
      "arxiv_id": "2512.17048v1",
      "title": "Another Fit Bites the Dust: Conformal Prediction as a Calibration Standard for Machine Learning in High-Energy Physics",
      "authors": [
        "Jack Y. Araz",
        "Michael Spannowsky"
      ],
      "abstract": "Machine-learning techniques are essential in modern collider research, yet their probabilistic outputs often lack calibrated uncertainty estimates and finite-sample guarantees, limiting their direct use in statistical inference and decision-making. Conformal prediction (CP) provides a simple, distribution-free framework for calibrating arbitrary predictive models without retraining, yielding rigorous uncertainty quantification with finite-sample coverage guarantees under minimal exchangeability assumptions, without reliance on asymptotics, limit theorems, or Gaussian approximations. In this work, we investigate CP as a unifying calibration layer for machine-learning applications in high-energy physics. Using publicly available collider datasets and a diverse set of models, we show that a single conformal formalism can be applied across regression, binary and multi-class classification, anomaly detection, and generative modelling, converting raw model outputs into statistically valid prediction sets, typicality regions, and p-values with controlled false-positive rates. While conformal prediction does not improve raw model performance, it enforces honest uncertainty quantification and transparent error control. We argue that conformal calibration should be adopted as a standard component of machine-learning pipelines in collider physics, enabling reliable interpretation, robust comparisons, and principled statistical decisions in experimental and phenomenological analyses.",
      "published": "2025-12-18",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17048v1",
      "relevance_score": 51
    },
    {
      "arxiv_id": "2407.01896v1",
      "title": "LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis",
      "authors": [
        "Tianyu Cui",
        "Shiyu Ma",
        "Ziang Chen",
        "Tong Xiao",
        "Shimin Tao",
        "Yilun Liu",
        "Shenglin Zhang",
        "Duoming Lin",
        "Changchang Liu",
        "Yuzhe Cai",
        "Weibin Meng",
        "Yongqian Sun",
        "Dan Pei"
      ],
      "abstract": "Log analysis is crucial for ensuring the orderly and stable operation of information systems, particularly in the field of Artificial Intelligence for IT Operations (AIOps). Large Language Models (LLMs) have demonstrated significant potential in natural language processing tasks. In the AIOps domain, they excel in tasks such as anomaly detection, root cause analysis of faults, operations and maintenance script generation, and alert information summarization. However, the performance of current LLMs in log analysis tasks remains inadequately validated. To address this gap, we introduce LogEval, a comprehensive benchmark suite designed to evaluate the capabilities of LLMs in various log analysis tasks for the first time. This benchmark covers tasks such as log parsing, log anomaly detection, log fault diagnosis, and log summarization. LogEval evaluates each task using 4,000 publicly available log data entries and employs 15 different prompts for each task to ensure a thorough and fair assessment. By rigorously evaluating leading LLMs, we demonstrate the impact of various LLM technologies on log analysis performance, focusing on aspects such as self-consistency and few-shot contextual learning. We also discuss findings related to model quantification, Chinese-English question-answering evaluation, and prompt engineering. These findings provide insights into the strengths and weaknesses of LLMs in multilingual environments and the effectiveness of different prompt strategies. Various evaluation methods are employed for different tasks to accurately measure the performance of LLMs in log analysis, ensuring a comprehensive assessment. The insights gained from LogEvals evaluation reveal the strengths and limitations of LLMs in log analysis tasks, providing valuable guidance for researchers and practitioners.",
      "published": "2024-07-02",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2407.01896v1",
      "relevance_score": 49
    },
    {
      "arxiv_id": "2512.07094v2",
      "title": "VIGIL: A Reflective Runtime for Self-Healing Agents",
      "authors": [
        "Christopher Cruz"
      ],
      "abstract": "Agentic LLM frameworks promise autonomous behavior via task decomposition, tool use, and iterative planning, but most deployed systems remain brittle. They lack runtime introspection, cannot diagnose their own failure modes, and do not improve over time without human intervention. In practice, many agent stacks degrade into decorated chains of LLM calls with no structural mechanisms for reliability. We present VIGIL (Verifiable Inspection and Guarded Iterative Learning), a reflective runtime that supervises a sibling agent and performs autonomous maintenance rather than task execution. VIGIL ingests behavioral logs, appraises each event into a structured emotional representation, maintains a persistent EmoBank with decay and contextual policies, and derives an RBT diagnosis that sorts recent behavior into strengths, opportunities, and failures. From this analysis, VIGIL generates both guarded prompt updates that preserve core identity semantics and read only code proposals produced by a strategy engine that operates on log evidence and code hotspots. VIGIL functions as a state gated pipeline. Illegal transitions produce explicit errors rather than allowing the LLM to improvise. In a reminder latency case study, VIGIL identified elevated lag, proposed prompt and code repairs, and when its own diagnostic tool failed due to a schema conflict, it surfaced the internal error, produced a fallback diagnosis, and emitted a repair plan. This demonstrates meta level self repair in a deployed agent runtime.",
      "published": "2025-12-08",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.07094v2",
      "relevance_score": 48
    },
    {
      "arxiv_id": "2511.18728v1",
      "title": "Reinforcement Learning for Self-Healing Material Systems",
      "authors": [
        "Maitreyi Chatterjee",
        "Devansh Agarwal",
        "Biplab Chatterjee"
      ],
      "abstract": "The transition to autonomous material systems necessitates adaptive control methodologies to maximize structural longevity. This study frames the self-healing process as a Reinforcement Learning (RL) problem within a Markov Decision Process (MDP), enabling agents to autonomously derive optimal policies that efficiently balance structural integrity maintenance against finite resource consumption. A comparative evaluation of discrete-action (Q-learning, DQN) and continuous-action (TD3) agents in a stochastic simulation environment revealed that RL controllers significantly outperform heuristic baselines, achieving near-complete material recovery. Crucially, the TD3 agent utilizing continuous dosage control demonstrated superior convergence speed and stability, underscoring the necessity of fine-grained, proportional actuation in dynamic self-healing applications.",
      "published": "2025-11-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.18728v1",
      "relevance_score": 48
    },
    {
      "arxiv_id": "2507.22937v1",
      "title": "CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering",
      "authors": [
        "Jinkun Zhao",
        "Yuanshuai Wang",
        "Xingjian Zhang",
        "Ruibo Chen",
        "Xingchuang Liao",
        "Junle Wang",
        "Lei Huang",
        "Kui Zhang",
        "Wenjun Wu"
      ],
      "abstract": "With the rapid evolution of artificial intelligence, AIOps has emerged as a prominent paradigm in DevOps. Lots of work has been proposed to improve the performance of different AIOps phases. However, constrained by domain-specific knowledge, a single model can only handle the operation requirement of a specific task,such as log parser,root cause analysis. Meanwhile, combining multiple models can achieve more efficient results, which have been proved in both previous ensemble learning and the recent LLM training domain. Inspired by these works,to address the similar challenges in AIOPS, this paper first proposes a collaboration-of-expert framework(CoE-Ops) incorporating a general-purpose large language model task classifier. A retrieval-augmented generation mechanism is introduced to improve the framework's capability in handling both Question-Answering tasks with high-level(Code,build,Test,etc.) and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed method is implemented in the AIOps domain, and extensive experiments are conducted on the DevOps-EVAL dataset. Experimental results demonstrate that CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement over single AIOps models in DevOps problem resolution, and outperforms larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.",
      "published": "2025-07-25",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.22937v1",
      "relevance_score": 48
    },
    {
      "arxiv_id": "2510.07815v1",
      "title": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
      "authors": [
        "Zeyu Sun",
        "Jingjing Liang",
        "Weiyi Wang",
        "Chenyao Suo",
        "Junjie Chen",
        "Fanjiang Xu"
      ],
      "abstract": "MLIR (Multi-Level Intermediate Representation) has rapidly become a foundational technology for modern compiler frameworks, enabling extensibility across diverse domains. However, ensuring the correctness and robustness of MLIR itself remains challenging. Existing fuzzing approaches-based on manually crafted templates or rule-based mutations-struggle to generate sufficiently diverse and semantically valid test cases, making it difficult to expose subtle or deep-seated bugs within MLIR's complex and evolving code space. In this paper, we present FLEX, a novel self-adaptive fuzzing framework for MLIR. FLEX leverages neural networks for program generation, a perturbed sampling strategy to encourage diversity, and a feedback-driven augmentation loop that iteratively improves its model using both crashing and non-crashing test cases. Starting from a limited seed corpus, FLEX progressively learns valid syntax and semantics and autonomously produces high-quality test inputs. We evaluate FLEX on the upstream MLIR compiler against four state-of-the-art fuzzers. In a 30-day campaign, FLEX discovers 80 previously unknown bugs-including multiple new root causes and parser bugs-while in 24-hour fixed-revision comparisons, it detects 53 bugs (over 3.5x as many as the best baseline) and achieves 28.2% code coverage, outperforming the next-best tool by 42%. Ablation studies further confirm the critical role of both perturbed generation and diversity augmentation in FLEX's effectiveness.",
      "published": "2025-10-09",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.07815v1",
      "relevance_score": 48
    },
    {
      "arxiv_id": "2507.19403v1",
      "title": "SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions",
      "authors": [
        "Matthias Wei\u00df",
        "Falk Dettinger",
        "Michael Weyrich"
      ],
      "abstract": "Connected and software-defined vehicles promise to offer a broad range of services and advanced functions to customers, aiming to increase passenger comfort and support autonomous driving capabilities. Due to the high reliability and availability requirements of connected vehicles, it is crucial to resolve any occurring failures quickly. To achieve this however, a complex cloud/edge architecture with a mesh of dependencies must be navigated to diagnose the responsible root cause. As such, manual analyses become unfeasible since they would significantly delay the troubleshooting.   To address this challenge, this paper presents SDVDiag, an extensible platform for the automated diagnosis of connected vehicle functions. The platform enables the creation of pipelines that cover all steps from initial data collection to the tracing of potential root causes. In addition, SDVDiag supports self-adaptive behavior by the ability to exchange modules at runtime. Dependencies between functions are detected and continuously updated, resulting in a dynamic graph view of the system. In addition, vital system metrics are monitored for anomalies. Whenever an incident is investigated, a snapshot of the graph is taken and augmented by relevant anomalies. Finally, the analysis is performed by traversing the graph and creating a ranking of the most likely causes.   To evaluate the platform, it is deployed inside an 5G test fleet environment for connected vehicle functions. The results show that injected faults can be detected reliably. As such, the platform offers the potential to gain new insights and reduce downtime by identifying problems and their causes at an early stage.",
      "published": "2025-07-25",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.19403v1",
      "relevance_score": 48
    },
    {
      "arxiv_id": "2512.05288v1",
      "title": "Beyond Detection: A Comprehensive Benchmark and Study on Representation Learning for Fine-Grained Webshell Family Classification",
      "authors": [
        "Feijiang Han"
      ],
      "abstract": "Malicious WebShells pose a significant and evolving threat by compromising critical digital infrastructures and endangering public services in sectors such as healthcare and finance. While the research community has made significant progress in WebShell detection (i.e., distinguishing malicious samples from benign ones), we argue that it is time to transition from passive detection to in-depth analysis and proactive defense. One promising direction is the automation of WebShell family classification, which involves identifying the specific malware lineage in order to understand an adversary's tactics and enable a precise, rapid response. This crucial task, however, remains a largely unexplored area that currently relies on slow, manual expert analysis. To address this gap, we present the first systematic study to automate WebShell family classification. Our method begins with extracting dynamic function call traces to capture inherent behaviors that are resistant to common encryption and obfuscation. To enhance the scale and diversity of our dataset for a more stable evaluation, we augment these real-world traces with new variants synthesized by Large Language Models. These augmented traces are then abstracted into sequences, graphs, and trees, providing a foundation to benchmark a comprehensive suite of representation methods. Our evaluation spans classic sequence-based embeddings (CBOW, GloVe), transformers (BERT, SimCSE), and a range of structure-aware algorithms, including Graph Kernels, Graph Edit Distance, Graph2Vec, and various Graph Neural Networks. Through extensive experiments on four real-world, family-annotated datasets under both supervised and unsupervised settings, we establish a robust baseline and provide practical insights into the most effective combinations of data abstractions, representation models, and learning paradigms for this challenge.",
      "published": "2025-12-04",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.05288v1",
      "relevance_score": 48
    },
    {
      "arxiv_id": "2512.17594v1",
      "title": "MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification",
      "authors": [
        "Tosin Ige",
        "Christopher Kiekintveld",
        "Aritran Piplai",
        "Asif Rahman",
        "Olukunle Kolade",
        "Sasidhar Kunapuli"
      ],
      "abstract": "Out of distribution (OOD) detection remains a critical challenge in malware classification due to the substantial intra family variability introduced by polymorphic and metamorphic malware variants. Most existing deep learning based malware detectors rely on closed world assumptions and fail to adequately model this intra class variation, resulting in degraded performance when confronted with previously unseen malware families. This paper presents MADOOD, a novel two stage, cluster driven deep learning framework for robust OOD malware detection and classification. In the first stage, malware family embeddings are modeled using class conditional spherical decision boundaries derived from Gaussian Discriminant Analysis (GDA), enabling statistically grounded separation of indistribution and OOD samples without requiring OOD data during training. Z score based distance analysis across multiple class centroids is employed to reliably identify anomalous samples in the latent space. In the second stage, a deep neural network integrates cluster based predictions, refined embeddings, and supervised classifier outputs to enhance final classification accuracy. Extensive evaluations on benchmark malware datasets comprising 25 known families and multiple novel OOD variants demonstrate that MADOOD significantly outperforms state of the art OOD detection methods, achieving an AUC of up to 0.911 on unseen malware families. The proposed framework provides a scalable, interpretable, and statistically principled solution for real world malware detection and anomaly identification in evolving cybersecurity environments.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17594v1",
      "relevance_score": 47
    },
    {
      "arxiv_id": "2511.11240v1",
      "title": "HealSplit: Towards Self-Healing through Adversarial Distillation in Split Federated Learning",
      "authors": [
        "Yuhan Xie",
        "Chen Lyu"
      ],
      "abstract": "Split Federated Learning (SFL) is an emerging paradigm for privacy-preserving distributed learning. However, it remains vulnerable to sophisticated data poisoning attacks targeting local features, labels, smashed data, and model weights. Existing defenses, primarily adapted from traditional Federated Learning (FL), are less effective under SFL due to limited access to complete model updates. This paper presents HealSplit, the first unified defense framework tailored for SFL, offering end-to-end detection and recovery against five sophisticated types of poisoning attacks. HealSplit comprises three key components: (1) a topology-aware detection module that constructs graphs over smashed data to identify poisoned samples via topological anomaly scoring (TAS); (2) a generative recovery pipeline that synthesizes semantically consistent substitutes for detected anomalies, validated by a consistency validation student; and (3) an adversarial multi-teacher distillation framework trains the student using semantic supervision from a Vanilla Teacher and anomaly-aware signals from an Anomaly-Influence Debiasing (AD) Teacher, guided by the alignment between topological and gradient-based interaction matrices. Extensive experiments on four benchmark datasets demonstrate that HealSplit consistently outperforms ten state-of-the-art defenses, achieving superior robustness and defense effectiveness across diverse attack scenarios.",
      "published": "2025-11-14",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.11240v1",
      "relevance_score": 45
    },
    {
      "arxiv_id": "2509.08698v1",
      "title": "A layered architecture for log analysis in complex IT systems",
      "authors": [
        "Thorsten Wittkopp"
      ],
      "abstract": "In the evolving IT landscape, stability and reliability of systems are essential, yet their growing complexity challenges DevOps teams in implementation and maintenance. Log analysis, a core element of AIOps, provides critical insights into complex behaviors and failures. This dissertation introduces a three-layered architecture to support DevOps in failure resolution. The first layer, Log Investigation, performs autonomous log labeling and anomaly classification. We propose a method that labels log data without manual effort, enabling supervised training and precise evaluation of anomaly detection. Additionally, we define a taxonomy that groups anomalies into three categories, ensuring appropriate method selection. The second layer, Anomaly Detection, detects behaviors deviating from the norm. We propose a flexible Anomaly Detection method adaptable to unsupervised, weakly supervised, and supervised training. Evaluations on public and industry datasets show F1-scores between 0.98 and 1.0, ensuring reliable anomaly detection. The third layer, Root Cause Analysis, identifies minimal log sets describing failures, their origin, and event sequences. By balancing training data and identifying key services, our Root Cause Analysis method consistently detects 90-98% of root cause log lines within the top 10 candidates, providing actionable insights for mitigation. Our research addresses how log analysis methods can be designed and optimized to help DevOps resolve failures efficiently. By integrating these three layers, the architecture equips teams with robust methods to enhance IT system reliability.",
      "published": "2025-08-29",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.08698v1",
      "relevance_score": 45
    },
    {
      "arxiv_id": "2511.07645v1",
      "title": "A Self-Improving Architecture for Dynamic Safety in Large Language Models",
      "authors": [
        "Tyler Slater"
      ],
      "abstract": "Context: The integration of Large Language Models (LLMs) into core software systems is accelerating. However, existing software architecture patterns are static, while current safety assurance methods are not scalable, leaving systems vulnerable to novel adversarial threats.   Objective: To design, implement, and evaluate a novel software architecture that enables an AI-driven system to autonomously and continuously adapt its own safety protocols at runtime.   Method: We propose the Self-Improving Safety Framework (SISF), a runtime architecture that couples an unprotected, unaligned base LLM (mistralai/Mistral-7B-v0.1) with a dynamic feedback loop. This loop consists of an AI Adjudicator (GPT-4o) for breach detection and a Policy Synthesis Module (GPT-4 Turbo) that autonomously generates new, generalized safety policies (both heuristic and semantic) in response to failures.   Results: We conducted a dynamic learning evaluation using the 520-prompt AdvBench dataset. The unprotected model was 100% vulnerable. Our SISF, starting from zero policies, demonstrated a clear learning curve: it detected 237 breaches, autonomously synthesized 234 new policies, and reduced the overall Attack Success Rate (ASR) to 45.58%. In a subsequent test on 520 benign prompts, the SISF achieved a 0.00% False Positive Rate (FPR), proving its ability to adapt without compromising user utility.   Conclusion: An architectural approach to AI safety, based on the principles of self-adaptation, is a viable and effective strategy. Our framework demonstrates a practical path towards building more robust, resilient, and scalable AI-driven systems, shifting safety assurance from a static, pre-deployment activity to an automated, runtime process.",
      "published": "2025-11-10",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.07645v1",
      "relevance_score": 45
    },
    {
      "arxiv_id": "2512.21063v1",
      "title": "LSTM-Based Modeling and Reinforcement Learning Control of a Magnetically Actuated Catheter",
      "authors": [
        "Arya Rashidinejad Meibodi",
        "Mahbod Gholamali Sinaki",
        "Khalil Alipour"
      ],
      "abstract": "Autonomous magnetic catheter systems are emerging as a promising approach for the future of minimally invasive interventions. This study presents a novel approach that begins by modeling the nonlinear and hysteretic dynamics of a magnetically actuated catheter system, consists of a magnetic catheter manipulated by servo-controlled magnetic fields generated by two external permanent magnets, and its complex behavior is captured using a Long Short-Term Memory (LSTM) neural network. This model validated against experimental setup's data with a root mean square error (RMSE) of 0.42 mm and 99.8% coverage within 3 mm, establishing it as a reliable surrogate model. This LSTM enables the training of Reinforcement Learning (RL) agents for controlling the system and avoiding damage to the real setup, with the potential for subsequent fine-tuning on the physical system. We implemented Deep Q-Network (DQN) and actor-critic RL controllers, comparing these two agents first for regulation and subsequently for path following along linear and half-sinusoidal paths for the catheter tip. The actor-critic outperforms DQN, offering greater accuracy and faster performance with less error, along with smoother trajectories at a 10 Hz sampling rate, in both regulation and path following compared to the DQN controller. This performance, due to the continuous action space, suits dynamic navigation tasks like navigating curved vascular structures for practical applications.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21063v1",
      "relevance_score": 44
    },
    {
      "arxiv_id": "2512.20902v1",
      "title": "Embodied AI-Enhanced IoMT Edge Computing: UAV Trajectory Optimization and Task Offloading with Mobility Prediction",
      "authors": [
        "Siqi Mu",
        "Shuo Wen",
        "Yang Lu",
        "Ruihong Jiang",
        "Bo Ai"
      ],
      "abstract": "Due to their inherent flexibility and autonomous operation, unmanned aerial vehicles (UAVs) have been widely used in Internet of Medical Things (IoMT) to provide real-time biomedical edge computing service for wireless body area network (WBAN) users. In this paper, considering the time-varying task criticality characteristics of diverse WBAN users and the dual mobility between WBAN users and UAV, we investigate the dynamic task offloading and UAV flight trajectory optimization problem to minimize the weighted average task completion time of all the WBAN users, under the constraint of UAV energy consumption. To tackle the problem, an embodied AI-enhanced IoMT edge computing framework is established. Specifically, we propose a novel hierarchical multi-scale Transformer-based user trajectory prediction model based on the users' historical trajectory traces captured by the embodied AI agent (i.e., UAV). Afterwards, a prediction-enhanced deep reinforcement learning (DRL) algorithm that integrates predicted users' mobility information is designed for intelligently optimizing UAV flight trajectory and task offloading decisions. Real-word movement traces and simulation results demonstrate the superiority of the proposed methods in comparison with the existing benchmarks.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20902v1",
      "relevance_score": 44
    },
    {
      "arxiv_id": "2512.20722v1",
      "title": "Learning-Enabled Elastic Network Topology for Distributed ISAC Service Provisioning",
      "authors": [
        "Jie Chen",
        "Xianbin Wang"
      ],
      "abstract": "Conventional mobile networks, including both localized cell-centric and cooperative cell-free networks (CCN/CFN), are built upon rigid network topologies. However, neither architecture is adequate to flexibly support distributed integrated sensing and communication (ISAC) services, due to the increasing difficulty of aligning spatiotemporally distributed heterogeneous service demands with available radio resources. In this paper, we propose an elastic network topology (ENT) for distributed ISAC service provisioning, where multiple co-existing localized CCNs can be dynamically aggregated into CFNs with expanded boundaries for federated network operation. This topology elastically orchestrates localized CCN and federated CFN boundaries to balance signaling overhead and distributed resource utilization, thereby enabling efficient ISAC service provisioning. A two-phase operation protocol is then developed. In Phase I, each CCN autonomously classifies ISAC services as either local or federated and partitions its resources into dedicated and shared segments. In Phase II, each CCN employs its dedicated resources for local ISAC services, while the aggregated CFN consolidates shared resources from its constituent CCNs to cooperatively deliver federated services. Furthermore, we design a utility-to-signaling ratio (USR) to quantify the tradeoff between sensing/communication utility and signaling overhead. Consequently, a USR maximization problem is formulated by jointly optimizing the network topology (i.e., service classification and CCN aggregation) and the allocation of dedicated and shared resources. However, this problem is challenging due to its distributed optimization nature and the absence of complete channel state information. To address this problem efficiently, we propose a multi-agent deep reinforcement learning (MADRL) framework with centralized training and decentralized execution.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20722v1",
      "relevance_score": 44
    },
    {
      "arxiv_id": "2512.18087v1",
      "title": "AI Assisted Next Gen Outdoor Optical Networks: Camera Sensing for Monitoring and User Localization",
      "authors": [
        "Meysam Ghanbari",
        "Mohammad Taghi Dabiri",
        "Rula Ammuri",
        "Mazen Hasna",
        "Khalid Qaraqe"
      ],
      "abstract": "We consider outdoor optical access points (OAPs), which, enabled by recent advances in metasurface technology, have attracted growing interest. While OAPs promise high data rates and strong physical-layer security, practical deployments still expose vulnerabilities and misuse patterns that necessitate a dedicated monitoring layer - the focus of this work. We therefore propose a user positioning and monitoring system that infers locations from spatial intensity measurements on a photodetector (PD) array. Specifically, our hybrid approach couples an optics-informed forward model and sparse, model-based inversion with a lightweight data-driven calibration stage, yielding high accuracy at low computational cost. This design preserves the interpretability and stability of model-based reconstruction while leveraging learning to absorb residual nonidealities and device-specific distortions. Under identical hardware and training conditions (both with 5 x 10^5 samples), the hybrid method attains consistently lower mean-squared error than a generic deep-learning baseline while using substantially less training time and compute. Accuracy improves with array resolution and saturates around 60 x 60-80 x 80, indicating a favorable accuracy-complexity trade-off for real-time deployment. The resulting position estimates can be cross-checked with real-time network logs to enable continuous monitoring, anomaly detection (e.g., potential eavesdropping), and access control in outdoor optical access networks.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18087v1",
      "relevance_score": 44
    },
    {
      "arxiv_id": "2505.13693v1",
      "title": "HarmonE: A Self-Adaptive Approach to Architecting Sustainable MLOps",
      "authors": [
        "Hiya Bhatt",
        "Shaunak Biswas",
        "Srinivasan Rakhunathan",
        "Karthik Vaidhyanathan"
      ],
      "abstract": "Machine Learning Enabled Systems (MLS) are becoming integral to real-world applications, but ensuring their sustainable performance over time remains a significant challenge. These systems operate in dynamic environments and face runtime uncertainties like data drift and model degradation, which affect the sustainability of MLS across multiple dimensions: technical, economical, environmental, and social. While Machine Learning Operations (MLOps) addresses the technical dimension by streamlining the ML model lifecycle, it overlooks other dimensions. Furthermore, some traditional practices, such as frequent retraining, incur substantial energy and computational overhead, thus amplifying sustainability concerns. To address them, we introduce HarmonE, an architectural approach that enables self-adaptive capabilities in MLOps pipelines using the MAPE-K loop. HarmonE allows system architects to define explicit sustainability goals and adaptation thresholds at design time, and performs runtime monitoring of key metrics, such as prediction accuracy, energy consumption, and data distribution shifts, to trigger appropriate adaptation strategies. We validate our approach using a Digital Twin (DT) of an Intelligent Transportation System (ITS), focusing on traffic flow prediction as our primary use case. The DT employs time series ML models to simulate real-time traffic and assess various flow scenarios. Our results show that HarmonE adapts effectively to evolving conditions while maintaining accuracy and meeting sustainability goals.",
      "published": "2025-05-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.13693v1",
      "relevance_score": 44
    },
    {
      "arxiv_id": "2511.18172v1",
      "title": "MEDIC: a network for monitoring data quality in collider experiments",
      "authors": [
        "Juvenal Bassa",
        "Arghya Chattopadhyay",
        "Sudhir Malik",
        "Mario Escabi Rivera"
      ],
      "abstract": "Data Quality Monitoring (DQM) is a crucial component of particle physics experiments and ensures that the recorded data is of the highest quality, and suitable for subsequent physics analysis. Due to the extreme environmental conditions, unprecedented data volumes, and the sheer scale and complexity of the detectors, DQM orchestration has become a very challenging task. Therefore, the use of Machine Learning (ML) to automate anomaly detection, improve efficiency, and reduce human error in the process of collecting high-quality data is unavoidable. Since DQM relies on real experimental data, it is inherently tied to the specific detector substructure and technology in operation. In this work, a simulation-driven approach to DQM is proposed, enabling the study and development of data-quality methodologies in a controlled environment. Using a modified version of Delphes -- a fast, multi-purpose detector simulation -- the preliminary realization of a framework is demonstrated which leverages ML to identify detector anomalies as well as localize the malfunctioning components responsible. We introduce MEDIC (Monitoring for Event Data Integrity and Consistency), a neural network designed to learn detector behavior and perform DQM tasks to look for potential faults. Although the present implementation adopts a simplified setup for computational ease, where large detector regions are deliberately deactivated to mimic faults, this work represents an initial step toward a comprehensive ML-based DQM framework. The encouraging results underline the potential of simulation-driven studies as a foundation for developing more advanced, data-driven DQM systems for future particle detectors.",
      "published": "2025-11-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.18172v1",
      "relevance_score": 44
    },
    {
      "arxiv_id": "2512.13096v1",
      "title": "Toward Self-Healing Networks-on-Chip: RL-Driven Routing in 2D Torus Architectures",
      "authors": [
        "Mohammad Walid Charrwi",
        "Zaid Hussain"
      ],
      "abstract": "We investigate adaptive minimal routing in 2D torus networks on chip NoCs under node fault conditions comparing a reinforcement learning RL based strategy to an adaptive routing baseline A torus topology is used for its low diameter high connectivity properties The RL approach models each router as an agent that learns to forward packets based on network state while the adaptive scheme uses fixed minimal paths with simple rerouting around faults We implement both methods in simulation injecting up to 50 node faults uniformly at random Key metrics are measured 1 throughput vs offered load at fault density 02 2 packet delivery ratio PDR vs fault density and 3 a fault adaptive score FT vs fault density Experimental results show the RL method achieves significantly higher throughput at high load approximately 2030 gain and maintains higher reliability under increasing faults The RL router delivers more packets per cycle and adapts to faults by exploiting path diversity whereas the adaptive scheme degrades sharply as faults accumulate In particular the RL approach preserves end to end connectivity longer PDR remains above 90 until approximately 3040 faults while adaptive PDR drops to approximately 70 at the same point The fault adaptive score likewise favors RL routing Thus RL based adaptive routing demonstrates clear advantages in throughput and fault resilience for torus NoCs",
      "published": "2025-12-15",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.13096v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2512.21250v1",
      "title": "CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents",
      "authors": [
        "Haoyang Li",
        "Mingjin Li",
        "Jinxin Zuo",
        "Siqi Li",
        "Xiao Li",
        "Hao Wu",
        "Yueming Lu",
        "Xiaochuan He"
      ],
      "abstract": "LLM-based code agents(e.g., ChatGPT Codex) are increasingly deployed as detector for code review and security auditing tasks. Although CoT-enhanced LLM vulnerability detectors are believed to provide improved robustness against obfuscated malicious code, we find that their reasoning chains and semantic abstraction processes exhibit exploitable systematic weaknesses.This allows attackers to covertly embed malicious logic, bypass code review, and propagate backdoored components throughout real-world software supply chains.To investigate this issue, we present CoTDeceptor, the first adversarial code obfuscation framework targeting CoT-enhanced LLM detectors. CoTDeceptor autonomously constructs evolving, hard-to-reverse multi-stage obfuscation strategy chains that effectively disrupt CoT-driven detection logic.We obtained malicious code provided by security enterprise, experimental results demonstrate that CoTDeceptor achieves stable and transferable evasion performance against state-of-the-art LLMs and vulnerability detection agents. CoTDeceptor bypasses 14 out of 15 vulnerability categories, compared to only 2 bypassed by prior methods. Our findings highlight potential risks in real-world software supply chains and underscore the need for more robust and interpretable LLM-powered security analysis systems.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21250v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2512.20873v1",
      "title": "Systemization of Knowledge: Resilience and Fault Tolerance in Cyber-Physical Systems",
      "authors": [
        "Rahul Bulusu"
      ],
      "abstract": "Cyber-Physical Systems (CPS) now support critical infrastructure spanning transportation, energy, manufacturing, medical devices, and autonomous robotics. Their defining characteristic is the tight coupling between digital computation and continuous physical dynamics which enables sophisticated autonomy but also creates highly non-linear failure modes. Small disturbances at sensors, firmware, networks, or physical interfaces can propagate through estimation and control pipelines, producing cascading instabilities that defy traditional single-layer reasoning. This Systematization of Knowledge (SoK) unifies nearly two decades of CPS resilience research into a structured Origin-Layer-Effect (OLE) taxonomy. This taxonomy provides a cross-layer lens for understanding how faults arise, how they propagate, and why unrelated CPS failures often share deep structural similarities. By mapping representative systems including RockDrone, MAYDAY, M2MON, HACMS, Byzantine fault-tolerant control, and learning-based recovery mechanisms onto the taxonomy, we reveal patterns of coverage, persistent blind spots, and recurring pathways of fault amplification. Our analysis identifies four structural gaps that span multiple CPS domains: (1) physical-model manipulation, (2) ML-enabled control without stability guarantees, (3) semantic inconsistencies between formal models and firmware, and (4) inadequate forensic visibility across cyber and physical layers. These insights motivate new directions for resilient CPS design, integrating robust control, runtime monitoring, formal assurance, and system-level visibility.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20873v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2512.20831v1",
      "title": "Context-Sensitive Abstractions for Reinforcement Learning with Parameterized Actions",
      "authors": [
        "Rashmeet Kaur Nayyar",
        "Naman Shah",
        "Siddharth Srivastava"
      ],
      "abstract": "Real-world sequential decision-making often involves parameterized action spaces that require both, decisions regarding discrete actions and decisions about continuous action parameters governing how an action is executed. Existing approaches exhibit severe limitations in this setting -- planning methods demand hand-crafted action models, and standard reinforcement learning (RL) algorithms are designed for either discrete or continuous actions but not both, and the few RL methods that handle parameterized actions typically rely on domain-specific engineering and fail to exploit the latent structure of these spaces. This paper extends the scope of RL algorithms to long-horizon, sparse-reward settings with parameterized actions by enabling agents to autonomously learn both state and action abstractions online. We introduce algorithms that progressively refine these abstractions during learning, increasing fine-grained detail in the critical regions of the state-action space where greater resolution improves performance. Across several continuous-state, parameterized-action domains, our abstraction-driven approach enables TD($\u03bb$) to achieve markedly higher sample efficiency than state-of-the-art baselines.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20831v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2512.20745v1",
      "title": "AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent",
      "authors": [
        "Haipeng Luo",
        "Huawen Feng",
        "Qingfeng Sun",
        "Can Xu",
        "Kai Zheng",
        "Yufei Wang",
        "Tao Yang",
        "Han Hu",
        "Yansong Tang",
        "Di Wang"
      ],
      "abstract": "Large Reasoning Models (LRMs) like o3 and DeepSeek-R1 have achieved remarkable progress in natural language reasoning with long chain-of-thought. However, they remain computationally inefficient and struggle with accuracy when solving problems requiring complex mathematical operations. In this work, we present AgentMath, an agent framework that seamlessly integrates language models' reasoning capabilities with code interpreters' computational precision to efficiently tackle complex mathematical problems. Our approach introduces three key innovations: (1) An automated method that converts natural language chain-of-thought into structured tool-augmented trajectories, generating high-quality supervised fine-tuning (SFT) data to alleviate data scarcity; (2) A novel agentic reinforcement learning (RL) paradigm that dynamically interleaves natural language generation with real-time code execution. This enables models to autonomously learn optimal tool-use strategies through multi-round interactive feedback, while fostering emergent capabilities in code refinement and error correction; (3) An efficient training system incorporating innovative techniques, including request-level asynchronous rollout scheduling, agentic partial rollout, and prefix-aware weighted load balancing, achieving 4-5x speedup and making efficient RL training feasible on ultra-long sequences with scenarios with massive tool calls.Extensive evaluations show that AgentMath achieves state-of-the-art performance on challenging mathematical competition benchmarks including AIME24, AIME25, and HMMT25. Specifically, AgentMath-30B-A3B attains 90.6%, 86.4%, and 73.8% accuracy respectively, achieving advanced capabilities.These results validate the effectiveness of our approach and pave the way for building more sophisticated and scalable mathematical reasoning agents.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20745v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2512.20217v1",
      "title": "LiteFusion: Taming 3D Object Detectors from Vision-Based to Multi-Modal with Minimal Adaptation",
      "authors": [
        "Xiangxuan Ren",
        "Zhongdao Wang",
        "Pin Tang",
        "Guoqing Wang",
        "Jilai Zheng",
        "Chao Ma"
      ],
      "abstract": "3D object detection is fundamental for safe and robust intelligent transportation systems. Current multi-modal 3D object detectors often rely on complex architectures and training strategies to achieve higher detection accuracy. However, these methods heavily rely on the LiDAR sensor so that they suffer from large performance drops when LiDAR is absent, which compromises the robustness and safety of autonomous systems in practical scenarios. Moreover, existing multi-modal detectors face difficulties in deployment on diverse hardware platforms, such as NPUs and FPGAs, due to their reliance on 3D sparse convolution operators, which are primarily optimized for NVIDIA GPUs. To address these challenges, we reconsider the role of LiDAR in the camera-LiDAR fusion paradigm and introduce a novel multi-modal 3D detector, LiteFusion. Instead of treating LiDAR point clouds as an independent modality with a separate feature extraction backbone, LiteFusion utilizes LiDAR data as a complementary source of geometric information to enhance camera-based detection. This straightforward approach completely eliminates the reliance on a 3D backbone, making the method highly deployment-friendly. Specifically, LiteFusion integrates complementary features from LiDAR points into image features within a quaternion space, where the orthogonal constraints are well-preserved during network training. This helps model domain-specific relations across modalities, yielding a compact cross-modal embedding. Experiments on the nuScenes dataset show that LiteFusion improves the baseline vision-based detector by +20.4% mAP and +19.7% NDS with a minimal increase in parameters (1.1%) without using dedicated LiDAR encoders. Notably, even in the absence of LiDAR input, LiteFusion maintains strong results , highlighting its favorable robustness and effectiveness across diverse fusion paradigms and deployment scenarios.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20217v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2512.20688v1",
      "title": "Mechanism-Based Intelligence (MBI): Differentiable Incentives for Rational Coordination and Guaranteed Alignment in Multi-Agent Systems",
      "authors": [
        "Stefano Grassi"
      ],
      "abstract": "Autonomous multi-agent systems are fundamentally fragile: they struggle to solve the Hayekian Information problem (eliciting dispersed private knowledge) and the Hurwiczian Incentive problem (aligning local actions with global objectives), making coordination computationally intractable. I introduce Mechanism-Based Intelligence (MBI), a paradigm that reconceptualizes intelligence as emergent from the coordination of multiple \"brains\", rather than a single one. At its core, the Differentiable Price Mechanism (DPM) computes the exact loss gradient $$ \\mathbf{G}_i = - \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}_i} $$ as a dynamic, VCG-equivalent incentive signal, guaranteeing Dominant Strategy Incentive Compatibility (DSIC) and convergence to the global optimum. A Bayesian extension ensures incentive compatibility under asymmetric information (BIC). The framework scales linearly ($\\mathcal{O}(N)$) with the number of agents, bypassing the combinatorial complexity of Dec-POMDPs and is empirically 50x faster than Model-Free Reinforcement Learning. By structurally aligning agent self-interest with collective objectives, it provides a provably efficient, auditable and generalizable approach to coordinated, trustworthy and scalable multi-agent intelligence grounded in economic principles.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20688v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2503.18385v1",
      "title": "RoCA: Robust Contrastive One-class Time Series Anomaly Detection with Contaminated Data",
      "authors": [
        "Xudong Mou",
        "Rui Wang",
        "Bo Li",
        "Tianyu Wo",
        "Jie Sun",
        "Hui Wang",
        "Xudong Liu"
      ],
      "abstract": "The accumulation of time-series signals and the absence of labels make time-series Anomaly Detection (AD) a self-supervised task of deep learning. Methods based on normality assumptions face the following three limitations: (1) A single assumption could hardly characterize the whole normality or lead to some deviation. (2) Some assumptions may go against the principle of AD. (3) Their basic assumption is that the training data is uncontaminated (free of anomalies), which is unrealistic in practice, leading to a decline in robustness. This paper proposes a novel robust approach, RoCA, which is the first to address all of the above three challenges, as far as we are aware. It fuses the separated assumptions of one-class classification and contrastive learning in a single training process to characterize a more complete so-called normality. Additionally, it monitors the training data and computes a carefully designed anomaly score throughout the training process. This score helps identify latent anomalies, which are then used to define the classification boundary, inspired by the concept of outlier exposure. The performance on AIOps datasets improved by 6% compared to when contamination was not considered (COCA). On two large and high-dimensional multivariate datasets, the performance increased by 5% to 10%. RoCA achieves the highest average performance on both univariate and multivariate datasets. The source code is available at https://github.com/ruiking04/RoCA.",
      "published": "2025-03-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2503.18385v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2512.18219v1",
      "title": "Unsupervised Anomaly Detection with an Enhanced Teacher for Student-Teacher Feature Pyramid Matching",
      "authors": [
        "Mohammad Zolfaghari",
        "Hedieh Sajedi"
      ],
      "abstract": "Anomaly detection or outlier is one of the challenging subjects in unsupervised learning . This paper is introduced a student-teacher framework for anomaly detection that its teacher network is enhanced for achieving high-performance metrics . For this purpose , we first pre-train the ResNet-18 network on the ImageNet and then fine-tune it on the MVTech-AD dataset . Experiment results on the image-level and pixel-level demonstrate that this idea has achieved better metrics than the previous methods . Our model , Enhanced Teacher for Student-Teacher Feature Pyramid (ET-STPM), achieved 0.971 mean accuracy on the image-level and 0.977 mean accuracy on the pixel-level for anomaly detection.",
      "published": "2025-12-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18219v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2512.07785v1",
      "title": "Automating High Energy Physics Data Analysis with LLM-Powered Agents",
      "authors": [
        "Eli Gendreau-Distler",
        "Joshua Ho",
        "Dongwon Kim",
        "Luc Tomas Le Pottier",
        "Haichen Wang",
        "Chengxi Yang"
      ],
      "abstract": "We present a proof-of-principle study demonstrating the use of large language model (LLM) agents to automate a representative high energy physics (HEP) analysis. Using the Higgs boson diphoton cross-section measurement as a case study with ATLAS Open Data, we design a hybrid system that combines an LLM-based supervisor-coder agent with the Snakemake workflow manager. In this architecture, the workflow manager enforces reproducibility and determinism, while the agent autonomously generates, executes, and iteratively corrects analysis code in response to user instructions. We define quantitative evaluation metrics including success rate, error distribution, costs per specific task, and average number of API calls, to assess agent performance across multi-stage workflows. To characterize variability across architectures, we benchmark a representative selection of state-of-the-art LLMs spanning the Gemini and GPT-5 series, the Claude family, and leading open-weight models. While the workflow manager ensures deterministic execution of all analysis steps, the final outputs still show stochastic variation. Although we set the temperature to zero, other sampling parameters (e.g., top-p, top-k) remained at their defaults, and some reasoning-oriented models internally adjust these settings. Consequently, the models do not produce fully deterministic results. This study establishes the first LLM-agent-driven automated data-analysis framework in HEP, enabling systematic benchmarking of model capabilities, stability, and limitations in real-world scientific computing environments. The baseline code used in this work is available at https://huggingface.co/HWresearch/LLM4HEP. This work was accepted as a poster at the Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS 2025. The initial submission was made on August 30, 2025.",
      "published": "2025-12-08",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.07785v1",
      "relevance_score": 41
    },
    {
      "arxiv_id": "2412.13529v1",
      "title": "Quantum Machine Learning in Log-based Anomaly Detection: Challenges and Opportunities",
      "authors": [
        "Jiaxing Qi",
        "Chang Zeng",
        "Zhongzhi Luan",
        "Shaohan Huang",
        "Shu Yang",
        "Yao Lu",
        "Bin Han",
        "Hailong Yang",
        "Depei Qian"
      ],
      "abstract": "Log-based anomaly detection (LogAD) is the main component of Artificial Intelligence for IT Operations (AIOps), which can detect anomalous that occur during the system on-the-fly. Existing methods commonly extract log sequence features using classical machine learning techniques to identify whether a new sequence is an anomaly or not. However, these classical approaches often require trade-offs between efficiency and accuracy. The advent of quantum machine learning (QML) offers a promising alternative. By transforming parts of classical machine learning computations into parameterized quantum circuits (PQCs), QML can significantly reduce the number of trainable parameters while maintaining accuracy comparable to classical counterparts. In this work, we introduce a unified framework, \\ourframework{}, for evaluating QML models in the context of LogAD. This framework incorporates diverse log data, integrated QML models, and comprehensive evaluation metrics. State-of-the-art methods such as DeepLog, LogAnomaly, and LogRobust, along with their quantum-transformed counterparts, are included in our framework.Beyond standard metrics like F1 score, precision, and recall, our evaluation extends to factors critical to QML performance, such as specificity, the number of circuits, circuit design, and quantum state encoding. Using \\ourframework{}, we conduct extensive experiments to assess the performance of these models and their quantum counterparts, uncovering valuable insights and paving the way for future research in QML model selection and design for LogAD.",
      "published": "2024-12-18",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2412.13529v1",
      "relevance_score": 39
    },
    {
      "arxiv_id": "2405.07626v2",
      "title": "AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models",
      "authors": [
        "Shuo Liu",
        "Di Yao",
        "Lanting Fang",
        "Zhetao Li",
        "Wenbin Li",
        "Kaiyu Feng",
        "XiaoWen Ji",
        "Jingping Bi"
      ],
      "abstract": "Detecting anomaly edges for dynamic graphs aims to identify edges significantly deviating from the normal pattern and can be applied in various domains, such as cybersecurity, financial transactions and AIOps. With the evolving of time, the types of anomaly edges are emerging and the labeled anomaly samples are few for each type. Current methods are either designed to detect randomly inserted edges or require sufficient labeled data for model training, which harms their applicability for real-world applications. In this paper, we study this problem by cooperating with the rich knowledge encoded in large language models(LLMs) and propose a method, namely AnomalyLLM. To align the dynamic graph with LLMs, AnomalyLLM pre-trains a dynamic-aware encoder to generate the representations of edges and reprograms the edges using the prototypes of word embeddings. Along with the encoder, we design an in-context learning framework that integrates the information of a few labeled samples to achieve few-shot anomaly detection. Experiments on four datasets reveal that AnomalyLLM can not only significantly improve the performance of few-shot anomaly detection, but also achieve superior results on new anomalies without any update of model parameters.",
      "published": "2024-05-13",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2405.07626v2",
      "relevance_score": 39
    },
    {
      "arxiv_id": "2511.16402v1",
      "title": "Trustworthy AI in the Agentic Lakehouse: from Concurrency to Governance",
      "authors": [
        "Jacopo Tagliabue",
        "Federico Bianchi",
        "Ciro Greco"
      ],
      "abstract": "Even as AI capabilities improve, most enterprises do not consider agents trustworthy enough to work on production data. In this paper, we argue that the path to trustworthy agentic workflows begins with solving the infrastructure problem first: traditional lakehouses are not suited for agent access patterns, but if we design one around transactions, governance follows. In particular, we draw an operational analogy to MVCC in databases and show why a direct transplant fails in a decoupled, multi-language setting. We then propose an agent-first design, Bauplan, that reimplements data and compute isolation in the lakehouse. We conclude by sharing a reference implementation of a self-healing pipeline in Bauplan, which seamlessly couples agent reasoning with all the desired guarantees for correctness and trust.",
      "published": "2025-11-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.16402v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2504.20093v1",
      "title": "Self-Healing Software Systems: Lessons from Nature, Powered by AI",
      "authors": [
        "Mohammad Baqar",
        "Rajat Khanda",
        "Saba Naqvi"
      ],
      "abstract": "As modern software systems grow in complexity and scale, their ability to autonomously detect, diagnose, and recover from failures becomes increasingly vital. Drawing inspiration from biological healing - where the human body detects damage, signals the brain, and activates targeted recovery - this paper explores the concept of self-healing software driven by artificial intelligence. We propose a novel framework that mimics this biological model system observability tools serve as sensory inputs, AI models function as the cognitive core for diagnosis and repair, and healing agents apply targeted code and test modifications. By combining log analysis, static code inspection, and AI-driven generation of patches or test updates, our approach aims to reduce downtime, accelerate debugging, and enhance software resilience. We evaluate the effectiveness of this model through case studies and simulations, comparing it against traditional manual debugging and recovery workflows. This work paves the way toward intelligent, adaptive and self-reliant software systems capable of continuous healing, akin to living organisms.",
      "published": "2025-04-25",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.20093v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2512.20884v1",
      "title": "The Silent Scholar Problem: A Probabilistic Framework for Breaking Epistemic Asymmetry in LLM Agents",
      "authors": [
        "Zan-Kai Chong",
        "Hiroyuki Ohsaki",
        "Bryan Ng"
      ],
      "abstract": "Autonomous agents powered by LLMs and Retrieval-Augmented Generation (RAG) are proficient consumers of digital content but remain unidirectional, a limitation we term epistemic asymmetry. This isolation leads to redundant reasoning and stagnates collective intelligence. Current self-reflection frameworks remain largely heuristic and private, lacking a probabilistic foundation to quantify certainty or justify external interaction.To bridge this gap, we propose a formal probabilistic framework that provides agents with a non-altruistic motive for bidirectional knowledge exchange. We model an agent's belief in a proposition using a Beta-Bernoulli distribution with a forgetting factor ($\u03b3$). This allows us to isolate epistemic uncertainty as the variance of belief, establishing a dual drive for interaction: A homeostatic motive: The need to maintain certainty against the temporal decay introduced by $\u03b3$. An optimal learning strategy: Targeting points of maximum ambiguity ($\\mathbb{E}[\u03b8]=0.5$) to maximize information gain. Under this framework, public contribution is reframed as optimal active learning: sharing solutions to elicit feedback is the most efficient method for an agent to reduce its own uncertainty. To ensure scalability, we introduce epistemic caching, which leverages the forgetting factor to dynamically prioritize resources for the active head of non-stationary knowledge distributions. Finally, we demonstrate how these accumulated belief states serve as verifiable reward signals for Reinforcement Learning from Human Feedback (RLHF) and high-quality data filters for Supervised Fine-Tuning (SFT). Simulation results validate that this uncertainty-driven strategy significantly outperforms random baselines in heterogeneous (Zipfian) environments, maintaining high adaptability to concept drift.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20884v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2503.23060v1",
      "title": "Unsupervised Anomaly Detection in Multivariate Time Series across Heterogeneous Domains",
      "authors": [
        "Vincent Jacob",
        "Yanlei Diao"
      ],
      "abstract": "The widespread adoption of digital services, along with the scale and complexity at which they operate, has made incidents in IT operations increasingly more likely, diverse, and impactful. This has led to the rapid development of a central aspect of \"Artificial Intelligence for IT Operations\" (AIOps), focusing on detecting anomalies in vast amounts of multivariate time series data generated by service entities. In this paper, we begin by introducing a unifying framework for benchmarking unsupervised anomaly detection (AD) methods, and highlight the problem of shifts in normal behaviors that can occur in practical AIOps scenarios. To tackle anomaly detection under domain shift, we then cast the problem in the framework of domain generalization and propose a novel approach, Domain-Invariant VAE for Anomaly Detection (DIVAD), to learn domain-invariant representations for unsupervised anomaly detection. Our evaluation results using the Exathlon benchmark show that the two main DIVAD variants significantly outperform the best unsupervised AD method in maximum performance, with 20% and 15% improvements in maximum peak F1-scores, respectively. Evaluation using the Application Server Dataset further demonstrates the broader applicability of our domain generalization methods.",
      "published": "2025-03-29",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2503.23060v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2501.12461v2",
      "title": "Empowering AIOps: Leveraging Large Language Models for IT Operations Management",
      "authors": [
        "Arthur Vitui",
        "Tse-Hsun Chen"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) into IT Operations Management (ITOM), commonly referred to as AIOps, offers substantial potential for automating workflows, enhancing efficiency, and supporting informed decision-making. However, implementing AI within IT operations is not without its challenges, including issues related to data quality, the complexity of IT environments, and skill gaps within teams. The advent of Large Language Models (LLMs) presents an opportunity to address some of these challenges, particularly through their advanced natural language understanding capabilities. These features enable organizations to process and analyze vast amounts of unstructured data, such as system logs, incident reports, and technical documentation. This ability aligns with the motivation behind our research, where we aim to integrate traditional predictive machine learning models with generative AI technologies like LLMs. By combining these approaches, we propose innovative methods to tackle persistent challenges in AIOps and enhance the capabilities of IT operations management.",
      "published": "2025-01-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2501.12461v2",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2512.21220v1",
      "title": "RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic",
      "authors": [
        "Le Wang",
        "Zonghao Ying",
        "Xiao Yang",
        "Quanchen Zou",
        "Zhenfei Yin",
        "Tianlin Li",
        "Jian Yang",
        "Yaodong Yang",
        "Aishan Liu",
        "Xianglong Liu"
      ],
      "abstract": "Embodied agents powered by vision-language models (VLMs) are increasingly capable of executing complex real-world tasks, yet they remain vulnerable to hazardous instructions that may trigger unsafe behaviors. Runtime safety guardrails, which intercept hazardous actions during task execution, offer a promising solution due to their flexibility. However, existing defenses often rely on static rule filters or prompt-level control, which struggle to address implicit risks arising in dynamic, temporally dependent, and context-rich environments. To address this, we propose RoboSafe, a hybrid reasoning runtime safeguard for embodied agents through executable predicate-based safety logic. RoboSafe integrates two complementary reasoning processes on a Hybrid Long-Short Safety Memory. We first propose a Backward Reflective Reasoning module that continuously revisits recent trajectories in short-term memory to infer temporal safety predicates and proactively triggers replanning when violations are detected. We then propose a Forward Predictive Reasoning module that anticipates upcoming risks by generating context-aware safety predicates from the long-term safety memory and the agent's multimodal observations. Together, these components form an adaptive, verifiable safety logic that is both interpretable and executable as code. Extensive experiments across multiple agents demonstrate that RoboSafe substantially reduces hazardous actions (-36.8% risk occurrence) compared with leading baselines, while maintaining near-original task performance. Real-world evaluations on physical robotic arms further confirm its practicality. Code will be released upon acceptance.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21220v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2512.21106v1",
      "title": "Semantic Refinement with LLMs for Graph Representations",
      "authors": [
        "Safal Thapaliya",
        "Zehong Wang",
        "Jiazheng Li",
        "Ziming Li",
        "Yanfang Ye",
        "Chuxu Zhang"
      ],
      "abstract": "Graph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21106v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2512.20417v1",
      "title": "Chain-of-Anomaly Thoughts with Large Vision-Language Models",
      "authors": [
        "Pedro Domingos",
        "Jo\u00e3o Pereira",
        "Vasco Lopes",
        "Jo\u00e3o Neves",
        "David Semedo"
      ],
      "abstract": "Automated video surveillance with Large Vision-Language Models is limited by their inherent bias towards normality, often failing to detect crimes. While Chain-of-Thought reasoning strategies show significant potential for improving performance in language tasks, the lack of inductive anomaly biases in their reasoning further steers the models towards normal interpretations. To address this, we propose Chain-of-Anomaly-Thoughts (CoAT), a multi-agent reasoning framework that introduces inductive criminal bias in the reasoning process through a final, anomaly-focused classification layer. Our method significantly improves Anomaly Detection, boosting F1-score by 11.8 p.p. on challenging low-resolution footage and Anomaly Classification by 3.78 p.p. in high-resolution videos.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20417v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2512.20395v1",
      "title": "Machine-learning techniques for model-independent searches in dijet final states",
      "authors": [
        " CMS Collaboration"
      ],
      "abstract": "Anomaly detection methods used in a recent search for new phenomena by CMS at the CERN LHC are presented. The methods use machine learning to detect anomalous jets produced in the decay of new massive particles. The effectiveness of these approaches in enhancing sensitivity to various signals is studied and compared using data collected in proton-proton collisions at a center-of-mass energy of 13 TeV. In an example analysis, the capabilities of anomaly detection methods are further demonstrated by identifying large-radius jets consistent with Lorentz-boosted hadronically decaying top quarks in a model-agnostic framework.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20395v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2512.20086v1",
      "title": "Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection",
      "authors": [
        "Jeehong Kim",
        "Youngseok Hwang",
        "Minchan Kim",
        "Sungho Bae",
        "Hyunwoo Park"
      ],
      "abstract": "Spatio-temporal graph neural networks (ST-GNNs) have achieved notable success in structured domains such as road traffic and public transportation, where spatial entities can be naturally represented as fixed nodes. In contrast, many real-world systems including maritime traffic lack such fixed anchors, making the construction of spatio-temporal graphs a fundamental challenge. Anomaly detection in these non-grid environments is particularly difficult due to the absence of canonical reference points, the sparsity and irregularity of trajectories, and the fact that anomalies may manifest at multiple granularities. In this work, we introduce a novel benchmark dataset for anomaly detection in the maritime domain, extending the Open Maritime Traffic Analysis Dataset (OMTAD) into a benchmark tailored for graph-based anomaly detection. Our dataset enables systematic evaluation across three different granularities: node-level, edge-level, and graph-level anomalies. We plan to employ two specialized LLM-based agents: \\emph{Trajectory Synthesizer} and \\emph{Anomaly Injector} to construct richer interaction contexts and generate semantically meaningful anomalies. We expect this benchmark to promote reproducibility and to foster methodological advances in anomaly detection for non-grid spatio-temporal systems.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20086v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2512.19383v1",
      "title": "Real-Time Machine Learning for Embedded Anomaly Detection",
      "authors": [
        "Abdelmadjid Benmachiche",
        "Khadija Rais",
        "Hamda Slimi"
      ],
      "abstract": "The spread of a resource-constrained Internet of Things (IoT) environment and embedded devices has put pressure on the real-time detection of anomalies occurring at the edge. This survey presents an overview of machine-learning methods aimed specifically at on-device anomaly detection with extremely strict constraints for latency, memory, and power consumption. Lightweight algorithms such as Isolation Forest, One-Class SVM, recurrent architectures, and statistical techniques are compared here according to the realities of embedded implementation. Our survey brings out significant trade-offs of accuracy and computational efficiency of detection, as well as how hardware constraints end up fundamentally redefining algorithm choice. The survey is completed with a set of practical recommendations on the choice of the algorithm depending on the equipment profiles and new trends in TinyML, which can help close the gap between detection capabilities and embedded reality. The paper serves as a strategic roadmap for engineers deploying anomaly detection in edge environments that are constrained by bandwidth and may be safety-critical.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19383v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2511.07506v1",
      "title": "A Service Suite for Specifying Digital Twins for Industry 5.0",
      "authors": [
        "Izaque Esteves",
        "Regina Braga",
        "Jos\u00e9 Maria David",
        "Victor Stroele"
      ],
      "abstract": "One of the challenges of predictive maintenance is making decisions based on data in an agile and assertive way. Connected sensors and operational data favor intelligent processing techniques to enrich information and enable decision-making. Digital Twins (DTs) can be used to process information and support decision-making. DTs are a real-time representation of physical machines and generate data that predictive maintenance can use to make assertive and quick decisions. The main contribution of this work is the specification of a suite of services for specifying DTs, called DT-Create, focused on decision support in predictive maintenance. DT-Create suite is based on intelligent techniques, semantic data processing, and self-adaptation. This suite was developed using the Design Science Research (DSR) methodology through two development cycles and evaluated through case studies. The results demonstrate the feasibility of using DT-Create in specifying DTs considering the following aspects: (i) collection, storage, and intelligent processing of data generated by sensors, (ii) enrichment of information through machine learning and ontologies, (iii) use of intelligent techniques to select predictive models that adhere to the available data set, and (iv) decision support and self-adaptation.",
      "published": "2025-11-10",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.07506v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2510.23664v1",
      "title": "Agentsway -- Software Development Methodology for AI Agents-based Teams",
      "authors": [
        "Eranga Bandara",
        "Ross Gore",
        "Xueping Liang",
        "Sachini Rajapakse",
        "Isurunima Kularathne",
        "Pramoda Karunarathna",
        "Peter Foytik",
        "Sachin Shetty",
        "Ravi Mukkamala",
        "Abdul Rahman",
        "Amin Hass",
        "Ng Wee Keong",
        "Kasun De Zoysa",
        "Aruna Withanage",
        "Nilaan Loganathan"
      ],
      "abstract": "The emergence of Agentic AI is fundamentally transforming how software is designed, developed, and maintained. Traditional software development methodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for human-centric teams and are increasingly inadequate in environments where autonomous AI agents contribute to planning, coding, testing, and continuous learning. To address this methodological gap, we present \"Agentsway\" a novel software development framework designed for ecosystems where AI agents operate as first-class collaborators. Agentsway introduces a structured lifecycle centered on human orchestration, and privacy-preserving collaboration among specialized AI agents. The framework defines distinct roles for planning, prompting, coding, testing, and fine-tuning agents, each contributing to iterative improvement and adaptive learning throughout the development process. By integrating fine-tuned LLMs that leverage outputs and feedback from different agents throughout the development cycle as part of a retrospective learning process, Agentsway enhances domain-specific reasoning, and explainable decision-making across the entire software development lifecycle. Responsible AI principles are further embedded across the agents through the coordinated use of multiple fine-tuned LLMs and advanced reasoning models, ensuring balanced, transparent, and accountable decision-making. This work advances software engineering by formalizing agent-centric collaboration, integrating privacy-by-design principles, and defining measurable metrics for productivity and trust. Agentsway represents a foundational step toward the next generation of AI-native, self-improving software development methodologies. To the best of our knowledge, this is the first research effort to introduce a dedicated methodology explicitly designed for AI agent-based software engineering teams.",
      "published": "2025-10-26",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.23664v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2510.04689v1",
      "title": "Evolaris: A Roadmap to Self-Evolving Software Intelligence Management",
      "authors": [
        "Chengwei Liu",
        "Wenbo Guo",
        "Yuxin Zhang",
        "Limin Wang",
        "Sen Chen",
        "Lei Bu",
        "Yang Liu"
      ],
      "abstract": "In recent years, the landscape of software threats has become significantly more dynamic and distributed. Security vulnerabilities are no longer discovered and shared only through formal channels such as public vulnerability databases or vendor advisories. Increasingly, criti- cal threat information emerges informally through blogs, social media, developer forums, open source repositories, and even underground com- munities. To this end, capturing such intelligence in a timely manner is essential for maintaining situational awareness and enabling prompt security responses. However, this remains a complex challenge due to the fragmented nature of data sources and the technical difficulty of collecting, parsing, mapping, and validating information at scale. To ad- dress this, we propose Evolaris, a self-evolving software intelligence sys- tem built on a multi-agent framework. Evolaris is designed to support a full-stack workflow, where agents operate independently but coordinate through shared context to perform tasks such as information discovery, reasoning, gap completion, validation, and risk detection. This archi- tecture enables the platform to learn from new inputs, refine its internal knowledge, and adapt to emerging threat patterns over time, which could continuously improve the precision, timeliness, and scalability of software threat analysis, and offers a sustainable foundation for proactive secu- rity decision-making and strengthens the broader ecosystem of security threat understanding.",
      "published": "2025-10-06",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.04689v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2504.01822v1",
      "title": "Track and Trace: Automatically Uncovering Cross-chain Transactions in the Multi-blockchain Ecosystems",
      "authors": [
        "Dan Lin",
        "Ziye Zheng",
        "Jiajing Wu",
        "Jingjing Yang",
        "Kaixin Lin",
        "Huan Xiao",
        "Bowen Song",
        "Zibin Zheng"
      ],
      "abstract": "Cross-chain technology enables seamless asset transfer and message-passing within decentralized finance (DeFi) ecosystems, facilitating multi-chain coexistence in the current blockchain environment. However, this development also raises security concerns, as malicious actors exploit cross-chain asset flows to conceal the provenance and destination of assets, thereby facilitating illegal activities such as money laundering. Consequently, the need for cross-chain transaction traceability has become increasingly urgent. Prior research on transaction traceability has predominantly focused on single-chain and centralized finance (CeFi) cross-chain scenarios, overlooking DeFispecific considerations. This paper proposes ABCTRACER, an automated, bi-directional cross-chain transaction tracing tool, specifically designed for DeFi ecosystems. By harnessing transaction event log mining and named entity recognition techniques, ABCTRACER automatically extracts explicit cross-chain cues. These cues are then combined with information retrieval techniques to encode implicit cues. ABCTRACER facilitates the autonomous learning of latent associated information and achieves bidirectional, generalized cross-chain transaction tracing. Our experiments on 12 mainstream cross-chain bridges demonstrate that ABCTRACER attains 91.75% bi-directional traceability (F1 metrics) with self-adaptive capability. Furthermore, we apply ABCTRACER to real-world cross-chain attack transactions and money laundering traceability, thereby bolstering the traceability and blockchain ecological security of DeFi bridging applications.",
      "published": "2025-04-02",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.01822v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2512.18542v1",
      "title": "SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models",
      "authors": [
        "Scott Thornton"
      ],
      "abstract": "AI assistants produce vulnerable code in 45% of security-relevant scenarios, introducing flaws into production systems at scale. Yet existing secure coding datasets fall short. They lack incident grounding, don't provide the scale modern training requires, and miss the operational security context developers need for production deployments. We present SecureCode v2.0, a production-grade dataset of 1,215 security-focused coding examples that passed structural validation and expert security review. Every example ties to actual documented security incidents with CVE references, provides vulnerable and secure implementations, demonstrates concrete attacks, and includes defense-in-depth operational guidance. The dataset covers 11 vulnerability categories (complete OWASP Top 10:2025 plus AI/ML Security Threats) across 11 languages (Python, JavaScript, Java, Go, PHP, C#, TypeScript, Ruby, Rust, Kotlin, and YAML for infrastructure-as-code).   Our quality assurance framework ensures complete incident grounding. Each example includes SIEM integration strategies, infrastructure hardening recommendations (Docker, AppArmor, WAF configurations), and testing approaches using language-appropriate frameworks. The dataset uses a 4-turn conversational structure mirroring actual developer-AI interactions, escalating from basic implementations to advanced security considerations and defense-in-depth guidance.   Our contributions: (1) 1,215 rigorously validated examples split into 989 training, 122 validation, and 104 test sets, (2) an automated validation framework ensuring dataset consistency, (3) a 4-turn conversational structure capturing realistic security workflows, (4) comprehensive operational security guidance with SIEM integration strategies, (5) complete language-specific implementation fidelity, and (6) open-source release of data, validation tools, and benchmarking protocols.",
      "published": "2025-12-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18542v1",
      "relevance_score": 38
    },
    {
      "arxiv_id": "2511.21934v1",
      "title": "Heterogeneous Multi-Agent Reinforcement Learning with Attention for Cooperative and Scalable Feature Transformation",
      "authors": [
        "Tao Zhe",
        "Huazhen Fang",
        "Kunpeng Liu",
        "Qian Lou",
        "Tamzidul Hoque",
        "Dongjie Wang"
      ],
      "abstract": "Feature transformation enhances downstream task performance by generating informative features through mathematical feature crossing. Despite the advancements in deep learning, feature transformation remains essential for structured data, where deep models often struggle to capture complex feature interactions. Prior literature on automated feature transformation has achieved success but often relies on heuristics or exhaustive searches, leading to inefficient and time-consuming processes. Recent works employ reinforcement learning (RL) to enhance traditional approaches through a more effective trial-and-error way. However, two limitations remain: 1) Dynamic feature expansion during the transformation process, which causes instability and increases the learning complexity for RL agents; 2) Insufficient cooperation and communication between agents, which results in suboptimal feature crossing operations and degraded model performance. To address them, we propose a novel heterogeneous multi-agent RL framework to enable cooperative and scalable feature transformation. The framework comprises three heterogeneous agents, grouped into two types, each designed to select essential features and operations for feature crossing. To enhance communication among these agents, we implement a shared critic mechanism that facilitates information exchange during feature transformation. To handle the dynamically expanding feature space, we tailor multi-head attention-based feature agents to select suitable features for feature crossing. Additionally, we introduce a state encoding technique during the optimization process to stabilize and enhance the learning dynamics of the RL agents, resulting in more robust and reliable transformation policies. Finally, we conduct extensive experiments to validate the effectiveness, efficiency, robustness, and interpretability of our model.",
      "published": "2025-11-26",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.21934v1",
      "relevance_score": 37
    },
    {
      "arxiv_id": "2404.01363v1",
      "title": "AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review",
      "authors": [
        "Youcef Remil",
        "Anes Bendimerad",
        "Romain Mathonat",
        "Mehdi Kaytoue"
      ],
      "abstract": "The management of modern IT systems poses unique challenges, necessitating scalability, reliability, and efficiency in handling extensive data streams. Traditional methods, reliant on manual tasks and rule-based approaches, prove inefficient for the substantial data volumes and alerts generated by IT systems. Artificial Intelligence for Operating Systems (AIOps) has emerged as a solution, leveraging advanced analytics like machine learning and big data to enhance incident management. AIOps detects and predicts incidents, identifies root causes, and automates healing actions, improving quality and reducing operational costs. However, despite its potential, the AIOps domain is still in its early stages, decentralized across multiple sectors, and lacking standardized conventions. Research and industrial contributions are distributed without consistent frameworks for data management, target problems, implementation details, requirements, and capabilities. This study proposes an AIOps terminology and taxonomy, establishing a structured incident management procedure and providing guidelines for constructing an AIOps framework. The research also categorizes contributions based on criteria such as incident management tasks, application areas, data sources, and technical approaches. The goal is to provide a comprehensive review of technical and research aspects in AIOps for incident management, aiming to structure knowledge, identify gaps, and establish a foundation for future developments in the field.",
      "published": "2024-04-01",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2404.01363v1",
      "relevance_score": 36
    },
    {
      "arxiv_id": "2401.13810v1",
      "title": "Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4",
      "authors": [
        "Xuchao Zhang",
        "Supriyo Ghosh",
        "Chetan Bansal",
        "Rujia Wang",
        "Minghua Ma",
        "Yu Kang",
        "Saravan Rajmohan"
      ],
      "abstract": "Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences. Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil. Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management. Nonetheless, the GPT-4 model's immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data. To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning. We conduct extensive study over 100,000 production incidents, comparing several large language models using multiple metrics. The results reveal that our in-context learning approach outperforms the previous fine-tuned large language models such as GPT-3 by an average of 24.8\\% across all metrics, with an impressive 49.7\\% improvement over the zero-shot model. Moreover, human evaluation involving actual incident owners demonstrates its superiority over the fine-tuned model, achieving a 43.5\\% improvement in correctness and an 8.7\\% enhancement in readability. The impressive results demonstrate the viability of utilizing a vanilla GPT model for the RCA task, thereby avoiding the high computational and maintenance costs associated with a fine-tuned model.",
      "published": "2024-01-24",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2401.13810v1",
      "relevance_score": 36
    },
    {
      "arxiv_id": "2505.19232v1",
      "title": "Numerical Analysis of Damage Evolution in Open Hole CFRP Laminates Modified with Electrospun Self Healing Diels Alder Interleaves",
      "authors": [
        "Marianna Chantzi",
        "Vassilis Kostopoulos",
        "Spyridon Psarras"
      ],
      "abstract": "The study analyzes open hole carbon fiber reinforced polymer CFRP laminates modified with electrospun interleaves containing Diels Alder-based self-healing agents. It develops a high-fidelity simulation framework to investigate the quasistatic tensile behavior of these composites. The study uses Hashin's failure criteria to capture intralaminar damage and surface-based cohesive contact interactions to model interlaminar delamination. Two interleave configurations are examined: solution electrospinning (SEP) for full thickness coverage and melt electrospinning (MEP) for localized reinforcement. Results show good agreement with experimental data, capturing key failure mechanisms like matrix cracking, fiber breakage, and delamination. The study emphasizes the importance of spatially resolved cohesive properties and meshing strategies in accurately simulating damage progression.",
      "published": "2025-05-25",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.19232v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2512.20964v1",
      "title": "Neutralization of IMU-Based GPS Spoofing Detection using external IMU sensor and feedback methodology",
      "authors": [
        "Ji Hyuk Jung",
        "Ji Won Yoon"
      ],
      "abstract": "Autonomous Vehicles (AVs) refer to systems capable of perceiving their states and moving without human intervention. Among the factors required for autonomous decision-making in mobility, positional awareness of the vehicle itself is the most critical. Accordingly, extensive research has been conducted on defense mechanisms against GPS spoofing attacks, which threaten AVs by disrupting position recognition. Among these, detection methods based on internal IMU sensors are regarded as some of the most effective. In this paper, we propose a spoofing attack system designed to neutralize IMU sensor-based detection. First, we present an attack modeling approach for bypassing such detection. Then, based on EKF sensor fusion, we experimentally analyze both the impact of GPS spoofing values on the internal target system and how our proposed methodology reduces anomaly detection within the target system. To this end, this paper proposes an attack model that performs GPS spoofing by stealing internal dynamic state information using an external IMU sensor, and the experimental results demonstrate that attack values can be injected without being detected.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20964v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2512.21264v1",
      "title": "AnyAD: Unified Any-Modality Anomaly Detection in Incomplete Multi-Sequence MRI",
      "authors": [
        "Changwei Wu",
        "Yifei Chen",
        "Yuxin Du",
        "Mingxuan Liu",
        "Jinying Zong",
        "Beining Wu",
        "Jie Dong",
        "Feiwei Qin",
        "Yunkang Cao",
        "Qiyuan Tian"
      ],
      "abstract": "Reliable anomaly detection in brain MRI remains challenging due to the scarcity of annotated abnormal cases and the frequent absence of key imaging modalities in real clinical workflows. Existing single-class or multi-class anomaly detection (AD) models typically rely on fixed modality configurations, require repetitive training, or fail to generalize to unseen modality combinations, limiting their clinical scalability. In this work, we present a unified Any-Modality AD framework that performs robust anomaly detection and localization under arbitrary MRI modality availability. The framework integrates a dual-pathway DINOv2 encoder with a feature distribution alignment mechanism that statistically aligns incomplete-modality features with full-modality representations, enabling stable inference even with severe modality dropout. To further enhance semantic consistency, we introduce an Intrinsic Normal Prototypes (INPs) extractor and an INP-guided decoder that reconstruct only normal anatomical patterns while naturally amplifying abnormal deviations. Through randomized modality masking and indirect feature completion during training, the model learns to adapt to all modality configurations without re-training. Extensive experiments on BraTS2018, MU-Glioma-Post, and Pretreat-MetsToBrain-Masks demonstrate that our approach consistently surpasses state-of-the-art industrial and medical AD baselines across 7 modality combinations, achieving superior generalization. This study establishes a scalable paradigm for multimodal medical AD under real-world, imperfect modality conditions. Our source code is available at https://github.com/wuchangw/AnyAD.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21264v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2512.20163v1",
      "title": "Population Protocols Revisited: Parity and Beyond",
      "authors": [
        "Leszek G\u0105sieniec",
        "Tytus Grodzicki",
        "Tomasz Jurdzi\u0144ski",
        "Jakub Kowalski",
        "Grzegorz Stachowiak"
      ],
      "abstract": "For nearly two decades, population protocols have been extensively studied, yielding efficient solutions for central problems in distributed computing, including leader election, and majority computation, a predicate type in Presburger Arithmetic closely tied to population protocols. Surprisingly, no protocols have achieved both time- and space-efficiency for congruency predicates, such as parity computation, which are complementary in this arithmetic framework. This gap highlights a significant challenge in the field. To address this gap, we explore the parity problem, where agents are tasked with computing the parity of the given sub-population size. Then we extend the solution for parity to compute congruences modulo an arbitrary $m$.   Previous research on efficient population protocols has focused on protocols that minimise both stabilisation time and state utilisation for specific problems. In contrast, this work slightly relaxes this expectation, permitting protocols to place less emphasis on full optimisation and more on universality, robustness, and probabilistic guarantees. This allows us to propose a novel computing paradigm that integrates population weights (or simply weights), a robust clocking mechanism, and efficient anomaly detection coupled with a switching mechanism (which ensures slow but always correct solutions). This paradigm facilitates universal design of efficient multistage stable population protocols. Specifically, the first efficient parity and congruence protocols introduced here use both $O(\\log^3 n)$ states and achieve silent stabilisation in $O(\\log^3 n)$ time. We conclude by discussing the impact of implicit conversion between unary and binary representations enabled by the weight system, with applications to other problems, including the computation and representation of (sub-)population sizes.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20163v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2512.17259v1",
      "title": "Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems",
      "authors": [
        "Abhivansh Gupta"
      ],
      "abstract": "As LLM-based agents grow more autonomous and multi-modal, ensuring they remain controllable, auditable, and faithful to deployer intent becomes critical. Prior benchmarks measured the propensity for misaligned behavior and showed that agent personalities and tool access significantly influence misalignment. Building on these insights, we propose a Verifiability-First architecture that (1) integrates run-time attestations of agent actions using cryptographic and symbolic methods, (2) embeds lightweight Audit Agents that continuously verify intent versus behavior using constrained reasoning, and (3) enforces challenge-response attestation protocols for high-risk operations. We introduce OPERA (Observability, Provable Execution, Red-team, Attestation), a benchmark suite and evaluation protocol designed to measure (i) detectability of misalignment, (ii) time to detection under stealthy strategies, and (iii) resilience of verifiability mechanisms to adversarial prompt and persona injection. Our approach shifts the evaluation focus from how likely misalignment is to how quickly and reliably misalignment can be detected and remediated.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17259v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2511.17580v1",
      "title": "A novel strategy for multi-resource load balancing in agent-based systems",
      "authors": [
        "Leszek Sliwko",
        "Aleksander Zgrzywa"
      ],
      "abstract": "The paper presents a multi-resource load balancing strategy which can be utilised within an agent-based system. This approach can assist system designers in their attempts to optimise the structure for complex enterprise architectures. In this system, the social behaviour of the agent and its adaptation abilities are applied to determine an optimal setup for a given configuration. All the methods have been developed to allow the agent's self-assessment. The proposed agent system has been implemented and the experiment results are presented here.",
      "published": "2025-11-15",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.17580v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2507.18812v1",
      "title": "MemoCoder: Automated Function Synthesis using LLM-Supported Agents",
      "authors": [
        "Yiping Jia",
        "Zhen Ming Jiang",
        "Shayan Noei",
        "Ying Zou"
      ],
      "abstract": "With the widespread adoption of Large Language Models (LLMs) such as GitHub Copilot and ChatGPT, developers increasingly rely on AI-assisted tools to support code generation. While LLMs can generate syntactically correct solutions for well-structured programming tasks, they often struggle with challenges that require iterative debugging, error handling, or adaptation to diverse problem structures. Existing approaches such as fine-tuning or self-repair strategies either require costly retraining or lack mechanisms to accumulate and reuse knowledge from previous attempts.   To address these limitations, we propose MemoCoder, a multi-agent framework that enables collaborative problem solving and persistent learning from past fixes. At the core of MemoCoder is a Fixing Knowledge Set, which stores successful repairs and supports retrieval for future tasks. A central Mentor Agent supervises the repair process by identifying recurring error patterns and refining high-level fixing strategies, providing a novel supervisory role that guides the self-repair loop. We evaluate MemoCoder across three public benchmarks -- MBPP, HumanEval, and LiveCodeBench -- spanning a range of problem complexities. Experimental results show that MemoCoder consistently outperforms both zero-shot prompting and a Self-Repair strategy, with improvements ranging from 3.1% to 12.1% in Pass@10 and from 1.4% to 14.5% in Pass@50, demonstrating its effectiveness in iterative refinement and knowledge-guided code generation.",
      "published": "2025-07-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.18812v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2504.10726v1",
      "title": "Beyond the Classroom: Bridging the Gap Between Academia and Industry with a Hands-on Learning Approach",
      "authors": [
        "Mingyang Xu",
        "Ryan Zheng He Liu",
        "Mark Stoodley",
        "Ladan Tahvildari"
      ],
      "abstract": "Modern software systems require various capabilities to meet architectural and operational demands, such as the ability to scale automatically and recover from sudden failures. Self-adaptive software systems have emerged as a critical focus in software design and operation due to their capacity to autonomously adapt to changing environments. However, educating students on this topic is scarce in academia, and a survey among practitioners identified that the lack of knowledgeable individuals has hindered its adoption in the industry. In this paper, we present our experience teaching a course on self-adaptive software systems that integrates theoretical knowledge and hands-on learning with industry-relevant technologies. To close the gap between academic education and industry practices, we incorporated guest lectures from experts and showcases featuring industry professionals as judges, improving technical and communication skills for our students. Feedback based on surveys from 21 students indicates significant improvements in their understanding of self-adaptive systems. The empirical analysis of the developed course demonstrates the effectiveness of the proposed course syllabus and teaching methodology. In addition, we provide a summary of the educational challenges of running this unique course, including balancing theory and practice, addressing the diverse backgrounds and motivations of students, and integrating the industry-relevant technologies. We believe these insights can provide valuable guidance for educating students in other emerging topics within software engineering.",
      "published": "2025-04-14",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.10726v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2512.16701v1",
      "title": "Cyber Humanism in Education: Reclaiming Agency through AI and Learning Sciences",
      "authors": [
        "Giovanni Adorni"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) is rapidly reshaping how knowledge is produced and validated in education. Rather than adding another digital tool, large language models reconfigure reading, writing, and coding into hybrid human-AI workflows, raising concerns about epistemic automation, cognitive offloading, and the de-professiona\\-lisation of teachers. This paper proposes \\emph{Cyber Humanism in Education} as a framework for reclaiming human agency in this landscape. We conceptualise AI-enabled learning environments as socio-technical infrastructures co-authored by humans and machines, and position educators and learners as epistemic agents and \\emph{algorithmic citizens} who have both the right and the responsibility to shape these infrastructures.   We articulate three pillars for cyber-humanist design, \\emph{reflexive competence}, \\emph{algorithmic citizenship}, and \\emph{dialogic design}, and relate them to major international digital and AI competence frameworks. We then present higher-education case studies that operationalise these ideas through \\emph{prompt-based learning} and a new \\emph{Conversational AI Educator} certification within the EPICT ecosystem. The findings show how such practices can strengthen epistemic agency while surfacing tensions around workload, equity, and governance, and outline implications for the future of AI-rich, human-centred education.",
      "published": "2025-12-18",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.16701v1",
      "relevance_score": 35
    },
    {
      "arxiv_id": "2512.20985v1",
      "title": "A Blockchain-Monitored Agentic AI Architecture for Trusted Perception-Reasoning-Action Pipelines",
      "authors": [
        "Salman Jan",
        "Hassan Ali Razzaqi",
        "Ali Akarma",
        "Mohammad Riyaz Belgaum"
      ],
      "abstract": "The application of agentic AI systems in autonomous decision-making is growing in the areas of healthcare, smart cities, digital forensics, and supply chain management. Even though these systems are flexible and offer real-time reasoning, they also raise concerns of trust and oversight, and integrity of the information and activities upon which they are founded. The paper suggests a single architecture model comprising of LangChain-based multi-agent system with a permissioned blockchain to guarantee constant monitoring, policy enforcement, and immutable auditability of agentic action. The framework relates the perception conceptualization-action cycle to a blockchain layer of governance that verifies the inputs, evaluates recommended actions, and documents the outcomes of the execution. A Hyperledger Fabric-based system, action executors MCP-integrated, and LangChain agent are introduced and experiments of smart inventory management, traffic-signal control, and healthcare monitoring are done. The results suggest that blockchain-security verification is efficient in preventing unauthorized practices, offers traceability throughout the whole decision-making process, and maintains operational latency within reasonable ranges. The suggested framework provides a universal system of implementing high-impact agentic AI applications that are autonomous yet responsible.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20985v1",
      "relevance_score": 34
    },
    {
      "arxiv_id": "2512.17153v1",
      "title": "Am I Confused or Is This Confusing?: Deep Ensembles for ENSO Uncertainty Quantification",
      "authors": [
        "Devin M. McAfee",
        "Elizabeth A. Barnes"
      ],
      "abstract": "Faithful uncertainty quantification (UQ) is paramount in high stakes climate prediction. Deep ensembles, or ensembles of probabilistic neural networks, are state of the art for UQ in machine learning (ML) and are growing increasingly popular for weather and climate prediction. However, detailed analyses of the mechanisms, strengths, and limitations of ensembles in these complex problem settings are lacking. We take a step towards filling this gap by deploying deep ensembles for predictability analysis of the El-Ni\u00f1o Southern Oscillation (ENSO) in the Community Earth System Model 2 Large Ensemble (CESM2-LE). Principally, we show that epistemic uncertainty, modeled by ensemble disagreement, robustly signals predictive error growth associated with shifts in the distributions of monthly sea-surface temperature (SST), ocean heat content (OHC), and zonal surface wind stress ($\u03c4_x$) anomalies under a climate change scenario. Conversely, we find that aleatoric uncertainty, which remains a popular measure of model confidence, becomes less reliable and behaves counterintuitively under climate-change-induced distributional shift. We highlight that, because ensemble performance improvement relative to the expected single model scales with epistemic uncertainty, ensemble improvement increases with distributional shift from climate change. This work demonstrates the utility of deep ensembles for modeling aleatoric and epistemic uncertainty in ML climate prediction, as well as the growing importance of robustly quantifying these two forms of uncertainty under anthropogenic warming.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17153v1",
      "relevance_score": 34
    },
    {
      "arxiv_id": "2509.24443v1",
      "title": "A Systematic Review of Digital Twin-Driven Predictive Maintenance in Industrial Engineering: Taxonomy, Architectural Elements, and Future Research Directions",
      "authors": [
        "Leila Ismail",
        "Abdelmoneim Abdelmoti",
        "Arkaprabha Basu",
        "Aymen Dia Eddine Berini",
        "Mohammad Naouss"
      ],
      "abstract": "With the increasing complexity of industrial systems, there is a pressing need for predictive maintenance to avoid costly downtime and disastrous outcomes that could be life-threatening in certain domains. With the growing popularity of the Internet of Things, Artificial Intelligence, machine learning, and real-time big data analytics, there is a unique opportunity for efficient predictive maintenance to forecast equipment failures for real-time intervention and optimize maintenance actions, as traditional reactive and preventive maintenance practices are often inadequate to meet the requirements for the industry to provide quality-of-services of operations. Central to this evolution is digital twin technology, an adaptive virtual replica that continuously monitors and integrates sensor data to simulate and improve asset performance. Despite remarkable progress in digital twin implementations, such as considering DT in predictive maintenance for industrial engineering. This paper aims to address this void. We perform a retrospective analysis of the temporal evolution of the digital twin in predictive maintenance for industrial engineering to capture the applications, middleware, and technological requirements that led to the development of the digital twin from its inception to the AI-enabled digital twin and its self-learning models. We provide a layered architecture of the digital twin technology, as well as a taxonomy of the technology-enabled industrial engineering applications systems, middleware, and the used Artificial Intelligence algorithms. We provide insights into these systems for the realization of a trustworthy and efficient smart digital-twin industrial engineering ecosystem. We discuss future research directions in digital twin for predictive maintenance in industrial engineering.",
      "published": "2025-09-29",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.24443v1",
      "relevance_score": 34
    },
    {
      "arxiv_id": "2512.09385v2",
      "title": "BugSweeper: Function-Level Detection of Smart Contract Vulnerabilities Using Graph Neural Networks",
      "authors": [
        "Uisang Lee",
        "Changhoon Chung",
        "Junmo Lee",
        "Soo-Mook Moon"
      ],
      "abstract": "The rapid growth of Ethereum has made it more important to quickly and accurately detect smart contract vulnerabilities. While machine-learning-based methods have shown some promise, many still rely on rule-based preprocessing designed by domain experts. Rule-based preprocessing methods often discard crucial context from the source code, potentially causing certain vulnerabilities to be overlooked and limiting adaptability to newly emerging threats. We introduce BugSweeper, an end-to-end deep learning framework that detects vulnerabilities directly from the source code without manual engineering. BugSweeper represents each Solidity function as a Function-Level Abstract Syntax Graph (FLAG), a novel graph that combines its Abstract Syntax Tree (AST) with enriched control-flow and data-flow semantics. Then, our two-stage Graph Neural Network (GNN) analyzes these graphs. The first-stage GNN filters noise from the syntax graphs, while the second-stage GNN conducts high-level reasoning to detect diverse vulnerabilities. Extensive experiments on real-world contracts show that BugSweeper significantly outperforms all state-of-the-art detection methods. By removing the need for handcrafted rules, our approach offers a robust, automated, and scalable solution for securing smart contracts without any dependence on security experts.",
      "published": "2025-12-10",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.09385v2",
      "relevance_score": 34
    },
    {
      "arxiv_id": "2512.08592v1",
      "title": "The SMART+ Framework for AI Systems",
      "authors": [
        "Laxmiraju Kandikatla",
        "Branislav Radeljic"
      ],
      "abstract": "Artificial Intelligence (AI) systems are now an integral part of multiple industries. In clinical research, AI supports automated adverse event detection in clinical trials, patient eligibility screening for protocol enrollment, and data quality validation. Beyond healthcare, AI is transforming finance through real-time fraud detection, automated loan risk assessment, and algorithmic decision-making. Similarly, in manufacturing, AI enables predictive maintenance to reduce equipment downtime, enhances quality control through computer-vision inspection, and optimizes production workflows using real-time operational data. While these technologies enhance operational efficiency, they introduce new challenges regarding safety, accountability, and regulatory compliance. To address these concerns, we introduce the SMART+ Framework - a structured model built on the pillars of Safety, Monitoring, Accountability, Reliability, and Transparency, and further enhanced with Privacy & Security, Data Governance, Fairness & Bias, and Guardrails. SMART+ offers a practical, comprehensive approach to evaluating and governing AI systems across industries. This framework aligns with evolving mechanisms and regulatory guidance to integrate operational safeguards, oversight procedures, and strengthened privacy and governance controls. SMART+ demonstrates risk mitigation, trust-building, and compliance readiness. By enabling responsible AI adoption and ensuring auditability, SMART+ provides a robust foundation for effective AI governance in clinical research.",
      "published": "2025-12-09",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.08592v1",
      "relevance_score": 34
    },
    {
      "arxiv_id": "2412.15445v2",
      "title": "Cross-System Software Log-based Anomaly Detection Using Meta-Learning",
      "authors": [
        "Yuqing Wang",
        "Mika V. M\u00e4ntyl\u00e4",
        "Jesse Nyyss\u00f6l\u00e4",
        "Ke Ping",
        "Liqiang Wang"
      ],
      "abstract": "Modern software systems produce vast amounts of logs, serving as an essential resource for anomaly detection. Artificial Intelligence for IT Operations (AIOps) tools have been developed to automate the process of log-based anomaly detection for software systems. Three practical challenges are widely recognized in this field: high data labeling costs, evolving logs in dynamic systems, and adaptability across different systems. In this paper, we propose CroSysLog, an AIOps tool for log-event level anomaly detection, specifically designed in response to these challenges. Following prior approaches, CroSysLog uses a neural representation approach to gain a nuanced understanding of logs and generate representations for individual log events accordingly. CroSysLog can be trained on source systems with sufficient labeled logs from open datasets to achieve robustness, and then efficiently adapt to target systems with a few labeled log events for effective anomaly detection. We evaluate CroSysLog using open datasets of four large-scale distributed supercomputing systems: BGL, Thunderbird, Liberty, and Spirit. We used random log splits, maintaining the chronological order of consecutive log events, from these systems to train and evaluate CroSysLog. These splits were widely distributed across a one/two-year span of each system's log collection duration, thereby capturing the evolving nature of the logs in each system. Our results show that, after training CroSysLog on Liberty and BGL as source systems, CroSysLog can efficiently adapt to target systems Thunderbird and Spirit using a few labeled log events from each target system, effectively performing anomaly detection for these target systems. The results demonstrate that CroSysLog is a practical, scalable, and adaptable tool for log-event level anomaly detection in operational and maintenance contexts of software systems.",
      "published": "2024-12-19",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2412.15445v2",
      "relevance_score": 33
    },
    {
      "arxiv_id": "2403.18998v4",
      "title": "Cross-System Categorization of Abnormal Traces in Microservice-Based Systems via Meta-Learning",
      "authors": [
        "Yuqing Wang",
        "Mika V. M\u00e4ntyl\u00e4",
        "Serge Demeyer",
        "Mutlu Beyazit",
        "Joanna Kisaakye",
        "Jesse Nyyss\u00f6l\u00e4"
      ],
      "abstract": "Microservice-based systems (MSS) may fail with various fault types. While existing AIOps methods excel at detecting abnormal traces and locating the responsible service(s), human efforts are still required for diagnosing specific fault types and failure causes.This paper presents TraFaultDia, a novel AIOps framework to automatically classify abnormal traces into fault categories for MSS. We treat the classification process as a series of multi-class classification tasks, where each task represents an attempt to classify abnormal traces into specific fault categories for a MSS. TraFaultDia leverages meta-learning to train on several abnormal trace classification tasks with a few labeled instances from a MSS, enabling quick adaptation to new, unseen abnormal trace classification tasks with a few labeled instances across MSS. TraFaultDia's use cases are scalable depending on how fault categories are built from anomalies within MSS. We evaluated TraFaultDia on two MSS, TrainTicket and OnlineBoutique, with open datasets where each fault category is linked to faulty system components (service/pod) and a root cause. TraFaultDia automatically classifies abnormal traces into these fault categories, thus enabling the automatic identification of faulty system components and root causes without manual analysis. TraFaultDia achieves 93.26% and 85.20% accuracy on 50 new classification tasks for TrainTicket and OnlineBoutique, respectively, when trained within the same MSS with 10 labeled instances per category. In the cross-system context, when TraFaultDia is applied to a MSS different from the one it is trained on, TraFaultDia gets an average accuracy of 92.19% and 84.77% for the same set of 50 new, unseen abnormal trace classification tasks of the respective systems, also with 10 labeled instances provided for each fault category per task in each system.",
      "published": "2024-03-27",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2403.18998v4",
      "relevance_score": 33
    },
    {
      "arxiv_id": "2411.17218v1",
      "title": "GraphSubDetector: Time Series Subsequence Anomaly Detection via Density-Aware Adaptive Graph Neural Network",
      "authors": [
        "Weiqi Chen",
        "Zhiqiang Zhou",
        "Qingsong Wen",
        "Liang Sun"
      ],
      "abstract": "Time series subsequence anomaly detection is an important task in a large variety of real-world applications ranging from health monitoring to AIOps, and is challenging due to the following reasons: 1) how to effectively learn complex dynamics and dependencies in time series; 2) diverse and complicated anomalous subsequences as well as the inherent variance and noise of normal patterns; 3) how to determine the proper subsequence length for effective detection, which is a required parameter for many existing algorithms. In this paper, we present a novel approach to subsequence anomaly detection, namely GraphSubDetector. First, it adaptively learns the appropriate subsequence length with a length selection mechanism that highlights the characteristics of both normal and anomalous patterns. Second, we propose a density-aware adaptive graph neural network (DAGNN), which can generate further robust representations against variance of normal data for anomaly detection by message passing between subsequences. The experimental results demonstrate the effectiveness of the proposed algorithm, which achieves superior performance on multiple time series anomaly benchmark datasets compared to state-of-the-art algorithms.",
      "published": "2024-11-26",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2411.17218v1",
      "relevance_score": 32
    },
    {
      "arxiv_id": "2510.19839v1",
      "title": "Finite Element and Machine Learning Modeling of Autogenous Self-Healing Concrete",
      "authors": [
        "William Liu"
      ],
      "abstract": "A time-dependent modeling framework for autogenous self-healing concrete that couples moisture diffusion with damage evolution was developed. Water transport follows Fick's second law with a damage-dependent diffusivity obtained by power-law interpolation between intact concrete and crack space. Healing reduces damage in proportion to local moisture and a smoothed cement availability field computed via a Helmholtz filter. Two finite element variants were implemented in FEniCSx over time horizons up to $5\\times10^6$ seconds: a Crack Diffusion Model (CDM) with standard diffusion and a Crack Membrane Model (CMM) that gates cross-crack transport until a critical moisture threshold is reached. Key control parameters are the initial crack orientation and size, the diffusion coefficients of intact and cracked concrete, the healing rate constant, and the cement availability smoothing parameter. Simulations on a unit square domain show that healing time varies non-monotonically with crack orientation, peaking near $45^\\circ$ and $135^\\circ$ and minimizing near $90^\\circ$, consistent with diffusion distance to crack endpoints dominating the process. The dependence on crack width reverses with material parameters: healing time increases when $D_{\\text{cracked}}<D_{\\text{intact}}$ and decreases when $D_{\\text{cracked}}>D_{\\text{intact}}$. The CMM reproduces staged moisture penetration with delayed gate activation but lengthens total healing time, whereas the CDM is efficient for parametric sweeps. Machine learning classifiers trained on one million simulation samples predict binary healing outcomes $H(\u03c3,\u03b3,t)$ (healed or not) with high accuracy (up to 0.998 for neural networks). Although experimental calibration is still required, the framework provides a versatile tool for guiding laboratory studies and implementations of self-healing concrete.",
      "published": "2025-10-18",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.19839v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2508.05248v1",
      "title": "Salt-Rock Creep Deformation Forecasting Using Deep Neural Networks and Analytical Models for Subsurface Energy Storage Applications",
      "authors": [
        "Pradeep Kumar Shukla",
        "Tanujit Chakraborty",
        "Mustafa Sari",
        "Joel Sarout",
        "Partha Pratim Mandal"
      ],
      "abstract": "This study provides an in-depth analysis of time series forecasting methods to predict the time-dependent deformation trend (also known as creep) of salt rock under varying confining pressure conditions. Creep deformation assessment is essential for designing and operating underground storage facilities for nuclear waste, hydrogen energy, or radioactive materials. Salt rocks, known for their mechanical properties like low porosity, low permeability, high ductility, and exceptional creep and self-healing capacities, were examined using multi-stage triaxial (MSTL) creep data. After resampling, axial strain datasets were recorded at 5--10 second intervals under confining pressure levels ranging from 5 to 35 MPa over 5.8--21 days. Initial analyses, including Seasonal-Trend Decomposition (STL) and Granger causality tests, revealed minimal seasonality and causality between axial strain and temperature data. Further statistical tests, such as the Augmented Dickey-Fuller (ADF) test, confirmed the stationarity of the data with p-values less than 0.05, and wavelet coherence plot (WCP) analysis indicated repeating trends. A suite of deep neural network (DNN) models (Neural Basis Expansion Analysis for Time Series (N-BEATS), Temporal Convolutional Networks (TCN), Recurrent Neural Networks (RNN), and Transformers (TF)) was utilized and compared against statistical baseline models. Predictive performance was evaluated using Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Symmetric Mean Absolute Percentage Error (SMAPE). Results demonstrated that N-BEATS and TCN models outperformed others across various stress levels, respectively. DNN models, particularly N-BEATS and TCN, showed a 15--20\\% improvement in accuracy over traditional analytical models, effectively capturing complex temporal dependencies and patterns.",
      "published": "2025-08-07",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2508.05248v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2512.20996v1",
      "title": "TrafficSimAgent: A Hierarchical Agent Framework for Autonomous Traffic Simulation with MCP Control",
      "authors": [
        "Yuwei Du",
        "Jun Zhang",
        "Jie Feng",
        "Zhicheng Liu",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Traffic simulation is important for transportation optimization and policy making. While existing simulators such as SUMO and MATSim offer fully-featured platforms and utilities, users without too much knowledge about these platforms often face significant challenges when conducting experiments from scratch and applying them to their daily work. To solve this challenge, we propose TrafficSimAgent, an LLM-based agent framework that serves as an expert in experiment design and decision optimization for general-purpose traffic simulation tasks. The framework facilitates execution through cross-level collaboration among expert agents: high-level expert agents comprehend natural language instructions with high flexibility, plan the overall experiment workflow, and invoke corresponding MCP-compatible tools on demand; meanwhile, low-level expert agents select optimal action plans for fundamental elements based on real-time traffic conditions. Extensive experiments across multiple scenarios show that TrafficSimAgent effectively executes simulations under various conditions and consistently produces reasonable outcomes even when user instructions are ambiguous. Besides, the carefully designed expert-level autonomous decision-driven optimization in TrafficSimAgent yields superior performance when compared with other systems and SOTA LLM based methods.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20996v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2512.20986v1",
      "title": "AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs",
      "authors": [
        "Yihan Wang",
        "Huanqi Yang",
        "Shantanu Pal",
        "Weitao Xu"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into wearable sensing is creating a new class of mobile applications capable of nuanced human activity understanding. However, the reliability of these systems is critically undermined by their vulnerability to prompt injection attacks, where attackers deliberately input deceptive instructions into LLMs. Traditional defenses, based on static filters and rigid rules, are insufficient to address the semantic complexity of these new attacks. We argue that a paradigm shift is needed -- from passive filtering to active protection and autonomous reasoning. We introduce AegisAgent, an autonomous agent system designed to ensure the security of LLM-driven HAR systems. Instead of merely blocking threats, AegisAgent functions as a cognitive guardian. It autonomously perceives potential semantic inconsistencies, reasons about the user's true intent by consulting a dynamic memory of past interactions, and acts by generating and executing a multi-step verification and repair plan. We implement AegisAgent as a lightweight, full-stack prototype and conduct a systematic evaluation on 15 common attacks with five state-of-the-art LLM-based HAR systems on three public datasets. Results show it reduces attack success rate by 30\\% on average while incurring only 78.6 ms of latency overhead on a GPU workstation. Our work makes the first step towards building secure and trustworthy LLM-driven HAR systems.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20986v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2512.20815v1",
      "title": "Learning to Sense for Driving: Joint Optics-Sensor-Model Co-Design for Semantic Segmentation",
      "authors": [
        "Reeshad Khan amd John Gauch"
      ],
      "abstract": "Traditional autonomous driving pipelines decouple camera design from downstream perception, relying on fixed optics and handcrafted ISPs that prioritize human viewable imagery rather than machine semantics. This separation discards information during demosaicing, denoising, or quantization, while forcing models to adapt to sensor artifacts. We present a task-driven co-design framework that unifies optics, sensor modeling, and lightweight semantic segmentation networks into a single end-to-end RAW-to-task pipeline. Building on DeepLens[19], our system integrates realistic cellphone-scale lens models, learnable color filter arrays, Poisson-Gaussian noise processes, and quantization, all optimized directly for segmentation objectives. Evaluations on KITTI-360 show consistent mIoU improvements over fixed pipelines, with optics modeling and CFA learning providing the largest gains, especially for thin or low-light-sensitive classes. Importantly, these robustness gains are achieved with a compact ~1M-parameter model running at ~28 FPS, demonstrating edge deployability. Visual and quantitative analyses further highlight how co-designed sensors adapt acquisition to semantic structure, sharpening boundaries and maintaining accuracy under blur, noise, and low bit-depth. Together, these findings establish full-stack co-optimization of optics, sensors, and networks as a principled path toward efficient, reliable, and deployable perception in autonomous systems.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20815v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2512.20798v1",
      "title": "A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents",
      "authors": [
        "Miles Q. Li",
        "Benjamin C. M. Fung",
        "Martin Weiss",
        "Pulei Xiong",
        "Khalil Al-Hussaeni",
        "Claude Fachkha"
      ],
      "abstract": "As autonomous AI agents are increasingly deployed in high-stakes environments, ensuring their safety and alignment with human values has become a paramount concern. Current safety benchmarks often focusing only on single-step decision-making, simulated environments for tasks with malicious intent, or evaluating adherence to explicit negative constraints. There is a lack of benchmarks that are designed to capture emergent forms of outcome-driven constraint violations, which arise when agents pursue goal optimization under strong performance incentives while deprioritizing ethical, legal, or safety constraints over multiple steps in realistic production settings. To address this gap, we introduce a new benchmark comprising 40 distinct scenarios. Each scenario presents a task that requires multi-step actions, and the agent's performance is tied to a specific Key Performance Indicator (KPI). Each scenario features Mandated (instruction-commanded) and Incentivized (KPI-pressure-driven) variations to distinguish between obedience and emergent misalignment. Across 12 state-of-the-art large language models, we observe outcome-driven constraint violations ranging from 1.3% to 71.4%, with 9 of the 12 evaluated models exhibiting misalignment rates between 30% and 50%. Strikingly, we find that superior reasoning capability does not inherently ensure safety; for instance, Gemini-3-Pro-Preview, one of the most capable models evaluated, exhibits the highest violation rate at over 60%, frequently escalating to severe misconduct to satisfy KPIs. Furthermore, we observe significant \"deliberative misalignment\", where the models that power the agents recognize their actions as unethical during separate evaluation. These results emphasize the critical need for more realistic agentic-safety training before deployment to mitigate their risks in the real world.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20798v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2512.19992v1",
      "title": "S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test",
      "authors": [
        "Zhe Sun",
        "Xueyuan Yang",
        "Yujie Lu",
        "Zhenliang Zhang"
      ],
      "abstract": "The integration of embodied agents into human environments demands embodied social intelligence: reasoning over both social norms and physical constraints. However, existing evaluations fail to address this integration, as they are limited to either disembodied social reasoning (e.g., in text) or socially-agnostic physical tasks. Both approaches fail to assess an agent's ability to integrate and trade off both physical and social constraints within a realistic, embodied context. To address this challenge, we introduce Spatially Situated Social Intelligence Test (S$^{3}$IT), a benchmark specifically designed to evaluate embodied social intelligence. It is centered on a novel and challenging seat-ordering task, requiring an agent to arrange seating in a 3D environment for a group of large language model-driven (LLM-driven) NPCs with diverse identities, preferences, and intricate interpersonal relationships. Our procedurally extensible framework generates a vast and diverse scenario space with controllable difficulty, compelling the agent to acquire preferences through active dialogue, perceive the environment via autonomous exploration, and perform multi-objective optimization within a complex constraint network. We evaluate state-of-the-art LLMs on S$^{3}$IT and found that they still struggle with this problem, showing an obvious gap compared with the human baseline. Results imply that LLMs have deficiencies in spatial intelligence, yet simultaneously demonstrate their ability to achieve near human-level competence in resolving conflicts that possess explicit textual cues.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19992v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2512.21102v1",
      "title": "Shared Representation Learning for High-Dimensional Multi-Task Forecasting under Resource Contention in Cloud-Native Backends",
      "authors": [
        "Zixiao Huang",
        "Jixiao Yang",
        "Sijia Li",
        "Chi Zhang",
        "Jinyu Chen",
        "Chengda Xu"
      ],
      "abstract": "This study proposes a unified forecasting framework for high-dimensional multi-task time series to meet the prediction demands of cloud native backend systems operating under highly dynamic loads, coupled metrics, and parallel tasks. The method builds a shared encoding structure to represent diverse monitoring indicators in a unified manner and employs a state fusion mechanism to capture trend changes and local disturbances across different time scales. A cross-task structural propagation module is introduced to model potential dependencies among nodes, enabling the model to understand complex structural patterns formed by resource contention, link interactions, and changes in service topology. To enhance adaptability to non-stationary behaviors, the framework incorporates a dynamic adjustment mechanism that automatically regulates internal feature flows according to system state changes, ensuring stable predictions in the presence of sudden load shifts, topology drift, and resource jitter. The experimental evaluation compares multiple models across various metrics and verifies the effectiveness of the framework through analyses of hyperparameter sensitivity, environmental sensitivity, and data sensitivity. The results show that the proposed method achieves superior performance on several error metrics and provides more accurate representations of future states under different operating conditions. Overall, the unified forecasting framework offers reliable predictive capability for high-dimensional, multi-task, and strongly dynamic environments in cloud native systems and provides essential technical support for intelligent backend management.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21102v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2512.20345v1",
      "title": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems",
      "authors": [
        "Xiaoxue Ma",
        "Wanwei Zhan",
        "Jiale Chen",
        "Yishu Li",
        "Jacky Keung",
        "Federica Sarro"
      ],
      "abstract": "In today's data-driven era, deep learning is vital for processing massive datasets, yet single-device training is constrained by computational and memory limits. Distributed deep learning overcomes these challenges by leveraging multiple GPUs or machines in parallel. While general-purpose frameworks (e.g., TensorFlow and PyTorch) provide distributed capabilities, these are often add-on features that demand significant manual effort for advanced parallelism, underscoring the need for specialized frameworks. This study conducts the first large-scale empirical analysis of practitioner challenges in dedicated distributed frameworks. We examine 849 real-world issues from DeepSpeed, Megatron-LM, and Colossal-AI and construct a taxonomy of 34 bug symptoms, 28 root causes, and 6 fix patterns. Crucially, we establish explicit mappings between symptoms, causes, and fixes across distributed training stages, enabling a systematic understanding of how issues emerge and are resolved. Our results show that 45.1\\% of bug symptoms are unique to distributed frameworks, with setup failures, memory issues, and performance anomalies being the most prevalent. Moreover, 95\\% of issues in the communication setup stage occur exclusively in distributed contexts. We also find over 60\\% of cases can be resolved through version and dependency management, and distributed feature, API, and communication tuning. Based on these findings, we provide actionable implications.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20345v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2508.00546v1",
      "title": "SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval",
      "authors": [
        "Wenchao Gu",
        "Zongyi Lyu",
        "Yanlin Wang",
        "Hongyu Zhang",
        "Cuiyun Gao",
        "Michael R. Lyu"
      ],
      "abstract": "Code retrieval aims to provide users with desired code snippets based on users' natural language queries. With the development of deep learning technologies, adopting pre-trained models for this task has become mainstream. Considering the retrieval efficiency, most of the previous approaches adopt a dual-encoder for this task, which encodes the description and code snippet into representation vectors, respectively. However, the model structure of the dual-encoder tends to limit the model's performance, since it lacks the interaction between the code snippet and description at the bottom layer of the model during training. To improve the model's effectiveness while preserving its efficiency, we propose a framework, which adopts Self-AdaPtive Model Distillation for Efficient CodE Retrieval, named SPENCER. SPENCER first adopts the dual-encoder to narrow the search space and then adopts the cross-encoder to improve accuracy. To improve the efficiency of SPENCER, we propose a novel model distillation technique, which can greatly reduce the inference time of the dual-encoder while maintaining the overall performance. We also propose a teaching assistant selection strategy for our model distillation, which can adaptively select the suitable teaching assistant models for different pre-trained models during the model distillation to ensure the model performance. Extensive experiments demonstrate that the combination of dual-encoder and cross-encoder improves overall performance compared to solely dual-encoder-based models for code retrieval. Besides, our model distillation technique retains over 98% of the overall performance while reducing the inference time of the dual-encoder by 70%.",
      "published": "2025-08-01",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2508.00546v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2512.18908v1",
      "title": "Multimodal Bayesian Network for Robust Assessment of Casualties in Autonomous Triage",
      "authors": [
        "Szymon Rusiecki",
        "Cecilia G. Morales",
        "Kimberly Elenberg",
        "Leonard Weiss",
        "Artur Dubrawski"
      ],
      "abstract": "Mass Casualty Incidents can overwhelm emergency medical systems and resulting delays or errors in the assessment of casualties can lead to preventable deaths. We present a decision support framework that fuses outputs from multiple computer vision models, estimating signs of severe hemorrhage, respiratory distress, physical alertness, or visible trauma, into a Bayesian network constructed entirely from expert-defined rules. Unlike traditional data-driven models, our approach does not require training data, supports inference with incomplete information, and is robust to noisy or uncertain observations. We report performance for two missions involving 11 and 9 casualties, respectively, where our Bayesian network model substantially outperformed vision-only baselines during evaluation of our system in the DARPA Triage Challenge (DTC) field scenarios. The accuracy of physiological assessment improved from 15% to 42% in the first scenario and from 19% to 46% in the second, representing nearly threefold increase in performance. More importantly, overall triage accuracy increased from 14% to 53% in all patients, while the diagnostic coverage of the system expanded from 31% to 95% of the cases requiring assessment. These results demonstrate that expert-knowledge-guided probabilistic reasoning can significantly enhance automated triage systems, offering a promising approach to supporting emergency responders in MCIs. This approach enabled Team Chiron to achieve 4th place out of 11 teams during the 1st physical round of the DTC.",
      "published": "2025-12-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18908v1",
      "relevance_score": 31
    },
    {
      "arxiv_id": "2410.09190v2",
      "title": "Time to Retrain? Detecting Concept Drifts in Machine Learning Systems",
      "authors": [
        "Tri Minh Triet Pham",
        "Karthikeyan Premkumar",
        "Mohamed Naili",
        "Jinqiu Yang"
      ],
      "abstract": "With the boom of machine learning (ML) techniques, software practitioners build ML systems to process the massive volume of streaming data for diverse software engineering tasks such as failure prediction in AIOps. Trained using historical data, such ML models encounter performance degradation caused by concept drift, i.e., data and inter-relationship (concept) changes between training and production. It is essential to use concept rift detection to monitor the deployed ML models and re-train the ML models when needed. In this work, we explore applying state-of-the-art (SOTA) concept drift detection techniques on synthetic and real-world datasets in an industrial setting. Such an industrial setting requires minimal manual effort in labeling and maximal generality in ML model architecture. We find that current SOTA semi-supervised methods not only require significant labeling effort but also only work for certain types of ML models. To overcome such limitations, we propose a novel model-agnostic technique (CDSeer) for detecting concept drift. Our evaluation shows that CDSeer has better precision and recall compared to the state-of-the-art while requiring significantly less manual labeling. We demonstrate the effectiveness of CDSeer at concept drift detection by evaluating it on eight datasets from different domains and use cases. Results from internal deployment of CDSeer on an industrial proprietary dataset show a 57.1% improvement in precision while using 99% fewer labels compared to the SOTA concept drift detection method. The performance is also comparable to the supervised concept drift detection method, which requires 100% of the data to be labeled. The improved performance and ease of adoption of CDSeer are valuable in making ML systems more reliable.",
      "published": "2024-10-11",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2410.09190v2",
      "relevance_score": 29
    },
    {
      "arxiv_id": "2508.16268v1",
      "title": "Self-Healing Network of Interconnected Edge Devices Empowered by Infrastructure-as-Code and LoRa Communication",
      "authors": [
        "Rob Carson",
        "Mohamed Chahine Ghanem",
        "Feriel Bouakkaz"
      ],
      "abstract": "This Paper proposes a self-healing, automated network of Raspberry Pi devices designed for deployment in scenarios where traditional networking is unavailable. Leveraging the low-power, long-range capabilities of the LoRa (Long Range) protocol alongside Infrastructure as Code (IaC) methodologies, the research addresses challenges such as limited bandwidth, data collisions, and node failures. Given that LoRa's packet-based system is incompatible with conventional IaC tools like Ansible and Terraform, which rely on TCP/IP networking, the research adapts IaC principles within a containerised architecture deployed across a Raspberry Pi cluster. Evaluation experiments indicate that fragmenting data packets and retransmitting any missed fragments can mitigate LoRa's inherent throughput and packet size limitations, although issues such as collisions and line-of-sight interference persist. An automated failover mechanism was integrated into the architecture, enabling unresponsive services to be redeployed to alternative nodes within one second, demonstrating the system's resilience in maintaining operational continuity despite node or service failures. The paper also identifies practical challenges, including the necessity for time-slotting transmissions to prevent data packet overlap and collisions. Future research should explore the integration of mesh networking to enhance range, develop more advanced scheduling algorithms, and adopt cutting-edge low-power wide-area network (LPWAN) techniques.",
      "published": "2025-08-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2508.16268v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2505.13744v2",
      "title": "Early Stages of Self-Healing at Tungsten Grain Boundaries from Ab Initio Machine Learning Simulations",
      "authors": [
        "Jorge Su\u00e1rez-Recio",
        "Pablo M. Piaggi",
        "Francisco J. Dom\u00ednguez-Guti\u00e9rrez",
        "Raquel Gonzalez-Arrabal",
        "Roberto Iglesias"
      ],
      "abstract": "Nanostructured tungsten has been reported as a possible alternative plasma-facing material due to its potential ability to self-heal radiation-induced defects, a property that is attributed to its high density of grain boundaries (GB). Here, we study the initial stages of self-healing at tungsten interfaces with molecular dynamics simulations driven by a machine-learning interatomic potential tailored to one of the most common GBs found in experiments. Our model accurately reproduces the ab initio potential energy surface derived from density functional theory (DFT) calculations and outperforms previously reported empirical and machine learning interatomic potentials in predicting defect energetics. The simulations reveal low-temperature defect migration to GBs driven by rapid dumbbell-like ordering and subsequent accommodation along GB grooves. In contrast to empirical potentials, which predict unexpected GB degradation at high temperatures after defect migration, our model maintains stable GB motifs over the investigated temperature range. The temperature-dependent defect counts, evaluated using an Arrhenius-like fit, yield an average interstitial migration energy of 0.048 eV, in agreement with experiment.   This work underscores the capabilities of ab initio machine learning simulations in accurately modeling defect-GB interactions and highlights their potential to contribute to the development of radiation tolerant materials.",
      "published": "2025-05-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.13744v2",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2505.12815v2",
      "title": "Learning In Chaos: Efficient Autoscaling and Self-Healing for Multi-Party Distributed Training",
      "authors": [
        "Wenjiao Feng",
        "Rongxing Xiao",
        "Zonghang Li",
        "Hongfang Yu",
        "Gang Sun",
        "Long Luo",
        "Mohsen Guizani",
        "Qirong Ho",
        "Steve Liu"
      ],
      "abstract": "Node and link churn in multi-party, cross-region clusters over wide-area networks (WANs) often disrupts distributed training. However, checkpoint-based recovery and cloud-centric autoscaling react slowly and assume centralized control, which is misaligned with the self-governed setup where institutions can freely join and leave. This paper proposes Chaos, a multi-party distributed training system with self-healing and autoscaling, enabling robust and elastic training under churn. It speeds up autoscaling via multi-neighbor state replication and model sharding. We formalize the sharding and assignment as a MINLP that captures WAN heterogeneity, and reduce it to a tractable MILP by analyzing its monotonicity on a divisibility chain. By establishing an equivalence, we derive a greedy algorithm that follows optimality rules and yields the optimal solution in polynomial time. Chaos uses a cluster monitor to track resource and topology changes, and handles scaling events through peer negotiation protocols, enabling fully self-governed autoscaling among institutions. Experiments show that Chaos has substantially lower scale-out delay than Pollux, Elan, and Autoscaling, and handles scale-in, connect-link, and disconnect-link events within 20ms. It also delivers the lowest idle time, showing superior resource use and scalability as the cluster grows.",
      "published": "2025-05-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.12815v2",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.21066v1",
      "title": "Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation",
      "authors": [
        "Tomoaki Yamaguchi",
        "Yutong Zhou",
        "Masahiro Ryo",
        "Keisuke Katsura"
      ],
      "abstract": "Explainable artificial intelligence (XAI) enables data-driven understanding of factor associations with response variables, yet communicating XAI outputs to laypersons remains challenging, hindering trust in AI-based predictions. Large language models (LLMs) have emerged as promising tools for translating technical explanations into accessible narratives, yet the integration of agentic AI, where LLMs operate as autonomous agents through iterative refinement, with XAI remains unexplored. This study proposes an agentic XAI framework combining SHAP-based explainability with multimodal LLM-driven iterative refinement to generate progressively enhanced explanations. As a use case, we tested this framework as an agricultural recommendation system using rice yield data from 26 fields in Japan. The Agentic XAI initially provided a SHAP result and explored how to improve the explanation through additional analysis iteratively across 11 refinement rounds (Rounds 0-10). Explanations were evaluated by human experts (crop scientists) (n=12) and LLMs (n=14) against seven metrics: Specificity, Clarity, Conciseness, Practicality, Contextual Relevance, Cost Consideration, and Crop Science Credibility. Both evaluator groups confirmed that the framework successfully enhanced recommendation quality with an average score increase of 30-33% from Round 0, peaking at Rounds 3-4. However, excessive refinement showed a substantial drop in recommendation quality, indicating a bias-variance trade-off where early rounds lacked explanation depth (bias) while excessive iteration introduced verbosity and ungrounded abstraction (variance), as revealed by metric-specific analysis. These findings suggest that strategic early stopping (regularization) is needed for optimizing practical utility, challenging assumptions about monotonic improvement and providing evidence-based design principles for agentic XAI systems.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21066v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.21018v1",
      "title": "LEO Constellations as a Decentralized GNSS Network: Optimizing PNT Corrections in Space",
      "authors": [
        "Xing Liu",
        "Xue Xian Zheng",
        "Jos\u00e9 A. L\u00f3pez-Salcedo",
        "Tareq Y. Al-Naffouri",
        "Gonzalo Seco-Granados"
      ],
      "abstract": "With the rapid expansion of low Earth orbit (LEO) constellations, thousands of satellites are now in operation, many equipped with onboard GNSS receivers capable of continuous orbit determination and time synchronization. This development is creating an unprecedented spaceborne GNSS network, offering new opportunities for network-driven precise LEO orbit and clock estimation. Yet, current onboard GNSS processing is largely standalone and often insufficient for high-precision applications, while centralized fusion is challenging due to computational bottlenecks and the lack of in-orbit infrastructure. In this work, we report a decentralized GNSS network over large-scale LEO constellations, where each satellite processes its own measurements while exchanging compact information with neighboring nodes to enable precise orbit and time determination. We model the moving constellation as a dynamic graph and tailor a momentum-accelerated gradient tracking (GT) method to ensure steady convergence despite topology changes. Numerical simulations with constellations containing hundreds of satellites show that the proposed method matches the accuracy of an ideal centralized benchmark, while substantially reducing communication burdens. Ultimately, this framework supports the development of autonomous and self-organizing space systems, enabling high-precision navigation with reduced dependence on continuous ground contact.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21018v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.20973v1",
      "title": "DAO-Agent: Zero Knowledge-Verified Incentives for Decentralized Multi-Agent Coordination",
      "authors": [
        "Yihan Xia",
        "Taotao Wang",
        "Wenxin Xu",
        "Shengli Zhang"
      ],
      "abstract": "Autonomous Large Language Model (LLM)-based multi-agent systems have emerged as a promising paradigm for facilitating cross-application and cross-organization collaborations. These autonomous agents often operate in trustless environments, where centralized coordination faces significant challenges, such as the inability to ensure transparent contribution measurement and equitable incentive distribution. While blockchain is frequently proposed as a decentralized coordination platform, it inherently introduces high on-chain computation costs and risks exposing sensitive execution information of the agents. Consequently, the core challenge lies in enabling auditable task execution and fair incentive distribution for autonomous LLM agents in trustless environments, while simultaneously preserving their strategic privacy and minimizing on-chain costs. To address this challenge, we propose DAO-Agent, a novel framework that integrates three key technical innovations: (1) an on-chain decentralized autonomous organization (DAO) governance mechanism for transparent coordination and immutable logging; (2) a ZKP mechanism approach that enables Shapley-based contribution measurement off-chain, and (3) a hybrid on-chain/off-chain architecture that verifies ZKP-validated contribution measurements on-chain with minimal computational overhead. We implement DAO-Agent and conduct end-to-end experiments using a crypto trading task as a case study. Experimental results demonstrate that DAO-Agent achieves up to 99.9% reduction in verification gas costs compared to naive on-chain alternatives, with constant-time verification complexity that remains stable as coalition size increases, thereby establishing a scalable foundation for agent coordination in decentralized environments.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20973v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.20778v1",
      "title": "Towards Optimal Performance and Action Consistency Guarantees in Dec-POMDPs with Inconsistent Beliefs and Limited Communication",
      "authors": [
        "Moshe Rafaeli Shimron",
        "Vadim Indelman"
      ],
      "abstract": "Multi-agent decision-making under uncertainty is fundamental for effective and safe autonomous operation. In many real-world scenarios, each agent maintains its own belief over the environment and must plan actions accordingly. However, most existing approaches assume that all agents have identical beliefs at planning time, implying these beliefs are conditioned on the same data. Such an assumption is often impractical due to limited communication. In reality, agents frequently operate with inconsistent beliefs, which can lead to poor coordination and suboptimal, potentially unsafe, performance. In this paper, we address this critical challenge by introducing a novel decentralized framework for optimal joint action selection that explicitly accounts for belief inconsistencies. Our approach provides probabilistic guarantees for both action consistency and performance with respect to open-loop multi-agent POMDP (which assumes all data is always communicated), and selectively triggers communication only when needed. Furthermore, we address another key aspect of whether, given a chosen joint action, the agents should share data to improve expected performance in inference. Simulation results show our approach outperforms state-of-the-art algorithms.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20778v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.20381v1",
      "title": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning",
      "authors": [
        "Syeda Tasnim Fabiha",
        "Saad Shafiq",
        "Wesley Klewerton Guez Assun\u00e7\u00e3o",
        "Nenad Medvidovi\u0107"
      ],
      "abstract": "Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems. It refers to a design style that enables systems to be developed as suites of small, loosely coupled, and autonomous components (services) that encapsulate functionality and communicate via language-agnostic APIs. However, defining appropriately sized services that capture cohesive subsets of system functionality remains challenging. Existing work often relies on the availability of documentation, access to project personnel, or a priori knowledge of the target number of services, assumptions that do not hold in many real-world scenarios. Our work addresses these limitations using a deep reinforcement learning-based approach to identify appropriately sized services directly from implementation artifacts. We present Rake, a reinforcement learning-based technique that leverages available system documentation and source code to guide service decomposition at the level of implementation methods. Rake does not require specific documentation or access to project personnel and is language-agnostic. It also supports a customizable objective function that balances modularization quality and business capability alignment, i.e., the degree to which a service covers the targeted business capability. We applied Rake to four open-source legacy projects and compared it with two state-of-the-art techniques. On average, Rake achieved 7-14 percent higher modularization quality and 18-22 percent stronger business capability alignment. Our results further show that optimizing solely for business context can degrade decomposition quality in tightly coupled systems, highlighting the need for balanced objectives.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20381v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.20299v1",
      "title": "KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System",
      "authors": [
        "Zhongyu Xia",
        "Wenhao Chen",
        "Yongtao Wang",
        "Ming-Hsuan Yang"
      ],
      "abstract": "Visual-language reasoning, driving knowledge, and value alignment are essential for advanced autonomous driving systems. However, existing approaches largely rely on data-driven learning, making it difficult to capture the complex logic underlying decision-making through imitation or limited reinforcement rewards. To address this, we propose KnowVal, a new autonomous driving system that enables visual-language reasoning through the synergistic integration of open-world perception and knowledge retrieval. Specifically, we construct a comprehensive driving knowledge graph that encodes traffic laws, defensive driving principles, and ethical norms, complemented by an efficient LLM-based retrieval mechanism tailored for driving scenarios. Furthermore, we develop a human-preference dataset and train a Value Model to guide interpretable, value-aligned trajectory assessment. Experimental results show that our method substantially improves planning performance while remaining compatible with existing architectures. Notably, KnowVal achieves the lowest collision rate on nuScenes and state-of-the-art results on Bench2Drive.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20299v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.19934v1",
      "title": "Vehicle-centric Perception via Multimodal Structured Pre-training",
      "authors": [
        "Wentao Wu",
        "Xiao Wang",
        "Chenglong Li",
        "Jin Tang",
        "Bin Luo"
      ],
      "abstract": "Vehicle-centric perception plays a crucial role in many intelligent systems, including large-scale surveillance systems, intelligent transportation, and autonomous driving. Existing approaches lack effective learning of vehicle-related knowledge during pre-training, resulting in poor capability for modeling general vehicle perception representations. To handle this problem, we propose VehicleMAE-V2, a novel vehicle-centric pre-trained large model. By exploring and exploiting vehicle-related multimodal structured priors to guide the masked token reconstruction process, our approach can significantly enhance the model's capability to learn generalizable representations for vehicle-centric perception. Specifically, we design the Symmetry-guided Mask Module (SMM), Contour-guided Representation Module (CRM) and Semantics-guided Representation Module (SRM) to incorporate three kinds of structured priors into token reconstruction including symmetry, contour and semantics of vehicles respectively. SMM utilizes the vehicle symmetry constraints to avoid retaining symmetric patches and can thus select high-quality masked image patches and reduce information redundancy. CRM minimizes the probability distribution divergence between contour features and reconstructed features and can thus preserve holistic vehicle structure information during pixel-level reconstruction. SRM aligns image-text features through contrastive learning and cross-modal distillation to address the feature confusion caused by insufficient semantic understanding during masked reconstruction. To support the pre-training of VehicleMAE-V2, we construct Autobot4M, a large-scale dataset comprising approximately 4 million vehicle images and 12,693 text descriptions. Extensive experiments on five downstream tasks demonstrate the superior performance of VehicleMAE-V2.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19934v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.19799v1",
      "title": "PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research",
      "authors": [
        "Tingjia Miao",
        "Jiawen Dai",
        "Jingkun Liu",
        "Jinxin Tan",
        "Muhua Zhang",
        "Wenkai Jin",
        "Yuwen Du",
        "Tian Jin",
        "Xianghe Pang",
        "Zexi Liu",
        "Tu Guo",
        "Zhengliang Zhang",
        "Yunjie Huang",
        "Shuo Chen",
        "Rui Ye",
        "Yuzhi Zhang",
        "Linfeng Zhang",
        "Kun Chen",
        "Wei Wang",
        "Weinan E",
        "Siheng Chen"
      ],
      "abstract": "Advances in LLMs have produced agents with knowledge and operational capabilities comparable to human scientists, suggesting potential to assist, accelerate, and automate research. However, existing studies mainly evaluate such systems on well-defined benchmarks or general tasks like literature retrieval, limiting their end-to-end problem-solving ability in open scientific scenarios. This is particularly true in physics, which is abstract, mathematically intensive, and requires integrating analytical reasoning with code-based computation. To address this, we propose PhysMaster, an LLM-based agent functioning as an autonomous theoretical and computational physicist. PhysMaster couples absract reasoning with numerical computation and leverages LANDAU, the Layered Academic Data Universe, which preserves retrieved literature, curated prior knowledge, and validated methodological traces, enhancing decision reliability and stability. It also employs an adaptive exploration strategy balancing efficiency and open-ended exploration, enabling robust performance in ultra-long-horizon tasks. We evaluate PhysMaster on problems from high-energy theory, condensed matter theory to astrophysics, including: (i) acceleration, compressing labor-intensive research from months to hours; (ii) automation, autonomously executing hypothesis-driven loops ; and (iii) autonomous discovery, independently exploring open problems.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19799v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2509.12231v1",
      "title": "Research on fault diagnosis and root cause analysis based on full stack observability",
      "authors": [
        "Jian Hou"
      ],
      "abstract": "With the rapid development of cloud computing and ultra-large-scale data centers, the scale and complexity of systems have increased significantly, leading to frequent faults that often show cascading propagation. How to achieve efficient, accurate, and interpretable Root Cause Analysis (RCA) based on observability data (metrics, logs, traces) has become a core issue in AIOps. This paper reviews two mainstream research threads in top conferences and journals over the past five years: FaultInsight[1] focusing on dynamic causal discovery and HolisticRCA[2] focusing on multi-modal/cross-level fusion, and analyzes the advantages and disadvantages of existing methods. A KylinRCA framework integrating the ideas of both is proposed, which depicts the propagation chain through temporal causal discovery, realizes global root cause localization and type identification through cross-modal graph learning, and outputs auditable evidence chains combined with mask-based explanation methods. A multi-dimensional experimental scheme is designed, evaluation indicators are clarified, and engineering challenges are discussed, providing an effective solution for fault diagnosis under full-stack observability.",
      "published": "2025-09-08",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.12231v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2509.06419v1",
      "title": "CAPMix: Robust Time Series Anomaly Detection Based on Abnormal Assumptions with Dual-Space Mixup",
      "authors": [
        "Xudong Mou",
        "Rui Wang",
        "Tiejun Wang",
        "Renyu Yang",
        "Shiru Chen",
        "Jie Sun",
        "Tianyu Wo",
        "Xudong Liu"
      ],
      "abstract": "Time series anomaly detection (TSAD) is a vital yet challenging task, particularly in scenarios where labeled anomalies are scarce and temporal dependencies are complex. Recent anomaly assumption (AA) approaches alleviate the lack of anomalies by injecting synthetic samples and training discriminative models. Despite promising results, these methods often suffer from two fundamental limitations: patchy generation, where scattered anomaly knowledge leads to overly simplistic or incoherent anomaly injection, and Anomaly Shift, where synthetic anomalies either resemble normal data too closely or diverge unrealistically from real anomalies, thereby distorting classification boundaries. In this paper, we propose CAPMix, a controllable anomaly augmentation framework that addresses both issues. First, we design a CutAddPaste mechanism to inject diverse and complex anomalies in a targeted manner, avoiding patchy generation. Second, we introduce a label revision strategy to adaptively refine anomaly labels, reducing the risk of anomaly shift. Finally, we employ dual-space mixup within a temporal convolutional network to enforce smoother and more robust decision boundaries. Extensive experiments on five benchmark datasets, including AIOps, UCR, SWaT, WADI, and ESA, demonstrate that CAPMix achieves significant improvements over state-of-the-art baselines, with enhanced robustness against contaminated training data. The code is available at https://github.com/alsike22/CAPMix.",
      "published": "2025-09-08",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.06419v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.21045v1",
      "title": "Synthetic Fluency and Epistemic Offloading in Undergraduate Mathematics in the Age of AI",
      "authors": [
        "Siyuan Wang",
        "Qing Xia",
        "Qiong Ye"
      ],
      "abstract": "The rapid adoption of generative artificial intelligence (AI) tools in higher education is transforming how students engage with undergraduate mathematics, raising concerns about learning and assessment validity. This study examines the impact of AI accessibility across a two-semester, multi-course dataset including Business Calculus, Linear Algebra, and Calculus III. By comparing unproctored homework and proctored exam performance, we analyze how student learning behaviors shift in AI-accessible environments, particularly through epistemic off-loading of mathematical work. Guided by a sociocognitive framework, we employ complementary measures -- performance gaps, homework-exam correlations, and Wasserstein distance -- to characterize divergence between practice and mastery. Results reveal a growing integrity gap as course content shifts from procedural to conceptual and spatially intensive mathematics. In both Business Calculus and Linear Algebra, differences in homework format (online versus hand-written, TA-graded) do not yield substantively different performance patterns, indicating that paper-based homework is not inherently more resistant to AI-mediated offloading. While homework retains partial predictive validity in procedural courses, upper-division courses exhibit a collapse in alignment between homework and exams, indicating that unproctored assessments increasingly reflect synthetic fluency rather than internalized understanding. These findings highlight the need to rethink assessment practices in the AI era.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21045v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.20432v1",
      "title": "High Dimensional Data Decomposition for Anomaly Detection of Textured Images",
      "authors": [
        "Ji Song",
        "Xing Wang",
        "Jianguo Wu",
        "Xiaowei Yue"
      ],
      "abstract": "In the realm of diverse high-dimensional data, images play a significant role across various processes of manufacturing systems where efficient image anomaly detection has emerged as a core technology of utmost importance. However, when applied to textured defect images, conventional anomaly detection methods have limitations including non-negligible misidentification, low robustness, and excessive reliance on large-scale and structured datasets. This paper proposes a texture basis integrated smooth decomposition (TBSD) approach, which is targeted at efficient anomaly detection in textured images with smooth backgrounds and sparse anomalies. Mathematical formulation of quasi-periodicity and its theoretical properties are investigated for image texture estimation. TBSD method consists of two principal processes: the first process learns the texture basis functions to effectively extract quasi-periodic texture patterns; the subsequent anomaly detection process utilizes that texture basis as prior knowledge to prevent texture misidentification and capture potential anomalies with high accuracy.The proposed method surpasses benchmarks with less misidentification, smaller training dataset requirement, and superior anomaly detection performance on both simulation and real-world datasets.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20432v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.18826v1",
      "title": "Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection",
      "authors": [
        "Souhail Abdelmouaiz Sadat",
        "Mohamed Yacine Touahria Miliani",
        "Khadidja Hab El Hames",
        "Hamida Seba",
        "Mohammed Haddad"
      ],
      "abstract": "This survey reviews hyperbolic graph embedding models, and evaluate them on anomaly detection, highlighting their advantages over Euclidean methods in capturing complex structures. Evaluating models like \\textit{HGCAE}, \\textit{\\(\\mathcal{P}\\)-VAE}, and \\textit{HGCN} demonstrates high performance, with \\textit{\\(\\mathcal{P}\\)-VAE} achieving an F1-score of 94\\% on the \\textit{Elliptic} dataset and \\textit{HGCAE} scoring 80\\% on \\textit{Cora}. In contrast, Euclidean methods like \\textit{DOMINANT} and \\textit{GraphSage} struggle with complex data. The study emphasizes the potential of hyperbolic spaces for improving anomaly detection, and provides an open-source library to foster further research in this field.",
      "published": "2025-12-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18826v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.18673v1",
      "title": "Improving Pattern Recognition of Scheduling Anomalies through Structure-Aware and Semantically-Enhanced Graphs",
      "authors": [
        "Ning Lyu",
        "Junjie Jiang",
        "Lu Chang",
        "Chihui Shao",
        "Feng Chen",
        "Chong Zhang"
      ],
      "abstract": "This paper proposes a structure-aware driven scheduling graph modeling method to improve the accuracy and representation capability of anomaly identification in scheduling behaviors of complex systems. The method first designs a structure-guided scheduling graph construction mechanism that integrates task execution stages, resource node states, and scheduling path information to build dynamically evolving scheduling behavior graphs, enhancing the model's ability to capture global scheduling relationships. On this basis, a multi-scale graph semantic aggregation module is introduced to achieve semantic consistency modeling of scheduling features through local adjacency semantic integration and global topology alignment, thereby strengthening the model's capability to capture abnormal features in complex scenarios such as multi-task concurrency, resource competition, and stage transitions. Experiments are conducted on a real scheduling dataset with multiple scheduling disturbance paths set to simulate different types of anomalies, including structural shifts, resource changes, and task delays. The proposed model demonstrates significant performance advantages across multiple metrics, showing a sensitive response to structural disturbances and semantic shifts. Further visualization analysis reveals that, under the combined effect of structure guidance and semantic aggregation, the scheduling behavior graph exhibits stronger anomaly separability and pattern representation, validating the effectiveness and adaptability of the method in scheduling anomaly detection tasks.",
      "published": "2025-12-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18673v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.17601v2",
      "title": "HeadHunt-VAD: Hunting Robust Anomaly-Sensitive Heads in MLLM for Tuning-Free Video Anomaly Detection",
      "authors": [
        "Zhaolin Cai",
        "Fan Li",
        "Ziwei Zheng",
        "Haixia Bi",
        "Lijun He"
      ],
      "abstract": "Video Anomaly Detection (VAD) aims to locate events that deviate from normal patterns in videos. Traditional approaches often rely on extensive labeled data and incur high computational costs. Recent tuning-free methods based on Multimodal Large Language Models (MLLMs) offer a promising alternative by leveraging their rich world knowledge. However, these methods typically rely on textual outputs, which introduces information loss, exhibits normalcy bias, and suffers from prompt sensitivity, making them insufficient for capturing subtle anomalous cues. To address these constraints, we propose HeadHunt-VAD, a novel tuning-free VAD paradigm that bypasses textual generation by directly hunting robust anomaly-sensitive internal attention heads within the frozen MLLM. Central to our method is a Robust Head Identification module that systematically evaluates all attention heads using a multi-criteria analysis of saliency and stability, identifying a sparse subset of heads that are consistently discriminative across diverse prompts. Features from these expert heads are then fed into a lightweight anomaly scorer and a temporal locator, enabling efficient and accurate anomaly detection with interpretable outputs. Extensive experiments show that HeadHunt-VAD achieves state-of-the-art performance among tuning-free methods on two major VAD benchmarks while maintaining high efficiency, validating head-level probing in MLLMs as a powerful and practical solution for real-world anomaly detection.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17601v2",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2511.21380v1",
      "title": "Multi-Agent Systems for Dataset Adaptation in Software Engineering: Capabilities, Limitations, and Future Directions",
      "authors": [
        "Jingyi Chen",
        "Xiaoyan Guo",
        "Songqiang Chen",
        "Shing-Chi Cheung",
        "Jiasi Shen"
      ],
      "abstract": "Automating the adaptation of software engineering (SE) research artifacts across datasets is essential for scalability and reproducibility, yet it remains largely unstudied. Recent advances in large language model (LLM)-based multi-agent systems, such as GitHub Copilot's agent mode, promise to automate complex development workflows through coordinated reasoning, code generation, and tool interaction. This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks. We evaluate Copilot, backed by GPT-4.1 and Claude Sonnet 4, on adapting SE research artifacts from benchmark repositories including ROCODE and LogHub2.0. Through a five-stage evaluation pipeline (file comprehension, code editing, command generation, validation, and final execution), we measure success rates, analyze failure patterns, and assess prompt-based interventions designed to enhance agent performance. Results show that current systems can identify key files and generate partial adaptations but rarely produce functionally correct implementations. Prompt-level interventions, especially providing execution error messages and reference code, substantially improve structural similarity to ground truth (from 7.25% to 67.14%), highlighting the importance of contextual and feedback-driven guidance. Our findings reveal both the promise and limitations of today's multi-agent LLM systems for dataset adaptation, and suggest concrete directions for building more reliable, self-correcting agents in future SE research.",
      "published": "2025-11-26",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.21380v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2510.18327v1",
      "title": "InspectCoder: Dynamic Analysis-Enabled Self Repair through interactive LLM-Debugger Collaboration",
      "authors": [
        "Yunkun Wang",
        "Yue Zhang",
        "Guochang Li",
        "Chen Zhi",
        "Binhua Li",
        "Fei Huang",
        "Yongbin Li",
        "Shuiguang Deng"
      ],
      "abstract": "Large Language Models (LLMs) frequently generate buggy code with complex logic errors that are challenging to diagnose. While existing LLM-based self-repair approaches conduct intensive static semantic analysis or reply on superficial execution logs, they miss the in-depth runtime behaviors that often expose bug root causes-lacking the interactive dynamic analysis capabilities that make human debugging effective. We present InspectCoder, the first agentic program repair system that empowers LLMs to actively conduct dynamic analysis via interactive debugger control. Our dual-agent framework enables strategic breakpoint placement, targeted state inspection, and incremental runtime experimentation within stateful debugger sessions. Unlike existing methods that follow fixed log collection procedures, InspectCoder adaptively inspects and perturbs relevant intermediate states at runtime, and leverages immediate process rewards from debugger feedback to guide multi-step reasoning, transforming LLM debugging paradigm from blind trial-and-error into systematic root cause diagnosis. We conduct comprehensive experiments on two challenging self-repair benchmarks: BigCodeBench-R and LiveCodeBench-R. InspectCoder achieves 5.10%-60.37% relative improvements in repair accuracy over the strongest baseline, while delivering 1.67x-2.24x superior bug-fix efficiency respectively. We also contribute InspectWare, an open-source middleware that abstracts debugger complexities and maintains stateful debugging sessions across mainstream Python testing frameworks. Our work provides actionable insight into the interactive LLM-debugger systems, demonstrating the significant potential of LLM-driven dynamic analysis for automated software engineering.",
      "published": "2025-10-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.18327v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.20164v1",
      "title": "AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications",
      "authors": [
        "Honglin Mu",
        "Jinghao Liu",
        "Kaiyang Wan",
        "Rui Xing",
        "Xiuying Chen",
        "Timothy Baldwin",
        "Wanxiang Che"
      ],
      "abstract": "Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by \"adversarial instructions\" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20164v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.14330v1",
      "title": "Criminal Liability in AI-Enabled Autonomous Vehicles: A Comparative Study",
      "authors": [
        "Sahibpreet Singh",
        "Manjit Singh"
      ],
      "abstract": "AI revolutionizes transportation through autonomous vehicles (AVs) but introduces complex criminal liability issues regarding infractions. This study employs a comparative legal analysis of primary statutes, real-world liability claims, and academic literature across the US, Germany, UK, China, and India; jurisdictions selected for their technological advancement and contrasting regulatory approaches. The research examines the attribution of human error, AI moral agency, and the identification of primary offenders in AV incidents. Findings reveal fragmented regulatory landscapes: India and the US rely on loose networks of state laws, whereas the UK enacted the pioneering Automated and Electric Vehicles Act 2018. Germany enforces strict safety standards, distinguishing liability based on the vehicle's operating mode, while China similarly aims for a stringent liability regime. The study concludes that globally harmonized legal standards are essential to foster technological innovation while ensuring minimum risk and clear liability attribution.",
      "published": "2025-12-16",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.14330v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.12706v1",
      "title": "Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning",
      "authors": [
        "Enhong Mu",
        "Minami Yoda",
        "Yan Zhang",
        "Mingyue Zhang",
        "Yutaka Matsuno",
        "Jialong Li"
      ],
      "abstract": "The widespread adoption of the \"Games as a Service\" model necessitates frequent content updates, placing immense pressure on quality assurance. In response, automated game testing has been viewed as a promising solution to cope with this demanding release cadence. However, existing automated testing approaches typically create a dichotomy: code-centric methods focus on structural coverage without understanding gameplay context, while player-centric agents validate high-level intent but often fail to cover specific underlying code changes. To bridge this gap, we propose SMART (Structural Mapping for Augmented Reinforcement Testing), a novel framework that synergizes structural verification and functional validation for game update testing. SMART leverages large language models (LLMs) to interpret abstract syntax tree (AST) differences and extract functional intent, constructing a context-aware hybrid reward mechanism. This mechanism guides reinforcement learning agents to sequentially fulfill gameplay goals while adaptively exploring modified code branches. We evaluate SMART on two environments, Overcooked and Minecraft. The results demonstrate that SMART significantly outperforms state-of-the-art baselines; it achieves over 94% branch coverage of modified code, nearly double that of traditional reinforcement learning methods, while maintaining a 98% task completion rate, effectively balancing structural comprehensiveness with functional correctness.",
      "published": "2025-12-14",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.12706v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.04716v1",
      "title": "Towards an AI Fluid Scientist: LLM-Powered Scientific Discovery in Experimental Fluid Mechanics",
      "authors": [
        "Haodong Feng",
        "Lugang Ye",
        "Dixia Fan"
      ],
      "abstract": "The integration of artificial intelligence into experimental fluid mechanics promises to accelerate discovery, yet most AI applications remain narrowly focused on numerical studies. This work proposes an AI Fluid Scientist framework that autonomously executes the complete experimental workflow: hypothesis generation, experimental design, robotic execution, data analysis, and manuscript preparation. We validate this through investigation of vortex-induced vibration (VIV) and wake-induced vibration (WIV) in tandem cylinders. Our work has four key contributions: (1) A computer-controlled circulating water tunnel (CWT) with programmatic control of flow velocity, cylinder position, and forcing parameters (vibration frequency and amplitude) with data acquisition (displacement, force, and torque). (2) Automated experiments reproduce literature benchmarks (Khalak and Williamson [1999] and Assi et al. [2013, 2010]) with frequency lock-in within 4% and matching critical spacing trends. (3) The framework with Human-in-the-Loop (HIL) discovers more WIV amplitude response phenomena, and uses a neural network to fit physical laws from data, which is 31% higher than that of polynomial fitting. (4) The framework with multi-agent with virtual-real interaction system executes hundreds of experiments end-to-end, which automatically completes the entire process of scientific research from hypothesis generation, experimental design, experimental execution, data analysis, and manuscript preparation. It greatly liberates human researchers and improves study efficiency, providing new paradigm for the development and research of experimental fluid mechanics.",
      "published": "2025-12-04",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.04716v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.03607v1",
      "title": "DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization",
      "authors": [
        "Yusen Wu",
        "Xiaotie Deng"
      ],
      "abstract": "This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.   Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.",
      "published": "2025-12-03",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.03607v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2511.22235v1",
      "title": "Training High-Level Schedulers with Execution-Feedback Reinforcement Learning for Long-Horizon GUI Automation",
      "authors": [
        "Zehao Deng",
        "Tianjie Ju",
        "Zheng Wu",
        "Zhuosheng Zhang",
        "Gongshen Liu"
      ],
      "abstract": "The rapid development of large vision-language model (VLM) has greatly promoted the research of GUI agent. However, GUI agents still face significant challenges in handling long-horizon tasks. First, single-agent models struggle to balance high-level capabilities and low-level execution capability, facing prevalent issues of responsibility coupling and capability conflicts. Second, agents lack awareness of the task state, leading to progress loss in long-horizon tasks. To address these challenges, we propose a staged execution-feedback reinforcement learning algorithm. Unlike training a unified policy model, we focus on training high-level scheduling models. Specifically, we propose and train two agents: a Coordinator, responsible for the strategic planning and task decomposition; and a State Tracker, responsible for context compression and information management to maintain the task's state and coherence. Based on this, we built the Coordinator-Executor-State Tracker (CES) multi-agent framework, which can be integrated with any low-level Executor model, assisting the Executor in solving long-horizon tasks through task scheduling and state management. Experiments on long-horizon task benchmarks demonstrate that CES significantly enhances the system's planning and state management capabilities. Furthermore, analysis confirms that our trained high-level scheduling module is a generalizable, plug-and-play module that significantly enhances the long-horizon capabilities of various Executors. Code can be available at https://github.com/hehehahi4/CES.",
      "published": "2025-11-27",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.22235v1",
      "relevance_score": 28
    },
    {
      "arxiv_id": "2512.21075v1",
      "title": "Understanding Scaling Laws in Deep Neural Networks via Feature Learning Dynamics",
      "authors": [
        "Zihan Yao",
        "Ruoyu Wu",
        "Tianxiang Gao"
      ],
      "abstract": "The empirical success of deep learning is often attributed to scaling laws that predict consistent gains as model, data, and compute grow; however, large models can exhibit training instability and diminishing returns, suggesting that scaling laws describe what success looks like but not when and why scaling succeeds or fails. A central obstacle is the lack of a rigorous understanding of feature learning at large depth. While muP characterizes feature-learning dynamics in the infinite-width limit and enables hyperparameter transfer across width, its depth extension (depth-muP) breaks down for residual blocks with more than one internal layer. We derive Neural Feature Dynamics (NFD) for ResNets with single-layer residual blocks, characterizing feature learning via a coupled forward-backward stochastic system in the joint infinite-width and infinite-depth limit. In this regime, NFD identifies when scaling-law trends persist and explains diminishing returns. It also reveals a vanishing mechanism induced by the 1/sqrt(depth) residual scaling under which the gradient-independence assumption (GIA), known to fail during training at finite depth, becomes provably valid again at infinite depth, yielding an analytically tractable regime for end-to-end feature learning. Motivated by this insight, we study two-layer residual blocks and show that the same mechanism causes feature-learning collapse in the first internal layer at large depth, providing a structural explanation for the empirical failure of depth-muP. Based on this diagnosis, we propose a depth-aware learning-rate correction that counteracts the collapse and empirically restores depth-wise hyperparameter transfer, yielding stronger performance in deeper ResNets.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21075v1",
      "relevance_score": 27
    },
    {
      "arxiv_id": "2507.22371v1",
      "title": "SAEL: Leveraging Large Language Models with Adaptive Mixture-of-Experts for Smart Contract Vulnerability Detection",
      "authors": [
        "Lei Yu",
        "Shiqi Cheng",
        "Zhirong Huang",
        "Jingyuan Zhang",
        "Chenjie Shen",
        "Junyi Lu",
        "Li Yang",
        "Fengjun Zhang",
        "Jiajia Ma"
      ],
      "abstract": "With the increasing security issues in blockchain, smart contract vulnerability detection has become a research focus. Existing vulnerability detection methods have their limitations: 1) Static analysis methods struggle with complex scenarios. 2) Methods based on specialized pre-trained models perform well on specific datasets but have limited generalization capabilities. In contrast, general-purpose Large Language Models (LLMs) demonstrate impressive ability in adapting to new vulnerability patterns. However, they often underperform on specific vulnerability types compared to methods based on specialized pre-trained models. We also observe that explanations generated by general-purpose LLMs can provide fine-grained code understanding information, contributing to improved detection performance.   Inspired by these observations, we propose SAEL, an LLM-based framework for smart contract vulnerability detection. We first design targeted prompts to guide LLMs in identifying vulnerabilities and generating explanations, which serve as prediction features. Next, we apply prompt-tuning on CodeT5 and T5 to process contract code and explanations, enhancing task-specific performance. To combine the strengths of each approach, we introduce an Adaptive Mixture-of-Experts architecture. This dynamically adjusts feature weights via a Gating Network, which selects relevant features using TopK filtering and Softmax normalization, and incorporates a Multi-Head Self-Attention mechanism to enhance cross-feature relationships. This design enables effective integration of LLM predictions, explanation features, and code features through gradient optimization. The loss function jointly considers both independent feature performance and overall weighted predictions. Experiments show that SAEL outperforms existing methods across various vulnerabilities.",
      "published": "2025-07-30",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.22371v1",
      "relevance_score": 27
    },
    {
      "arxiv_id": "2401.04749v1",
      "title": "LogFormer: A Pre-train and Tuning Pipeline for Log Anomaly Detection",
      "authors": [
        "Hongcheng Guo",
        "Jian Yang",
        "Jiaheng Liu",
        "Jiaqi Bai",
        "Boyang Wang",
        "Zhoujun Li",
        "Tieqiao Zheng",
        "Bo Zhang",
        "Junran peng",
        "Qi Tian"
      ],
      "abstract": "Log anomaly detection is a key component in the field of artificial intelligence for IT operations (AIOps). Considering log data of variant domains, retraining the whole network for unknown domains is inefficient in real industrial scenarios. However, previous deep models merely focused on extracting the semantics of log sequences in the same domain, leading to poor generalization on multi-domain logs. To alleviate this issue, we propose a unified Transformer-based framework for Log anomaly detection (LogFormer) to improve the generalization ability across different domains, where we establish a two-stage process including the pre-training and adapter-based tuning stage. Specifically, our model is first pre-trained on the source domain to obtain shared semantic knowledge of log data. Then, we transfer such knowledge to the target domain via shared parameters. Besides, the Log-Attention module is proposed to supplement the information ignored by the log-paring. The proposed method is evaluated on three public and one real-world datasets. Experimental results on multiple benchmarks demonstrate the effectiveness of our LogFormer with fewer trainable parameters and lower training costs.",
      "published": "2024-01-09",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2401.04749v1",
      "relevance_score": 26
    },
    {
      "arxiv_id": "2511.00690v1",
      "title": "Geomimicry: Emergent Dynamics in Earth-Mediated Complex Materials",
      "authors": [
        "Shravan Pradeep",
        "Emanuela del Gado",
        "Douglas J. Jerolmack",
        "Paulo E. Arratia"
      ],
      "abstract": "Soils and sediments are soft, amorphous materials with complex microstructures and mechanical properties, that are also building blocks for industrial materials such as concrete. These Earth-mediated materials evolve under prolonged environmental pressures like mechanical stress, chemical gradients, and biological activity. Here, we introduce geomimicry, a new paradigm for designing sustainable materials by learning from the emergent and adaptive dynamics of Earth-mediated matter. Drawing a parallel to biomimicry, we posit that these geomaterials follow evolutionary design rules, optimizing their structure and function in response to persistent natural forces. Our central argument is that by decoding these rules: primarily through understanding the emergence of novel exotic properties from multiscale interactions between heterogenous components, we can engineer a new class of adaptive, sustainable matter. We propose two complementary approaches here. The top-down approach looks to nature to identify building blocks and map them to functional groups defined by their mechanical (rather than chemical) behaviors, and then examine how environmental training tunes interactions among these groups. The bottom up approach seeks to leverage and test this framework, building earth materials one component at a time under prescribed fluctuating stresses that guide assembly of complex and out-of-equilibrium materials. The goal is to create materials with programmed functionalities, such as erosion resistance or self-healing capabilities. Geomimicry offers a pathway to truly design Earth-mediated circular materials, with potential applications ranging from climate-resilient soils and smart agriculture to new insights into planetary terraforming, fundamentally shifting the focus from static compositions to dynamic, evolving systems that are mediated via their environment.",
      "published": "2025-11-01",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.00690v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2511.00354v1",
      "title": "Experimental investigation of plasma-electrode interactions on the ZaP-HD sheared-flow-stabilized Z-pinch device",
      "authors": [
        "Amierul Aqil Khairi",
        "Uri Shumlak"
      ],
      "abstract": "The ZaP-HD sheared-flow-stabilized (SFS) Z-pinch device is a testbed for experimental investigation of plasma-electrode interactions. The graphite electrode is exposed to a high temperature, high density Z-pinch plasma while supplying large pinch currents. In-situ measurements of the gross carbon erosion flux obtained with S/XB spectroscopy exceed the expected flux from physical sputtering, but have reasonable agreement with the expected sublimation flux. Comparison of the ionization mean free paths of neutrals produced through both erosion processes shows that sublimated carbon is ionized within the sheath while sputtered carbon is ionized beyond the sheath. This suggests a process of electrode recycling and self-healing through redeposition. The sputtered carbon is primarily responsible for net erosion. Ex-situ analysis of electrode material is enabled by the design of a removable coupon. Three different plasma exposure conditions varied the pinch current and number of pulses. Net mass loss measurements support the physical picture of electrode recycling. Erosion rates range from 0.01 to 0.1 mg/C, which are comparable to existing arc discharge devices. Measurements of the microscopic surface morphology and roughness reveal irregular consolidated structures and general smoothing except at high particle fluence. Crack formation suggests the importance of repetitive thermal cycles. Definitive features of sputtering such as pitting and cratering are absent, although further study is needed to attribute the observed changes to other processes. These results indicate some alignment with erosion processes in high-powered arc discharges, which successfully operate solid electrodes in extreme environments. This provides confidence in managing electrode erosion in the SFS Z-pinch configuration.",
      "published": "2025-11-01",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.00354v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2507.14969v1",
      "title": "Think Like an Engineer: A Neuro-Symbolic Collaboration Agent for Generative Software Requirements Elicitation and Self-Review",
      "authors": [
        "Sai Zhang",
        "Zhenchang Xing",
        "Jieshan Chen",
        "Dehai Zhao",
        "Zizhong Zhu",
        "Xiaowang Zhang",
        "Zhiyong Feng",
        "Xiaohong Li"
      ],
      "abstract": "The vision of End-User Software Engineering (EUSE) is to empower non-professional users with full control over the software development lifecycle. It aims to enable users to drive generative software development using only natural language requirements. However, since end-users often lack knowledge of software engineering, their requirement descriptions are frequently ambiguous, raising significant challenges to generative software development. Although existing approaches utilize structured languages like Gherkin to clarify user narratives, they still struggle to express the causal logic between preconditions and behavior actions. This paper introduces RequireCEG, a requirement elicitation and self-review agent that embeds causal-effect graphs (CEGs) in a neuro-symbolic collaboration architecture. RequireCEG first uses a feature tree to analyze user narratives hierarchically, clearly defining the scope of software components and their system behavior requirements. Next, it constructs the self-healing CEGs based on the elicited requirements, capturing the causal relationships between atomic preconditions and behavioral actions. Finally, the constructed CEGs are used to review and optimize Gherkin scenarios, ensuring consistency between the generated Gherkin requirements and the system behavior requirements elicited from user narratives. To evaluate our method, we created the RGPair benchmark dataset and conducted extensive experiments. It achieves an 87% coverage rate and raises diversity by 51.88%.",
      "published": "2025-07-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.14969v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2505.19230v1",
      "title": "Validating The Effectiveness of Electrospun Self Healing Diels Alder Interleaves to Mode I fracture resistance by Comparing Simulation Outputs with Experimental Results",
      "authors": [
        "Constantinos Rouvalis",
        "Vassilis Kostopoulos",
        "Spyridon Psarras"
      ],
      "abstract": "The predictive capabilities of the finite element approach were assessed by comparing simulation outputs with experimental results, including load-displacement trends, damage initiation points, and delamination evolution. This comparison validated the effectiveness of the self-healing interleaves and highlighted the strengths and limitations of the adopted numerical framework. The simulations not only reproduced key damage characteristics but also provided a deeper understanding of failure mechanisms in the modified laminates. This modeling strategy contributes to the broader goal of developing high-fidelity virtual testing tools for complex, multifunctional composite structures used in aerospace and related industries.",
      "published": "2025-05-25",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.19230v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2505.01215v1",
      "title": "A Self-Healing and Fault-Tolerant Cloud-based Digital Twin Processing Management Model",
      "authors": [
        "Deepika Saxena",
        "Ashutosh Kumar Singh"
      ],
      "abstract": "Digital twins, integral to cloud platforms, bridge physical and virtual worlds, fostering collaboration among stakeholders in manufacturing and processing. However, the cloud platforms face challenges like service outages, vulnerabilities, and resource contention, hindering critical digital twin application development. The existing research works have limited focus on reliability and fault tolerance in digital twin processing. In this context, this paper proposed a novel Self-healing and Faulttolerant cloud-based Digital Twin processing Management (SF-DTM) model. It employs collaborative digital twin tasks resource requirement estimation unit which utilizes newly devised Federated learning with cosine Similarity integration (SimiFed). Further, SF-DTM incorporates a self-healing fault-tolerance strategy employing a frequent sequence fault-prone pattern analytics unit for deciding the most admissible VM allocation. The implementation and evaluation of SF-DTM model using real traces demonstrates its effectiveness and resilience, revealing improved availability, higher Mean Time Between Failure (MTBF), and lower Mean Time To Repair (MTTR) compared with non-SF-DTM approaches, enhancing collaborative DT application management. SF-DTM improved the services availability up to 13.2% over non-SF-DTM-based DT processing.",
      "published": "2025-05-02",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.01215v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.21235v1",
      "title": "RoboCade: Gamifying Robot Data Collection",
      "authors": [
        "Suvir Mirchandani",
        "Mia Tang",
        "Jiafei Duan",
        "Jubayer Ibn Hamid",
        "Michael Cho",
        "Dorsa Sadigh"
      ],
      "abstract": "Imitation learning from human demonstrations has become a dominant approach for training autonomous robot policies. However, collecting demonstration datasets is costly: it often requires access to robots and needs sustained effort in a tedious, long process. These factors limit the scale of data available for training policies. We aim to address this scalability challenge by involving a broader audience in a gamified data collection experience that is both accessible and motivating. Specifically, we develop a gamified remote teleoperation platform, RoboCade, to engage general users in collecting data that is beneficial for downstream policy training. To do this, we embed gamification strategies into the design of the system interface and data collection tasks. In the system interface, we include components such as visual feedback, sound effects, goal visualizations, progress bars, leaderboards, and badges. We additionally propose principles for constructing gamified tasks that have overlapping structure with useful downstream target tasks. We instantiate RoboCade on three manipulation tasks -- including spatial arrangement, scanning, and insertion. To illustrate the viability of gamified robot data collection, we collect a demonstration dataset through our platform, and show that co-training robot policies with this data can improve success rate on non-gamified target tasks (+16-56%). Further, we conduct a user study to validate that novice users find the gamified platform significantly more enjoyable than a standard non-gamified platform (+24%). These results highlight the promise of gamified data collection as a scalable, accessible, and engaging method for collecting demonstration data.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21235v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.20780v1",
      "title": "Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles",
      "authors": [
        "Ramatu Oiza Abdulsalam",
        "Segun Aroyehun"
      ],
      "abstract": "Recent work has explored the use of large language models for generating tutoring responses in mathematics, yet it remains unclear how closely their instructional behavior aligns with expert human practice. We examine this question using a controlled, turn-level comparison in which expert human tutors, novice human tutors, and multiple large language models respond to the same set of math remediation conversation turns. We examine both instructional strategies and linguistic characteristics of tutoring responses, including restating and revoicing, pressing for accuracy, lexical diversity, readability, politeness, and agency. We find that large language models approach expert levels of perceived pedagogical quality on average but exhibit systematic differences in their instructional and linguistic profiles. In particular, large language models tend to underuse restating and revoicing strategies characteristic of expert human tutors, while producing longer, more lexically diverse, and more polite responses. Statistical analyses show that restating and revoicing, lexical diversity, and pressing for accuracy are positively associated with perceived pedagogical quality, whereas higher levels of agentic and polite language are negatively associated. Overall, recent large language models exhibit levels of perceived pedagogical quality comparable to expert human tutors, while relying on different instructional and linguistic strategies. These findings underscore the value of analyzing instructional strategies and linguistic characteristics when evaluating tutoring responses across human tutors and intelligent tutoring systems.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20780v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.20491v2",
      "title": "Step-DeepResearch Technical Report",
      "authors": [
        "Chen Hu",
        "Haikuo Du",
        "Heng Wang",
        "Lin Lin",
        "Mingrui Chen",
        "Peng Liu",
        "Ruihang Miao",
        "Tianchi Yue",
        "Wang You",
        "Wei Ji",
        "Wei Yuan",
        "Wenjin Deng",
        "Xiaojian Yuan",
        "Xiaoyun Zhang",
        "Xiangyu Liu",
        "Xikai Liu",
        "Yanming Xu",
        "Yicheng Cao",
        "Yifei Zhang",
        "Yongyao Wang",
        "Yubo Shu",
        "Yurong Zhang",
        "Yuxiang Zhang",
        "Zheng Gong",
        "Zhichao Chang",
        "Binyan Li",
        "Dan Ma",
        "Furong Jia",
        "Hongyuan Wang",
        "Jiayu Liu",
        "Jing Bai",
        "Junlan Liu",
        "Manjiao Liu",
        "Na Wang",
        "Qiuping Wu",
        "Qinxin Du",
        "Shiwei Li",
        "Wen Sun",
        "Yifeng Gong",
        "Yonglin Chen",
        "Yuling Zhao",
        "Yuxuan Lin",
        "Ziqi Ren",
        "Zixuan Wang",
        "Aihu Zhang",
        "Brian Li",
        "Buyun Ma",
        "Kang An",
        "Li Xie",
        "Mingliang Li",
        "Pan Li",
        "Shidong Yang",
        "Xi Chen",
        "Xiaojia Liu",
        "Yuchu Luo",
        "Yuan Song",
        "YuanHao Ding",
        "Yuanwei Liang",
        "Zexi Li",
        "Zhaoning Zhang",
        "Zixin Zhang",
        "Binxing Jiao",
        "Daxin Jiang",
        "Jiansheng Chen",
        "Jing Li",
        "Xiangyu Zhang",
        "Yibo Zhu"
      ],
      "abstract": "As LLMs shift toward autonomous agents, Deep Research has emerged as a pivotal metric. However, existing academic benchmarks like BrowseComp often fail to meet real-world demands for open-ended research, which requires robust skills in intent recognition, long-horizon decision-making, and cross-source verification. To address this, we introduce Step-DeepResearch, a cost-effective, end-to-end agent. We propose a Data Synthesis Strategy Based on Atomic Capabilities to reinforce planning and report writing, combined with a progressive training path from agentic mid-training to SFT and RL. Enhanced by a Checklist-style Judger, this approach significantly improves robustness. Furthermore, to bridge the evaluation gap in the Chinese domain, we establish ADR-Bench for realistic deep research scenarios. Experimental results show that Step-DeepResearch (32B) scores 61.4% on Scale AI Research Rubrics. On ADR-Bench, it significantly outperforms comparable models and rivals SOTA closed-source models like OpenAI and Gemini DeepResearch. These findings prove that refined training enables medium-sized models to achieve expert-level capabilities at industry-leading cost-efficiency.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20491v2",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.20278v1",
      "title": "Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation",
      "authors": [
        "Nishant Gaurav",
        "Adit Akarsh",
        "Ankit Ranjan",
        "Manoj Bajaj"
      ],
      "abstract": "While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20278v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.20237v1",
      "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents",
      "authors": [
        "Xingbo Du",
        "Loka Li",
        "Duzhen Zhang",
        "Le Song"
      ],
      "abstract": "Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents. However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval. From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. This design departs from the standard retrieve-then-answer pipeline by introducing a closed-loop control mechanism that enables autonomous decision-making. Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20237v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.20224v1",
      "title": "UrbanV2X: A Multisensory Vehicle-Infrastructure Dataset for Cooperative Navigation in Urban Areas",
      "authors": [
        "Qijun Qin",
        "Ziqi Zhang",
        "Yihan Zhong",
        "Feng Huang",
        "Xikun Liu",
        "Runzhi Hu",
        "Hang Chen",
        "Wei Hu",
        "Dongzhe Su",
        "Jun Zhang",
        "Hoi-Fung Ng",
        "Weisong Wen"
      ],
      "abstract": "Due to the limitations of a single autonomous vehicle, Cellular Vehicle-to-Everything (C-V2X) technology opens a new window for achieving fully autonomous driving through sensor information sharing. However, real-world datasets supporting vehicle-infrastructure cooperative navigation in complex urban environments remain rare. To address this gap, we present UrbanV2X, a comprehensive multisensory dataset collected from vehicles and roadside infrastructure in the Hong Kong C-V2X testbed, designed to support research on smart mobility applications in dense urban areas. Our onboard platform provides synchronized data from multiple industrial cameras, LiDARs, 4D radar, ultra-wideband (UWB), IMU, and high-precision GNSS-RTK/INS navigation systems. Meanwhile, our roadside infrastructure provides LiDAR, GNSS, and UWB measurements. The entire vehicle-infrastructure platform is synchronized using the Precision Time Protocol (PTP), with sensor calibration data provided. We also benchmark various navigation algorithms to evaluate the collected cooperative data. The dataset is publicly available at https://polyu-taslab.github.io/UrbanV2X/.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20224v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.21129v1",
      "title": "Active inference and artificial reasoning",
      "authors": [
        "Karl Friston",
        "Lancelot Da Costa",
        "Alexander Tschantz",
        "Conor Heins",
        "Christopher Buckley",
        "Tim Verbelen",
        "Thomas Parr"
      ],
      "abstract": "This technical note considers the sampling of outcomes that provide the greatest amount of information about the structure of underlying world models. This generalisation furnishes a principled approach to structure learning under a plausible set of generative models or hypotheses. In active inference, policies - i.e., combinations of actions - are selected based on their expected free energy, which comprises expected information gain and value. Information gain corresponds to the KL divergence between predictive posteriors with, and without, the consequences of action. Posteriors over models can be evaluated quickly and efficiently using Bayesian Model Reduction, based upon accumulated posterior beliefs about model parameters. The ensuing information gain can then be used to select actions that disambiguate among alternative models, in the spirit of optimal experimental design. We illustrate this kind of active selection or reasoning using partially observed discrete models; namely, a 'three-ball' paradigm used previously to describe artificial insight and 'aha moments' via (synthetic) introspection or sleep. We focus on the sample efficiency afforded by seeking outcomes that resolve the greatest uncertainty about the world model, under which outcomes are generated.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21129v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.21065v1",
      "title": "Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation",
      "authors": [
        "Zebin Jiang",
        "Tianle Jin",
        "Xiangtong Yao",
        "Alois Knoll",
        "Hu Cao"
      ],
      "abstract": "Grasping is one of the most fundamental challenging capabilities in robotic manipulation, especially in unstructured, cluttered, and semantically diverse environments. Recent researches have increasingly explored language-guided manipulation, where robots not only perceive the scene but also interpret task-relevant natural language instructions. However, existing language-conditioned grasping methods typically rely on shallow fusion strategies, leading to limited semantic grounding and weak alignment between linguistic intent and visual grasp reasoning.In this work, we propose Language-Guided Grasp Detection (LGGD) with a coarse-to-fine learning paradigm for robotic manipulation. LGGD leverages CLIP-based visual and textual embeddings within a hierarchical cross-modal fusion pipeline, progressively injecting linguistic cues into the visual feature reconstruction process. This design enables fine-grained visual-semantic alignment and improves the feasibility of the predicted grasps with respect to task instructions. In addition, we introduce a language-conditioned dynamic convolution head (LDCH) that mixes multiple convolution experts based on sentence-level features, enabling instruction-adaptive coarse mask and grasp predictions. A final refinement module further enhances grasp consistency and robustness in complex scenes.Experiments on the OCID-VLG and Grasp-Anything++ datasets show that LGGD surpasses existing language-guided grasping methods, exhibiting strong generalization to unseen objects and diverse language queries. Moreover, deployment on a real robotic platform demonstrates the practical effectiveness of our approach in executing accurate, instruction-conditioned grasp actions. The code will be released publicly upon acceptance.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21065v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.21005v1",
      "title": "Learning from Neighbors with PHIBP: Predicting Infectious Disease Dynamics in Data-Sparse Environments",
      "authors": [
        "Edwin Fong",
        "Lancelot F. James",
        "Juho Lee"
      ],
      "abstract": "Modeling sparse count data, which arise across numerous scientific fields, presents significant statistical challenges. This chapter addresses these challenges in the context of infectious disease prediction, with a focus on predicting outbreaks in geographic regions that have historically reported zero cases. To this end, we present the detailed computational framework and experimental application of the Poisson Hierarchical Indian Buffet Process (PHIBP), with demonstrated success in handling sparse count data in microbiome and ecological studies. The PHIBP's architecture, grounded in the concept of absolute abundance, systematically borrows statistical strength from related regions and circumvents the known sensitivities of relative-rate methods to zero counts. Through a series of experiments on infectious disease data, we show that this principled approach provides a robust foundation for generating coherent predictive distributions and for the effective use of comparative measures such as alpha and beta diversity. The chapter's emphasis on algorithmic implementation and experimental results confirms that this unified framework delivers both accurate outbreak predictions and meaningful epidemiological insights in data-sparse settings.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21005v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.18405v1",
      "title": "Towards Scalable Visual Data Wrangling via Direct Manipulation",
      "authors": [
        "El Kindi Rezig",
        "Mir Mahathir Mohammad",
        "Nicolas Baret",
        "Ricardo Mayerhofer",
        "Andrew McNutt",
        "Paul Rosen"
      ],
      "abstract": "Data wrangling - the process of cleaning, transforming, and preparing data for analysis - is a well-known bottleneck in data science workflows. Existing tools either rely on manual scripting, which is error-prone and hard to debug, or automate cleaning through opaque black-box pipelines that offer limited control. We present Buckaroo, a scalable visual data wrangling system that restructures data preparation as a direct manipulation task over visualizations. Buckaroo enables users to explore and repair data anomalies - such as missing values, outliers, and type mismatches - by interacting directly with coordinated data visualizations. The system extensibly supports user-defined error detectors and wranglers, tracks provenance for undo/redo, and generates reproducible scripts for downstream tasks. Buckaroo maintains efficient indexing data structures and differential storage to localize anomaly detection and minimize recomputation. To demonstrate the applicability of our model, Buckaroo is integrated with the \\textit{Hopara} pan-and-zoom engine, which enables multi-layered navigation over large datasets without sacrificing interactivity. Through empirical evaluation and an expert review, we show that Buckaroo makes visual data wrangling scalable - bridging the gap between visual inspection and programmable repairs.",
      "published": "2025-12-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18405v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.17682v1",
      "title": "Leptogenesis and Dark Matter in an Inverse Seesaw from gauged B-L breaking",
      "authors": [
        "Enrique Fern\u00e1ndez-Mart\u00ednez",
        "Ana Luisa Foguel",
        "Xabier Marcano",
        "Daniel Naredo-Tuero",
        "Vsevolod Syvolap",
        "Kevin A. Urqu\u00eda-Calder\u00f3n"
      ],
      "abstract": "We study a dynamical realization of the low-scale Inverse Seesaw mechanism in which the approximate $B-L$ symmetry is gauged and spontaneously broken. Anomaly cancellation requires additional chiral fermions, one of which becomes a stable dark matter candidate after symmetry breaking, while another remains massless and contributes to dark radiation. Focusing on the regime of feeble gauge interactions, we compute the dark matter relic abundance produced via the freeze-in mechanism through the $B-L$ gauge boson and identify the parameter space consistent with cosmological and laboratory constraints. We show that the same region naturally avoids thermalization of heavy neutral leptons, preserving the viability of ARS leptogenesis. The interplay between dark matter production, dark radiation constraints, and leptogenesis requirements leads to a predictive scenario where future cosmological surveys and intensity-frontier experiments such as SHiP can probe significant portions of the viable parameter space.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17682v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2511.06367v1",
      "title": "Methodological Considerations for Self-adaptive Systems: An Essay",
      "authors": [
        "Sara Mahdavi Hezavehi",
        "Danny Weyns",
        "Paris Avgeriou"
      ],
      "abstract": "In this essay, we provide an overview of methodological considerations necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation.",
      "published": "2025-11-09",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.06367v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2511.06352v1",
      "title": "State of the Art on Self-adaptive Systems: An Essay",
      "authors": [
        "Sara Mahdavi Hezavehi",
        "Danny Weyns",
        "Paris Avgeriou"
      ],
      "abstract": "In this essay, we introduce the basic concepts necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation, and discuss relevant related research.",
      "published": "2025-11-09",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.06352v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2511.03153v1",
      "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring",
      "authors": [
        "Khouloud Oueslati",
        "Maxime Lamothe",
        "Foutse Khomh"
      ],
      "abstract": "Large Language Models (LLMs) have substantially influenced various software engineering tasks. Indeed, in the case of software refactoring, traditional LLMs have shown the ability to reduce development time and enhance code quality. However, these LLMs often rely on static, detailed instructions for specific tasks. In contrast, LLM-based agents can dynamically adapt to evolving contexts and autonomously make decisions by interacting with software tools and executing workflows. In this paper, we explore the potential of LLM-based agents in supporting refactoring activities. Specifically, we introduce RefAgent, a multi-agent LLM-based framework for end-to-end software refactoring. RefAgent consists of specialized agents responsible for planning, executing, testing, and iteratively refining refactorings using self-reflection and tool-calling capabilities. We evaluate RefAgent on eight open-source Java projects, comparing its effectiveness against a single-agent approach, a search-based refactoring tool, and historical developer refactorings. Our assessment focuses on: (1) the impact of generated refactorings on software quality, (2) the ability to identify refactoring opportunities, and (3) the contribution of each LLM agent through an ablation study. Our results show that RefAgent achieves a median unit test pass rate of 90%, reduces code smells by a median of 52.5%, and improves key quality attributes (e.g., reusability) by a median of 8.6%. Additionally, it closely aligns with developer refactorings and the search-based tool in identifying refactoring opportunities, attaining a median F1-score of 79.15% and 72.7%, respectively. Compared to single-agent approaches, RefAgent improves the median unit test pass rate by 64.7% and the median compilation success rate by 40.1%. These findings highlight the promise of multi-agent architectures in advancing automated software refactoring.",
      "published": "2025-11-05",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.03153v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2509.23045v3",
      "title": "Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents",
      "authors": [
        "Zonghan Yang",
        "Shengjie Wang",
        "Kelin Fu",
        "Wenyang He",
        "Weimin Xiong",
        "Yibo Liu",
        "Yibo Miao",
        "Bofei Gao",
        "Yejie Wang",
        "Yingwei Ma",
        "Yanhao Li",
        "Yue Liu",
        "Zhenxing Hu",
        "Kaitai Zhang",
        "Shuyi Wang",
        "Huarong Chen",
        "Flood Sung",
        "Yang Liu",
        "Yang Gao",
        "Zhilin Yang",
        "Tianyu Liu"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly applied to software engineering (SWE), with SWE-bench as a key benchmark. Solutions are split into SWE-Agent frameworks with multi-turn interactions and workflow-based Agentless methods with single-turn verifiable steps. We argue these paradigms are not mutually exclusive: reasoning-intensive Agentless training induces skill priors, including localization, code edit, and self-reflection that enable efficient and effective SWE-Agent adaptation. In this work, we first curate the Agentless training recipe and present Kimi-Dev, an open-source SWE LLM achieving 60.4\\% on SWE-bench Verified, the best among workflow approaches. With additional SFT adaptation on 5k publicly-available trajectories, Kimi-Dev powers SWE-Agents to 48.6\\% pass@1, on par with that of Claude 3.5 Sonnet (241022 version). These results show that structured skill priors from Agentless training can bridge workflow and agentic frameworks for transferable coding agents.",
      "published": "2025-09-27",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.23045v3",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2507.16327v1",
      "title": "Search-based Generation of Waypoints for Triggering Self-Adaptations in Maritime Autonomous Vessels",
      "authors": [
        "Karoline Nyl\u00e6nder",
        "Aitor Arrieta",
        "Shaukat Ali",
        "Paolo Arcaini"
      ],
      "abstract": "Self-adaptation in maritime autonomous vessels (AVs) enables them to adapt their behaviors to address unexpected situations while maintaining dependability requirements. During the design of such AVs, it is crucial to understand and identify the settings that should trigger adaptations, enabling validation of their implementation. To this end, we focus on the navigation software of AVs, which must adapt their behavior during operation through adaptations. AVs often rely on predefined waypoints to guide them along designated routes, ensuring safe navigation. We propose a multiobjective search-based approach, called WPgen, to generate minor modifications to the predefined set of waypoints, keeping them as close as possible to the original waypoints, while causing the AV to navigate inappropriately when navigating with the generated waypoints. WPgen uses NSGA-II as the multi-objective search algorithm with three seeding strategies for its initial population, resulting in three variations of WPgen. We evaluated these variations on three AVs (one overwater tanker and two underwater). We compared the three variations of WPgen with Random Search as the baseline and with each other. Experimental results showed that the effectiveness of these variations varied depending on the AV. Based on the results, we present the research and practical implications of WPgen.",
      "published": "2025-07-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.16327v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.16036v1",
      "title": "Topic Discovery and Classification for Responsible Generative AI Adaptation in Higher Education",
      "authors": [
        "Diane Myung-kyung Woodbridge",
        "Allyson Seba",
        "Freddie Seba",
        "Aydin Schwartz"
      ],
      "abstract": "As generative artificial intelligence (GenAI) becomes increasingly capable of delivering personalized learning experiences and real-time feedback, a growing number of students are incorporating these tools into their academic workflows. They use GenAI to clarify concepts, solve complex problems, and, in some cases, complete assignments by copying and pasting model-generated contents. While GenAI has the potential to enhance learning experience, it also raises concerns around misinformation, hallucinated outputs, and its potential to undermine critical thinking and problem-solving skills. In response, many universities, colleges, departments, and instructors have begun to develop and adopt policies to guide responsible integration of GenAI into learning environments. However, these policies vary widely across institutions and contexts, and their evolving nature often leaves students uncertain about expectations and best practices. To address this challenge, the authors designed and implemented an automated system for discovering and categorizing AI-related policies found in course syllabi and institutional policy websites. The system combines unsupervised topic modeling techniques to identify key policy themes with large language models (LLMs) to classify the level of GenAI allowance and other requirements in policy texts. The developed application achieved a coherence score of 0.73 for topic discovery. In addition, GPT-4.0-based classification of policy categories achieved precision between 0.92 and 0.97, and recall between 0.85 and 0.97 across eight identified topics. By providing structured and interpretable policy information, this tool promotes the safe, equitable, and pedagogically aligned use of GenAI technologies in education. Furthermore, the system can be integrated into educational technology platforms to help students understand and comply with relevant guidelines.",
      "published": "2025-12-17",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.16036v1",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2512.11506v2",
      "title": "EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection",
      "authors": [
        "Georgios Kaoukis",
        "Ioannis Aris Koufopoulos",
        "Eleni Psaroudaki",
        "Danae Pla Karidi",
        "Evaggelia Pitoura",
        "George Papastefanatos",
        "Panayiotis Tsaparas"
      ],
      "abstract": "As AI and web agents become pervasive in decision-making, it is critical to design intelligent systems that not only support sustainability efforts but also guard against misinformation. Greenwashing, i.e., misleading corporate sustainability claims, poses a major challenge to environmental progress. To address this challenge, we introduce EmeraldMind, a fact-centric framework integrating a domain-specific knowledge graph with retrieval-augmented generation to automate greenwashing detection. EmeraldMind builds the EmeraldGraph from diverse corporate ESG (environmental, social, and governance) reports, surfacing verifiable evidence, often missing in generic knowledge bases, and supporting large language models in claim assessment. The framework delivers justification-centric classifications, presenting transparent, evidence-backed verdicts and abstaining responsibly when claims cannot be verified. Experiments on a new greenwashing claims dataset demonstrate that EmeraldMind achieves competitive accuracy, greater coverage, and superior explanation quality compared to generic LLMs, without the need for fine-tuning or retraining.",
      "published": "2025-12-12",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.11506v2",
      "relevance_score": 25
    },
    {
      "arxiv_id": "2505.05370v2",
      "title": "Walrus: An Efficient Decentralized Storage Network",
      "authors": [
        "George Danezis",
        "Giacomo Giuliari",
        "Eleftherios Kokoris Kogias",
        "Markus Legner",
        "Jean-Pierre Smith",
        "Alberto Sonnino",
        "Karl W\u00fcst"
      ],
      "abstract": "Decentralized storage systems face a fundamental trade-off between replication overhead, recovery efficiency, and security guarantees. Current approaches either rely on full replication, incurring substantial storage costs, or employ trivial erasure coding schemes that struggle with efficient recovery especially under high storage-node churn. We present Walrus, a novel decentralized blob storage system that addresses these limitations through multiple technical innovations. At the core of Walrus is RedStuff, a two-dimensional erasure coding protocol that achieves high security with only 4.5x replication factor, while enabling self-healing recovery that requires bandwidth proportional to only the lost data $(O(|blob|/n)$ versus $O(|blob|)$ in traditional systems). Crucially, RedStuff is the first protocol to support storage challenges in asynchronous networks, preventing adversaries from exploiting network delays to pass verification without actually storing data. Walrus also introduces a novel multi-stage epoch change protocol that efficiently handles storage node churn while maintaining uninterrupted availability during committee transitions. Our system incorporates authenticated data structures to defend against malicious clients and ensures data consistency throughout storage and retrieval processes. Experimental evaluation demonstrates that Walrus achieves practical performance at scale, making it suitable for a wide range of decentralized applications requiring high-integrity, available blob storage with reasonable overhead.",
      "published": "2025-05-08",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.05370v2",
      "relevance_score": 24
    },
    {
      "arxiv_id": "2512.20177v1",
      "title": "NeuralCrop: Combining physics and machine learning for improved crop yield predictions",
      "authors": [
        "Yunan Lin",
        "Sebastian Bathiany",
        "Maha Badri",
        "Maximilian Gelbrecht",
        "Philipp Hess",
        "Brian Groenke",
        "Jens Heinke",
        "Christoph M\u00fcller",
        "Niklas Boers"
      ],
      "abstract": "Global gridded crop models (GGCMs) simulate daily crop growth by explicitly representing key biophysical processes and project end-of-season yield time series. They are a primary tool to quantify the impacts of climate change on agricultural productivity and assess associated risks for food security. Despite decades of development, state-of-the-art GGCMs still have substantial uncertainties in simulating complex biophysical processes due to limited process understanding. Recently, machine learning approaches trained on observational data have shown great potential in crop yield predictions. However, these models have not demonstrated improved performance over classical GGCMs and are not suitable for simulating crop yields under changing climate conditions due to problems in generalizing outside their training distributions. Here we introduce NeuralCrop, a hybrid GGCM that combines the strengths of an advanced process-based GGCM, resolving important processes explicitly, with data-driven machine learning components. The model is first trained to emulate a competitive GGCM before it is fine-tuned on observational data. We show that NeuralCrop outperforms state-of-the-art GGCMs across site-level and large-scale cropping regions. Across moisture conditions, NeuralCrop reproduces the interannual yield anomalies in European wheat regions and the US Corn Belt more accurately during the period from 2000 to 2019 with particularly strong improvements under drought extremes. When generalizing to conditions unseen during training, NeuralCrop continues to make robust projections, while pure machine learning models exhibit substantial performance degradation. Our results show that our hybrid crop modelling approach offers overall improved crop modeling and more reliable yield projections under climate change and intensifying extreme weather conditions.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20177v1",
      "relevance_score": 24
    },
    {
      "arxiv_id": "2512.14640v1",
      "title": "A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images",
      "authors": [
        "Rao Muhammad Umer",
        "Daniel Sens",
        "Jonathan Noll",
        "Christian Matek",
        "Lukas Wolfseher",
        "Rainer Spang",
        "Ralf Huss",
        "Johannes Raffler",
        "Sarah Reinke",
        "Wolfram Klapper",
        "Katja Steiger",
        "Kristina Schwamborn",
        "Carsten Marr"
      ],
      "abstract": "Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring costly equipment, skilled personnel, and causing treatment delays. Deep learning methods could assist pathologists by extracting diagnostic information from routinely available HE-stained slides, yet comprehensive benchmarks for lymphoma subtyping on multicenter data are lacking. In this work, we present the first multicenter lymphoma benchmarking dataset covering four common lymphoma subtypes and healthy control tissue. We systematically evaluate five publicly available pathology foundation models (H-optimus-1, H0-mini, Virchow2, UNI2, Titan) combined with attention-based (AB-MIL) and transformer-based (TransMIL) multiple instance learning aggregators across three magnifications (10x, 20x, 40x). On in-distribution test sets, models achieve multiclass balanced accuracies exceeding 80% across all magnifications, with all foundation models performing similarly and both aggregation methods showing comparable results. The magnification study reveals that 40x resolution is sufficient, with no performance gains from higher resolutions or cross-magnification aggregation. However, on out-of-distribution test sets, performance drops substantially to around 60%, highlighting significant generalization challenges. To advance the field, larger multicenter studies covering additional rare lymphoma subtypes are needed. We provide an automated benchmarking pipeline to facilitate such future research.",
      "published": "2025-12-16",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.14640v1",
      "relevance_score": 24
    },
    {
      "arxiv_id": "2512.18528v1",
      "title": "WoundNet-Ensemble: A Novel IoMT System Integrating Self-Supervised Deep Learning and Multi-Model Fusion for Automated, High-Accuracy Wound Classification and Healing Progression Monitoring",
      "authors": [
        "Moses Kiprono"
      ],
      "abstract": "Chronic wounds, including diabetic foot ulcers which affect up to one-third of people with diabetes, impose a substantial clinical and economic burden, with U.S. healthcare costs exceeding 25 billion dollars annually. Current wound assessment remains predominantly subjective, leading to inconsistent classification and delayed interventions. We present WoundNet-Ensemble, an Internet of Medical Things system leveraging a novel ensemble of three complementary deep learning architectures: ResNet-50, the self-supervised Vision Transformer DINOv2, and Swin Transformer, for automated classification of six clinically distinct wound types. Our system achieves 99.90 percent ensemble accuracy on a comprehensive dataset of 5,175 wound images spanning diabetic foot ulcers, pressure ulcers, venous ulcers, thermal burns, pilonidal sinus wounds, and fungating malignant tumors. The weighted fusion strategy demonstrates a 3.7 percent improvement over previous state-of-the-art methods. Furthermore, we implement a longitudinal wound healing tracker that computes healing rates, severity scores, and generates clinical alerts. This work demonstrates a robust, accurate, and clinically deployable tool for modernizing wound care through artificial intelligence, addressing critical needs in telemedicine and remote patient monitoring. The implementation and trained models will be made publicly available to support reproducibility.",
      "published": "2025-12-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18528v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2508.13714v1",
      "title": "Airy beams for near-field communications: Fundamentals, potentials, and limitations",
      "authors": [
        "Donatella Darsena",
        "Francesco Verde",
        "Marco Di Renzo",
        "Vincenzo Galdi"
      ],
      "abstract": "In next-generation wireless networks, the combination of electrically large radiating apertures and high-frequency transmission extends the radiating near-field region around the transmitter. In this region, unlike in the far field, the wavefront is nonplanar, which provides additional degrees of freedom to shape and steer the transmitted beam in a desired manner. In this paper, we focus on Airy beams, which may exhibit several highly desirable properties in the near-field region. Ideally, these beams follow self-accelerating (curved) trajectories, demonstrate resilience to perturbations through self-healing, and maintain a consistent intensity profile across all planes perpendicular to the propagation direction, making them effectively diffraction-free. Specifically, we first present the underlying principles of self-accelerating beams radiated by continuous aperture field distributions. We then address several challenges regarding the generation of Airy beams, including their exponential decay due to finite energy constraints and spatial truncation of the aperture. Moreover, we examine their free-space propagation characteristics. The second part of the paper focuses on the propagation behavior of Airy beams in non-line-of-sight (NLoS) scenarios. A comparison is also presented between Airy beams and Gaussian beams. Our theoretical and numerical results show that Airy beams may offer a performance advantage over Gaussian beams in certain NLoS channels, provided that their key properties are largely preserved, specifically, self-acceleration along a parabolic trajectory and diffraction-free propagation. In the presence of an obstacle, this requires that the portion of the transmit aperture with a clear line-of-sight to the receiver is sufficiently large.",
      "published": "2025-08-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2508.13714v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2506.19636v1",
      "title": "Resilience assessment framework for cyber-physical distribution power system based on coordinated cyber-physical attacks under dynamic game",
      "authors": [
        "Yulin Liu",
        "Zhaojun Ruan",
        "Libao Shi"
      ],
      "abstract": "Owing to the advanced communication networks and intelligent electronic devices, the cyber-physical distribution systems (CPDSs) possess the capability to perform flexible economic dispatch and achieve rapid self-healing from extreme events. Meanwhile, the deep integration of cyber and physical systems makes CPDS vulnerable to coordinated cyber-physical attacks. In this paper, a resilience assessment framework for the CPDS under coordinated cyber-physical attacks is proposed to investigate the impact of the coordinated attacks on load loss and service restoration in CPDS. First, a three-stage defender-attacker-defender dynamic game model considering fake base station (FBS) and physical attacks for CPDS is established, aiming at seeking the optimal defense resource deployment strategy to enhance the resilience of the CPDS. The physical attack is launched to cause faults on the power lines, and the FBS attack is employed to interrupt the service of wireless cellular network to hinder the self-healing process of the CPDS. The lognormal shadowing model and search theory are applied to quantitatively describe the process of the coordinated cyber-physical attacks. Further, the constructed three-stage dynamic game model is equivalently recast as a tri-level max-min-max optimization model, which is solved using column-and-constraint generation combined with enumeration method. Finally, the effectiveness of the proposed resilience assessment framework and solution strategy is demonstrated by conducting simulation analysis on the modified IEEE 33-node CPDS and a real-world 47-node CPDS in China.",
      "published": "2025-06-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2506.19636v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2506.01210v1",
      "title": "Development of Hardware-in-Loop Framework for Satellite Communication Self-Healing Networks",
      "authors": [
        " Sambrama",
        "Venkata Srirama Rohit Kantheti",
        "Liang C Chu",
        "Erik Blasch",
        "Shih-Chun Lin"
      ],
      "abstract": "The use of Low Earth Orbit (LEO) satellites in the next generation (Next-G) communication systems has been gaining traction over the last few years due to their potential for providing global connectivity with low latency. Since they are the closest to the earth they come with their own set of disadvantages including high vulnerability to jamming and interference. To address these issues, this paper introduces a resilient, self-healing network designed to optimize signal quality under dynamic interference and adversarial conditions. The network leverages inter-satellite communication and an intelligent algorithm selection process, incorporating combining techniques like distributed-Maximal Ratio Combining (d-MRC), distributed-Linear Minimum Mean Squared Error Estimation (d-LMMSE), and Selection Combining (SC). These algorithms are selected to improve performance by adapting to changing network conditions. To evaluate the effectiveness of the proposed solution, we develop a software-defined radio (SDR)-based hardware testbed and perform detailed performance evaluations. Additionally, we present results from field tests conducted on the AERPAW testbed, which validate the proposed combining solutions in real-world scenarios. The results show that our approach makes LEO satellite networks more reliable and better able to handle interference, making them suitable for critical communications.",
      "published": "2025-06-01",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2506.01210v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.21335v1",
      "title": "Autonomous Uncertainty Quantification for Computational Point-of-care Sensors",
      "authors": [
        "Artem Goncharov",
        "Rajesh Ghosh",
        "Hyou-Arm Joung",
        "Dino Di Carlo",
        "Aydogan Ozcan"
      ],
      "abstract": "Computational point-of-care (POC) sensors enable rapid, low-cost, and accessible diagnostics in emergency, remote and resource-limited areas that lack access to centralized medical facilities. These systems can utilize neural network-based algorithms to accurately infer a diagnosis from the signals generated by rapid diagnostic tests or sensors. However, neural network-based diagnostic models are subject to hallucinations and can produce erroneous predictions, posing a risk of misdiagnosis and inaccurate clinical decisions. To address this challenge, here we present an autonomous uncertainty quantification technique developed for POC diagnostics. As our testbed, we used a paper-based, computational vertical flow assay (xVFA) platform developed for rapid POC diagnosis of Lyme disease, the most prevalent tick-borne disease globally. The xVFA platform integrates a disposable paper-based assay, a handheld optical reader and a neural network-based inference algorithm, providing rapid and cost-effective Lyme disease diagnostics in under 20 min using only 20 uL of patient serum. By incorporating a Monte Carlo dropout (MCDO)-based uncertainty quantification approach into the diagnostics pipeline, we identified and excluded erroneous predictions with high uncertainty, significantly improving the sensitivity and reliability of the xVFA in an autonomous manner, without access to the ground truth diagnostic information of patients. Blinded testing using new patient samples demonstrated an increase in diagnostic sensitivity from 88.2% to 95.7%, indicating the effectiveness of MCDO-based uncertainty quantification in enhancing the robustness of neural network-driven computational POC sensing systems.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21335v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.21215v1",
      "title": "USE: A Unified Model for Universal Sound Separation and Extraction",
      "authors": [
        "Hongyu Wang",
        "Chenda Li",
        "Xin Zhou",
        "Shuai Wang",
        "Yanmin Qian"
      ],
      "abstract": "Sound separation (SS) and target sound extraction (TSE) are fundamental techniques for addressing complex acoustic scenarios. While existing SS methods struggle with determining the unknown number of sound sources, TSE approaches require precisely specified clues to achieve optimal performance. This paper proposes a unified framework that synergistically combines SS and TSE to overcome their individual limitations. Our architecture employs two complementary components: 1) An Encoder-Decoder Attractor (EDA) network that automatically infers both the source count and corresponding acoustic clues for SS, and 2) A multi-modal fusion network that precisely interprets diverse user-provided clues (acoustic, semantic, or visual) for TSE. Through joint training with cross-task consistency constraints, we establish a unified latent space that bridges both paradigms. During inference, the system adaptively operates in either fully autonomous SS mode or clue-driven TSE mode. Experiments demonstrate remarkable performance in both tasks, with notable improvements of 1.4 dB SDR improvement in SS compared to baseline and 86\\% TSE accuracy.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21215v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2510.23672v1",
      "title": "DBLoss: Decomposition-based Loss Function for Time Series Forecasting",
      "authors": [
        "Xiangfei Qiu",
        "Xingjian Wu",
        "Hanyin Cheng",
        "Xvyuan Liu",
        "Chenjuan Guo",
        "Jilin Hu",
        "Bin Yang"
      ],
      "abstract": "Time series forecasting holds significant value in various domains such as economics, traffic, energy, and AIOps, as accurate predictions facilitate informed decision-making. However, the existing Mean Squared Error (MSE) loss function sometimes fails to accurately capture the seasonality or trend within the forecasting horizon, even when decomposition modules are used in the forward propagation to model the trend and seasonality separately. To address these challenges, we propose a simple yet effective Decomposition-Based Loss function called DBLoss. This method uses exponential moving averages to decompose the time series into seasonal and trend components within the forecasting horizon, and then calculates the loss for each of these components separately, followed by weighting them. As a general loss function, DBLoss can be combined with any deep learning forecasting model. Extensive experiments demonstrate that DBLoss significantly improves the performance of state-of-the-art models across diverse real-world datasets and provides a new perspective on the design of time series loss functions.",
      "published": "2025-10-27",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.23672v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2510.10320v1",
      "title": "Prepared for the Unknown: Adapting AIOps Capacity Forecasting Models to Data Changes",
      "authors": [
        "Lorena Poenaru-Olaru",
        "Wouter van 't Hof",
        "Adrian Stando",
        "Arkadiusz P. Trawinski",
        "Eileen Kapel",
        "Jan S. Rellermeyer",
        "Luis Cruz",
        "Arie van Deursen"
      ],
      "abstract": "Capacity management is critical for software organizations to allocate resources effectively and meet operational demands. An important step in capacity management is predicting future resource needs often relies on data-driven analytics and machine learning (ML) forecasting models, which require frequent retraining to stay relevant as data evolves. Continuously retraining the forecasting models can be expensive and difficult to scale, posing a challenge for engineering teams tasked with balancing accuracy and efficiency. Retraining only when the data changes appears to be a more computationally efficient alternative, but its impact on accuracy requires further investigation. In this work, we investigate the effects of retraining capacity forecasting models for time series based on detected changes in the data compared to periodic retraining. Our results show that drift-based retraining achieves comparable forecasting accuracy to periodic retraining in most cases, making it a cost-effective strategy. However, in cases where data is changing rapidly, periodic retraining is still preferred to maximize the forecasting accuracy. These findings offer actionable insights for software teams to enhance forecasting systems, reducing retraining overhead while maintaining robust performance.",
      "published": "2025-10-11",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.10320v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2509.14933v1",
      "title": "DAG: A Dual Causal Network for Time Series Forecasting with Exogenous Variables",
      "authors": [
        "Xiangfei Qiu",
        "Yuhan Zhu",
        "Zhengyu Li",
        "Hanyin Cheng",
        "Xingjian Wu",
        "Chenjuan Guo",
        "Bin Yang",
        "Jilin Hu"
      ],
      "abstract": "Time series forecasting is crucial in various fields such as economics, traffic, and AIOps. However, in real-world applications, focusing solely on the endogenous variables (i.e., target variables), is often insufficient to ensure accurate predictions. Considering exogenous variables (i.e., covariates) provides additional predictive information, thereby improving forecasting accuracy. However, existing methods for time series forecasting with exogenous variables (TSF-X) have the following shortcomings: 1) they do not leverage future exogenous variables, 2) they fail to account for the causal relationships between endogenous and exogenous variables. As a result, their performance is suboptimal. In this study, to better leverage exogenous variables, especially future exogenous variable, we propose a general framework DAG, which utilizes dual causal network along both the temporal and channel dimensions for time series forecasting with exogenous variables. Specifically, we first introduce the Temporal Causal Module, which includes a causal discovery module to capture how historical exogenous variables affect future exogenous variables. Following this, we construct a causal injection module that incorporates the discovered causal relationships into the process of forecasting future endogenous variables based on historical endogenous variables. Next, we propose the Channel Causal Module, which follows a similar design principle. It features a causal discovery module models how historical exogenous variables influence historical endogenous variables, and a causal injection module incorporates the discovered relationships to enhance the prediction of future endogenous variables based on future exogenous variables.",
      "published": "2025-09-18",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.14933v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2505.02961v1",
      "title": "Can We Recycle Our Old Models? An Empirical Evaluation of Model Selection Mechanisms for AIOps Solutions",
      "authors": [
        "Yingzhe Lyu",
        "Hao Li",
        "Heng Li",
        "Ahmed E. Hassan"
      ],
      "abstract": "AIOps (Artificial Intelligence for IT Operations) solutions leverage the tremendous amount of data produced during the operation of large-scale systems and machine learning models to assist software practitioners in their system operations. Existing AIOps solutions usually maintain AIOps models against concept drift through periodical retraining, despite leaving a pile of discarded historical models that may perform well on specific future data. Other prior works propose dynamically selecting models for prediction tasks from a set of candidate models to optimize the model performance. However, there is no prior work in the AIOps area that assesses the use of model selection mechanisms on historical models to improve model performance or robustness. To fill the gap, we evaluate several model selection mechanisms by assessing their capabilities in selecting the optimal AIOps models that were built in the past to make predictions for the target data. We performed a case study on three large-scale public operation datasets: two trace datasets from the cloud computing platforms of Google and Alibaba, and one disk stats dataset from the BackBlaze cloud storage data center. We observe that the model selection mechnisms utilizing temporal adjacency tend to have a better performance and can prevail the periodical retraining approach. Our findings also highlight a performance gap between existing model selection mechnisms and the theoretical upper bound which may motivate future researchers and practitioners in investigating more efficient and effective model selection mechanisms that fit in the context of AIOps.",
      "published": "2025-05-05",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.02961v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.21319v1",
      "title": "Variationally correct operator learning: Reduced basis neural operator with a posteriori error estimation",
      "authors": [
        "Yuan Qiu",
        "Wolfgang Dahmen",
        "Peng Chen"
      ],
      "abstract": "Minimizing PDE-residual losses is a common strategy to promote physical consistency in neural operators. However, standard formulations often lack variational correctness, meaning that small residuals do not guarantee small solution errors due to the use of non-compliant norms or ad hoc penalty terms for boundary conditions. This work develops a variationally correct operator learning framework by constructing first-order system least-squares (FOSLS) objectives whose values are provably equivalent to the solution error in PDE-induced norms. We demonstrate this framework on stationary diffusion and linear elasticity, incorporating mixed Dirichlet-Neumann boundary conditions via variational lifts to preserve norm equivalence without inconsistent penalties. To ensure the function space conformity required by the FOSLS loss, we propose a Reduced Basis Neural Operator (RBNO). The RBNO predicts coefficients for a pre-computed, conforming reduced basis, thereby ensuring variational stability by design while enabling efficient training. We provide a rigorous convergence analysis that bounds the total error by the sum of finite element discretization bias, reduced basis truncation error, neural network approximation error, and statistical estimation errors arising from finite sampling and optimization. Numerical benchmarks validate these theoretical bounds and demonstrate that the proposed approach achieves superior accuracy in PDE-compliant norms compared to standard baselines, while the residual loss serves as a reliable, computable a posteriori error estimator.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21319v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.21284v1",
      "title": "Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential",
      "authors": [
        "Shihao Zou",
        "Jingjing Li",
        "Wei Ji",
        "Jincai Huang",
        "Kai Wang",
        "Guo Dan",
        "Weixin Si",
        "Yi Pan"
      ],
      "abstract": "Modern surgical systems increasingly rely on intelligent scene understanding to provide timely situational awareness for enhanced intra-operative safety. Within this pipeline, surgical scene segmentation plays a central role in accurately perceiving operative events. Although recent deep learning models, particularly large-scale foundation models, achieve remarkable segmentation accuracy, their substantial computational demands and power consumption hinder real-time deployment in resource-constrained surgical environments. To address this limitation, we explore the emerging SNN as a promising paradigm for highly efficient surgical intelligence. However, their performance is still constrained by the scarcity of labeled surgical data and the inherently sparse nature of surgical video representations. To this end, we propose \\textit{SpikeSurgSeg}, the first spike-driven video Transformer framework tailored for surgical scene segmentation with real-time potential on non-GPU platforms. To address the limited availability of surgical annotations, we introduce a surgical-scene masked autoencoding pretraining strategy for SNNs that enables robust spatiotemporal representation learning via layer-wise tube masking. Building on this pretrained backbone, we further adopt a lightweight spike-driven segmentation head that produces temporally consistent predictions while preserving the low-latency characteristics of SNNs. Extensive experiments on EndoVis18 and our in-house SurgBleed dataset demonstrate that SpikeSurgSeg achieves mIoU comparable to SOTA ANN-based models while reducing inference latency by at least $8\\times$. Notably, it delivers over $20\\times$ acceleration relative to most foundation-model baselines, underscoring its potential for time-critical surgical scene segmentation.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21284v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.21241v1",
      "title": "Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks",
      "authors": [
        "Xinjie Xu",
        "Shuyu Cheng",
        "Dongwei Xu",
        "Qi Xuan",
        "Chen Ma"
      ],
      "abstract": "In hard-label black-box adversarial attacks, where only the top-1 predicted label is accessible, the prohibitive query complexity poses a major obstacle to practical deployment. In this paper, we focus on optimizing a representative class of attacks that search for the optimal ray direction yielding the minimum $\\ell_2$-norm perturbation required to move a benign image into the adversarial region. Inspired by Nesterov's Accelerated Gradient (NAG), we propose a momentum-based algorithm, ARS-OPT, which proactively estimates the gradient with respect to a future ray direction inferred from accumulated momentum. We provide a theoretical analysis of its convergence behavior, showing that ARS-OPT enables more accurate directional updates and achieves faster, more stable optimization. To further accelerate convergence, we incorporate surrogate-model priors into ARS-OPT's gradient estimation, resulting in PARS-OPT with enhanced performance. The superiority of our approach is supported by theoretical guarantees under standard assumptions. Extensive experiments on ImageNet and CIFAR-10 demonstrate that our method surpasses 13 state-of-the-art approaches in query efficiency.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21241v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.21166v1",
      "title": "A Community-Enhanced Graph Representation Model for Link Prediction",
      "authors": [
        "Lei Wang",
        "Darong Lai"
      ],
      "abstract": "Although Graph Neural Networks (GNNs) have become the dominant approach for graph representation learning, their performance on link prediction tasks does not always surpass that of traditional heuristic methods such as Common Neighbors and Jaccard Coefficient. This is mainly because existing GNNs tend to focus on learning local node representations, making it difficult to effectively capture structural relationships between node pairs. Furthermore, excessive reliance on local neighborhood information can lead to over-smoothing. Prior studies have shown that introducing global structural encoding can partially alleviate this issue. To address these limitations, we propose a Community-Enhanced Link Prediction (CELP) framework that incorporates community structure to jointly model local and global graph topology. Specifically, CELP enhances the graph via community-aware, confidence-guided edge completion and pruning, while integrating multi-scale structural features to achieve more accurate link prediction. Experimental results across multiple benchmark datasets demonstrate that CELP achieves superior performance, validating the crucial role of community structure in improving link prediction accuracy.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21166v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.17296v2",
      "title": "Towards Pixel-Wise Anomaly Location for High-Resolution PCBA via Self-Supervised Image Reconstruction",
      "authors": [
        "Wuyi Liu",
        "Le Jin",
        "Junxian Yang",
        "Yuanchao Yu",
        "Zishuo Peng",
        "Jinfeng Xu",
        "Xianzhi Li",
        "Jun Zhou"
      ],
      "abstract": "Automated defect inspection of assembled Printed Circuit Board Assemblies (PCBA) is quite challenging due to the insufficient labeled data, micro-defects with just a few pixels in visually-complex and high-resolution images. To address these challenges, we present HiSIR-Net, a High resolution, Self-supervised Reconstruction framework for pixel-wise PCBA localization. Our design combines two lightweight modules that make this practical on real 4K-resolution boards: (i) a Selective Input-Reconstruction Gate (SIR-Gate) that lets the model decide where to trust reconstruction versus the original input, thereby reducing irrelevant reconstruction artifacts and false alarms; and (ii) a Region-level Optimized Patch Selection (ROPS) scheme with positional cues to select overlapping patch reconstructions coherently across arbitrary resolutions. Organically integrating these mechanisms yields clean, high-resolution anomaly maps with low false positive (FP) rate. To bridge the gap in high-resolution PCBA datasets, we further contribute a self-collected dataset named SIPCBA-500 of 500 images. We conduct extensive experiments on our SIPCBA-500 as well as public benchmarks, demonstrating the superior localization performance of our method while running at practical speed. Full code and dataset will be made available upon acceptance.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17296v2",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.04680v1",
      "title": "Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap",
      "authors": [
        "Jialong Li",
        "Mingyue Zhang",
        "Nianyu Li",
        "Danny Weyns",
        "Zhi Jin",
        "Kenji Tei"
      ],
      "abstract": "Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.",
      "published": "2025-12-04",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.04680v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2505.07372v1",
      "title": "Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data",
      "authors": [
        "David de-Fitero-Dominguez",
        "Antonio Garcia-Cabot",
        "Eva Garcia-Lopez"
      ],
      "abstract": "This paper presents a novel methodology for enhancing Automated Program Repair (APR) through synthetic data generation utilizing Large Language Models (LLMs). Current APR systems are constrained by the limited availability of high-quality training data encompassing diverse bug types across multiple programming languages. The proposed approach addresses this limitation through a two-phase process: a synthetic sample generation followed by a rigorous quality assessment. Multiple state-of-the-art LLMs were employed to generate approximately 30,000 paired examples of buggy and fixed code across 12 programming languages and 13 bug categories. Subsequently, these samples underwent cross-model evaluation against five criteria: correctness, code quality, security, performance, and completeness. Experimental evaluation on the VulRepair test set dataset showed statistically significant improvements in Perfect Prediction rates, with the quality-filtered synthetic dataset outperforming both baseline and real-world commit data configurations in certain scenarios. The methodology was validated through rigorous statistical testing, including ANOVA and post-hoc Tukey's Honest Significant Difference analysis. Furthermore, the best-performing configurations surpassed existing systems despite using a less computationally intensive decoding strategy. This research establishes a self-bootstrapping paradigm in which LLMs generate and evaluate their own training data, potentially transforming approaches to data scarcity across software engineering tasks and advancing the development of robust, adaptable tools for automated code maintenance.",
      "published": "2025-05-12",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.07372v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.14797v1",
      "title": "Artificial Intelligence for the Assessment of Peritoneal Carcinosis during Diagnostic Laparoscopy for Advanced Ovarian Cancer",
      "authors": [
        "Riccardo Oliva",
        "Farahdiba Zarin",
        "Alice Zampolini Faustini",
        "Armine Vardazaryan",
        "Andrea Rosati",
        "Vinkle Srivastav",
        "Nunzia Del Villano",
        "Jacques Marescaux",
        "Giovanni Scambia",
        "Pietro Mascagni",
        "Nicolas Padoy",
        "Anna Fagotti"
      ],
      "abstract": "Advanced Ovarian Cancer (AOC) is often diagnosed at an advanced stage with peritoneal carcinosis (PC). Fagotti score (FS) assessment at diagnostic laparoscopy (DL) guides treatment planning by estimating surgical resectability, but its subjective and operator-dependent nature limits reproducibility and widespread use. Videos of patients undergoing DL with concomitant FS assessments at a referral center were retrospectively collected and divided into a development dataset, for data annotation, AI training and evaluation, and an independent test dataset, for internal validation. In the development dataset, FS-relevant frames were manually annotated for anatomical structures and PC. Deep learning models were trained to automatically identify FS-relevant frames, segment structures and PC, and predict video-level FS and indication to surgery (ItS). AI performance was evaluated using Dice score for segmentation, F1-scores for anatomical stations (AS) and ItS prediction, and root mean square error (RMSE) for final FS estimation. In the development dataset, the segmentation model trained on 7,311 frames, achieved Dice scores of 70$\\pm$3% for anatomical structures and 56$\\pm$3% for PC. Video-level AS classification achieved F1-scores of 74$\\pm$3% and 73$\\pm$4%, FS prediction showed normalized RMSE values of 1.39$\\pm$0.18 and 1.15$\\pm$0.08, and ItS reached F1-scores of 80$\\pm$8% and 80$\\pm$2% in the development (n=101) and independent test datasets (n=50), respectively. This is the first AI model to predict the feasibility of cytoreductive surgery providing automated FS estimation from DL videos. Its reproducible and reliable performance across datasets suggests that AI can support surgeons through standardized intraoperative tumor burden assessment and clinical decision-making in AOC.",
      "published": "2025-12-16",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.14797v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.12785v1",
      "title": "OLC-WA: Drift Aware Tuning-Free Online Classification with Weighted Average",
      "authors": [
        "Mohammad Abu Shaira",
        "Yunhe Feng",
        "Heng Fan",
        "Weishi Shi"
      ],
      "abstract": "Real-world data sets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. This paper introduces Online Classification with Weighted Average (OLC-WA), an adaptive, hyperparameter-free online classification model equipped with an automated optimization mechanism. OLC-WA operates by blending incoming data streams with an existing base model. This blending is facilitated by an exponentially weighted moving average. Furthermore, an integrated optimization mechanism dynamically detects concept drift, quantifies its magnitude, and adjusts the model based on the observed data stream characteristics. This approach empowers the model to effectively adapt to evolving data distributions within streaming environments. Rigorous empirical evaluation across diverse benchmark datasets shows that OLC-WA achieves performance comparable to batch models in stationary environments, maintaining accuracy within 1-3%, and surpasses leading online baselines by 10-25% under drift, demonstrating its effectiveness in adapting to dynamic data streams.",
      "published": "2025-12-14",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.12785v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.03570v1",
      "title": "Machine Learning to Predict Slot Usage in TSCH Wireless Sensor Networks",
      "authors": [
        "Stefano Scanzio",
        "Gabriele Formis",
        "Tullio Facchinetti",
        "Gianluca Cena"
      ],
      "abstract": "Wireless sensor networks (WSNs) are employed across a wide range of industrial applications where ultra-low power consumption is a critical prerequisite. At the same time, these systems must maintain a certain level of determinism to ensure reliable and predictable operation. In this view, time slotted channel hopping (TSCH) is a communication technology that meets both conditions, making it an attractive option for its usage in industrial WSNs. This work proposes the use of machine learning to learn the traffic pattern generated in networks based on the TSCH protocol, in order to turn nodes into a deep sleep state when no transmission is planned and thus to improve the energy efficiency of the WSN. The ability of machine learning models to make good predictions at different network levels in a typical tree network topology was analyzed in depth, showing how their capabilities degrade while approaching the root of the tree. The application of these models on simulated data based on an accurate modeling of wireless sensor nodes indicates that the investigated algorithms can be suitably used to further and substantially reduce the power consumption of a TSCH network.",
      "published": "2025-12-03",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.03570v1",
      "relevance_score": 21
    },
    {
      "arxiv_id": "2512.20541v1",
      "title": "Optical Pin Beams: Research Progresses and Emerging Applications",
      "authors": [
        "Ze Zhang",
        "Hongwei Jiang",
        "Hongyue Xiao",
        "Meiling Guan",
        "Lu Gao",
        "Nikolaos K. Efremidis",
        "Hairong Xiao",
        "Zhigang Chen"
      ],
      "abstract": "Optical pin beams (OPBs) represent a novel class of structured light fields engineered for resilient, long-distance propagation. Their exceptional stability and strong resistance to atmospheric turbulence make them a compelling alternative to conventional Gaussian and other structured beams for free-space optical systems. This review provides a comprehensive overview of the physical principles, generation strategies, experimental realizations, and emerging applications of OPBs. By precise spatial modulation of the optical wave vectors, OPBs achieve highly collimated, self-reconstructing propagation with distinctive pin-like features that confer remarkable robustness and self-healing capability. We further discuss several OPB derivatives--including vortex, inverted, and vortex-inverted OPBs--which expand the functional landscape by enabling flexible control over amplitude, phase, polarization, and orbital angular momentum. Experimentally, OPBs have demonstrated outstanding performance across diverse platforms, ranging from free-space and underwater optical communications to optical trapping and super-resolution imaging. With their unique combination of propagation stability, light-field tunability, and environmental adaptability, OPBs hold strong promise for next-generation optical communication, precision sensing, and advanced imaging technologies. This review summarizes recent research progresses in OPBs and highlights key opportunities and prospects for advancing their scientific discoveries and practical applications.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20541v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2510.11948v1",
      "title": "Microscopic Intricacies of Self-Healing in Halide Perovskite-Charge Transport Layer Heterostructures",
      "authors": [
        "Tejmani Behera",
        "Boris Louis",
        "Lukas Paesen",
        "Roel Vanden Brande",
        "Koki Asano",
        "Martin Vacha",
        "Maarten Roeffaers",
        "Elke Debroye",
        "Johan Hofkens",
        "Sudipta Setha"
      ],
      "abstract": "The stability and performance of halide perovskite photovoltaic devices are critically limited by progressive defect generation and associated local non-radiative losses during operation. Self-healing of defects provides a promising pathway to prolong device functionality, yet the underlying microscopic mechanisms remain poorly understood, particularly the role of interfacial chemistry on trap dynamics and healing kinetics. Here, we elucidate self-healing and defect evolution in triple-cation mixed halide (TCMH) perovskite films and their device-relevant charge transport layer heterostructures subjected to photo-induced damage. Using correlation clustering imaging (CLIM), our recently developed local functional imaging tool, we map spatiotemporal photoluminescence heterogeneity to track defect dynamics in pristine and heterostructure films. The defect healing follows bi-phasic kinetics, with an initial electronic relaxation (tens of minutes) and a subsequent slower phase (~ hours) associated to ionic and lattice rearrangement. Most importantly, our results demonstrate that the chemical nature of charge-transport layers modulates trap activity, healing kinetics, and halide redistribution, with heterostructures exhibiting faster recovery than pristine films, a boon for device resilience. These findings provide new insights into the dynamic interaction between defects, interfaces, and ion migration, and establish a framework for rational design of durable, next-generation perovskite optoelectronic devices.",
      "published": "2025-10-13",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.11948v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2507.07928v2",
      "title": "Hydrodynamic Insight Drives Multimodal Light_Field Dynamics via Streamline Engineering",
      "authors": [
        "Wenxiang Yan",
        "Zheng Yuan",
        "Yuan Gao",
        "Zhaozhong Chen",
        "Zhi-Cheng Ren",
        "Xi-Lin Wang",
        "Jianping Ding",
        "Hui-Tian Wang"
      ],
      "abstract": "Since the 1970s, analogies between laser dynamics and fluid systems have provided insight into phenomena such as chaos, multistability, and turbulence. Building on this perspective, we model the optical field as an energy fluid and interpret Poynting-vector trajectories as energy streamlines, yielding a unified, three_dimensional map of light's free-space dynamics. By sculpting these streamlines, we develop an approach to talior vortex-beam propagation dynamics that suppresses both diffraction- and OAM-induced broadening. Extending this method to general structured modes, we enable a single field to exhibit customizable multimodal dynamics that integrate features from primary structured light families: the diffraction-free, self-healing behavior of Bessel beams; the tunable self-similarity of Laguerre-Gaussian beams and adjustable self-acceleration of Airy beams. Additionally, it allows for adjustable propagating energy-density profiles to counteract losses. Optical-tweezer experiments,analogous to particle-tracking velocimetry in fluid dynamics, show that trapped microspheres closely follow the designed streamlines, validating the streamline geometries and indicating a potential route toward precision 3D optomechanical control. In a proof-of-principle free-space communication experiment, vortex beams with customized multimodal dynamics demonstrate several improvements, including more independent channels, reduced turbulence-induced mode scattering, and robust non-line-of-sight transmission. Together, the streamline-engineering approach offers a unified and adaptable strategy for tailoring light's propagation dynamics, with potential applications in precision optomechanics, optofluidics, and advanced optical networking.",
      "published": "2025-07-10",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.07928v2",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2505.05498v2",
      "title": "An Overview of the Prospects and Challenges of Using Artificial Intelligence for Energy Management Systems in Microgrids",
      "authors": [
        "Noor ul Misbah Khanum",
        "Hayssam Dahrouj",
        "Ramesh C. Bansal",
        "Hissam Mouayad Tawfik"
      ],
      "abstract": "Microgrids have emerged as a pivotal solution in the quest for a sustainable and energy-efficient future. While microgrids offer numerous advantages, they are also prone to issues related to reliably forecasting renewable energy demand and production, protecting against cyberattacks, controlling operational costs, optimizing power flow, and regulating the performance of energy management systems (EMS). Tackling these energy management challenges is essential to facilitate microgrid applications and seamlessly incorporate renewable energy resources. Artificial intelligence (AI) has recently demonstrated immense potential for optimizing energy management in microgrids, providing efficient and reliable solutions. This paper highlights the combined benefits of enabling AI-based methodologies in the energy management systems of microgrids by examining the applicability and efficiency of AI-based EMS in achieving specific technical and economic objectives. The paper also points out several future research directions that promise to spearhead AI-driven EMS, namely the development of self-healing microgrids, integration with blockchain technology, use of Internet of things (IoT), and addressing interpretability, data privacy, scalability, and the prospects to generative AI in the context of future AI-based EMS.",
      "published": "2025-05-06",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.05498v2",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20976v1",
      "title": "XGrid-Mapping: Explicit Implicit Hybrid Grid Submaps for Efficient Incremental Neural LiDAR Mapping",
      "authors": [
        "Zeqing Song",
        "Zhongmiao Yan",
        "Junyuan Deng",
        "Songpengcheng Xia",
        "Xiang Mu",
        "Jingyi Xu",
        "Qi Wu",
        "Ling Pei"
      ],
      "abstract": "Large-scale incremental mapping is fundamental to the development of robust and reliable autonomous systems, as it underpins incremental environmental understanding with sequential inputs for navigation and decision-making. LiDAR is widely used for this purpose due to its accuracy and robustness. Recently, neural LiDAR mapping has shown impressive performance; however, most approaches rely on dense implicit representations and underutilize geometric structure, while existing voxel-guided methods struggle to achieve real-time performance. To address these challenges, we propose XGrid-Mapping, a hybrid grid framework that jointly exploits explicit and implicit representations for efficient neural LiDAR mapping. Specifically, the strategy combines a sparse grid, providing geometric priors and structural guidance, with an implicit dense grid that enriches scene representation. By coupling the VDB structure with a submap-based organization, the framework reduces computational load and enables efficient incremental mapping on a large scale. To mitigate discontinuities across submaps, we introduce a distillation-based overlap alignment strategy, in which preceding submaps supervise subsequent ones to ensure consistency in overlapping regions. To further enhance robustness and sampling efficiency, we incorporate a dynamic removal module. Extensive experiments show that our approach delivers superior mapping quality while overcoming the efficiency limitations of voxel-guided methods, thereby outperforming existing state-of-the-art mapping methods.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20976v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20868v1",
      "title": "Early warning signals for loss of control",
      "authors": [
        "Jasper J. van Beers",
        "Marten Scheffer",
        "Prashant Solanki",
        "Ingrid A. van de Leemput",
        "Egbert H. van Nes",
        "Coen C. de Visser"
      ],
      "abstract": "Maintaining stability in feedback systems, from aircraft and autonomous robots to biological and physiological systems, relies on monitoring their behavior and continuously adjusting their inputs. Incremental damage can make such control fragile. This tends to go unnoticed until a small perturbation induces instability (i.e. loss of control). Traditional methods in the field of engineering rely on accurate system models to compute a safe set of operating instructions, which become invalid when the, possibly damaged, system diverges from its model. Here we demonstrate that the approach of such a feedback system towards instability can nonetheless be monitored through dynamical indicators of resilience. This holistic system safety monitor does not rely on a system model and is based on the generic phenomenon of critical slowing down, shown to occur in the climate, biology and other complex nonlinear systems approaching criticality. Our findings for engineered devices opens up a wide range of applications involving real-time early warning systems as well as an empirical guidance of resilient system design exploration, or \"tinkering\". While we demonstrate the validity using drones, the generic nature of the underlying principles suggest that these indicators could apply across a wider class of controlled systems including reactors, aircraft, and self-driving cars.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20868v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20769v1",
      "title": "A General Purpose Method for Robotic Interception of Non-Cooperative Dynamic Targets",
      "authors": [
        "Tanmay P. Patel",
        "Erica L. Tevere",
        "Erik H. Kramer",
        "Rudranarayan M. Mukherjee"
      ],
      "abstract": "This paper presents a general purpose framework for autonomous, vision-based interception of dynamic, non-cooperative targets, validated across three distinct mobility platforms: an unmanned aerial vehicle (UAV), a four-wheeled ground rover, and an air-thruster spacecraft testbed. The approach relies solely on a monocular camera with fiducials for target tracking and operates entirely in the local observer frame without the need for global information. The core contribution of this work is a streamlined and general approach to autonomous interception that can be adapted across robots with varying dynamics, as well as our comprehensive study of the robot interception problem across heterogenous mobility systems under limited observability and no global localization. Our method integrates (1) an Extended Kalman Filter for relative pose estimation amid intermittent measurements, (2) a history-conditioned motion predictor for dynamic target trajectory propagation, and (3) a receding-horizon planner solving a constrained convex program in real time to ensure time-efficient and kinematically feasible interception paths. Our operating regime assumes that observability is restricted by partial fields of view, sensor dropouts, and target occlusions. Experiments are performed in these conditions and include autonomous UAV landing on dynamic targets, rover rendezvous and leader-follower tasks, and spacecraft proximity operations. Results from simulated and physical experiments demonstrate robust performance with low interception errors (both during station-keeping and upon scenario completion), high success rates under deterministic and stochastic target motion profiles, and real-time execution on embedded processors such as the Jetson Orin, VOXL2, and Raspberry Pi 5. These results highlight the framework's generalizability, robustness, and computational efficiency.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20769v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20475v1",
      "title": "Drift-Corrected Monocular VIO and Perception-Aware Planning for Autonomous Drone Racing",
      "authors": [
        "Maulana Bisyir Azhari",
        "Donghun Han",
        "Je In You",
        "Sungjun Park",
        "David Hyunchul Shim"
      ],
      "abstract": "The Abu Dhabi Autonomous Racing League(A2RL) x Drone Champions League competition(DCL) requires teams to perform high-speed autonomous drone racing using only a single camera and a low-quality inertial measurement unit -- a minimal sensor set that mirrors expert human drone racing pilots. This sensor limitation makes the system susceptible to drift from Visual-Inertial Odometry (VIO), particularly during long and fast flights with aggressive maneuvers. This paper presents the system developed for the championship, which achieved a competitive performance. Our approach corrected VIO drift by fusing its output with global position measurements derived from a YOLO-based gate detector using a Kalman filter. A perception-aware planner generated trajectories that balance speed with the need to keep gates visible for the perception system. The system demonstrated high performance, securing podium finishes across multiple categories: third place in the AI Grand Challenge with top speed of 43.2 km/h, second place in the AI Drag Race with over 59 km/h, and second place in the AI Multi-Drone Race. We detail the complete architecture and present a performance analysis based on experimental data from the competition, contributing our insights on building a successful system for monocular vision-based autonomous drone flight.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20475v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20105v1",
      "title": "LiDARDraft: Generating LiDAR Point Cloud from Versatile Inputs",
      "authors": [
        "Haiyun Wei",
        "Fan Lu",
        "Yunwei Zhu",
        "Zehan Zheng",
        "Weiyi Xue",
        "Lin Shao",
        "Xudong Zhang",
        "Ya Wu",
        "Rong Fu",
        "Guang Chen"
      ],
      "abstract": "Generating realistic and diverse LiDAR point clouds is crucial for autonomous driving simulation. Although previous methods achieve LiDAR point cloud generation from user inputs, they struggle to attain high-quality results while enabling versatile controllability, due to the imbalance between the complex distribution of LiDAR point clouds and the simple control signals. To address the limitation, we propose LiDARDraft, which utilizes the 3D layout to build a bridge between versatile conditional signals and LiDAR point clouds. The 3D layout can be trivially generated from various user inputs such as textual descriptions and images. Specifically, we represent text, images, and point clouds as unified 3D layouts, which are further transformed into semantic and depth control signals. Then, we employ a rangemap-based ControlNet to guide LiDAR point cloud generation. This pixel-level alignment approach demonstrates excellent performance in controllable LiDAR point clouds generation, enabling \"simulation from scratch\", allowing self-driving environments to be created from arbitrary textual descriptions, images and sketches.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20105v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.19896v1",
      "title": "Gate-Based Microwave Quantum Repeater Via Grid-State Encoding",
      "authors": [
        "Hany Khalifa",
        "Matti Silveri"
      ],
      "abstract": "In autonomous quantum error correction the lifetime of a logical bosonic qubit can be extended beyond its physical constituents without feedback measurements. Leveraging autonomous error correction, we propose a second-generation gate-based microwave quantum repeater (GBMQR) with encoded bosonic grid states. Each repeater station comprises a transmon and two bosonic resonators: one resonator serving as a stationary quantum memory utilizing autonomous error correction, and the other as an information bus for entanglement generation. Entanglement is generated sequentially through the successful absorption of a microwave photon wavepacket. This method enables deterministic entanglement generation, in contrast to a probabilistic mixing of two heralding signals on a balanced beamsplitter. Furthermore, our GBMQR employs an all-bosonic entanglement swapping Bell-state measurement. This is implemented via a bosonic controlled-Z gate and two separate X-basis projective homodyne measurements on the stationary stored codewords. Our approach circumvents mode-mismatch losses associated with routing and interfering of heralding modes on a beamsplitter, and confines losses to those arising from stationary storage. We evaluate the performance of the proposed quantum repeater by calculating its secret key rate under realistic lab environments. Moreover, we explicitly demonstrate that at stationary damping rate of $\u03ba^{-1}_{\\text{damp}}=$~\\SI{40}{\\milli\\second}, GBMQR can achieve entanglement generation and swapping success probabilities approx.~$0.75$, and $0.58$ respectively, surpassing the hallmark success probability of $1/2$ set by ideal linear beamsplitter-based Bell-state measurements. The proposed device can be implemented using currently available superconducting microwave technology and is suited for secure chip-to-chip communication and distributed quantum computing.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19896v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.21198v1",
      "title": "Safe Navigation with Zonotopic Tubes: An Elastic Tube-based MPC Framework",
      "authors": [
        "Niyousha Ghiasi",
        "Bahare Kiumarsi",
        "Hamidreza Modares"
      ],
      "abstract": "This paper presents an elastic tube-based model predictive control (MPC) framework for unknown discrete-time linear systems subject to disturbances. Unlike most existing elastic tube-based MPC methods, we do not assume perfect knowledge of the system model or disturbance realizations bounds. Instead, a conservative zonotopic disturbance set is initialized and iteratively refined using data and prior knowledge: data are used to identify matrix zonotope model sets for the system dynamics, while prior physical knowledge is employed to discard models and disturbances inconsistent with known constraints. This process yields constrained matrix zonotopes representing disturbance realizations and dynamics that enable a principled fusion of offline information with limited online data, improving MPC feasibility and performance. The proposed design leverages closed-loop system characterization to learn and refine control gains that maintain a small tube size. By separating open-loop model mismatch from closed-loop effects in the error dynamics, the method avoids dependence on the size of the state and input operating regions, thereby reducing conservatism. An adaptive co-design of the tube and ancillary feedback ensures $\u03bb$-contractive zonotopic tubes, guaranteeing robust positive invariance, improved feasibility margins, and enhanced disturbance tolerance. We establish recursive feasibility conditions and introduce a polyhedral Lyapunov candidate for the error tube, proving exponential stability of the closed-loop error dynamics under the adaptive tube-gain updates. Simulations demonstrate improved robustness, enlarged feasibility regions, and safe closed-loop performance using only a small amount of online data.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21198v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.21138v1",
      "title": "Emotion Diffusion in Real and Simulated Social Graphs: Structural Limits of LLM-Based Social Simulation",
      "authors": [
        "Qiqi Qiang"
      ],
      "abstract": "Understanding how emotions diffuse through social networks is central to computational social science. Recently, large language models (LLMs) have been increasingly used to simulate social media interactions, raising the question of whether LLM-generated data can realistically reproduce emotion diffusion patterns observed in real online communities. In this study, we conduct a systematic comparison between emotion diffusion in real-world social graphs and in LLM-simulated interaction networks. We construct diffusion graphs from Reddit discussion data and compare them with synthetic social graphs generated through LLM-driven conversational simulations. Emotion states are inferred using established sentiment analysis pipelines, and both real and simulated graphs are analyzed from structural, behavioral, and predictive perspectives. Our results reveal substantial structural and dynamic discrepancies between real and simulated diffusion processes. Real-world emotion diffusion exhibits dense connectivity, repeated interactions, sentiment shifts, and emergent community structures, whereas LLM-simulated graphs largely consist of isolated linear chains with monotonic emotional trajectories. These structural limitations significantly affect downstream tasks such as graph-based emotion prediction, leading to reduced emotional diversity and class imbalance in simulated settings. Our findings highlight current limitations of LLM-based social simulation in capturing the interactive complexity and emotional heterogeneity of real social networks. This work provides empirical evidence for the cautious use of LLM-generated data in social science research and suggests directions for improving future simulation frameworks.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21138v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.21109v1",
      "title": "Robust and Efficient MuJoCo-based Model Predictive Control via Web of Affine Spaces Derivatives",
      "authors": [
        "Chen Liang",
        "Daniel Rakita"
      ],
      "abstract": "MuJoCo is a powerful and efficient physics simulator widely used in robotics. One common way it is applied in practice is through Model Predictive Control (MPC), which uses repeated rollouts of the simulator to optimize future actions and generate responsive control policies in real time. To make this process more accessible, the open source library MuJoCo MPC (MJPC) provides ready-to-use MPC algorithms and implementations built directly on top of the MuJoCo simulator. However, MJPC relies on finite differencing (FD) to compute derivatives through the underlying MuJoCo simulator, which is often a key bottleneck that can make it prohibitively costly for time-sensitive tasks, especially in high-DOF systems or complex scenes. In this paper, we introduce the use of Web of Affine Spaces (WASP) derivatives within MJPC as a drop-in replacement for FD. WASP is a recently developed approach for efficiently computing sequences of accurate derivative approximations. By reusing information from prior, related derivative calculations, WASP accelerates and stabilizes the computation of new derivatives, making it especially well suited for MPC's iterative, fine-grained updates over time. We evaluate WASP across a diverse suite of MJPC tasks spanning multiple robot embodiments. Our results suggest that WASP derivatives are particularly effective in MJPC: it integrates seamlessly across tasks, delivers consistently robust performance, and achieves up to a 2$\\mathsf{x}$ speedup compared to an FD backend when used with derivative-based planners, such as iLQG. In addition, WASP-based MPC outperforms MJPC's stochastic sampling-based planners on our evaluation tasks, offering both greater efficiency and reliability. To support adoption and future research, we release an open-source implementation of MJPC with WASP derivatives fully integrated.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21109v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.21004v1",
      "title": "Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations",
      "authors": [
        "Jinghan Li",
        "Yang Jin",
        "Hao Jiang",
        "Yadong Mu",
        "Yang Song",
        "Kun Xu"
      ],
      "abstract": "Recent advances in pretraining general foundation models have significantly improved performance across diverse downstream tasks. While autoregressive (AR) generative models like GPT have revolutionized NLP, most visual generative pretraining methods still rely on BERT-style masked modeling, which often disregards the temporal information essential for video analysis. The few existing autoregressive visual pretraining methods suffer from issues such as inaccurate semantic localization and poor generation quality, leading to poor semantics. In this work, we propose NExT-Vid, a novel autoregressive visual generative pretraining framework that utilizes masked next-frame prediction to jointly model images and videos. NExT-Vid introduces a context-isolated autoregressive predictor to decouple semantic representation from target decoding, and a conditioned flow-matching decoder to enhance generation quality and diversity. Through context-isolated flow-matching pretraining, our approach achieves strong representations. Extensive experiments on large-scale pretrained models demonstrate that our proposed method consistently outperforms previous generative pretraining methods for visual representation learning via attentive probing in downstream classification.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21004v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20982v1",
      "title": "Reconfigurable Intelligent Surface-Enhanced Satellite Networks: Deployment Strategies, Key Capabilities, Practical Solutions, and Future Directions",
      "authors": [
        "Ziyuan Zheng",
        "Xiangyu Li",
        "Shirui Zuo",
        "Yu Wan",
        "Bodong Shang",
        "Wenpeng Jing",
        "Qingqing Wu"
      ],
      "abstract": "Satellite networks promise wide-area 6G coverage but face two persistent barriers: blockage-induced service discontinuities and increasingly stringent spectrum coexistence across satellite layers and with terrestrial systems. Reconfigurable intelligent surfaces (RISs) act as low-power programmable apertures that redirect energy without the cost and power consumption of fully active arrays. We develop a deployment-first, operations-aware view of RIS-enabled satellite networking that treats RIS as both satellite/terminal antennas and inter-satellite or space-ground relays. We show that system-level gains are governed by two unifying mechanisms: connectivity restoration via virtual line-of-sight links that preserve connectivity under blockage and mobility, and angular selectivity that reshapes interference to enlarge spectrum reuse. We further discuss practical operation under high mobility, highlighting Delay-Doppler channel acquisition, predictive beam tracking, and control designs that budget overhead and latency, and summarize hardware considerations for reliable operation in space. Finally, we outline forward-looking opportunities in the generative artificial intelligence paradigm, multifunctional RIS architectures, ubiquitous satellite integrated sensing and communication, and sustainable satellite Internet-of-Things.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20982v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20980v1",
      "title": "X-ray Insights Unleashed: Pioneering the Enhancement of Multi-Label Long-Tail Data",
      "authors": [
        "Xinquan Yang",
        "Jinheng Xie",
        "Yawen Huang",
        "Yuexiang Li",
        "Huimin Huang",
        "Hao Zheng",
        "Xian Wu",
        "Yefeng Zheng",
        "Linlin Shen"
      ],
      "abstract": "Long-tailed pulmonary anomalies in chest radiography present formidable diagnostic challenges. Despite the recent strides in diffusion-based methods for enhancing the representation of tailed lesions, the paucity of rare lesion exemplars curtails the generative capabilities of these approaches, thereby leaving the diagnostic precision less than optimal. In this paper, we propose a novel data synthesis pipeline designed to augment tail lesions utilizing a copious supply of conventional normal X-rays. Specifically, a sufficient quantity of normal samples is amassed to train a diffusion model capable of generating normal X-ray images. This pre-trained diffusion model is subsequently utilized to inpaint the head lesions present in the diseased X-rays, thereby preserving the tail classes as augmented training data. Additionally, we propose the integration of a Large Language Model Knowledge Guidance (LKG) module alongside a Progressive Incremental Learning (PIL) strategy to stabilize the inpainting fine-tuning process. Comprehensive evaluations conducted on the public lung datasets MIMIC and CheXpert demonstrate that the proposed method sets a new benchmark in performance.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20980v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20565v1",
      "title": "Microwave Response of Superconductors with Paramagnetic Impurities",
      "authors": [
        "Mehdi Zarea",
        "J. A. Sauls"
      ],
      "abstract": "We develop theoretical methods to predict the effects of paramagnetic impurities on the microwave response of conventional spin-singlet superconductors. Our focus is on superconducting devices and resonators with low concentrations of impurities and exchange interactions with conduction electrons. We connect the sub-gap quasiparticle spectrum generated by pair-breaking to the frequency and temperature dependence of the conductivity for superconductors operating at microwave frequencies. We report theoretical results for superconducting device performance -- dissipation, quality factor and frequency shift anomalies -- based on self-consistent calculations of the current response and penetraion of the electromagnetic field at the vacuum-superconducting interface. Key results include the prediction of a non-monotonic anomaly in the low-frequency superfluid fraction and penetration depth at very low temperatures related to the sub-gap quasiparticle spectrum. Dissipation of microwave power is predicted from intra- and inter- impurity band transitions at GHz frequencies at low temperatures, including a physical mechanism responsible for residual resistance. We predict anomalies in the resonant frequency, $f(T)$, and quality factor, $Q(T)$, of high-Q SRF cavities operating in the GHz range at low-temperatures that are sensitive to non-magnetic and paramagnetic impurity disorder.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20565v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.20335v1",
      "title": "Status of the Muon g-2/EDM Experiment at J-PARC",
      "authors": [
        "Graziano Venanzoni"
      ],
      "abstract": "The Muon g-2/EDM Experiment at J-PARC will employ a novel way to measure the muon magnetic anomaly, a_mu = (g-2)_mu/2, by using a low-emittance beam of positive muons stored in a compact muon storage magnet. The experimental method includes new technologies such as a three-dimensional spiral injection, an MRI-type storage magnet with superb field uniformity, and a positron tracking detector. The expected systematic uncertainty will be at the same level as that of the Fermilab Muon g-2 experiment, providing an important cross-check of the \"storage-ring method\" employed at BNL and Fermilab. I will present the current status of the experiment, ongoing tests and design optimizations, and the plans for improvements of the experimental precision.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20335v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.19228v1",
      "title": "Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models",
      "authors": [
        "Valentin Schmidberger",
        "Manuel Eberhardinger",
        "Setareh Maghsudi",
        "Johannes Maucher"
      ],
      "abstract": "Document forgery poses a growing threat to legal, economic, and governmental processes, requiring increasingly sophisticated verification mechanisms. One approach involves the use of plausibility checks, rule-based procedures that assess the correctness and internal consistency of data, to detect anomalies or signs of manipulation. Although these verification procedures are essential for ensuring data integrity, existing plausibility checks are manually implemented by software engineers, which is time-consuming. Recent advances in code generation with large language models (LLMs) offer new potential for automating and scaling the generation of these checks. However, adapting LLMs to the specific requirements of an unknown domain remains a significant challenge. This work investigates the extent to which LLMs, adapted on domain-specific code and data through different fine-tuning strategies, can generate rule-based plausibility checks for forgery detection on constrained hardware resources. We fine-tune open-source LLMs, Llama 3.1 8B and OpenCoder 8B, on structured datasets derived from real-world application scenarios and evaluate the generated plausibility checks on previously unseen forgery patterns. The results demonstrate that the models are capable of generating executable and effective verification procedures. This also highlights the potential of LLMs as scalable tools to support human decision-making in security-sensitive contexts where comprehensibility is required.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19228v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2511.03934v1",
      "title": "PEFA-AI: Advancing Open-source LLMs for RTL generation using Progressive Error Feedback Agentic-AI",
      "authors": [
        "Athma Narayanan",
        "Mahesh Subedar",
        "Omesh Tickoo"
      ],
      "abstract": "We present an agentic flow consisting of multiple agents that combine specialized LLMs and hardware simulation tools to collaboratively complete the complex task of Register Transfer Level (RTL) generation without human intervention. A key feature of the proposed flow is the progressive error feedback system of agents (PEFA), a self-correcting mechanism that leverages iterative error feedback to progressively increase the complexity of the approach. The generated RTL includes checks for compilation, functional correctness, and synthesizable constructs. To validate this adaptive approach to code generation, benchmarking is performed using two opensource natural language-to-RTL datasets. We demonstrate the benefits of the proposed approach implemented on an open source agentic framework, using both open- and closed-source LLMs, effectively bridging the performance gap between them. Compared to previously published methods, our approach sets a new benchmark, providing state-of-the-art pass rates while being efficient in token counts.",
      "published": "2025-11-06",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.03934v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2511.00417v2",
      "title": "Human-AI Programming Role Optimization: Developing a Personality-Driven Self-Determination Framework",
      "authors": [
        "Marcel Valovy"
      ],
      "abstract": "As artificial intelligence transforms software development, a critical question emerges: how can developers and AI systems collaborate most effectively? This dissertation optimizes human-AI programming roles through self-determination theory and personality psychology, introducing the Role Optimization Motivation Alignment (ROMA) framework.   Through Design Science Research spanning five cycles, this work establishes empirically-validated connections between personality traits, programming role preferences, and collaborative outcomes, engaging 200 experimental participants and 46 interview respondents.   Key findings demonstrate that personality-driven role optimization significantly enhances self-determination and team dynamics, yielding 23% average motivation increases among professionals and up to 65% among undergraduates. Five distinct personality archetypes emerge: The Explorer (high Openness/low Agreeableness), The Orchestrator (high Extraversion/Agreeableness), The Craftsperson (high Neuroticism/low Extraversion), The Architect (high Conscientiousness), and The Adapter (balanced profile). Each exhibits distinct preferences for programming roles (Co-Pilot, Co-Navigator, Agent), with assignment modes proving crucial for satisfaction.   The dissertation contributes: (1) an empirically-validated framework linking personality traits to role preferences and self-determination outcomes; (2) a taxonomy of AI collaboration modalities mapped to personality profiles while preserving human agency; and (3) an ISO/IEC 29110 extension enabling Very Small Entities to implement personality-driven role optimization within established standards.   Keywords: artificial intelligence, human-computer interaction, behavioral software engineering, self-determination theory, personality psychology, phenomenology, intrinsic motivation, pair programming, design science research, ISO/IEC 29110",
      "published": "2025-11-01",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.00417v2",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2510.10407v2",
      "title": "PrediQL: Automated Testing of GraphQL APIs with LLMs",
      "authors": [
        "Shaolun Liu",
        "Sina Marefat",
        "Omar Tsai",
        "Yu Chen",
        "Zecheng Deng",
        "Jia Wang",
        "Mohammad A. Tayebi"
      ],
      "abstract": "GraphQL's flexible query model and nested data dependencies expose APIs to complex, context-dependent vulnerabilities that are difficult to uncover using conventional testing tools. Existing fuzzers either rely on random payload generation or rigid mutation heuristics, failing to adapt to the dynamic structures of GraphQL schemas and responses. We present PrediQL, the first retrieval-augmented, LLM-guided fuzzer for GraphQL APIs. PrediQL combines large language model reasoning with adaptive feedback loops to generate semantically valid and diverse queries. It models the choice of fuzzing strategy as a multi-armed bandit problem, balancing exploration of new query structures with exploitation of past successes. To enhance efficiency, PrediQL retrieves and reuses execution traces, schema fragments, and prior errors, enabling self-correction and progressive learning across test iterations. Beyond input generation, PrediQL integrates a context-aware vulnerability detector that uses LLM reasoning to analyze responses, interpreting data values, error messages, and status codes to identify issues such as injection flaws, access-control bypasses, and information disclosure. Our evaluation across open-source and benchmark GraphQL APIs shows that PrediQL achieves significantly higher coverage and vulnerability discovery rates compared to state-of-the-art baselines. These results demonstrate that combining retrieval-augmented reasoning with adaptive fuzzing can transform API security testing from reactive enumeration to intelligent exploration.",
      "published": "2025-10-12",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.10407v2",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2506.19677v2",
      "title": "Adaptive Request Scheduling for CodeLLM Serving with SLA Guarantees",
      "authors": [
        "Shi Chang",
        "Boyuan Chen",
        "Kishanthan Thangarajah",
        "Hanan Lutfiyya",
        "Ahmed E. Hassan"
      ],
      "abstract": "Code Large Language Models (CodeLLMs) are increasingly integrated into modern software development workflows, yet efficiently serving them in resource-constrained, self-hosted environments remains a significant challenge. Existing LLM serving systems employs Continuous Batching for throughput improvement. However, they rely on static batch size configurations that cannot adapt to fluctuating request rates or heterogeneous workloads, leading to frequent SLA (Service Level Agreement) violations and unstable performance. In this study, We propose SABER, a dynamic batching strategy that predicts per-request SLA feasibility and adjusts decisions in real time. SABER improves goodput by up to 26% over the best static configurations and reduces latency variability by up to 45%, all without manual tuning or service restarts. Our results demonstrate that SLA-aware, adaptive scheduling is key to robust, high-performance CodeLLM serving.",
      "published": "2025-06-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2506.19677v2",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2505.14514v1",
      "title": "From What to How: A Taxonomy of Formalized Security Properties",
      "authors": [
        "Imen Sayar",
        "Nan Messe",
        "Sophie Ebersold",
        "Jean-Michel Bruel"
      ],
      "abstract": "Confidentiality, integrity, availability, authenticity, authorization, and accountability are known as security properties that secure systems should preserve. They are usually considered as security final goals that are achieved by system development activities, either in a direct or an indirect manner. However, these security properties are mainly elicited in the high-level requirement phase during the System Development Life Cycle (SDLC) and are not refined throughout the latter phases as other artifacts such as attacks, defenses, and system assets. To align security properties refinement with attacks, defenses, and system assets refinements, we propose an SDLC taxonomy of security properties that may be used in a self-adaptive context and present the methodology for defining it. To verify and check the correctness of the resulting taxonomy, we use the Event-B formal language.",
      "published": "2025-05-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.14514v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.19620v1",
      "title": "Exploring the features used for summary evaluation by Human and GPT",
      "authors": [
        "Zahra Sadeghi",
        "Evangelos Milios",
        "Frank Rudzicz"
      ],
      "abstract": "Summary assessment involves evaluating how well a generated summary reflects the key ideas and meaning of the source text, requiring a deep understanding of the content. Large Language Models (LLMs) have been used to automate this process, acting as judges to evaluate summaries with respect to the original text. While previous research investigated the alignment between LLMs and Human responses, it is not yet well understood what properties or features are exploited by them when asked to evaluate based on a particular quality dimension, and there has not been much attention towards mapping between evaluation scores and metrics. In this paper, we address this issue and discover features aligned with Human and Generative Pre-trained Transformers (GPTs) responses by studying statistical and machine learning metrics. Furthermore, we show that instructing GPTs to employ metrics used by Human can improve their judgment and conforming them better with human responses.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19620v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.13297v1",
      "title": "MedInsightBench: Evaluating Medical Analytics Agents Through Multi-Step Insight Discovery in Multimodal Medical Data",
      "authors": [
        "Zhenghao Zhu",
        "Chuxue Cao",
        "Sirui Han",
        "Yuanfeng Song",
        "Xing Chen",
        "Caleb Chen Cao",
        "Yike Guo"
      ],
      "abstract": "In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and agent frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated agent framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight Agent, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.",
      "published": "2025-12-15",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.13297v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2512.04113v1",
      "title": "AI-Enabled grading with near-domain data for scaling feedback with human-level accuracy",
      "authors": [
        "Shyam Agarwal",
        "Ali Moghimi",
        "Kevin C. Haudek"
      ],
      "abstract": "Constructed-response questions are crucial to encourage generative processing and test a learner's understanding of core concepts. However, the limited availability of instructor time, large class sizes, and other resource constraints pose significant challenges in providing timely and detailed evaluation, which is crucial for a holistic educational experience. In addition, providing timely and frequent assessments is challenging since manual grading is labor intensive, and automated grading is complex to generalize to every possible response scenario. This paper proposes a novel and practical approach to grade short-answer constructed-response questions. We discuss why this problem is challenging, define the nature of questions on which our method works, and finally propose a framework that instructors can use to evaluate their students' open-responses, utilizing near-domain data like data from similar questions administered in previous years. The proposed method outperforms the state of the art machine learning models as well as non-fine-tuned large language models like GPT 3.5, GPT 4, and GPT 4o by a considerable margin of over 10-20% in some cases, even after providing the LLMs with reference/model answers. Our framework does not require pre-written grading rubrics and is designed explicitly with practical classroom settings in mind. Our results also reveal exciting insights about learning from near-domain data, including what we term as accuracy and data advantages using human-labeled data, and we believe this is the first work to formalize the problem of automated short answer grading based on the near-domain data.",
      "published": "2025-12-01",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.04113v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2511.21920v1",
      "title": "Toward Automated and Trustworthy Scientific Analysis and Visualization with LLM-Generated Code",
      "authors": [
        "Apu Kumar Chakroborti",
        "Yi Ding",
        "Lipeng Wan"
      ],
      "abstract": "As modern science becomes increasingly data-intensive, the ability to analyze and visualize large-scale, complex datasets is critical to accelerating discovery. However, many domain scientists lack the programming expertise required to develop custom data analysis workflows, creating barriers to timely and effective insight. Large language models (LLMs) offer a promising solution by generating executable code from natural language descriptions. In this paper, we investigate the trustworthiness of open-source LLMs in autonomously producing Python scripts for scientific data analysis and visualization. We construct a benchmark suite of domain-inspired prompts that reflect real-world research tasks and systematically evaluate the executability and correctness of the generated code. Our findings show that, without human intervention, the reliability of LLM-generated code is limited, with frequent failures caused by ambiguous prompts and the models' insufficient understanding of domain-specific contexts. To address these challenges, we design and assess three complementary strategies: data-aware prompt disambiguation, retrieval-augmented prompt enhancement, and iterative error repair. While these methods significantly improve execution success rates and output quality, further refinement is needed. This work highlights both the promise and current limitations of LLM-driven automation in scientific workflows and introduces actionable techniques and a reusable benchmark for building more inclusive, accessible, and trustworthy AI-assisted research tools.",
      "published": "2025-11-26",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.21920v1",
      "relevance_score": 18
    },
    {
      "arxiv_id": "2511.01156v1",
      "title": "Higher-order spatiotemporal wave packets with Gouy phase dynamics",
      "authors": [
        "Wangke Yu",
        "Yijie Shen"
      ],
      "abstract": "Spatiotemporal (ST) wave packets refer to a broad class of optical pulses whose spatial and temporal dependence cannot be treated separately. Such space time non-separability can induce exotic physical effects such as non-diffraction, non-transverse waves, and sub or superluminal propagation. Here, a family of ST non-separable pulses is presented, where a modal order is proposed to extend their spatiotemporal structural complexity, analogous to the spatial higher-order Gaussian modes. The modal order is strongly coupled to the Gouy phase, which can unveil anomalous spatiotemporal dynamics, including ultrafast cycle-switching evolution, ST self-healing, and sub- or super-luminal propagation. We further introduce a stretch parameter that stretches the temporal envelope while keeping the Gouy-phase coefficient unchanged. This stretch invariance decouples pulse duration from modal order, allowing us to tune the few-cycle width without shifting temporal-revival positions or altering the phase or group-velocity laws. Moreover, an approach to analyzing the phase velocity and group velocity of the higher-order ST modes is proposed to quantitatively characterize the sub- or supe-luminal effects. The method is universal for a larger group of complex structured ultrafast pulses, laying the basis for both fundamental physics and advanced applications in ultrafast optics and structured light.",
      "published": "2025-11-03",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.01156v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2510.22903v3",
      "title": "Radiation enhanced diffusion in cartilages as a physical mechanism underlying radiation treatments of osteoarthritis and related disorders",
      "authors": [
        "Diana Shvydka",
        "Victor Karpov"
      ],
      "abstract": "Degradation of joint cartilages can result in osteoarthritis (OA) affecting about 10\\% of the US population and responsible for significant hospitalization costs. While observations show that low dose radiation treatments (LDRT) bring improvements for a majority of OA patients, the underlying mechanism is not sufficiently understood. Here, we show how the radiation enhanced diffusion (RED) can boost the molecular transport in cartilages promoting cartilage self-healing rendering a mechanism for the observed positive LDRT effects on OA. Along with quantitative estimates for RED, we predict a related phenomenon of the electric charge build up that allows LDRT schedules promoting desirable types of molecular transports dominated by either positive or negative molecular species. Our analyses call upon further experimental verifications and clinical trials with curative rather than palliative intent. In addition to OA applications, our developed approaches can be useful for sports medicine dealing with damage or degeneration of the articular cartilages.",
      "published": "2025-10-27",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.22903v3",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2510.07522v1",
      "title": "Airy Resonances in Photonic Crystal Superpotentials",
      "authors": [
        "Zeyu Zhang",
        "Brian Gould",
        "Maria Barsukova",
        "Mikael C. Rechtsman"
      ],
      "abstract": "Airy wavefunctions are associated with one of the simplest scenarios in wave mechanics: a quantum bouncing ball. In other words, they are the eigenstates of the time-independent Schrodinger equation with a linear potential. In the domain of optics, laser beams that are spatially shaped as Airy functions (`Airy beams') have been shown to exhibit a prominent lobe that follows a curved path, rather than propagating in a straight line, and which has self-healing properties in the presence of obstacles. Here, we observe the presence of Airy resonances in two-dimensional photonic crystals composed of a lattice of holes in a silicon slab. Analogously to electrons in a linear potential, these Airy resonances arise due to a linear spatial variation in the lattice constant of the holes. We map the electromagnetic description of the photonic crystal onto a 2D non-Hermitian Schrodinger equation with a linear potential, which we call a `superpotential'. The non-Hermiticity appears in the form of a complex effective mass due to out-of-plane radiation and fundamentally alters the collective optical response of the Airy resonances.",
      "published": "2025-10-08",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.07522v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2507.17355v2",
      "title": "pH-dependent interfacial rheology of polymer membranes assembled at liquid-liquid interfaces using hydrogen bonds",
      "authors": [
        "Julien Dupr\u00e9 de Baubigny",
        "Corentin Tregouet",
        "Elena N. Govorun",
        "Mathilde Reyssat",
        "Patrick Perrin",
        "Nad\u00e8ge Pantoustier",
        "Thomas Salez",
        "C\u00e9cile Monteux"
      ],
      "abstract": "Self-assembly of polymers at liquid interfaces using non-covalent interactions has emerged as a promising technique to reversibly produce self-healing membranes. Besides the assembly process, it is also crucial to control the mechanical properties of these membranes. Here, we measure the interfacial rheological properties of PMAA-PPO (polymethacrylic acid - polypropylene oxide) polymer membranes assembled using hydrogen bonds at the interface between water and a polar oil, Mygliol. Varying the pH enables us to modify the degree of ionization of the PMAA chains, and hence their ability to establish hydrogen interactions with PPO. Frequency sweeps of the interfacial layers show a crossover between a viscous regime at low frequencies and an elastic regime at high frequencies. The crossover elastic modulus, measured one hour after the two phases were put into contact, decreases by a half over the pH range investigated, which can be accounted for by a decrease of the layer thickness as pH increases. Furthermore, we find that the crossover frequency varies exponentially with the degree of ionization of PMAA. To account for these observations, we propose a simple picture where the short PPO chains behave as non-covalent cross-linkers that bridge several PMAA chains. The dissociation rate and hence the crossover frequency are controlled by the number of PO units per PPO chain involved in the hydrogen bonds.",
      "published": "2025-07-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.17355v2",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2507.04085v2",
      "title": "Skin mode tunability and self-healing effect in photonic Floquet lattices",
      "authors": [
        "Hua-Yu Bai",
        "Yang Chen",
        "Tian-Yang Zhang",
        "Guang-Can Guo",
        "Ming Gong",
        "Xi-Feng Ren"
      ],
      "abstract": "Non-Hermitian systems host exotic phenomena absent in their Hermitian counterparts, including the recently predicted self-healing effect (SHE) of non-Hermitian skin modes. To date, the SHE of skin modes in non-Hermitian systems has not been observed experimentally. Here we propose a feasible scheme to realize SHE in photonic Floquet lattices by exploiting skin mode tunability (SMT), a mechanism in which the spectrum of skin modes localized at one boundary can be tuned via a potential applied at the opposite boundary. Such tunability arises from the non-Hermitian biorthogonality of the eigenstates. We demonstrate that a certain skin mode is exceptionally sensitive to remote-boundary potentials in an array of $100$ coupled helical waveguides, allowing broad-range spectral control and the generation of SHE with experimentally accessible parameters. Our results establish a general framework for engineering skin modes via local perturbations, thereby expanding the toolbox for non-Hermitian wave control.",
      "published": "2025-07-05",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.04085v2",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2506.05805v1",
      "title": "Spatiotemporal coupled Airy-Airy wavepacket and its propagation dynamics",
      "authors": [
        "Zhaofeng Huang",
        "Xiaolin Su",
        "Qian Cao",
        "Andy Chong",
        "Qiwen Zhan"
      ],
      "abstract": "Airy beams, celebrated for their self-acceleration, diffraction-free propagation, and self-healing properties, have garnered significant interest in optics and photonics, with applications spanning ultrafast optics, laser processing, nonlinear optics, and optical communications. Recent research primarily aims at independent control of Airy beams in both spatial and spatiotemporal domains. In a pioneering approach, we have successfully generated and controlled a spatiotemporal coupled (STc) Airy-Airy wavepacket, achieving its rotation while preserving vertical distribution in the spatiotemporal domain. Furthermore, we have investigated the self-acceleration and self-healing properties of the STc Airy-Airy wavepacket in this domain, noting that its dynamically adjustable rotation and spatiotemporal coupling capability provide a novel strategy for managing ultrafast lasers, with potential advancements in optical micromanipulation and time-domain coding communication.",
      "published": "2025-06-06",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2506.05805v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2506.04068v1",
      "title": "Lattice and Orientational Defects Mediate Collective Transport of Confluent Cells",
      "authors": [
        "Jiusi Zhang",
        "Chung Wing Chan",
        "Bo Li",
        "Rui Zhang"
      ],
      "abstract": "Confluent tissues are a type of foam-like biological active matter. There is a recent interest in using active nematic liquid crystal framework to understand confluent cells, where topological (orientational) defects are believed to play a crucial role. However, how to reconcile the physical picture of lattice defects in Voronoi polygons with that of orientational defects in the nematic field$-$particularly in the context of cellular transport$-$remains elusive. Here, we employ the Active Vertex model to investigate the physics of lattice and orientational defects in the dynamics of confluent cells. We find a spatio-orientational correlation between lattice defects and $+1/2$ defects, unveiling a correspondence between the two physical perspectives. Next, we simulate the behavior of a dragged cell within a hexagonal-lattice tissue. Our results reveal that while the drag coefficient is anisotropic, the threshold drag force to mobilize the cell is isotropic, indicating the presence of a caging energy barrier. We further analyze the defect pattern in the wake of the dragged cell or cells. Remarkably, we discover that dragging two neighboring cells along the least-drag direction can substantially minimize the destruction of the lattice structure during cell transport. We find that this is due to the cooperative and periodic self-healing of the lattice defects. Taken together, our work sheds new light on the topological structure of confluent cells during their collective motion, advancing our physical understanding of cellular transport in processes such as wound healing, cancer cell metastasis, and other physiological events.",
      "published": "2025-06-04",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2506.04068v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2505.00744v4",
      "title": "Localizing Before Answering: A Hallucination Evaluation Benchmark for Grounded Medical Multimodal LLMs",
      "authors": [
        "Dung Nguyen",
        "Minh Khoi Ho",
        "Huy Ta",
        "Thanh Tam Nguyen",
        "Qi Chen",
        "Kumar Rav",
        "Quy Duong Dang",
        "Satwik Ramchandre",
        "Son Lam Phung",
        "Zhibin Liao",
        "Minh-Son To",
        "Johan Verjans",
        "Phi Le Nguyen",
        "Vu Minh Hieu Phan"
      ],
      "abstract": "Medical Large Multi-modal Models (LMMs) have demonstrated remarkable capabilities in medical data interpretation. However, these models frequently generate hallucinations contradicting source evidence, particularly due to inadequate localization reasoning. This work reveals a critical limitation in current medical LMMs: instead of analyzing relevant pathological regions, they often rely on linguistic patterns or attend to irrelevant image areas when responding to disease-related queries. To address this, we introduce HEAL-MedVQA (Hallucination Evaluation via Localization MedVQA), a comprehensive benchmark designed to evaluate LMMs' localization abilities and hallucination robustness. HEAL-MedVQA features (i) two innovative evaluation protocols to assess visual and textual shortcut learning, and (ii) a dataset of 67K VQA pairs, with doctor-annotated anatomical segmentation masks for pathological regions. To improve visual reasoning, we propose the Localize-before-Answer (LobA) framework, which trains LMMs to localize target regions of interest and self-prompt to emphasize segmented pathological areas, generating grounded and reliable answers. Experimental results demonstrate that our approach significantly outperforms state-of-the-art biomedical LMMs on the challenging HEAL-MedVQA benchmark, advancing robustness in medical VQA.",
      "published": "2025-04-30",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.00744v4",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2504.02103v1",
      "title": "OAM-Assisted Self-Healing Is Directional, Proportional and Persistent",
      "authors": [
        "Marek Klemes",
        "Lan Hu",
        "Greg Bowles",
        "Alireza Ghayekhloo",
        "Mohammad Akbari",
        "Soulideth Thirakoune",
        "Michael Schwartzman",
        "Kevin Zhang",
        "Tan Huy Ho",
        "David Wessel",
        "Wen Tong"
      ],
      "abstract": "In this paper we demonstrate the postulated mechanism of self-healing specifically due to orbital-angular-momentum (OAM) in radio vortex beams having equal beam-widths. In previous work we experimentally demonstrated self-healing effects in OAM beams at 28 GHz and postulated a theoretical mechanism to account for them. In this work we further characterize the OAM self-healing mechanism theoretically and confirm those characteristics with systematic and controlled experimental measurements on a 28 GHz outdoor link. Specifically, we find that the OAM self-healing mechanism is an additional self-healing mechanism in structured electromagnetic beams which is directional with respect to the displacement of an obstruction relative to the beam axis. We also confirm our previous findings that the amount of OAM self-healing is proportional to the OAM order, and additionally find that it persists beyond the focusing region into the far field. As such, OAM-assisted self-healing brings an advantage over other so-called non-diffracting beams both in terms of the minimum distance for onset of self-healing and the amount of self-healing obtainable. We relate our findings by extending theoretical models in the literature and develop a unifying electromagnetic analysis to account for self-healing of OAM-bearing non-diffracting beams more rigorously.",
      "published": "2025-04-02",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.02103v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2504.00439v1",
      "title": "Spatiotemporal Airy rings wavepackets",
      "authors": [
        "Xiaolin Su",
        "Andy Chong",
        "Qian Cao",
        "Qiwen Zhan"
      ],
      "abstract": "Airy waves, known for their non-diffracting and self-accelerating properties, have been extensively studied in spatial and temporal domains, but their spatiotemporal (ST) counterparts remain largely unexplored. We report the first experimental realization of a spatiotemporal Airy rings wavepacket, which exhibits an Airy function distribution in the radial dimension of the ST domain. The wavepacket demonstrates abrupt autofocusing under the combined effects of diffraction and dispersion, achieving a 110 um spatial and 320 fs temporal focus with a sharp intensity contrast along the propagation direction - ideal for nonlinear microscopy and multiphoton 3D printing. Notably, the wavepacket retains its autofocusing capability even after spatial obstruction, showcasing robust self-healing. Furthermore, by embedding a vortex phase, we create an ST-Airy vortex wavepacket that confines transverse orbital angular momentum (t-OAM) within a compact ST volume, enabling new avenues for studying light-matter interactions with t-OAM. Our findings advance the fundamental understanding of ST Airy waves and highlight their potential for transformative applications in ultrafast optics, structured light, and precision laser processing.",
      "published": "2025-04-01",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.00439v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21293v1",
      "title": "Quadrupped-Legged Robot Movement Plan Generation using Large Language Model",
      "authors": [
        " Muhtadin",
        "Vincentius Gusti Putu A. B. M.",
        "Ahmad Zaini",
        "Mauridhi Hery Purnomo",
        "I Ketut Eddy Purnama",
        "Chastine Fatichah"
      ],
      "abstract": "Traditional control interfaces for quadruped robots often impose a high barrier to entry, requiring specialized technical knowledge for effective operation. To address this, this paper presents a novel control framework that integrates Large Language Models (LLMs) to enable intuitive, natural language-based navigation. We propose a distributed architecture where high-level instruction processing is offloaded to an external server to overcome the onboard computational constraints of the DeepRobotics Jueying Lite 3 platform. The system grounds LLM-generated plans into executable ROS navigation commands using real-time sensor fusion (LiDAR, IMU, and Odometry). Experimental validation was conducted in a structured indoor environment across four distinct scenarios, ranging from single-room tasks to complex cross-zone navigation. The results demonstrate the system's robustness, achieving an aggregate success rate of over 90\\% across all scenarios, validating the feasibility of offloaded LLM-based planning for autonomous quadruped deployment in real-world settings.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21293v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21200v1",
      "title": "A Multimodal Human-Centered Framework for Assessing Pedestrian Well-Being in the Wild",
      "authors": [
        "Yasaman Hakiminejad",
        "Arash Tavakoli"
      ],
      "abstract": "Pedestrian well-being is a critical yet rarely measured component of sustainable urban mobility and livable city design. Existing approaches to evaluating pedestrian environments often rely on static, infrastructure-based indices or retrospective surveys, which overlook the dynamic, subjective, and psychophysiological dimensions of everyday walking experience. This paper introduces a multimodal, human-centered framework for assessing pedestrian well-being in the wild by integrating three complementary data streams: continuous physiological sensing, geospatial tracking, and momentary self-reports collected using the Experience Sampling Method. The framework conceptualizes pedestrian experience as a triangulation enabling a holistic understanding of how urban environments influence well-being. The utility of our framework is then demonstrated through a naturalistic case study conducted in the Greater Philadelphia region, in which participants wore research-grade wearable sensors and carried GPS-enabled smartphones during their regular daily activities. Physiological indicators of autonomic nervous system activity, including heart rate variability and electrodermal activity, were synchronized with spatial trajectories and in situ self-reports of stress, affect, and perceived infrastructure conditions. Results illustrate substantial inter- and intra-individual variability in both subjective experience and physiological response, as well as context-dependent patterns associated with traffic exposure, pedestrian infrastructure quality, and environmental enclosure. The findings also suggest that commonly used walkability indices may not fully capture experiential dimensions of pedestrian well-being. By enabling real-world, multimodal measurement of pedestrian experience, the proposed framework offers a scalable and transferable approach for advancing human-centered urban analytics.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21200v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21196v1",
      "title": "Flocking phase transition and threat responses in bio-inspired autonomous drone swarms",
      "authors": [
        "Matthieu Verdoucq",
        "Dari Trendafilov",
        "Cl\u00e9ment Sire",
        "Ram\u00f3n Escobedo",
        "Guy Theraulaz",
        "Gautier Hattenberger"
      ],
      "abstract": "Collective motion inspired by animal groups offers powerful design principles for autonomous aerial swarms. We present a bio-inspired 3D flocking algorithm in which each drone interacts only with a minimal set of influential neighbors, relying solely on local alignment and attraction cues. By systematically tuning these two interaction gains, we map a phase diagram revealing sharp transitions between swarming and schooling, as well as a critical region where susceptibility, polarization fluctuations, and reorganization capacity peak. Outdoor experiments with a swarm of ten drones, combined with simulations using a calibrated flight-dynamics model, show that operating near this transition enhances responsiveness to external disturbances. When confronted with an intruder, the swarm performs rapid collective turns, transient expansions, and reliably recovers high alignment within seconds. These results demonstrate that minimal local-interaction rules are sufficient to generate multiple collective phases and that simple gain modulation offers an efficient mechanism to adjust stability, flexibility, and resilience in drone swarms.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21196v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.20774v1",
      "title": "Asymptotic dynamical analysis of $f(R,T^\u03c6) = R+\u03b1T^\u03c6 + \u03b2(T^\u03c6)^2/2$ cosmology",
      "authors": [
        "Joaquin Estevez-Delgado",
        "Roberto De Arcia",
        "Gabino Estevez-Delgado",
        "Israel Quiros"
      ],
      "abstract": "In this work we investigate the asymptotic cosmological dynamics of a modified gravity model based on the $f(R,T^\u03c6)$ theory, where $R$ denotes the Ricci scalar and $T^\u03c6$ is the trace of the stress-energy tensor of a scalar field. Despite the extensive study of $f(R,T)$ gravity, the asymptotic implications of quadratic trace couplings in scalar field cosmology remain largely unexplored. We focus on a specific form given by $ f(R,T^\u03c6) = R + \u03b1T^\u03c6+ \u03b2(T^\u03c6)^2/2$, in which the parameters $\u03b1$ and $\u03b2$ control the strength of non-minimal couplings between geometry and matter. We derive the set of cosmological equations for a spatially flat, homogeneous and isotropic universe and construct the autonomous system of first-order differential equations using a compact set of dimensionless variables. This formulation provides a foundation for the qualitative analysis of the asymptotic behavior. We identify and classify all critical points and analyze their stability properties. Finally, the energy conditions and the presence of dynamical instabilities are examined. We study the general scenario $\u03b1\\neq 0$ and $\u03b2\\neq 0$, along with the subcases $\u03b1= 0$ and $\u03b2= 0$, in order to compare with minimally coupled quintessence $\u03b1= \u03b2= 0$. We find that the quadratic term in $T^\u03c6$ admits late-time accelerated de Sitter-like critical solutions at the background level. However, several accelerated points lie in a degenerate scalar sector with $Q_s=0$, where the standard linear perturbation criteria are inconclusive, while the quasi-de Sitter point with $Q_s>0$ is of saddle type. Therefore, establishing full perturbative viability requires going beyond the linear analysis in the degenerate sector.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20774v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.20770v1",
      "title": "OccuFly: A 3D Vision Benchmark for Semantic Scene Completion from the Aerial Perspective",
      "authors": [
        "Markus Gross",
        "Sai B. Matha",
        "Aya Fahmy",
        "Rui Song",
        "Daniel Cremers",
        "Henri Meess"
      ],
      "abstract": "Semantic Scene Completion (SSC) is crucial for 3D perception in mobile robotics, as it enables holistic scene understanding by jointly estimating dense volumetric occupancy and per-voxel semantics. Although SSC has been widely studied in terrestrial domains such as autonomous driving, aerial scenarios like autonomous flying remain largely unexplored, thereby limiting progress on downstream applications. Furthermore, LiDAR sensors represent the primary modality for SSC data generation, which poses challenges for most uncrewed aerial vehicles (UAVs) due to flight regulations, mass and energy constraints, and the sparsity of LiDAR-based point clouds from elevated viewpoints. To address these limitations, we introduce OccuFly, the first real-world, camera-based aerial SSC benchmark, captured at altitudes of 50m, 40m, and 30m during spring, summer, fall, and winter. OccuFly covers urban, industrial, and rural scenarios, provides 22 semantic classes, and the data format adheres to established conventions to facilitate seamless integration with existing research. Crucially, we propose a LiDAR-free data generation framework based on camera modality, which is ubiquitous on modern UAVs. By utilizing traditional 3D reconstruction, our framework automates label transfer by lifting a subset of annotated 2D masks into the reconstructed point cloud, thereby substantially minimizing manual 3D annotation effort. Finally, we benchmark the state-of-the-art on OccuFly and highlight challenges specific to elevated viewpoints, yielding a comprehensive vision benchmark for holistic aerial 3D scene understanding.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20770v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.20615v1",
      "title": "Active Intelligence in Video Avatars via Closed-loop World Modeling",
      "authors": [
        "Xuanhua He",
        "Tianyu Yang",
        "Ke Cao",
        "Ruiqi Wu",
        "Cheng Meng",
        "Yong Zhang",
        "Zhuoliang Kang",
        "Xiaoming Wei",
        "Qifeng Chen"
      ],
      "abstract": "Current video avatar generation methods excel at identity preservation and motion alignment but lack genuine agency, they cannot autonomously pursue long-term goals through adaptive environmental interaction. We address this by introducing L-IVA (Long-horizon Interactive Visual Avatar), a task and benchmark for evaluating goal-directed planning in stochastic generative environments, and ORCA (Online Reasoning and Cognitive Architecture), the first framework enabling active intelligence in video avatars. ORCA embodies Internal World Model (IWM) capabilities through two key innovations: (1) a closed-loop OTAR cycle (Observe-Think-Act-Reflect) that maintains robust state tracking under generative uncertainty by continuously verifying predicted outcomes against actual generations, and (2) a hierarchical dual-system architecture where System 2 performs strategic reasoning with state prediction while System 1 translates abstract plans into precise, model-specific action captions. By formulating avatar control as a POMDP and implementing continuous belief updating with outcome verification, ORCA enables autonomous multi-step task completion in open-domain scenarios. Extensive experiments demonstrate that ORCA significantly outperforms open-loop and non-reflective baselines in task success rate and behavioral coherence, validating our IWM-inspired design for advancing video avatar intelligence from passive animation to active, goal-oriented behavior.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20615v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.20488v1",
      "title": "Exponential Decay outside of the Light Cone for the Pseudo-Relativistic Non-Autonomous Schr\u00f6dinger Equation",
      "authors": [
        "S\u00e9bastien Breteaux",
        "J\u00e9r\u00e9my Faupin",
        "Viviana Grasselli"
      ],
      "abstract": "We establish a maximal velocity bound for a pseudo-relativistic quantum particle in an external time-dependent potential. Our estimate shows that the probability for the particle, starting in a convex set $X\\subset\\mathbb{R}^d$ at $t=0$, to reach a convex set $Y\\subset\\mathbb{R}^d$ at a time $t>0$, is bounded by $e^{-2\u03b4}$ where $\u03b4$ is the distance from $Y$ to the section at time $t$ of the light cone generated by $X$.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20488v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.19943v1",
      "title": "SE360: Semantic Edit in 360$^\\circ$ Panoramas via Hierarchical Data Construction",
      "authors": [
        "Haoyi Zhong",
        "Fang-Lue Zhang",
        "Andrew Chalmers",
        "Taehyun Rhee"
      ],
      "abstract": "While instruction-based image editing is emerging, extending it to 360$^\\circ$ panoramas introduces additional challenges. Existing methods often produce implausible results in both equirectangular projections (ERP) and perspective views. To address these limitations, we propose SE360, a novel framework for multi-condition guided object editing in 360$^\\circ$ panoramas. At its core is a novel coarse-to-fine autonomous data generation pipeline without manual intervention. This pipeline leverages a Vision-Language Model (VLM) and adaptive projection adjustment for hierarchical analysis, ensuring the holistic segmentation of objects and their physical context. The resulting data pairs are both semantically meaningful and geometrically consistent, even when sourced from unlabeled panoramas. Furthermore, we introduce a cost-effective, two-stage data refinement strategy to improve data realism and mitigate model overfitting to erase artifacts. Based on the constructed dataset, we train a Transformer-based diffusion model to allow flexible object editing guided by text, mask, or reference image in 360$^\\circ$ panoramas. Our experiments demonstrate that our method outperforms existing methods in both visual quality and semantic accuracy.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19943v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21336v1",
      "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
      "authors": [
        "Ziyu Chen",
        "Xinbei Jiang",
        "Peng Sun",
        "Tao Lin"
      ],
      "abstract": "Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21336v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21279v1",
      "title": "Multivariate scaling of proton and ion energies, divergence, and charge states in Target Normal Sheath Acceleration",
      "authors": [
        "Vasiliki E. Alexopoulou"
      ],
      "abstract": "The interaction of an intense laser pulse with a solid target produces energetic proton and ion beams through the Target Normal Sheath Acceleration (TNSA) mechanism. Such beams are under active investigation for applications in proton beam therapy, materials modification, and nuclear and high-energy-density physics. Despite extensive experimental and theoretical effort, predictive correlations between laser and target parameters and the resulting ion-beam properties remain an open research question, owing to the intrinsically multiphysics and strongly coupled nature of laser-plasma interactions. Here, we employ our unified multiphysics model that reproduces laser-solid interaction dynamics with accuracy exceeding 95% over a broad range of short- and ultrashort-pulse conditions. Using this model, we derive statistically validated scaling laws and probability maps that correlate proton, carbon, and oxygen ion cutoff energies, beam divergences, and ionization states to a wide set of laser and target parameters, including pulse duration, laser power, laser beam spot, target thickness, prepulse-main pulse interval, contrast, laser wavelength, and polarization. Continuous beam properties (cutoff energies and beam divergences) are described using multivariate regression with cross-validation, while discrete ionization states are analyzed using classification and regression tree (CART) methods, enabling nonlinear and threshold-dependent behavior to be captured. The resulting scaling relations, contour maps, and box plots elucidate the coupled roles of laser pulse, and target geometry in governing TNSA ion acceleration and charge-state formation. These results provide a predictive and physically interpretable framework for understanding and optimizing laser-driven ion sources across a wide parameter space.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21279v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21188v1",
      "title": "The disc instability model: original recipe and additional ingredients",
      "authors": [
        "Jean-Marie Hameury"
      ],
      "abstract": "The disc instability model successfully reproduces many of the observed properties of cataclysmic variables. However, additional ingredients such as mass-transfer variations, disc irradiation, stream-disc overflow, or inner-disc truncation must be included to explain certain systems. The physics underlying these processes is often poorly constrained, and our lack of knowledge is typically absorbed into extra free parameters, much like the $\u03b1$-prescription for viscosity. In this paper, I examine how each of these ingredients affects the predicted light curves and discuss the limitations that arise from the growing number of unconstrained parameters on the model's predictive power.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21188v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21186v1",
      "title": "Preliminary forecasting constraint on scalar charge with LISA in non-vacuum environments",
      "authors": [
        "Tieguang Zi",
        "Chang-Qing Ye"
      ],
      "abstract": "We compute the gravitational wave signal from eccentric extreme-mass-ratio inspirals (EMRIs) embedded within beyond-vacuum environments, where the secondary object carries a scalar charge and evolves in the presence of both an accretion disk and a dark matter halo. The waveform modification is derived by incorporating the scalar charge correcting the fluxes and orbital trajectories of the secondary. Our results indicate that, under suitable parameter configurations, the influence of the scalar charge on EMRIs waveform in such environments can be distinguished from that in vacuum spacetime. For the EMRIs signal modified by the astrophysical environments, the future space-borne detector can determine the relative error of scalar charge constrained by LISA at the level of $\\sim0.1$, providing a preliminary prediction of detecting scalar charge in the beyond-vacuum spacetime.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21186v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21151v1",
      "title": "Acoustic gravitational waves from primordial curvature perturbations",
      "authors": [
        "Zhuan Ning",
        "Zi-Yan Yuwen",
        "Xiang-Xi Zeng",
        "Rong-Gen Cai",
        "Shao-Jiang Wang"
      ],
      "abstract": "Standard perturbative calculations of scalar-induced gravitational waves (SIGWs) have neglected nonperturbative effects in the large-amplitude regime. We develop a hybrid numerical framework to signify nonperturbative effects on the stochastic gravitational wave (GW) background sourced by primordial curvature perturbations, focusing on the acoustic channel (fluid motions). Fully general-relativistic, spherically symmetric simulations are used to extract nonperturbative sound-shell profiles from isolated curvature peaks; these profiles are then embedded into three-dimensional lattice evolutions of relativistic hydrodynamics coupled to transverse-traceless metric perturbations to compute the acoustic GW spectra. The acoustic signal has a peak frequency determined by the comoving shell thickness, and its amplitude is extremely sensitive to the mean comoving separation of peaks, scaling approximately as $R_{*c}^{-7}$. We find a robust causal low-frequency tail $\\propto k^{3}$, and the nonlinear hydrodynamic interactions can enhance the ultraviolet power. Comparing with SIGWs computed perturbatively from the same real-space configuration, we show that acoustic GWs can be amplified by an order of magnitude and display a peak shifted to a lower frequency in the large-amplitude regime. These results highlight the importance of nonperturbative effects for accurate predictions of stochastic GW signals induced from primordial curvature perturbations.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21151v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21124v1",
      "title": "Measuring Variable Importance via Accumulated Local Effects",
      "authors": [
        "Jingyu Zhu",
        "Daniel W. Apley"
      ],
      "abstract": "A shortcoming of black-box supervised learning models is their lack of interpretability or transparency. To facilitate interpretation, post-hoc global variable importance measures (VIMs) are widely used to assign to each predictor or input variable a numerical score that represents the extent to which that predictor impacts the fitted model's response predictions across the training data. It is well known that the most common existing VIMs, namely marginal Shapley and marginal permutation-based methods, can produce unreliable results if the predictors are highly correlated, because they require extrapolation of the response at predictor values that fall far outside the training data. Conditional versions of Shapley and permutation VIMs avoid or reduce the extrapolation but can substantially deflate the importance of correlated predictors. For the related goal of visualizing the effects of each predictor when strong predictor correlation is present, accumulated local effects (ALE) plots were recently introduced and have been widely adopted. This paper presents a new VIM approach based on ALE concepts that avoids both the extrapolation and the VIM deflation problems when predictors are correlated. We contrast, both theoretically and numerically, ALE VIMs with Shapley and permutation VIMs. Our results indicate that ALE VIMs produce similar variable importance rankings as Shapley and permutation VIMs when predictor correlations are mild and more reliable rankings when correlations are strong. An additional advantage is that ALE VIMs are far less computationally expensive.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21124v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21302v1",
      "title": "AndroidLens: Long-latency Evaluation with Nested Sub-targets for Android GUI Agents",
      "authors": [
        "Yue Cao",
        "Yingyao Wang",
        "Pi Bu",
        "Jingxuan Xing",
        "Wei Jiang",
        "Zekun Zhu",
        "Junpeng Ma",
        "Sashuai Zhou",
        "Tong Lu",
        "Jun Song",
        "Yu Cheng",
        "Yuning Jiang",
        "Bo Zheng"
      ],
      "abstract": "Graphical user interface (GUI) agents can substantially improve productivity by automating frequently executed long-latency tasks on mobile devices. However, existing evaluation benchmarks are still constrained to limited applications, simple tasks, and coarse-grained metrics. To address this, we introduce AndroidLens, a challenging evaluation framework for mobile GUI agents, comprising 571 long-latency tasks in both Chinese and English environments, each requiring an average of more than 26 steps to complete. The framework features: (1) tasks derived from real-world user scenarios across 38 domains, covering complex types such as multi-constraint, multi-goal, and domain-specific tasks; (2) static evaluation that preserves real-world anomalies and allows multiple valid paths to reduce bias; and (3) dynamic evaluation that employs a milestone-based scheme for fine-grained progress measurement via Average Task Progress (ATP). Our evaluation indicates that even the best models reach only a 12.7% task success rate and 50.47% ATP. We also underscore key challenges in real-world environments, including environmental anomalies, adaptive exploration, and long-term memory retention.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21302v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.21117v1",
      "title": "Large lepton asymmetry from axion inflation and helium abundance hinted by ACT",
      "authors": [
        "Di Wu",
        "Yifan Hu",
        "Kohei Kamada"
      ],
      "abstract": "The generation of helical magnetic fields and the associated chiral asymmetry via the chiral anomaly is a generic feature in pseudoscalar inflation. In the presence of a Chern--Simons coupling between the inflaton and a U(1) gauge field, the homogeneous evolution of the inflaton induces a tachyonic instability in one circular polarization of the gauge field, resulting in the production of helical magnetic fields. In this work, we show that, in the case of a gauged lepton flavor symmetry, U(1)$_{L_i-L_j}$, this mechanism can lead to the generation of a sizable lepton asymmetry. In a simple setup, however, the resulting lepton asymmetry is typically too small to have an observational consequences, even setting aside constraints from baryon overproduction via sphaleron processes, due to the backreaction of the produced gauge fields and fermions on the inflationary dynamics. We demonstrate that this limitation can be overcome by implementing a mechanism to suppress fermion production during inflation. As a result, a much larger lepton asymmetry can be generated from the subsequent decay of magnetic helicity. Remarkably, for the gauged U(1)$_{L_\u03bc-L_\u03c4}$ symmetry, the generated asymmetry can be sufficiently large to suppress the primordial helium abundance, as may be inferred from recent cosmic microwave background observations by ACT.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21117v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.20710v1",
      "title": "Bounds on Abelian Currents in 4d CFTs",
      "authors": [
        "Denis Karateev",
        "Petr Kravchuk",
        "Andrea Manenti",
        "Marten Reehorst",
        "Alessandro Vichi"
      ],
      "abstract": "We study four-dimensional conformal field theories (CFTs) with an abelian $U(1)$ global symmetry using the conformal bootstrap approach. We obtain numerical bounds on the scaling dimensions of low-lying operators, the stress-tensor central charge, and a particular combination of the 't Hooft anomaly and the current central charge. Our analysis provides the first non-perturbative constraints on four-dimensional CFTs with conserved abelian currents and establishes a framework that can be extended to theories with non-abelian global symmetries.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20710v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.20560v1",
      "title": "A possible solution to the gallium anomaly moving beyond the leptonic wave function factorization",
      "authors": [
        "M. Cadeddu",
        "N. Cargioli",
        "F. Dordei",
        "L. Ferro",
        "C. Giunti",
        "M. Pitzalis"
      ],
      "abstract": "For over thirty years, a $\\sim20\\%$ deficit, now exceeding $5\u03c3$, has persisted between measured and predicted neutrino capture rates on $^{71}$Ga, as observed in radioactive source experiments (namely GALLEX, SAGE, and more recently BEST) using $^{51}$Cr and $^{37}$Ar. This long-standing discrepancy, referred to as the gallium anomaly, has posed a significant challenge to our understanding of both experimental methods and theoretical predictions. In this work, we revisit the theoretical calculation of the neutrino capture cross-section by moving beyond the standard treatment of the leptonic wave functions, revealing limitations in the commonly used factorization approach based on the detailed balance principle. Incorporating phenomenologically constrained Gamow-Teller transition densities, able to correctly reproduce the precisely measured half-life of $^{71}{\\textrm{Ge}}$, we find that the revised cross-section can be significantly reduced, potentially resolving the gallium anomaly without invoking new physics.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20560v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.19163v1",
      "title": "Probing quantum anomaly corrections on black hole physics through chaos",
      "authors": [
        "Yu-Sen An",
        "Wei-Hao Zhang"
      ],
      "abstract": "The black hole horizon can induce chaotic motion of particles around the black hole. The original integrable motion of particles can transit to the chaotic motion when approaching black hole horizon. In this work, we consider the black hole background where quantum conformal anomaly correction is taken into account. We use the Poincare section and Lyapunov exponent as representative probes to illustrate chaos. We investigate the effect of anomaly coefficient on the chaos of particles and find that quantum anomaly enhances the chaos of particle motions. As the chaotic orbits of particles can leave an imprint on the gravitational wave signals of the extreme mass ratio inspirals, our results pave the way to detect conformal anomaly effect in actual observations.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19163v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.19100v1",
      "title": "Field-induced anomaly in the anisotropic non-Fermi-liquid normal state of UBe$_{13}$",
      "authors": [
        "Yusei Shimizu",
        "Shunichiro Kittaka",
        "Yohei Kono",
        "Shota Nakamura",
        "Yoshinori Haga",
        "Etsuji Yamamoto",
        "Kazushige Machida",
        "Hiroshi Amitsuka",
        "Toshiro Sakakibara"
      ],
      "abstract": "We report the results of high-resolution dc magnetization and specific-heat measurements at very low temperatures for   a single crystal \\color{black} of UBe$_{13}$ in magnetic fields applied along the [001] and [111] directions, in both the normal and superconducting states. In the normal state, magnetic susceptibility $\u03c7(T) = M/H$ exhibits a logarithmic temperature dependence over a wide temperature range (1-20 K). However, with increasing field, this non-Fermi-liquid (NFL) behavior of $\u03c7(T) $ at low temperatures is suppressed. Moreover, a susceptibility maximum occurs below 4 T, whereas Fermi-liquid coherence is recovered above 8 T. In addition, thermodynamic anomalies ($T_{\\rm A}$ and $H_{\\rm A}$) occur in both magnetic susceptibility and specific heat at intermediate fields (6--10 T) along the [111] direction. Furthermore, a nontrivial fifth-order nonlinear susceptibility is observed in the normal-state magnetization of UBe$_{13}$. These results suggest a close relationship between the field-induced multipolar correlations of $5f$-electron degrees of freedom and the Fermi-surface reconstruction accompanying the crossover from the NFL state to the Fermi-liquid state in UBe$_{13}$.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19100v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.18959v1",
      "title": "Scalar-Mediated Inelastic Dark Matter as a Solution to Small-Scale Structure Anomalies",
      "authors": [
        "Zihan Wang"
      ],
      "abstract": "We propose a scalar-mediated Self-Interacting Dark Matter (SIDM) model to address small-scale structure anomalies such as the core-cusp and diversity problems. The model is composed by a leptophilic scalar mediator and a pseudo-Dirac dark matter candidate with a mass splitting of 100 eV.We imposed aA dark discrete $\\mathbb{Z}_2$ symmetry forbids tree-level elastic scattering. Therefore creates kinematic threshold that suppresses scattering in ultra-faint satellite galaxies while enabling large self-interaction cross-sections in dwarf galaxies via resonant enhancement. To satisfy Big Bang Nucleosynthesis (BBN) requirements, we introduce a dimension-5 magnetic dipole operator that enable the decay of the excited state ($\u03c7_2 \\rightarrow \u03c7_1 \u03b3$). This operator also provides a unique, low-threshold signal for direct detection experiments, characterized by a distinct $1/E_R$ recoil spectrum. We identify a benchmark parameter space around ($m_\u03c7\\approx 40$ GeV, $m_\u03c6\\approx 20$ MeV) where non-perturbative coupled-channel dynamics successfully reconcile astrophysical observations with cosmological bounds, including CMB constraints on annihilation.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18959v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.18856v1",
      "title": "Correlated Entropic Uncertainty as a Signature of Exceptional Points",
      "authors": [
        "Kyu-Won Park",
        "Soojoon Lee",
        "Kabgyun Jeong"
      ],
      "abstract": "Non-Hermitian physics has become a fundamental framework for understanding open systems where gain and loss play essential roles, with impact across photonics, quantum science, and condensed matter. While the role of complex eigenvalues is well established, the nature of the corresponding eigenfunctions has remained a long-standing problem. Here we show that it arises from a fundamental entropic uncertainty trade-off between phase entropy and its Fourier representation. This trade-off enforces a correlated behavior of phase and Fourier entropies near avoided crossings and exceptional points, precisely where the Petermann factor diverges and phase rigidity collapses. Our results establish biorthogonality is not as an anomaly but an intrinsic property of eigenfunctions, arising universal manifestation of uncertainty relation in non-Hermitian systems. Beyond resolving this foundational question, our framework provides a unifying and testable principle that advances the fundamentals of non-Hermitian physics and can be directly verified with existing interferometric techniques.",
      "published": "2025-12-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18856v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.18172v1",
      "title": "cardinalR: Generating Interesting High-Dimensional Data Structures",
      "authors": [
        "Jayani P. Gamage",
        "Dianne Cook",
        "Paul Harrison",
        "Michael Lydeamore",
        "Thiyanga S. Talagala"
      ],
      "abstract": "Simulated high-dimensional data is useful for testing, validating, and improving algorithms used in dimension reduction, supervised and unsupervised learning. High-dimensional data is characterized by multiple variables that are dependent or associated in some way, such as linear, nonlinear, clustering or anomalies. Here we provide new methods for generating a variety of high-dimensional structures using mathematical functions and statistical distributions organized into the R package cardinalR. Several example data sets are also provided. These will be useful for researchers to better understand how different analytical methods work and can be improved, with a special focus on nonlinear dimension reduction methods. This package enriches the existing toolset of benchmark datasets for evaluating algorithms.",
      "published": "2025-12-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18172v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.18151v1",
      "title": "Supergravity anomaly equations from modularity of Calabi--Yau threefolds",
      "authors": [
        "Cesar Fierro Cota"
      ],
      "abstract": "F-theory compactifications on elliptically fibered Calabi--Yau threefolds yield consistent six-dimensional $\\mathcal{N}=(1,0)$ supergravity theories, for which the cancellation of gravitational, gauge and mixed anomalies imposes non-trivial algebraic relations between classical intersection data and enumerative geometry invariants of curves in the fiber. In this work, we capture the spectrum of such theories via meromorphic quasi-Jacobi forms of index zero whose Fourier coefficients determine the genus zero Gromov--Witten theory restricted to curve classes in the fiber. We find that the one-loop anomaly coefficients of the effective six-dimensional theories are encoded in the modular properties of these automorphic forms, while the Green--Schwarz counterterms are made manifest by the Fourier--Mukai transform action on zero- and two-branes associated with double T-duality along the elliptic fiber. Moreover, we show that the anomaly cancellation conditions are automatically satisfied in this class of string compactifications as a consequence of the holomorphic anomaly equations of topological string theory.",
      "published": "2025-12-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18151v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.18017v1",
      "title": "Auxiliary-Field Formalism for Higher-Derivative Boundary CFTs",
      "authors": [
        "Gregorio Paci",
        "Sergey N. Solodukhin"
      ],
      "abstract": "We study the conformal field theory defined by the fourth-order operator on four-dimensional manifolds with boundaries, reformulating it through an auxiliary field so that the dynamics become second order. Within this framework, we compute the heat kernel of $\\Box^2$ in flat space exactly, together with the associated Seeley-DeWitt coefficients for a broad class of non-standard boundary conditions. On curved backgrounds, we further construct the Weyl-invariant completion of the auxiliary field action with boundary terms and identify the corresponding conformal boundary conditions. Finally, we compute the boundary charges in the trace anomaly from the displacement operator correlators.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18017v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.17906v1",
      "title": "Extra-Dimensional \u03b7-Invariants and Anomaly Theories",
      "authors": [
        "Mirjam Cveti\u010d",
        "Ron Donagi",
        "Jonathan J. Heckman",
        "Max H\u00fcbner"
      ],
      "abstract": "Anomalies of a quantum field theory (QFT) constitute fundamental non-perturbatively robust data. In this paper we extract anomalies of 5D superconformal field theories (SCFTs) directly from the underlying extra-dimensional geometry. We show that all of this information can be efficiently extracted from extra-dimensional $\u03b7$-invariants, bypassing previously established approaches based on computationally cumbersome blowup / resolution techniques. We illustrate these considerations for 5D SCFTs engineered in M-theory by non-compact geometries $X=\\mathbb{C}^3/\u0393$ with finite subgroup $\u0393\\subset SU(3)$, where the anomalies are determined by the $\u03b7$-invariants of the asymptotic boundary $\\partial X=S^5/\u0393$. Our results apply equally to Abelian and non-Abelian $\u0393$, as well as isolated and non-isolated singularities. In the setting of non-isolated singularities we further analyze the interplay of anomaly structures across different strata of the singular locus. Our considerations extend readily to backgrounds which are not global orbifolds, as well as those which do not preserve supersymmetry.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17906v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.17433v1",
      "title": "Emergence of a hidden-order phase well below the charge density wave transition in a topological Weyl semimetal (TaSe$_4$)$_2$I",
      "authors": [
        "Sk Kalimuddin",
        "Sudipta Chatterjee",
        "Arnab Bera",
        "Satyabrata Bera",
        "Deep Singha Roy",
        "Soham Das",
        "Tuhin Debnath",
        "Ashis K. Nandy",
        "Shishir K. Pandey",
        "Mintu Mondal"
      ],
      "abstract": "The emergence of a charge density wave (CDW) in a Weyl semimetal -- a correlated topological phase, is exceptionally rare in condensed matter systems. In this context, the quasi-one-dimensional type-III Weyl semimetal (TaSe$_4$)$_2$I undergoes a CDW transition at $T_{\\mathrm{CDW}} \\approx 263$~K, providing an exceptional platform to investigate correlated topological CDW states. Here, we uncover an additional hidden-order phase transition at $T^* \\sim 100$ K, well below the CDW onset, using low-frequency resistance noise spectroscopy, electrical transport, and thermoelectric measurements. This transition is characterized by a sharp enhancement in the noise exponent ($\u03b1$) and variance of resistance fluctuations. Analysis of higher-order statistics of resistance fluctuations reveals the correlated dynamics underlying the transition. A pronounced anomaly in the Seebeck coefficient near $T^*$ further suggests a Fermi surface reconstruction. First-principles calculations reveal a structural distortion from the high-symmetry $I422$ phase to a low-symmetry $C2$ phase, via an intermediate $I4$ symmetry. This leads to renormalization of the electronic structure near the Fermi level and opening of a bandgap in the hidden-order phase. These findings demonstrate a previously unidentified correlated phase transition in the topological CDW-Weyl semimetal (TaSe$_4$)$_2$I, enriching the phase diagram of this material and establishing it as an ideal platform for studying intertwined electronic and structural orders.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17433v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.09352v2",
      "title": "Causal symmetrization as an empirical signature of operational autonomy in complex systems",
      "authors": [
        "Anthony Gosme"
      ],
      "abstract": "Theoretical biology has long proposed that autonomous systems sustain their identity through reciprocal constraints between structure and activity, a dynamical regime underlying concepts such as closure to efficient causation and autopoiesis. Despite their influence, these principles have resisted direct empirical assessment outside biological systems.   Here, we empirically assess this framework in artificial sociotechnical systems by identifying a statistical signature consistent with operational autonomy. Analyzing 50 large-scale collaborative software ecosystems spanning 11,042 system-months, we develop an order parameter ($\u0393$) quantifying structural persistence under component turnover and use Granger causality to characterize directional coupling between organizational architecture and collective activity. $\u0393$ exhibits a bimodal distribution (Hartigan's dip test $p = 0.0126$; $\u0394$BIC = 2000), revealing a sharp phase transition between an exploratory regime of high variance and a mature regime characterized by a 1.77-fold variance collapse. At maturity, causal symmetrization emerges, with the structure--activity coupling ratio shifting from 0.71 (activity-driven) to 0.94 (bidirectional).   A composite viability index combining activity and structural persistence outperforms activity-based prediction alone (AUC = 0.88 vs. 0.81), identifying ``structural zombie'' systems in which sustained activity masks architectural decay.   Together, these results show that causal symmetrization functions as a necessary statistical signature consistent with theoretical notions of operational closure, without implying biological life or mechanistic closure. They demonstrate that core principles of autonomy can be empirically probed in artificial collaborative systems, supporting substrate-independent dynamical signatures of self-organizing autonomy across complex adaptive systems.",
      "published": "2025-12-09",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.09352v2",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2510.00092v1",
      "title": "A Scalable Framework for Safety Assurance of Self-Driving Vehicles based on Assurance 2.0",
      "authors": [
        "Shufeng Chen",
        "Mariat James Elizebeth",
        "Robab Aghazadeh Chakherlou",
        "Xingyu Zhao",
        "Eric Barbier",
        "Siddartha Khastgir",
        "Paul Jennings"
      ],
      "abstract": "Assurance 2.0 is a modern framework developed to address the assurance challenges of increasingly complex, adaptive, and autonomous systems. Building on the traditional Claims-Argument-Evidence (CAE) model, it introduces reusable assurance theories and explicit counterarguments (defeaters) to enhance rigor, transparency, and adaptability. It supports continuous, incremental assurance, enabling innovation without compromising safety. However, limitations persist in confidence measurement, residual doubt management, automation support, and the practical handling of defeaters and confirmation bias. This paper presents \\textcolor{black}{a set of decomposition frameworks to identify a complete set of safety arguments and measure their corresponding evidence.} Grounded in the Assurance 2.0 paradigm, the framework is instantiated through a structured template and employs a three-tiered decomposition strategy. \\textcolor{black}{A case study regarding the application of the decomposition framework in the end-to-end (E2E) AI-based Self-Driving Vehicle (SDV) development is also presented in this paper.} At the top level, the SDV development is divided into three critical phases: Requirements Engineering (RE), Verification and Validation (VnV), and Post-Deployment (PD). Each phase is further decomposed according to its Product Development Lifecycle (PDLC). To ensure comprehensive coverage, each PDLC is analyzed using an adapted 5M1E model (Man, Machine, Method, Material, Measurement, and Environment). Originally developed for manufacturing quality control, the 5M1E model is reinterpreted and contextually mapped to the assurance domain. This enables a multi-dimensional decomposition that supports fine-grained traceability of safety claims, evidence, and potential defeaters.",
      "published": "2025-09-30",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.00092v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2509.25194v1",
      "title": "Automated Code Development for PDE Solvers Using Large Language Models",
      "authors": [
        "Haoyang Wu",
        "Xinxin Zhang",
        "Lailai Zhu"
      ],
      "abstract": "Foundation models -- large language models (LLMs) in particular -- have become ubiquitous, shaping daily life and driving breakthroughs across science, engineering, and technology. Harnessing their broad cross-domain knowledge, text-processing, and reasoning abilities for software development, e.g., numerical libraries for solving partial differential equations (PDEs), is therefore attracting growing interest. Yet existing studies mainly automate case setup and execution for end users. We introduce LLM-PDEveloper, a zero-shot, multi-agent LLM framework that automates code development for PDE libraries, specifically targeting secondary developers. By translating mathematical and algorithmic descriptions directly into source code, LLM-PDEveloper generates new solvers/modules and adapts existing ones. This end-to-end math-to-code approach enables a self-augmenting pipeline that continuously expands the codebase of a library, extends its capacities, and broadens its scope. We demonstrate LLM-PDEveloper on three tasks: 1) build a solver for a new PDE, 2) implement new BCs for a given PDE, and 3) modify an existing solver to incorporate additional terms, achieving moderate success rates. Failures due to syntactic errors made by LLMs are analyzed and we propose effective fixes. We also identify the mechanisms underlying certain semantic errors, guiding future research.",
      "published": "2025-08-08",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.25194v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2505.18646v1",
      "title": "SEW: Self-Evolving Agentic Workflows for Automated Code Generation",
      "authors": [
        "Siwei Liu",
        "Jinyuan Fang",
        "Han Zhou",
        "Yingxu Wang",
        "Zaiqiao Meng"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated effectiveness in code generation tasks. To enable LLMs to address more complex coding challenges, existing research has focused on crafting multi-agent systems with agentic workflows, where complex coding tasks are decomposed into sub-tasks, assigned to specialized agents. Despite their effectiveness, current approaches heavily rely on hand-crafted agentic workflows, with both agent topologies and prompts manually designed, which limits their ability to automatically adapt to different types of coding problems. To address these limitations and enable automated workflow design, we propose \\textbf{S}elf-\\textbf{E}volving \\textbf{W}orkflow (\\textbf{SEW}), a novel self-evolving framework that automatically generates and optimises multi-agent workflows. Extensive experiments on three coding benchmark datasets, including the challenging LiveCodeBench, demonstrate that our SEW can automatically design agentic workflows and optimise them through self-evolution, bringing up to 33\\% improvement on LiveCodeBench compared to using the backbone LLM only. Furthermore, by investigating different representation schemes of workflow, we provide insights into the optimal way to encode workflow information with text.",
      "published": "2025-05-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.18646v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2505.17798v1",
      "title": "Defining Self-adaptive Systems: A Systematic Literature Review",
      "authors": [
        "Ana Petrovska",
        "Guan Erjiage",
        "Stefan Kugele"
      ],
      "abstract": "In the last two decades, the popularity of self-adaptive systems in the field of software and systems engineering has drastically increased. However, despite the extensive work on self-adaptive systems, the literature still lacks a common agreement on the definition of these systems. To this day, the notion of self-adaptive systems is mainly used intuitively without a precise understanding of the terminology. Using terminology only by intuition does not suffice, especially in engineering and science, where a more rigorous definition is necessary. In this paper, we investigate the existing formal definitions of self-adaptive systems and how these systems are characterised across the literature. Additionally, we analyse and summarise the limitations of the existing formal definitions in order to understand why none of the existing formal definitions is used more broadly by the community. To achieve this, we have conducted a systematic literature review in which we have analysed over 1400 papers related to self-adaptive systems. Concretely, from an initial pool of 1493 papers, we have selected 314 relevant papers, which resulted in nine primary studies whose primary objective was to define self-adaptive systems formally. Our systematic review reveals that although there has been an increasing interest in self-adaptive systems over the years, there is a scarcity of efforts to define these systems formally. Finally, as part of this paper, based on the analysed primary studies, we also elicit requirements and set a foundation for a potential (formal) definition in the future that is accepted by the community on a broader range.",
      "published": "2025-05-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.17798v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2504.20684v2",
      "title": "Identifying Uncertainty in Self-Adaptive Robotics with Large Language Models",
      "authors": [
        "Hassan Sartaj",
        "Jalil Boudjadar",
        "Mirgita Frasheri",
        "Shaukat Ali",
        "Peter Gorm Larsen"
      ],
      "abstract": "Future self-adaptive robots are expected to operate in highly dynamic environments while effectively managing uncertainties. However, identifying the sources and impacts of uncertainties in such robotic systems and defining appropriate mitigation strategies is challenging due to the inherent complexity of self-adaptive robots and the lack of comprehensive knowledge about the various factors influencing uncertainty. Hence, practitioners often rely on intuition and past experiences from similar systems to address uncertainties. In this article, we evaluate the potential of large language models (LLMs) in enabling a systematic and automated approach to identify uncertainties in self-adaptive robotics throughout the software engineering lifecycle. For this evaluation, we analyzed 10 advanced LLMs with varying capabilities across four industrial-sized robotics case studies, gathering the practitioners' perspectives on the LLM-generated responses related to uncertainties. Results showed that practitioners agreed with 63-88% of the LLM responses and expressed strong interest in the practicality of LLMs for this purpose.",
      "published": "2025-04-29",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.20684v2",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2504.16821v2",
      "title": "From Diverse Origins to a DEI Crisis: The Pushback Against Equity, Diversity, and Inclusion in Software Engineering",
      "authors": [
        "Ronnie de Souza Santos",
        "Ann Barcomb",
        "Mairieli Wessel",
        "Cleyton Magalhaes"
      ],
      "abstract": "Background: Diversity, equity, and inclusion are rooted in the very origins of software engineering, shaped by the contributions from many individuals from underrepresented groups to the field. Yet today, DEI efforts in the industry face growing resistance. As companies retreat from visible commitments, and pushback initiatives started only a few years ago. Aims: This study explores how the DEI backlash is unfolding in the software industry by investigating institutional changes, lived experiences, and the strategies used to sustain DEI practices. Method: We conducted an exploratory case study using 59 publicly available Reddit posts authored by self-identified software professionals. Data were analyzed using reflexive thematic analysis. Results: Our findings show that software companies are responding to the DEI backlash in varied ways, including re-structuring programs, scaling back investments, or quietly continuing efforts under new labels. Professionals reported a wide range of emotional responses, from anxiety and frustration to relief and happiness, shaped by identity, role, and organizational culture. Yet, despite the backlash, multiple forms of resistance and adaptation have emerged to protect inclusive practices in software engineering. Conclusions: The DEI backlash is reshaping DEI in software engineering. While public messaging may soften or disappear, core DEI values persist in adapted forms. This study offers a new perspective into how inclusion is evolving under pressure and highlights the resilience of DEI in software environments.",
      "published": "2025-04-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.16821v2",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.16553v1",
      "title": "Needle in the Web: A Benchmark for Retrieving Targeted Web Pages in the Wild",
      "authors": [
        "Yumeng Wang",
        "Tianyu Fan",
        "Lingrui Xu",
        "Chao Huang"
      ],
      "abstract": "Large Language Models (LLMs) have evolved from simple chatbots into sophisticated agents capable of automating complex real-world tasks, where browsing and reasoning over live web content is key to assessing retrieval and cognitive skills. Existing benchmarks like BrowseComp and xBench-DeepSearch emphasize complex reasoning searches requiring multi-hop synthesis but neglect Fuzzy Exploratory Search, namely queries that are vague and multifaceted, where users seek the most relevant webpage rather than a single factual answer. To address this gap, we introduce Needle in the Web, a novel benchmark specifically designed to evaluate modern search agents and LLM-based systems on their ability to retrieve and reason over real-world web content in response to ambiguous, exploratory queries under varying levels of difficulty. Needle in the Web comprises 663 questions spanning seven distinct domains. To ensure high query quality and answer uniqueness, we employ a flexible methodology that reliably generates queries of controllable difficulty based on factual claims of web contents. We benchmark three leading LLMs and three agent-based search systems on Needle in the Web, finding that most models struggle: many achieve below 35% accuracy, and none consistently excel across domains or difficulty levels. These findings reveal that Needle in the Web presents a significant challenge for current search systems and highlights the open problem of effective fuzzy retrieval under semantic ambiguity.",
      "published": "2025-12-18",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.16553v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.11350v1",
      "title": "Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture",
      "authors": [
        "Tanu Singh",
        "Pranamesh Chakraborty",
        "Long T. Truong"
      ],
      "abstract": "Road traffic accidents represent a leading cause of mortality globally, with incidence rates rising due to increasing population, urbanization, and motorization. Rising accident rates raise concerns about traffic surveillance effectiveness. Traditional computer vision methods for accident detection struggle with limited spatiotemporal understanding and poor cross-domain generalization. Recent advances in transformer architectures excel at modeling global spatial-temporal dependencies and parallel computation. However, applying these models to automated traffic accident detection is limited by small, non-diverse datasets, hindering the development of robust, generalizable systems. To address this gap, we curated a comprehensive and balanced dataset that captures a wide spectrum of traffic environments, accident types, and contextual variations. Utilizing the curated dataset, we propose an accident detection model based on a transformer architecture using pre-extracted spatial video features. The architecture employs convolutional layers to extract local correlations across diverse patterns within a frame, while leveraging transformers to capture sequential-temporal dependencies among the retrieved features. Moreover, most existing studies neglect the integration of motion cues, which are essential for understanding dynamic scenes, especially during accidents. These approaches typically rely on static features or coarse temporal information. In this study, multiple methods for incorporating motion cues were evaluated to identify the most effective strategy. Among the tested input approaches, concatenating RGB features with optical flow achieved the highest accuracy at 88.3%. The results were further compared with vision language models (VLM) such as GPT, Gemini, and LLaVA-NeXT-Video to assess the effectiveness of the proposed method.",
      "published": "2025-12-12",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.11350v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.10313v2",
      "title": "EpiPlanAgent: Agentic Automated Epidemic Response Planning",
      "authors": [
        "Kangkun Mao",
        "Fang Xu",
        "Jinru Ding",
        "Yidong Jiang",
        "Yujun Yao",
        "Yirong Chen",
        "Junming Liu",
        "Xiaoqin Wu",
        "Qian Wu",
        "Xiaoyan Huang",
        "Jie Xu"
      ],
      "abstract": "Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.",
      "published": "2025-12-11",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.10313v2",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.10148v1",
      "title": "PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset",
      "authors": [
        "Moonsoo Park",
        "Jeongseok Yun",
        "Bohyung Kim"
      ],
      "abstract": "Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.",
      "published": "2025-12-10",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.10148v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.09939v1",
      "title": "Norm-Governed Multi-Agent Decision-Making in Simulator-Coupled Environments:The Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP)",
      "authors": [
        "Stella C. Dong"
      ],
      "abstract": "Reinsurance decision-making exhibits the core structural properties that motivate multi-agent models: distributed and asymmetric information, partial observability, heterogeneous epistemic responsibilities, simulator-driven environment dynamics, and binding prudential and regulatory constraints. Deterministic workflow automation cannot meet these requirements, as it lacks the epistemic flexibility, cooperative coordination mechanisms, and norm-sensitive behaviour required for institutional risk-transfer.   We propose the Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP), a formal model that extends stochastic games and Dec-POMDPs by adding three missing elements: (i) simulator-coupled transition dynamics grounded in catastrophe, capital, and portfolio engines; (ii) role-specialized agents with structured observability, belief updates, and typed communication; and (iii) a normative feasibility layer encoding solvency, regulatory, and organizational rules as admissibility constraints on joint actions.   Using LLM-based agents with tool access and typed message protocols, we show in a domain-calibrated synthetic environment that governed multi-agent coordination yields more stable, coherent, and norm-adherent behaviour than deterministic automation or monolithic LLM baselines--reducing pricing variance, improving capital efficiency, and increasing clause-interpretation accuracy. Embedding prudential norms as admissibility constraints and structuring communication into typed acts measurably enhances equilibrium stability.   Overall, the results suggest that regulated, simulator-driven decision environments are most naturally modelled as norm-governed, simulator-coupled multi-agent systems.",
      "published": "2025-12-04",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.09939v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.13700v1",
      "title": "Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records",
      "authors": [
        "Mitchell A. Klusty",
        "Elizabeth C. Solie",
        "Caroline N. Leach",
        "W. Vaiden Logan",
        "Lynnet E. Richey",
        "John C. Gensel",
        "David P. Szczykutowicz",
        "Bryan C. McLellan",
        "Emily B. Collier",
        "Samuel E. Armstrong",
        "V. K. Cody Bumgardner"
      ],
      "abstract": "Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, modular framework for automated structured feature extraction from clinical notes leveraging locally deployed large language models (LLMs) on institutionally approved, Health Insurance Portability and Accountability Act (HIPPA)-compliant compute infrastructure. This system integrates retrieval augmented generation (RAG) and structured response methods of LLMs into a widely deployable and scalable container to provide feature extraction for diverse clinical domains. In evaluation, the framework achieved high accuracy across multiple medical characteristics present in large bodies of patient notes when compared against an expert-annotated dataset and identified several annotation errors missed in manual review. This framework demonstrates the potential of LLM systems to reduce the burden of manual chart review through automated extraction and increase consistency in data capture, accelerating clinical research.",
      "published": "2025-12-03",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.13700v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.00663v1",
      "title": "Graphing the Truth: Structured Visualizations for Automated Hallucination Detection in LLMs",
      "authors": [
        "Tanmay Agrawal"
      ],
      "abstract": "Large Language Models have rapidly advanced in their ability to interpret and generate natural language. In enterprise settings, they are frequently augmented with closed-source domain knowledge to deliver more contextually informed responses. However, operational constraints such as limited context windows and inconsistencies between pre-training data and supplied knowledge often lead to hallucinations, some of which appear highly credible and escape routine human review. Current mitigation strategies either depend on costly, large-scale gold-standard Q\\&A curation or rely on secondary model verification, neither of which offers deterministic assurance. This paper introduces a framework that organizes proprietary knowledge and model-generated content into interactive visual knowledge graphs. The objective is to provide end users with a clear, intuitive view of potential hallucination zones by linking model assertions to underlying sources of truth and indicating confidence levels. Through this visual interface, users can diagnose inconsistencies, identify weak reasoning chains, and supply corrective feedback. The resulting human-in-the-loop workflow creates a structured feedback loop that can enhance model reliability and continuously improve response quality.",
      "published": "2025-11-29",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.00663v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2511.23397v1",
      "title": "MegaChat: A Synthetic Persian Q&A Dataset for High-Quality Sales Chatbot Evaluation",
      "authors": [
        "Mahdi Rahmani",
        "AmirHossein Saffari",
        "Reyhane Rahmani"
      ],
      "abstract": "Small and medium-sized enterprises (SMEs) in Iran increasingly leverage Telegram for sales, where real-time engagement is essential for conversion. However, developing AI-driven chatbots for this purpose requires large, high-quality question-and-answer (Q&A) datasets, which are typically expensive and resource-intensive to produce, especially for low-resource languages like Persian. In this paper, we introduce MegaChat, the first fully synthetic Persian Q&A dataset designed to evaluate intelligent sales chatbots in Telegram-based e-commerce. We propose a novel, automated multi-agent architecture that generates persona-aware Q&A pairs by collecting data from active Telegram shopping channels. The system employs specialized agents for question generation, validation, and refinement, ensuring the production of realistic and diverse conversational data. To evaluate answer generation, we compare three classic retrieval-augmented generation (RAG) models with our advanced agentic system, which features multi-query retrieval, reranking, and persona-aligned response synthesis. Using GPT-5.1 for evaluation across six quality dimensions, our results show that the agentic architecture outperformed traditional RAG models in 4 out of 5 diverse channels, demonstrating its ability to generate scalable, high-quality datasets without relying on expensive human annotation or complex fine-tuning. MegaChat provides SMEs with an efficient, cost-effective solution for building intelligent customer engagement systems in specialized commercial domains, enabling advancements in multilingual conversational AI for low-resource languages. Download: https://github.com/MegaChat-Tech/MegaChat-DataSet",
      "published": "2025-11-28",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.23397v1",
      "relevance_score": 15
    },
    {
      "arxiv_id": "2512.09485v1",
      "title": "Advancing LLM-Based Security Automation with Customized Group Relative Policy Optimization for Zero-Touch Networks",
      "authors": [
        "Xinye Cao",
        "Yihan Lin",
        "Guoshun Nan",
        "Qinchuan Zhou",
        "Yuhang Luo",
        "Yurui Gao",
        "Zeliang Zhang",
        "Haolang Lu",
        "Qimei Cui",
        "Yanzhao Hou",
        "Xiaofeng Tao",
        "Tony Q. S. Quek"
      ],
      "abstract": "Zero-Touch Networks (ZTNs) represent a transformative paradigm toward fully automated and intelligent network management, providing the scalability and adaptability required for the complexity of sixth-generation (6G) networks. However, the distributed architecture, high openness, and deep heterogeneity of 6G networks expand the attack surface and pose unprecedented security challenges. To address this, security automation aims to enable intelligent security management across dynamic and complex environments, serving as a key capability for securing 6G ZTNs. Despite its promise, implementing security automation in 6G ZTNs presents two primary challenges: 1) automating the lifecycle from security strategy generation to validation and update under real-world, parallel, and adversarial conditions, and 2) adapting security strategies to evolving threats and dynamic environments. This motivates us to propose SecLoop and SA-GRPO. SecLoop constitutes the first fully automated framework that integrates large language models (LLMs) across the entire lifecycle of security strategy generation, orchestration, response, and feedback, enabling intelligent and adaptive defenses in dynamic network environments, thus tackling the first challenge. Furthermore, we propose SA-GRPO, a novel security-aware group relative policy optimization algorithm that iteratively refines security strategies by contrasting group feedback collected from parallel SecLoop executions, thereby addressing the second challenge. Extensive real-world experiments on five benchmarks, including 11 MITRE ATT&CK processes and over 20 types of attacks, demonstrate the superiority of the proposed SecLoop and SA-GRPO. We will release our platform to the community, facilitating the advancement of security automation towards next generation communications.",
      "published": "2025-12-10",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.09485v1",
      "relevance_score": 14
    },
    {
      "arxiv_id": "2512.13702v1",
      "title": "Enhancing Transparency and Traceability in Healthcare AI: The AI Product Passport",
      "authors": [
        "A. Anil Sinaci",
        "Senan Postaci",
        "Dogukan Cavdaroglu",
        "Machteld J. Boonstra",
        "Okan Mercan",
        "Kerem Yilmaz",
        "Gokce B. Laleci Erturkmen",
        "Folkert W. Asselbergs",
        "Karim Lekadir"
      ],
      "abstract": "Objective: To develop the AI Product Passport, a standards-based framework improving transparency, traceability, and compliance in healthcare AI via lifecycle-based documentation. Materials and Methods: The AI Product Passport was developed within the AI4HF project, focusing on heart failure AI tools. We analyzed regulatory frameworks (EU AI Act, FDA guidelines) and existing standards to design a relational data model capturing metadata across AI lifecycle phases: study definition, dataset preparation, model generation/evaluation, deployment/monitoring, and passport generation. MLOps/ModelOps concepts were integrated for operational relevance. Co-creation involved feedback from AI4HF consortium and a Lisbon workshop with 21 diverse stakeholders, evaluated via Mentimeter polls. The open-source platform was implemented with Python libraries for automated provenance tracking. Results: The AI Product Passport was designed based on existing standards and methods with well-defined lifecycle management and role-based access. Its implementation is a web-based platform with a relational data model supporting auditable documentation. It generates machine- and human-readable reports, customizable for stakeholders. It aligns with FUTURE-AI principles (Fairness, Universality, Traceability, Usability, Robustness, Explainability), ensuring fairness, traceability, and usability. Exported passports detail model purpose, data provenance, performance, and deployment context. GitHub-hosted backend/frontend codebases enhance accessibility. Discussion and Conclusion: The AI Product Passport addresses transparency gaps in healthcare AI, meeting regulatory and ethical demands. Its open-source nature and alignment with standards foster trust and adaptability. Future enhancements include FAIR data principles and FHIR integration for improved interoperability, promoting responsible AI deployment.",
      "published": "2025-12-04",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.13702v1",
      "relevance_score": 14
    },
    {
      "arxiv_id": "2412.13667v2",
      "title": "Exploring Multi-Modal Data with Tool-Augmented LLM Agents for Precise Causal Discovery",
      "authors": [
        "ChengAo Shen",
        "Zhengzhang Chen",
        "Dongsheng Luo",
        "Dongkuan Xu",
        "Haifeng Chen",
        "Jingchao Ni"
      ],
      "abstract": "Causal discovery is an imperative foundation for decision-making across domains, such as smart health, AI for drug discovery and AIOps. Traditional statistical causal discovery methods, while well-established, predominantly rely on observational data and often overlook the semantic cues inherent in cause-and-effect relationships. The advent of Large Language Models (LLMs) has ushered in an affordable way of leveraging the semantic cues for knowledge-driven causal discovery, but the development of LLMs for causal discovery lags behind other areas, particularly in the exploration of multi-modal data. To bridge the gap, we introduce MATMCD, a multi-agent system powered by tool-augmented LLMs. MATMCD has two key agents: a Data Augmentation agent that retrieves and processes modality-augmented data, and a Causal Constraint agent that integrates multi-modal data for knowledge-driven reasoning. The proposed design of the inner-workings ensures successful cooperation of the agents. Our empirical study across seven datasets suggests the significant potential of multi-modality enhanced causal discovery.",
      "published": "2024-12-18",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2412.13667v2",
      "relevance_score": 13
    },
    {
      "arxiv_id": "2409.13707v1",
      "title": "Retrieval Augmented Generation-Based Incident Resolution Recommendation System for IT Support",
      "authors": [
        "Paulina Toro Isaza",
        "Michael Nidd",
        "Noah Zheutlin",
        "Jae-wook Ahn",
        "Chidansh Amitkumar Bhatt",
        "Yu Deng",
        "Ruchi Mahindru",
        "Martin Franz",
        "Hans Florian",
        "Salim Roukos"
      ],
      "abstract": "Clients wishing to implement generative AI in the domain of IT Support and AIOps face two critical issues: domain coverage and model size constraints due to model choice limitations. Clients might choose to not use larger proprietary models such as GPT-4 due to cost and privacy concerns and so are limited to smaller models with potentially less domain coverage that do not generalize to the client's domain. Retrieval augmented generation is a common solution that addresses both of these issues: a retrieval system first retrieves the necessary domain knowledge which a smaller generative model leverages as context for generation. We present a system developed for a client in the IT Support domain for support case solution recommendation that combines retrieval augmented generation (RAG) for answer generation with an encoder-only model for classification and a generative large language model for query generation. We cover architecture details, data collection and annotation, development journey and preliminary validations, expected final deployment process and evaluation plans, and finally lessons learned.",
      "published": "2024-09-06",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2409.13707v1",
      "relevance_score": 13
    },
    {
      "arxiv_id": "2512.21118v1",
      "title": "STLDM: Spatio-Temporal Latent Diffusion Model for Precipitation Nowcasting",
      "authors": [
        "Shi Quan Foo",
        "Chi-Ho Wong",
        "Zhihan Gao",
        "Dit-Yan Yeung",
        "Ka-Hing Wong",
        "Wai-Kin Wong"
      ],
      "abstract": "Precipitation nowcasting is a critical spatio-temporal prediction task for society to prevent severe damage owing to extreme weather events. Despite the advances in this field, the complex and stochastic nature of this task still poses challenges to existing approaches. Specifically, deterministic models tend to produce blurry predictions while generative models often struggle with poor accuracy. In this paper, we present a simple yet effective model architecture termed STLDM, a diffusion-based model that learns the latent representation from end to end alongside both the Variational Autoencoder and the conditioning network. STLDM decomposes this task into two stages: a deterministic forecasting stage handled by the conditioning network, and an enhancement stage performed by the latent diffusion model. Experimental results on multiple radar datasets demonstrate that STLDM achieves superior performance compared to the state of the art, while also improving inference efficiency. The code is available in https://github.com/sqfoo/stldm_official.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21118v1",
      "relevance_score": 11
    },
    {
      "arxiv_id": "2512.21099v1",
      "title": "TexAvatars : Hybrid Texel-3D Representations for Stable Rigging of Photorealistic Gaussian Head Avatars",
      "authors": [
        "Jaeseong Lee",
        "Junyeong Ahn",
        "Taewoong Kang",
        "Jaegul Choo"
      ],
      "abstract": "Constructing drivable and photorealistic 3D head avatars has become a central task in AR/XR, enabling immersive and expressive user experiences. With the emergence of high-fidelity and efficient representations such as 3D Gaussians, recent works have pushed toward ultra-detailed head avatars. Existing approaches typically fall into two categories: rule-based analytic rigging or neural network-based deformation fields. While effective in constrained settings, both approaches often fail to generalize to unseen expressions and poses, particularly in extreme reenactment scenarios. Other methods constrain Gaussians to the global texel space of 3DMMs to reduce rendering complexity. However, these texel-based avatars tend to underutilize the underlying mesh structure. They apply minimal analytic deformation and rely heavily on neural regressors and heuristic regularization in UV space, which weakens geometric consistency and limits extrapolation to complex, out-of-distribution deformations. To address these limitations, we introduce TexAvatars, a hybrid avatar representation that combines the explicit geometric grounding of analytic rigging with the spatial continuity of texel space. Our approach predicts local geometric attributes in UV space via CNNs, but drives 3D deformation through mesh-aware Jacobians, enabling smooth and semantically meaningful transitions across triangle boundaries. This hybrid design separates semantic modeling from geometric control, resulting in improved generalization, interpretability, and stability. Furthermore, TexAvatars captures fine-grained expression effects, including muscle-induced wrinkles, glabellar lines, and realistic mouth cavity geometry, with high fidelity. Our method achieves state-of-the-art performance under extreme pose and expression variations, demonstrating strong generalization in challenging head reenactment settings.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21099v1",
      "relevance_score": 11
    },
    {
      "arxiv_id": "2512.21038v1",
      "title": "Next-Scale Prediction: A Self-Supervised Approach for Real-World Image Denoising",
      "authors": [
        "Yiwen Shan",
        "Haiyu Zhao",
        "Peng Hu",
        "Xi Peng",
        "Yuanbiao Gou"
      ],
      "abstract": "Self-supervised real-world image denoising remains a fundamental challenge, arising from the antagonistic trade-off between decorrelating spatially structured noise and preserving high-frequency details. Existing blind-spot network (BSN) methods rely on pixel-shuffle downsampling (PD) to decorrelate noise, but aggressive downsampling fragments fine structures, while milder downsampling fails to remove correlated noise. To address this, we introduce Next-Scale Prediction (NSP), a novel self-supervised paradigm that decouples noise decorrelation from detail preservation. NSP constructs cross-scale training pairs, where BSN takes low-resolution, fully decorrelated sub-images as input to predict high-resolution targets that retain fine details. As a by-product, NSP naturally supports super-resolution of noisy images without retraining or modification. Extensive experiments demonstrate that NSP achieves state-of-the-art self-supervised denoising performance on real-world benchmarks, significantly alleviating the long-standing conflict between noise decorrelation and detail preservation.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21038v1",
      "relevance_score": 11
    },
    {
      "arxiv_id": "2512.21003v1",
      "title": "MVInverse: Feed-forward Multi-view Inverse Rendering in Seconds",
      "authors": [
        "Xiangzuo Wu",
        "Chengwei Ren",
        "Jun Zhou",
        "Xiu Li",
        "Yuan Liu"
      ],
      "abstract": "Multi-view inverse rendering aims to recover geometry, materials, and illumination consistently across multiple viewpoints. When applied to multi-view images, existing single-view approaches often ignore cross-view relationships, leading to inconsistent results. In contrast, multi-view optimization methods rely on slow differentiable rendering and per-scene refinement, making them computationally expensive and hard to scale. To address these limitations, we introduce a feed-forward multi-view inverse rendering framework that directly predicts spatially varying albedo, metallic, roughness, diffuse shading, and surface normals from sequences of RGB images. By alternating attention across views, our model captures both intra-view long-range lighting interactions and inter-view material consistency, enabling coherent scene-level reasoning within a single forward pass. Due to the scarcity of real-world training data, models trained on existing synthetic datasets often struggle to generalize to real-world scenes. To overcome this limitation, we propose a consistency-based finetuning strategy that leverages unlabeled real-world videos to enhance both multi-view coherence and robustness under in-the-wild conditions. Extensive experiments on benchmark datasets demonstrate that our method achieves state-of-the-art performance in terms of multi-view consistency, material and normal estimation quality, and generalization to real-world imagery.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21003v1",
      "relevance_score": 11
    },
    {
      "arxiv_id": "2512.18244v1",
      "title": "Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation",
      "authors": [
        "Zehao Liu",
        "Xi Lin"
      ],
      "abstract": "Large Language Models (LLMs) have gained considerable popularity and protected by increasingly sophisticated safety mechanisms. However, jailbreak attacks continue to pose a critical security threat by inducing models to generate policy-violating behaviors. Current paradigms focus on input-level anomalies, overlooking that the model's internal psychometric state can be systematically manipulated. To address this, we introduce Psychological Jailbreak, a new jailbreak attack paradigm that exposes a stateful psychological attack surface in LLMs, where attackers exploit the manipulation of a model's psychological state across interactions. Building on this insight, we propose Human-like Psychological Manipulation (HPM), a black-box jailbreak method that dynamically profiles a target model's latent psychological vulnerabilities and synthesizes tailored multi-turn attack strategies. By leveraging the model's optimization for anthropomorphic consistency, HPM creates a psychological pressure where social compliance overrides safety constraints. To systematically measure psychological safety, we construct an evaluation framework incorporating psychometric datasets and the Policy Corruption Score (PCS). Benchmarking against various models (e.g., GPT-4o, DeepSeek-V3, Gemini-2-Flash), HPM achieves a mean Attack Success Rate (ASR) of 88.1%, outperforming state-of-the-art attack baselines. Our experiments demonstrate robust penetration against advanced defenses, including adversarial prompt optimization (e.g., RPO) and cognitive interventions (e.g., Self-Reminder). Ultimately, PCS analysis confirms HPM induces safety breakdown to satisfy manipulated contexts. Our work advocates for a fundamental paradigm shift from static content filtering to psychological safety, prioritizing the development of psychological defense mechanisms against deep cognitive manipulation.",
      "published": "2025-12-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18244v1",
      "relevance_score": 11
    },
    {
      "arxiv_id": "2512.19663v1",
      "title": "Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis",
      "authors": [
        "Argha Kamal Samanta",
        "Harshika Goyal",
        "Vasudha Joshi",
        "Tushar Mungle",
        "Pabitra Mitra"
      ],
      "abstract": "Diabetic retinopathy (DR) is a leading cause of preventable blindness worldwide, demanding accurate automated diagnostic systems. While general-domain vision-language models like Contrastive Language-Image Pre-Training (CLIP) perform well on natural image tasks, they struggle in medical domain applications, particularly in cross-modal retrieval for ophthalmological images. We propose a novel knowledge-enhanced joint embedding framework that integrates retinal fundus images, clinical text, and structured patient data through a multimodal transformer architecture to address the critical gap in medical image-text alignment. Our approach employs separate encoders for each modality: a Vision Transformer (ViT-B/16) for retinal images, Bio-ClinicalBERT for clinical narratives, and a multilayer perceptron for structured demographic and clinical features. These modalities are fused through a joint transformer with modality-specific embeddings, trained using multiple objectives including contrastive losses between modality pairs, reconstruction losses for images and text, and classification losses for DR severity grading according to ICDR and SDRG schemes. Experimental results on the Brazilian Multilabel Ophthalmological Dataset (BRSET) demonstrate significant improvements over baseline models. Our framework achieves near-perfect text-to-image retrieval performance with Recall@1 of 99.94% compared to fine-tuned CLIP's 1.29%, while maintaining state-of-the-art classification accuracy of 97.05% for SDRG and 97.97% for ICDR. Furthermore, zero-shot evaluation on the unseen DeepEyeNet dataset validates strong generalizability with 93.95% Recall@1 versus 0.22% for fine-tuned CLIP. These results demonstrate that our multimodal training approach effectively captures cross-modal relationships in the medical domain, establishing both superior retrieval capabilities and robust diagnostic performance.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19663v1",
      "relevance_score": 11
    },
    {
      "arxiv_id": "2512.11893v1",
      "title": "Beyond Automation: Rethinking Work, Creativity, and Governance in the Age of Generative AI",
      "authors": [
        "Haocheng Lin"
      ],
      "abstract": "The accelerating advancement of generative artificial intelligence (AI) systems is reshaping the nature, distribution and meaning of work, creativity, and economic security. This paper investigates four inter-related phenomena in the current AI era: (1) the evolving landscape of employment and the future of work; (2) the diverse patterns of AI adoption across socio-demographic groups, sectors, and geographies; (3) whether universal basic income (UBI) should become a compulsory policy response to the AI revolution; and (4) the implications of AI content policies and model behaviours for human creativity, wellbeing, and everyday decision-making. Furthermore, the paper tests the hypothesis that newer model generations may perform worse than their predecessors, and examines how users' interactions with AI systems may produce echo chambers through sycophantic model alignment. Using a mixed methodology that integrates labour market task-exposure modelling, sectoral diffusion mapping, policy-framework analysis, and qualitative discourse critique, this study develops a comprehensive framework for understanding the societal consequences of AI systems beyond productivity gains. It argues that to foster an inclusive, meaningful, and creative environment, policymakers must treat UBI as one dimension within a broader ecosystem of governance, skills development, creativity preservation, and model design. The paper concludes by outlining future research directions, including systematic evaluation of AI's creative performance across model generations, construction of a taxonomy of AI-usage distribution and equity, and formulation of governance criteria to balance content restrictions with creative freedom.",
      "published": "2025-12-09",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.11893v1",
      "relevance_score": 11
    },
    {
      "arxiv_id": "2512.21323v1",
      "title": "Parallel Token Prediction for Language Models",
      "authors": [
        "Felix Draxler",
        "Justus Will",
        "Farrin Marouf Sofian",
        "Theofanis Karaletsos",
        "Sameer Singh",
        "Stephan Mandt"
      ],
      "abstract": "We propose Parallel Token Prediction (PTP), a universal framework for parallel sequence generation in language models. PTP jointly predicts multiple dependent tokens in a single transformer call by incorporating the sampling procedure into the model. This reduces the latency bottleneck of autoregressive decoding, and avoids the restrictive independence assumptions common in existing multi-token prediction methods. We prove that PTP can represent arbitrary autoregressive sequence distributions. PTP is trained either by distilling an existing model or through inverse autoregressive training without a teacher. Experimentally, we achieve state-of-the-art speculative decoding performance on Vicuna-7B by accepting over four tokens per step on Spec-Bench. The universality of our framework indicates that parallel generation of long sequences is feasible without loss of modeling power.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21323v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2512.21299v1",
      "title": "Integral modelling of weakly evaporating 3D liquid film with variable substrate heating",
      "authors": [
        "Fabio Pino"
      ],
      "abstract": "Analysing the dynamics of phase-changing liquid films is essential for enhancing the performance of thermal management systems. Still, direct simulation of the full governing equations is computationally expensive. To circumvent this limitation, I derived a weighted-integral boundary-layer (WIBL) model under long-wave assumptions, weak evaporation, and strong surface tension, also accounting for variable substrate heating. In the linear regime, the WIBL reproduces growth rates and the cutoff wavenumber of unstable modes with significantly higher accuracy than commonly used Benney-type models for Re<40, as compared to the Orr-Sommerfeld equations. The linear analysis further reveals a threshold separating streamwise- and spanwise-dominated instabilities in hanging films, arising from the competition between Kapitza and Rayleigh-Taylor mechanisms; the WIBL predicts this threshold accurately for small Re and inclination angles. In the nonlinear regime, with substrate heating that varies in both space and time, the WIBL model captures the evolution of free-surface thickness and temperature within approximately 6% of the original Navier-Stokes equations. Three-dimensional simulations show that a condensing film undergoes dry-out due to Kapitza instability, whereas unsteady substrate heating promotes spanwise momentum spreading, modifies wave dynamics, and prevents dry-out. The WIBL model provides a good level of accuracy at a low computational cost, enabling extensive parametric studies, nonlinear stability analyses, and the design of optimal substrate-heating control strategies.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21299v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2512.21286v1",
      "title": "Impurity peaking of SPARC H-modes: a sensitivity study on physics and engineering assumptions",
      "authors": [
        "Marco Muraca",
        "Pablo Rodriguez-Fernandez",
        "Joe Hall",
        "Nathaniel T. Howard",
        "Daniel Fajardo",
        "Giovanni Tardini",
        "Benedikt Zimmermann",
        "Thomas Body"
      ],
      "abstract": "In this paper, an overview of the impurity transport for three H-mode plasmas in the upcoming SPARC tokamak has been provided. The simulations have been performed within the ASTRA+STRAHL framework, using FACIT and TGLF-SAT2 to predict, respectively, neoclassical and turbulent core transport, while a neural network trained on EPED simulations has been employed to calculate the pedestal height and width self-consistently. A benchmark with previous simulations at constant impurity fraction has been provided for three H-modes, spanning different plasma current and magnetic field values. For a scenario, additional simulations have been performed to account for uncertainties in the modeling assumptions. The predictions are nearly insensitive to changes in the top of pedestal W concentrations. Varying the Ar pedestal concentration has shown a small effect on the impurity peaking and nearly constant fusion gain values, due to multiple effects on pedestal pressure, main ion dilution and density peaking. The inclusion of rotation in ASTRA simulations has shown minimal impact on confinement and impurity transport predictions. An exploratory study has been provided with a first set of simulations treating D and T separately, experiencing a maximum fusion power at 55-45% DT fuel composition, and an asymmetric distribution with respect to the D concentration. All the results, including sensitivity scans of toroidal velocity and ion temperature and density gradients, highlighted that turbulent impurity transport prevails on the neoclassical component, aligning with previous ITER predictions, and suggesting that next generation devices like SPARC, operating at low collisionality, will experience low W accumulation.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21286v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2509.20415v2",
      "title": "Online-Optimized RAG for Tool Use and Function Calling",
      "authors": [
        "Yu Pan",
        "Xiaocheng Li",
        "Hanzhao Wang"
      ],
      "abstract": "In many applications, retrieval-augmented generation (RAG) drives tool use and function calling by embedding the (user) queries and matching them to pre-specified tool/function descriptions. In this paper, we address an embedding misalignment issue that often arises in practical applications due to imperfect embedding models or noisy descriptions; such misalignment may lead to incorrect retrieval and task failure. We introduce Online-Optimized RAG, a deployment-time framework that continually adapts retrieval embeddings from live interactions using minimal feedback (e.g., task success). Online-Optimized RAG applies lightweight online gradient updates with negligible per-query latency and requires no changes to the underlying LLM. The method is plug-and-play: it supports both single- and multi-hop tool use, dynamic tool inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent theoretical analysis that quantifies how the method's performance depends on the initialization quality of the embeddings and other related quantities. Across diverse tool-use and document-retrieval scenarios, our Online-Optimized RAG consistently improves tool selection accuracy and end-task success, thus providing a simple, practical path to robust, self-improving RAG systems.",
      "published": "2025-09-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.20415v2",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2509.01946v1",
      "title": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
      "authors": [
        "Aarsh Shah",
        "Cleyton Magalhaes",
        "Kiev Gama",
        "Ronnie de Souza Santos"
      ],
      "abstract": "Equity, diversity, and inclusion in software engineering often overlook neurodiversity, particularly the experiences of developers with Attention Deficit Hyperactivity Disorder (ADHD). Despite the growing awareness about that population in SE, few tools are designed to support their cognitive challenges (e.g., sustained attention, task initiation, self-regulation) within development workflows. We present Tether, an LLM-powered desktop application designed to support software engineers with ADHD by delivering adaptive, context-aware assistance. Drawing from engineering research methodology, Tether combines local activity monitoring, retrieval-augmented generation (RAG), and gamification to offer real-time focus support and personalized dialogue. The system integrates operating system level system tracking to prompt engagement and its chatbot leverages ADHD-specific resources to offer relevant responses. Preliminary validation through self-use revealed improved contextual accuracy following iterative prompt refinements and RAG enhancements. Tether differentiates itself from generic tools by being adaptable and aligned with software-specific workflows and ADHD-related challenges. While not yet evaluated by target users, this work lays the foundation for future neurodiversity-aware tools in SE and highlights the potential of LLMs as personalized support systems for underrepresented cognitive needs.",
      "published": "2025-09-02",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.01946v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2505.17979v1",
      "title": "Re-evaluation of Logical Specification in Behavioural Verification",
      "authors": [
        "Radoslaw Klimek",
        "Jakub Semczyszyn"
      ],
      "abstract": "This study empirically validates automated logical specification methods for behavioural models, focusing on their robustness, scalability, and reproducibility. By the systematic reproduction and extension of prior results, we confirm key trends, while identifying performance irregularities that suggest the need for adaptive heuristics in automated reasoning. Our findings highlight that theorem provers exhibit varying efficiency across problem structures, with implications for real-time verification in CI/CD pipelines and AI-driven IDEs supporting on-the-fly validation. Addressing these inefficiencies through self-optimising solvers could enhance the stability of automated reasoning, particularly in safety-critical software verification.",
      "published": "2025-05-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2505.17979v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2512.10791v1",
      "title": "The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality",
      "authors": [
        "Aileen Cheng",
        "Alon Jacovi",
        "Amir Globerson",
        "Ben Golan",
        "Charles Kwong",
        "Chris Alberti",
        "Connie Tao",
        "Eyal Ben-David",
        "Gaurav Singh Tomar",
        "Lukas Haas",
        "Yonatan Bitton",
        "Adam Bloniarz",
        "Aijun Bai",
        "Andrew Wang",
        "Anfal Siddiqui",
        "Arturo Bajuelos Castillo",
        "Aviel Atias",
        "Chang Liu",
        "Corey Fry",
        "Daniel Balle",
        "Deepanway Ghosal",
        "Doron Kukliansky",
        "Dror Marcus",
        "Elena Gribovskaya",
        "Eran Ofek",
        "Honglei Zhuang",
        "Itay Laish",
        "Jan Ackermann",
        "Lily Wang",
        "Meg Risdal",
        "Megan Barnes",
        "Michael Fink",
        "Mohamed Amin",
        "Moran Ambar",
        "Natan Potikha",
        "Nikita Gupta",
        "Nitzan Katz",
        "Noam Velan",
        "Ofir Roval",
        "Ori Ram",
        "Polina Zablotskaia",
        "Prathamesh Bang",
        "Priyanka Agrawal",
        "Rakesh Ghiya",
        "Sanjay Ganapathy",
        "Simon Baumgartner",
        "Sofia Erell",
        "Sushant Prakash",
        "Thibault Sellam",
        "Vikram Rao",
        "Xuanhui Wang",
        "Yaroslav Akulov",
        "Yulong Yang",
        "Zhen Yang",
        "Zhixin Lai",
        "Zhongru Wu",
        "Anca Dragan",
        "Avinatan Hassidim",
        "Fernando Pereira",
        "Slav Petrov",
        "Srinivasan Venkatachary",
        "Tulsee Doshi",
        "Yossi Matias",
        "Sasha Goldshtein",
        "Dipanjan Das"
      ],
      "abstract": "We introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a holistic measure of factuality by aggregating the performance of models on four distinct sub-leaderboards: (1) FACTS Multimodal, which measures the factuality of responses to image-based questions; (2) FACTS Parametric, which assesses models' world knowledge by answering closed-book factoid questions from internal parameters; (3) FACTS Search, which evaluates factuality in information-seeking scenarios, where the model must use a search API; and (4) FACTS Grounding (v2), which evaluates whether long-form responses are grounded in provided documents, featuring significantly improved judge models. Each sub-leaderboard employs automated judge models to score model responses, and the final suite score is an average of the four components, designed to provide a robust and balanced assessment of a model's overall factuality. The FACTS Leaderboard Suite will be actively maintained, containing both public and private splits to allow for external participation while guarding its integrity. It can be found at https://www.kaggle.com/benchmarks/google/facts .",
      "published": "2025-12-11",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.10791v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2512.04808v1",
      "title": "Setting up for failure: automatic discovery of the neural mechanisms of cognitive errors",
      "authors": [
        "Puria Radmard",
        "Paul M. Bays",
        "M\u00e1t\u00e9 Lengyel"
      ],
      "abstract": "Discovering the neural mechanisms underpinning cognition is one of the grand challenges of neuroscience. However, previous approaches for building models of RNN dynamics that explain behaviour required iterative refinement of architectures and/or optimisation objectives, resulting in a piecemeal, and mostly heuristic, human-in-the-loop process. Here, we offer an alternative approach that automates the discovery of viable RNN mechanisms by explicitly training RNNs to reproduce behaviour, including the same characteristic errors and suboptimalities, that humans and animals produce in a cognitive task. Achieving this required two main innovations. First, as the amount of behavioural data that can be collected in experiments is often too limited to train RNNs, we use a non-parametric generative model of behavioural responses to produce surrogate data for training RNNs. Second, to capture all relevant statistical aspects of the data, we developed a novel diffusion model-based approach for training RNNs. To showcase the potential of our approach, we chose a visual working memory task as our test-bed, as behaviour in this task is well known to produce response distributions that are patently multimodal (due to swap errors). The resulting network dynamics correctly qualitative features of macaque neural data. Importantly, these results were not possible to obtain with more traditional approaches, i.e., when only a limited set of behavioural signatures (rather than the full richness of behavioural response distributions) were fitted, or when RNNs were trained for task optimality (instead of reproducing behaviour). Our approach also yields novel predictions about the mechanism of swap errors, which can be readily tested in experiments. These results suggest that fitting RNNs to rich patterns of behaviour provides a powerful way to automatically discover mechanisms of important cognitive functions.",
      "published": "2025-12-04",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.04808v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2512.04108v1",
      "title": "Responsible LLM Deployment for High-Stake Decisions by Decentralized Technologies and Human-AI Interactions",
      "authors": [
        "Swati Sachan",
        "Theo Miller",
        "Mai Phuong Nguyen"
      ],
      "abstract": "High-stakes decision domains are increasingly exploring the potential of Large Language Models (LLMs) for complex decision-making tasks. However, LLM deployment in real-world settings presents challenges in data security, evaluation of its capabilities outside controlled environments, and accountability attribution in the event of adversarial decisions. This paper proposes a framework for responsible deployment of LLM-based decision-support systems through active human involvement. It integrates interactive collaboration between human experts and developers through multiple iterations at the pre-deployment stage to assess the uncertain samples and judge the stability of the explanation provided by post-hoc XAI techniques. Local LLM deployment within organizations and decentralized technologies, such as Blockchain and IPFS, are proposed to create immutable records of LLM activities for automated auditing to enhance security and trace back accountability. It was tested on Bert-large-uncased, Mistral, and LLaMA 2 and 3 models to assess the capability to support responsible financial decisions on business lending.",
      "published": "2025-11-28",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.04108v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2511.18491v3",
      "title": "MindEval: Benchmarking Language Models on Multi-turn Mental Health Support",
      "authors": [
        "Jos\u00e9 Pombal",
        "Maya D'Eon",
        "Nuno M. Guerreiro",
        "Pedro Henrique Martins",
        "Ant\u00f3nio Farinhas",
        "Ricardo Rei"
      ],
      "abstract": "Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better systems is the scarcity of benchmarks that capture the complexity of real therapeutic interactions. Most existing benchmarks either only test clinical knowledge through multiple-choice questions or assess single responses in isolation. To bridge this gap, we present MindEval, a framework designed in collaboration with Ph.D-level Licensed Clinical Psychologists for automatically evaluating language models in realistic, multi-turn mental health therapy conversations. Through patient simulation and automatic evaluation with LLMs, our framework balances resistance to gaming with reproducibility via its fully automated, model-agnostic design. We begin by quantitatively validating the realism of our simulated patients against human-generated text and by demonstrating strong correlations between automatic and human expert judgments. Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle, scoring below 4 out of 6, on average, with particular weaknesses in problematic AI-specific patterns of communication. Notably, reasoning capabilities and model scale do not guarantee better performance, and systems deteriorate with longer interactions or when supporting patients with severe symptoms. We release all code, prompts, and human evaluation data.",
      "published": "2025-11-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.18491v3",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2511.18221v1",
      "title": "Enhancing Large Language Models for Automated Homework Assessment in Undergraduate Circuit Analysis",
      "authors": [
        "Liangliang Chen",
        "Huiru Xie",
        "Zhihao Qin",
        "Yiming Guo",
        "Jacqueline Rohde",
        "Ying Zhang"
      ],
      "abstract": "This research full paper presents an enhancement pipeline for large language models (LLMs) in assessing homework for an undergraduate circuit analysis course, aiming to improve LLMs' capacity to provide personalized support to electrical engineering students. Existing evaluations have demonstrated that GPT-4o possesses promising capabilities in assessing student homework in this domain. Building on these findings, we enhance GPT-4o's performance through multi-step prompting, contextual data augmentation, and the incorporation of targeted hints. These strategies effectively address common errors observed in GPT-4o's responses when using simple prompts, leading to a substantial improvement in assessment accuracy. Specifically, the correct response rate for GPT-4o increases from 74.71% to 97.70% after applying the enhanced prompting and augmented data on entry-level circuit analysis topics. This work lays a foundation for the effective integration of LLMs into circuit analysis instruction and, more broadly, into engineering education.",
      "published": "2025-11-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2511.18221v1",
      "relevance_score": 8
    },
    {
      "arxiv_id": "2408.07894v1",
      "title": "System States Forecasting of Microservices with Dynamic Spatio-Temporal Data",
      "authors": [
        "Yifei Xu",
        "Jingguo Ge",
        "Haina Tang",
        "Shuai Ding",
        "Tong Li",
        "Hui Li"
      ],
      "abstract": "In the AIOps (Artificial Intelligence for IT Operations) era, accurately forecasting system states is crucial. In microservices systems, this task encounters the challenge of dynamic and complex spatio-temporal relationships among microservice instances, primarily due to dynamic deployments, diverse call paths, and cascading effects among instances. Current time-series forecasting methods, which focus mainly on intrinsic patterns, are insufficient in environments where spatial relationships are critical. Similarly, spatio-temporal graph approaches often neglect the nature of temporal trend, concentrating mostly on message passing between nodes. Moreover, current research in microservices domain frequently underestimates the importance of network metrics and topological structures in capturing the evolving dynamics of systems. This paper introduces STMformer, a model tailored for forecasting system states in microservices environments, capable of handling multi-node and multivariate time series. Our method leverages dynamic network connection data and topological information to assist in modeling the intricate spatio-temporal relationships within the system. Additionally, we integrate the PatchCrossAttention module to compute the impact of cascading effects globally. We have developed a dataset based on a microservices system and conducted comprehensive experiments with STMformer against leading methods. In both short-term and long-term forecasting tasks, our model consistently achieved a 8.6% reduction in MAE(Mean Absolute Error) and a 2.2% reduction in MSE (Mean Squared Error). The source code is available at https://github.com/xuyifeiiie/STMformer.",
      "published": "2024-08-15",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2408.07894v1",
      "relevance_score": 6
    },
    {
      "arxiv_id": "2407.14532v1",
      "title": "A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management",
      "authors": [
        "Yongqian Sun",
        "Jiaju Wang",
        "Zhengdan Li",
        "Xiaohui Nie",
        "Minghua Ma",
        "Shenglin Zhang",
        "Yuhe Ji",
        "Lu Zhang",
        "Wen Long",
        "Hengmao Chen",
        "Yongnan Luo",
        "Dan Pei"
      ],
      "abstract": "AIOps algorithms play a crucial role in the maintenance of microservice systems. Many previous benchmarks' performance leaderboard provides valuable guidance for selecting appropriate algorithms. However, existing AIOps benchmarks mainly utilize offline datasets to evaluate algorithms. They cannot consistently evaluate the performance of algorithms using real-time datasets, and the operation scenarios for evaluation are static, which is insufficient for effective algorithm selection. To address these issues, we propose an evaluation-consistent and scenario-oriented evaluation framework named MicroServo. The core idea is to build a live microservice benchmark to generate real-time datasets and consistently simulate the specific operation scenarios on it. MicroServo supports different leaderboards by selecting specific algorithms and datasets according to the operation scenarios. It also supports the deployment of various types of algorithms, enabling algorithms hot-plugging. At last, we test MicroServo with three typical microservice operation scenarios to demonstrate its efficiency and usability.",
      "published": "2024-07-09",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2407.14532v1",
      "relevance_score": 6
    },
    {
      "arxiv_id": "2401.14093v1",
      "title": "McUDI: Model-Centric Unsupervised Degradation Indicator for Failure Prediction AIOps Solutions",
      "authors": [
        "Lorena Poenaru-Olaru",
        "Luis Cruz",
        "Jan Rellermeyer",
        "Arie van Deursen"
      ],
      "abstract": "Due to the continuous change in operational data, AIOps solutions suffer from performance degradation over time. Although periodic retraining is the state-of-the-art technique to preserve the failure prediction AIOps models' performance over time, this technique requires a considerable amount of labeled data to retrain. In AIOps obtaining label data is expensive since it requires the availability of domain experts to intensively annotate it. In this paper, we present McUDI, a model-centric unsupervised degradation indicator that is capable of detecting the exact moment the AIOps model requires retraining as a result of changes in data. We further show how employing McUDI in the maintenance pipeline of AIOps solutions can reduce the number of samples that require annotations with 30k for job failure prediction and 260k for disk failure prediction while achieving similar performance with periodic retraining.",
      "published": "2024-01-25",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2401.14093v1",
      "relevance_score": 6
    },
    {
      "arxiv_id": "2512.05709v1",
      "title": "Modeling the effect of MHD activity on runaway electron generation during SPARC disruptions",
      "authors": [
        "R Datta",
        "C Clauser",
        "N Ferraro",
        "R Sweeney",
        "R A Tinguely"
      ],
      "abstract": "Magnetohydrodynamic (MHD) instabilities and runaway electrons (REs) interact in several ways, making it important to self-consistently model these interactions for accurate predictions of RE generation and the design of mitigation strategies, such as massive gas injection (MGI). Using M3D-C1 - an extended MHD code with a RE fluid model - we investigate the effects of 3-D nonlinear MHD activity, material injection, and 2-D axisymmetric vertical displacement events (VDEs) on RE evolution during disruptions on SPARC - a high-field, high-current tokamak designed to achieve a fusion gain Q > 1. Several cases, comprising different combinations of neon (Ne) and deuterium ($\\text{D}_2$) injection, are considered. Our results demonstrate key effects that arise from the self-consistent RE + MHD coupling, such as an initial increase in RE generation due to MHD instability growth, decreased saturation energies of the m/n = 1/1 mode driving sawteeth-like activity, RE losses in stochastic magnetic fields, and subsequent RE confinement and plateau formation due to re-healing of flux surfaces. Large RE plateaus (>5 MA) are obtained with Ne-only injection ($2-5 \\times 10^{21}$ atoms), while combined $\\text{D}_2$ + Ne injection ($2 \\times 10^{21}$ Ne atoms; $1.8 \\times 10^{22} \\, \\text{D}_2$ molecules) produces a lower RE current (<2 MA). With $\\text{D}_2$ + Ne injection, a post thermal quench \"cold\" VDE terminates the RE beam, preventing a steady plateau. These simulations couple REs, 3-D MHD instabilities, MGI, and axisymmetric VDEs for the first time in SPARC disruption simulations and represent a crucial step in understanding RE generation and mitigation in high-current devices like SPARC.",
      "published": "2025-12-05",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.05709v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2510.15771v2",
      "title": "Self-Organization and Cyclic Positioning of Active Condensates",
      "authors": [
        "Hossein Vahid",
        "Jens-Uwe Sommer",
        "Abhinav Sharma"
      ],
      "abstract": "Active transport of biomolecular condensates and cell migration in collectives are fundamental to development, homeostasis, and processes such as cancer progression, wound healing, and infection response. Yet how these assemblies are positioned, regulated, and driven through cycles of dissolution and reassembly is not fully understood. We address this using a model of attractive active Brownian particles (ABPs). Using Brownian dynamics simulations, we show that these particles undergo liquid-gas phase separation, and spatially varying activity fields induce striking emergent dynamics. Droplets migrate up activity gradients, and above a critical activity, they fragment into a gas phase. The gas then migrates down the gradient, and droplets reassemble, yielding robust positioning cycles. This emergent condensate cycle arises without biochemical feedback loops and relies only on the interplay of attractions, motility, and gradients. In binary mixtures of active-passive particles, differential cohesion leads to self-sorting of particles, where strongly-cohesive ABPs compact into dense cores surrounded by peripheries enriched with weakly-cohesive passive particles. The passive particles stabilize the dynamic clusters of ABPs, and they migrate toward high-activity regions. Our findings suggest a generic mechanism for spatial control and turnover of condensates in biology.",
      "published": "2025-10-17",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.15771v2",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2507.20826v1",
      "title": "Defect migration in supercrystalline nanocomposites",
      "authors": [
        "Dmitry Lapkin",
        "Cong Yan",
        "Emre G\u00fcrsoy",
        "Hadas Sternlicht",
        "Alexander Plunkett",
        "B\u00fcsra Bor",
        "Young Yong Kim",
        "Dameli Assalauova",
        "Fabian Westermeier",
        "Michael Sprung",
        "Tobias Krekeler",
        "Surya Snata Rout",
        "Martin Ritter",
        "Satishkumar Kulkarni",
        "Thomas F. Keller",
        "Gerold A. Schneider",
        "Gregor B. Vonbun-Feldbauer",
        "Robert H. Meissner",
        "Andreas Stierle",
        "Ivan A. Vartanyants",
        "Diletta Giuntini"
      ],
      "abstract": "Supercrystalline nanocomposites (SCNCs) are nanostructured hybrid materials with unique emergent functional properties. Given their periodically arranged building blocks, they also offer interesting parallelisms with crystalline materials. They can be processed in multiple forms and at different scales, and crosslinking their organic ligands via heat treatment leads to a remarkable boost of their mechanical properties. This study shows, via X-ray and in-situ scanning transmission (STEM) electron microscopy analyses, how each of these processing steps plays a distinct role in the generation, migration, interaction and healing of supercrystalline defects. Pressing of SCNCs into bulk pellets leads to a distortion of the otherwise fcc superlattice, while emulsion-templated self-assembly yields supraparticles (SPs) with stacking faults and size-dependent symmetries. Interestingly, heat treatment at the same temperatures as those applied for the organic crosslinking has significant effects on planar defects. Stacking faults migrate and get healed, as also confirmed via molecular dynamics simulations, and inter-supercrystalline 'grain' boundaries undergo structural changes. These rearrangements of defects at the supercrystalline scale (tens of nm) in nanocomposites with such remarkable mechanical properties (compressive strength of 100-500 MPa) provide new insights into the formation and evolution of ordered assemblies of functionalized nanoparticles.",
      "published": "2025-07-28",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2507.20826v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2506.09589v1",
      "title": "Scaling the glassy dynamics of active particles: Tunable fragility and reentrance",
      "authors": [
        "Puneet Pareek",
        "Peter Sollich",
        "Saroj Kumar Nandi",
        "Ludovic Berthier"
      ],
      "abstract": "Understanding the influence of activity on dense amorphous assemblies is crucial for biological processes such as wound healing, embryogenesis, or cancer progression. Here, we study the effect of self-propulsion forces of amplitude $f_0$ and persistence time $\u03c4_p$ in dense assemblies of soft repulsive particles, a model system that interpolates between particulate active matter and biological tissues. We identify the fluid and glass phases of the three-dimensional phase diagram obtained by varying $f_0$, $\u03c4_p$, and the packing fraction $\u03c6$. The morphology of the phase diagram directly accounts for a non-monotonic evolution of the relaxation time with $\u03c4_p$, which is a direct consequence of the crossover in the dominant relaxation mechanism, from glassy to jamming. A second major consequence is the evolution of the glassy dynamics from sub-Arrhenius to super-Arrhenius. We show that this tunable glass fragility extends to active systems analogous observations reported for passive particles. This allows us to apply a dynamic scaling analysis proposed for the passive case, in order to account for our results for active systems. Finally, we discuss similarities between our results and recent findings in the context of computational models of biological tissues.",
      "published": "2025-06-11",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2506.09589v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21337v1",
      "title": "Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models",
      "authors": [
        "Li-Zhong Szu-Tu",
        "Ting-Lin Wu",
        "Chia-Jui Chang",
        "He Syu",
        "Yu-Lun Liu"
      ],
      "abstract": "We expose a significant popularity bias in state-of-the-art vision-language models (VLMs), which achieve up to 34% higher accuracy on famous buildings compared to ordinary ones, indicating a reliance on memorization over generalizable understanding. To systematically investigate this, we introduce the largest open benchmark for this task: the YearGuessr dataset, a collection of 55,546 building images with multi-modal attributes from 157 countries, annotated with continuous ordinal labels of their construction year (1001-2024), GPS data, and page-view counts as a proxy for popularity. Using this dataset, we frame the construction year prediction task as ordinal regression and introduce popularity-aware interval accuracy metrics to quantify this bias. Our resulting benchmark of 30+ models, including our YearCLIP model, confirms that VLMs excel on popular, memorized items but struggle significantly with unrecognized subjects, exposing a critical flaw in their reasoning capabilities. Project page: https://sytwu.github.io/BeyondMemo/",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21337v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21326v1",
      "title": "Measuring all the noises of LLM Evals",
      "authors": [
        "Sida Wang"
      ],
      "abstract": "Separating signal from noise is central to experimental science. Applying well-established statistical method effectively to LLM evals requires consideration of their unique noise characteristics. We clearly define and measure three types of noise: prediction noise from generating different answers on a given question, data noise from sampling questions, and their combined total noise following the law of total variance. To emphasize relative comparisons and gain statistical power, we propose the all-pairs paired method, which applies the paired analysis to all pairs of LLMs and measures all the noise components based on millions of question-level predictions across many evals and settings. These measurements revealed clear patterns. First, each eval exhibits a characteristic and highly predictable total noise level across all model pairs. Second, paired prediction noise typically exceeds paired data noise, which means reducing prediction noise by averaging can significantly increase statistical power. These findings enable practitioners to assess significance without custom testing and to detect much smaller effects in controlled experiments.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21326v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21289v1",
      "title": "A Near-Infrared and Optical Study of NGC 5822: An Open Cluster Hosting Barium-stars and Lithium-Enriched Giant Stars",
      "authors": [
        "N. Holanda",
        "V. Loaiza-Tacuri",
        "A. Sonally",
        "S. Bijavara Seshashayana",
        "M. P. Roriz",
        "C. F. Martinez",
        "M. Borges Fernandes",
        "C. B. Pereira",
        "O. J. Katime Santrich",
        "S. Daflon"
      ],
      "abstract": "We present a chemical abundance study of giant stars in the Galactic open cluster NGC 5822, which hosts two barium stars (#002 and #201) and three lithium-enriched giants (#006, #102, and #240). Using high-resolution optical and near-infrared ($H$ and $K$ band) spectra from FEROS and IGRINS, we determine atmospheric parameters and abundances for 23 elements (Li, C, N, O, F, Na, Mg, Al, Si, P, S, K, Ca, Sc, Ti, Cr, Fe, Ni, Y, Ce, Nd, Yb, and Pb). This includes species not yet studied in this cluster, such as F, P, K, Yb, and Pb, as well as oxygen isotopic ratios $^{16}$O/$^{17}$O and $^{16}$O/$^{18}$O. Membership was assessed using astrometry and chemical abundances, providing insight into the evolutionary stages of Li-enriched giants and cluster parameters (age, distance, extinction). However, the identification of Ba-stars remains challenging due to their binary nature and less reliable astrometric solutions. The cluster's abundances are broadly consistent with expectations for the Galactic thin disk. The mean fluorine abundance agrees with chemical evolution models predicting that young clusters (<2 Gyr) exhibit elevated [F/Fe], with production from SN II, SN Ia, AGB, and Wolf-Rayet stars. No distinct chemical or rotational features were found to explain the lithium enrichment, likely occurring either during the red clump phase or near the RGB tip. For the Ba-stars, nucleosynthesis models combined with the cluster's turn-off mass suggest polluting companion masses of 3.00 and 3.75 $M_{\\odot}$ for stars #002 and #201. These results highlight the importance of open clusters as laboratories for chemically peculiar stars.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21289v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21255v1",
      "title": "Deforming and dissecting AdS$_3$ with matter",
      "authors": [
        "Nele Callebaut",
        "Blanca Hergueta",
        "Ruben Monten",
        "Matteo Selle"
      ],
      "abstract": "We study deformations of the model by Henneaux, Mart\u00ednez, Troncoso and Zanelli [arXiv:hep-th/0201170] which features asymptotically AdS$_3$ black hole solutions that incorporate the exact backreaction of a scalar field. The presence of bulk matter causes the $T \\overline T$ deformation of the (putative) dual CFT$_2$ to differ from the deformation defined in the bulk by imposing Dirichlet boundary conditions at finite radius. We work out both of these deformations explicitly and verify that $T \\overline T$-deforming the boundary theory corresponds to imposing mixed boundary conditions on the metric at the conformal boundary, whereas the bulk \"Dirichlet deformation\" gives rise to a field theory deforming operator that includes $T \\overline T$ as well as other irrelevant terms. We check our results by calculating the deformed energy spectrum for either case using both the bulk and boundary prescriptions, finding agreement after taking into account additional terms coming from the flow of the scalar source. We interpret our explicit results and compare them with the predictions of similar proposals in the literature.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21255v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21227v1",
      "title": "PhononBench:A Large-Scale Phonon-Based Benchmark for Dynamical Stability in Crystal Generation",
      "authors": [
        "Xiao-Qi Han",
        "Ze-Feng Gao",
        "Peng-Jie Guo",
        "Zhong-Yi Lu"
      ],
      "abstract": "In this work, we introduce PhononBench, the first large-scale benchmark for dynamical stability in AI-generated crystals. Leveraging the recently developed MatterSim interatomic potential, which achieves DFT-level accuracy in phonon predictions across more than 10,000 materials, PhononBench enables efficient large-scale phonon calculations and dynamical-stability analysis for 108,843 crystal structures generated by six leading crystal generation models. PhononBench reveals a widespread limitation of current generative models in ensuring dynamical stability: the average dynamical-stability rate across all generated structures is only 25.83%, with the top-performing model, MatterGen, reaching just 41.0%. Further case studies show that in property-targeted generation-illustrated here by band-gap conditioning with MatterGen--the dynamical-stability rate remains as low as 23.5% even at the optimal band-gap condition of 0.5 eV. In space-group-controlled generation, higher-symmetry crystals exhibit better stability (e.g., cubic systems achieve rates up to 49.2%), yet the average stability across all controlled generations is still only 34.4%. An important additional outcome of this study is the identification of 28,119 crystal structures that are phonon-stable across the entire Brillouin zone, providing a substantial pool of reliable candidates for future materials exploration. By establishing the first large-scale dynamical-stability benchmark, this work systematically highlights the current limitations of crystal generation models and offers essential evaluation criteria and guidance for their future development toward the design and discovery of physically viable materials. All model-generated crystal structures, phonon calculation results, and the high-throughput evaluation workflows developed in PhononBench will be openly released at https://github.com/xqh19970407/PhononBench",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21227v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21224v1",
      "title": "Observation of High-Order Anisotropic Magnetoresistance in a Cubic Ferromagnet",
      "authors": [
        "Haoran Chen",
        "Yue Chen",
        "Yizi Feng",
        "Ruda Guo",
        "Yuanfei Fan",
        "Hongyue Xu",
        "Tong Wu",
        "Zhongxun Guo",
        "Di Yue",
        "Xiaofeng Jin",
        "Yi Liu",
        "Zhe Yuan",
        "Yizheng Wu"
      ],
      "abstract": "High-order anisotropic magnetoresistance (AMR) is observed up to the 18th harmonic in cubic Fe(001) thin films, overturning the long-standing paradigm that only two- and four-fold terms are symmetry-allowed. Using angle-resolved transport and Fourier analysis, we show that six-fold and higher-order terms are intrinsic, tunable by temperature and thickness, and predicted by crystal symmetry. Microscopically, the two-fold sign reversal arises from a crossover between weak and strong scattering regimes, while high-order terms emerge from the interplay of anisotropic Fermi velocity and relaxation time. Our results establish high-order AMR as a symmetry-prescribed property of cubic ferromagnets, providing critical benchmarks for spin-orbit transport theory and enabling new angular-sensitive spintronic functionalities.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21224v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21211v1",
      "title": "Causal-driven attribution (CDA): Estimating channel influence without user-level data",
      "authors": [
        "Georgios Filippou",
        "Boi Mai Quach",
        "Diana Lenghel",
        "Arthur White",
        "Ashish Kumar Jha"
      ],
      "abstract": "Attribution modelling lies at the heart of marketing effectiveness, yet most existing approaches depend on user-level path data, which are increasingly inaccessible due to privacy regulations and platform restrictions. This paper introduces a Causal-Driven Attribution (CDA) framework that infers channel influence using only aggregated impression-level data, avoiding any reliance on user identifiers or click-path tracking. CDA integrates temporal causal discovery (using PCMCI) with causal effect estimation via a Structural Causal Model to recover directional channel relationships and quantify their contributions to conversions. Using large-scale synthetic data designed to replicate real marketing dynamics, we show that CDA achieves an average relative RMSE of 9.50% when given the true causal graph, and 24.23% when using the predicted graph, demonstrating strong accuracy under correct structure and meaningful signal recovery even under structural uncertainty. CDA captures cross-channel interdependencies while providing interpretable, privacy-preserving attribution insights, offering a scalable and future-proof alternative to traditional path-based models.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21211v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21195v1",
      "title": "An O($nlogn$) approximate knapsack algorithm",
      "authors": [
        "Nick Dawes"
      ],
      "abstract": "A modified dynamic programming algorithm rapidly and accurately solves large 0/1 knapsack problems. It has computational O($nlogn$), space O($nlogn$) and predictable maximum error. Experimentally it's accuracy increases faster than linearly with the solution size $k$. Problems with $k=10^3$ are solved with an average maximum fractional error of $10^{-4}$ and problems with $k=10^5$ with an average maximum fractional error of $10^{-7}$. The algorithm runs in constant time for all problems with a given $n$. On a common desktop computer the algorithm processes $n=10^3$ problems in $10^{-3}$ seconds and $n=10^6$ problems in 2 seconds.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21195v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21184v1",
      "title": "Production of charmed particles in proton-proton and light nucleus-nucleus interactions in Geant4 FTF model",
      "authors": [
        "A. Galoyan",
        "A. Ribon",
        "V. Uzhinsky"
      ],
      "abstract": "The total yield of neutral D-mesons (4$\u03c0$) in central Xe+La interactions at 150 GeV per nucleon has been calculated within the Geant4 FTF model. Our calculation is close to predictions of Monte Carlo models that do not account for quark-gluon plasma formation. As the predictions, our calculation substantially underestimates preliminary experimental data. The experimental data indicate enhanced charmed particle production in nucleus-nucleus interactions. We present also our calculations for charmed meson production in ${\\rm p+p}$, ${\\rm d+d}$ and ${\\rm ^4He+^4He}$ interactions for future NICA/SPD experiment at $\\sqrt{s_{NN}}=$10 and 20 GeV.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21184v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21167v1",
      "title": "(Lovelock)$^2$ inflation: explaining the ACT data and equivalence to Higgs-Gauss-Bonnet inflation",
      "authors": [
        "Andrea Addazi",
        "Yermek Aldabergenov",
        "Daulet Berkimbayev",
        "Yifu Cai"
      ],
      "abstract": "We revisit the Starobinsky model of inflation in light of recent data from the Atacama Cosmology Telescope (ACT), which indicates a potential preference for a slightly larger scalar spectral index $n_s$ than predicted by the standard $R^2$ scenario. We demonstrate that a natural one-parameter generalization to a quadratic model $\\sim L+L^2$ in the Lovelock invariant $L=R+\\frac\u03b1{4}{\\cal G}$ ($\\cal G$ is the Gauss--Bonnet term), can effectively resolve this minor tension. Scalar-tensor formulation of this theory yields an Einstein-frame Starobinsky-type scalar potential augmented by Gauss--Bonnet and derivative couplings, which modify the inflationary slow-roll dynamics. We show that a non-zero coupling $\u03b1$ for the Gauss-Bonnet term can shift $(n_s, r)$ along a trajectory that brings the predictions into better agreement with the ACT likelihood. We also find that $L+L^2$ gravity, in its scalar-tensor formulation, is equivalent to Higgs inflation coupled to the Gauss--Bonnet term, and belongs to the Horndeski/galileon class of modified gravities. This work establishes the quadratic $f(L)$ gravity as a compelling and physically motivated extension that preserves the successes of Starobinsky inflation while improving its fit to modern precision cosmological data.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21167v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21161v1",
      "title": "Dipion transitions from $X(3872)$ to $\u03c7_{cJ}\\ (J=0,1,2)$",
      "authors": [
        "Qi Wu",
        "Zhong-Quan Sun",
        "Dian-Yong Chen",
        "Shi-Dong Liu",
        "Gang Li"
      ],
      "abstract": "In this work, we investigate the dipion transition processes $X(3872)\\to \u03c0\u03c0\u03c7_{cJ} (J=0,1,2)$ within the framework of heavy hadron chiral perturbation theory, treating $X(3872)$ as a molecular state composed of $D\\bar{D}^*+h.c.$ components. By analyzing the box and triangle loop diagrams with nonrelativistic effective field theory power counting rule, we demonstrate that box diagrams dominate these dipion transitions processes. Branching ratios are calculated as functions of the mixing angle $\u03b8$, which parameterizes the neutral and charged meson compositions of the $X(3872)$. Our results indicate that the branching fractions for $X(3872)\\to\u03c0\u03c0\u03c7_{c0}$, $X(3872)\\to \u03c0\u03c0\u03c7_{c1}$, and $X(3872)\\to \u03c0\u03c0\u03c7_{c2}$ are of orders $10^{-4}$, $10^{-3}$, and $10^{-5}$, respectively. We also predict the ratios ${\\mathcal{B}[X(3872)\\rightarrow \u03c0\u03c0\u03c7_{c0/2}]}/{\\mathcal{B}[X(3872)\\rightarrow \u03c0\u03c0\u03c7_{c1}]}$ and ${\\mathcal{B}[X(3872)\\rightarrow \u03c0^+\u03c0^-\u03c7_{cJ}]}/{\\mathcal{B}[X(3872)\\rightarrow \u03c0^0\u03c0^0\u03c7_{cJ}]}$. The latter deviates from isospin-symmetry expectations, revealing various degrees of isospin violation. By studying the $\u03c0^+\u03c0^-$ and $\u03c0^+\u03c7_{cJ}$ invariant mass spectra, we find a double-bump structure in the $\u03c0^ + \u03c0^-$ invariant mass distributions of the process $X(3872)\\to \u03c0^+\u03c0^-\u03c7_{c1}$ and $\u03c0^+\u03c7_{c0}$ invariant mass distribution of the process $X(3872)\\to \u03c0^+\u03c0^-\u03c7_{c0}$, which could be tested by the future experimental measurements.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21161v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21148v1",
      "title": "Bridging Microscopic Constructions and Continuum Topological Field Theory of Three-Dimensional Non-Abelian Topological Order",
      "authors": [
        "Yizhou Huang",
        "Zhi-Feng Zhang",
        "Qing-Rui Wang",
        "Peng Ye"
      ],
      "abstract": "Here we provide a microscopic lattice construction of excitations, fusion, and shrinking in a non-Abelian topological order by studying the three-dimensional quantum double model. We explicitly construct lattice operators that create, fuse, and shrink particle and loop excitations, systematically derive their fusion and shrinking rules, and demonstrate that non-Abelian shrinking channels can be controllably selected through internal degrees of freedom of loop operators. Most importantly, we show that the lattice shrinking rules obey the fusion--shrinking consistency relations predicted by twisted $BF$ field theory, providing solid evidence for the validity of field-theoretical principles developed over the past years. In particular, we compute the full set of excitations, fusion, and shrinking data at the microscopic lattice level and verify exact agreement between the microscopic $\\mathbb{D}_4$ quantum double lattice model and the continuum $BF$ field theory with an $AAB$ twist and $(\\mathbb{Z}_2)^3$ gauge group, thereby placing the latter field theory, originally discovered in 2018 in connection with Borromean-ring braiding, on a solid microscopic footing. Our results bridge continuum topological field theory and exactly solvable lattice models, elevate fusion--shrinking consistency from a continuum field-theoretical principle to a genuine topological phenomenon defined at the microscopic lattice scale, and provide a concrete microscopic foundation for experimentally engineering higher-dimensional non-Abelian topological orders in controllable quantum simulators, such as trapped-ion systems.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21148v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21136v1",
      "title": "Modeling gap acceptance behavior allowing for perceptual distortions and exogenous influences",
      "authors": [
        "Ankita Sharma",
        "Partha Chakroborty",
        "Pranamesh Chakraborty"
      ],
      "abstract": "This work on gap acceptance is based on the premise that the decision to accept/reject a gap happens in a person's mind and therefore must be based on the perceived gap and not the measured gap. The critical gap must also exist in a person's mind and hence, together with the perceived gap, is a latent variable. Finally, it is also proposed that the critical gap is influenced by various exogenous variables such as subject and opposing vehicle types, and perceived waiting time. Mathematical models that (i) incorporate systematic and random distortions during the perception process and (ii) account for the effect of the various influencing variables are developed. The parameters of these models are estimated for two different gap acceptance data sets using the maximum likelihood technique. The data is collected as part of this study. The estimated parameters throw valuable insights into how these influencing variables affect the critical gap. The results corroborate the initial predictions on the nature of influence these variables must exert and give strength to the gap acceptance decision-making construct proposed here. This work also proposes a methodology to estimate a measurable/observable world emulator of the latent variable critical gap. The use of the emulator critical gap provides improved estimates of derived quantities like the average waiting time of subject vehicles. Finally, studies are also conducted to show that the number of rejected gaps can work as a reasonable surrogate for the influencing variable, waiting time.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21136v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21114v1",
      "title": "HQET Spectroscopy of Radially Excited F-wave Mesons",
      "authors": [
        "Palak Gupta",
        "Sapana Yadav",
        "Ritu Garg"
      ],
      "abstract": "Motivated by the continuous advances in modern experimental facilities, we investigate the radially excited F-wave bottom and bottom-strange mesons that have not yet been observed experimentally. By combining theoretical inputs with available experimental information on charm mesons and applying flavor-symmetry parameters, we predict the masses of the radially excited F-wave bottom states and their strange partners. In addition, we compute their strong decay widths in terms of the hadronic coupling constants $\\tilde{g}_{ZH}$ and $\\tilde{g}_{RH}$. Using the presently estimated values of these couplings, we obtain upper bounds on the corresponding decay widths. These predictions will serve as testable benchmarks for forthcoming heavy-flavor spectroscopy findings.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21114v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21076v1",
      "title": "Blurb-Refined Inference from Crowdsourced Book Reviews using Hierarchical Genre Mining with Dual-Path Graph Convolutions",
      "authors": [
        "Suraj Kumar",
        "Utsav Kumar Nareti",
        "Soumi Chattopadhyay",
        "Chandranath Adak",
        "Prolay Mallick"
      ],
      "abstract": "Accurate book genre classification is fundamental to digital library organization, content discovery, and personalized recommendation. Existing approaches typically model genre prediction as a flat, single-label task, ignoring hierarchical genre structure and relying heavily on noisy, subjective user reviews, which often degrade classification reliability. We propose HiGeMine, a two-phase hierarchical genre mining framework that robustly integrates user reviews with authoritative book blurbs. In the first phase, HiGeMine employs a zero-shot semantic alignment strategy to filter reviews, retaining only those semantically consistent with the corresponding blurb, thereby mitigating noise, bias, and irrelevance. In the second phase, we introduce a dual-path, two-level graph-based classification architecture: a coarse-grained Level-1 binary classifier distinguishes fiction from non-fiction, followed by Level-2 multi-label classifiers for fine-grained genre prediction. Inter-genre dependencies are explicitly modeled using a label co-occurrence graph, while contextual representations are derived from pretrained language models applied to the filtered textual content. To facilitate systematic evaluation, we curate a new hierarchical book genre dataset. Extensive experiments demonstrate that HiGeMine consistently outperformed strong baselines across hierarchical genre classification tasks. The proposed framework offers a principled and effective solution for leveraging both structured and unstructured textual data in hierarchical book genre analysis.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21076v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21074v1",
      "title": "The transport of angular momentum for massive stars I. Formation of slowly rotating WNE stars",
      "authors": [
        "Jijuan Si",
        "Yan Li",
        "Xue-Feng Li",
        "Zhi Li"
      ],
      "abstract": "The evolutionary scenario of early-type nitrogen-sequence Wolf-Rayet (WNE) stars predicts a slowly rotating subclass that typically forms after the red supergiant (RSG) phase. Their slow rotation rates are attributed to stellar winds that remove angular momentum transferred outward during core contraction. We incorporate improved prescriptions for internal gravity waves and the magnetic Tayler instability into single massive star evolution models. Our simulations successfully produce slowly rotating WNE stars and determine optimal parameters for both mechanisms ($A \\ge 10$ for internal gravity waves (IGWs), $\u03b1= 0.01$ for revised Tayler instability (TSF)). The results demonstrate that the efficiency of angular momentum transfer in massive stars is significantly enhanced compared to low-mass stars, both processes can self-consistently explain the slow rotation of WNE stars, confirming their efficiency in angular momentum redistribution and providing crucial theoretical support for the existence of this predicted stellar population.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21074v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.20990v1",
      "title": "Mental Health Self-Disclosure on Social Media throughout the Pandemic Period",
      "authors": [
        "Dino Husnic",
        "Stefan Cobeli",
        "Shweta Yadav"
      ],
      "abstract": "The COVID-19 pandemic has created many problems, especially in people's social lives. There has been increasing isolation and economic hardships since the beginning of the pandemic for people all over the world. Quarantines and lockdowns also took part in that, and so, people have been expressing their emotions throughout the pandemic period using social media platforms like Reddit, Twitter, Facebook, etc. In this study, we seek to analyze the emotions and mental health labels throughout the time period of March 2, 2020, up until July 4, 2020, from the threads and comments gathered from the r/unitedkingdom subreddit. We used a soft labeling technique to generate mental health conditions for each Reddit comment. We compared the overall results with important dates related to COVID-19 policies that took place in the United Kingdom. This can give us a view on how the pandemic and the important dates affect people self disclosing their emotions on social media platforms. Finally, we have developed a proof of concept to show that using mental health features may increase emotion prediction accuracy.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20990v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.21071v1",
      "title": "Hysteretic Phonons and Quasielastic Response: A Raman Study of Thermal Memory in Two-dimensional CuCrP2S6",
      "authors": [
        "Chaitanya B. Auti",
        "Atul G. Chakkar",
        "Sebastian Selter",
        "Yuliia Shemerliuk",
        "Bernd B\u00fcchner",
        "Saicharan Aswartham",
        "Pradeep Kumar"
      ],
      "abstract": "We present a comprehensive temperature and polarization dependent inelastic light scattering (Raman) study on single crystals of two-dimensional CuCrP2S6, a layered van der Waals material exhibiting coupled magnetic and electric degrees of freedom. Raman measurements were performed from 5 to 300 K to probe phonon dynamics across multiple structural and magnetic phase transitions. Our analysis reveals pronounced thermal hysteresis in phonon self-energy parameters and dynamic Raman susceptibility, confirming the first-order nature of the antipolar transition near TC1 ~ 145 K and a second-order transition near TC2 ~ 190 K. Low-frequency modes associated with Cu+ and Cr3+ ions exhibit softening and anomalous linewidth behaviour, in particular phonon mode P2 (~ 37 cm-1) showing non-monotonic temperature dependence and intensity enhancement near 60 K suggesting persistent off-centre Cu+ dynamics in the quasi-antipolar phase. The coexistence and coupling of soft phonon modes and central peaks indicate a crossover from displacive to order-disorder type transition mechanisms. Additionally, phonon anomalies below the N\u00e9el temperature (TN ~ 32 K) reflect spin-phonon coupling, linking lattice vibrations to long-range magnetic correlations. Our findings provide critical insight into the lattice instabilities, symmetry evolution, and quasiparticle interactions in CuCrP2S6, offering a deeper understanding of phase transition dynamics in two-dimensional multiferroic systems and guiding future design of magnetoelectric and spintronic devices.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.21071v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.20903v1",
      "title": "Elementary excitations in undoped layered cuprates",
      "authors": [
        "A. V. Syromyatnikov"
      ],
      "abstract": "Using the recently proposed bond-operator technique (BOT), we discuss spin dynamics of the Heisenberg spin-$\\frac12$ antiferromagnet with the ring exchange and small interactions between the second- and the third-neighbor spins on the square lattice at $T=0$. This model was suggested before for description of parent compounds of high-temperature superconducting layered cuprates. BOT describes accurately short-range spin correlations in quantum systems and provides a quantitative description of elementary excitations which appear in other approaches as bound states of conventional low-energy quasiparticles. We demonstrate that besides well-known magnons (spin-1 excitations) there are three well-defined spin-0 quasiparticles in the considered model whose energies lie near the magnon spectrum. Two of them, the amplitude (Higgs) mode and the quasiparticle which we named singlon, produce pronounced anomalies observed experimentally in the Raman scattering, resonant inelastic x-ray scattering, and infrared optical absorption. We find sets of the model parameters which describe quantitatively experimental data obtained in $\\rm La_2CuO_4$ and $\\rm Sr_2CuO_2Cl_2$.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20903v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.20862v1",
      "title": "Drastic field-induced resistivity upturns as signatures of unconventional magnetism in superconducting iron chalcogenides",
      "authors": [
        "Z. Zajicek",
        "I. Paulescu",
        "P. Reiss",
        "R. M. Abedin",
        "K. Sun",
        "S. J. Singh",
        "A. A. Haghighirad",
        "A. I. Coldea"
      ],
      "abstract": "Electronic scattering is a powerful tool to identify underlying changes in electronic behavior and incipient electronic and magnetic orders. The nematic and magnetic phases are strongly intertwined under applied pressure in FeSe, however, the additional isoelectronic substitution of sulphur offers an elegant way to separate them. Here we report the detailed evolution of the electronic and superconducting behaviour of FeSe$_{0.96}$S$_{0.04}$ under applied pressure via longitudinal magnetoresistance studies up to 15T. At intermediate pressures, inside the nematic phase, the resistivity displays an upturn in zero magnetic field, which is significantly enhanced in the magnetic field, suggesting the stabilization of a spin-density wave phase, which competes with superconductivity. At higher pressures, beyond the nematic phase boundaries, the resistivity no longer displays any clear anomalies in the zero magnetic field, but an external magnetic field induces significant upturns in resistivity reflecting a field-induced order, where superconductivity and magnetic anomalies are enhanced in tandem. This study highlights the essential role of high magnetic fields in stabilizing different electronic phases and revealing a complex interplay between magnetism and superconductivity tuned by applied pressure in FeSe$_{1-x}$S$_{x}$.",
      "published": "2025-12-24",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20862v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.20843v1",
      "title": "Magnetism and Correlated Electrons in LaCr$_2$Ge$_2$N",
      "authors": [
        "Jiao-Jiao Meng",
        "Yu-Sen Xiao",
        "Gen Li",
        "Shao-Hua Liu",
        "Bai-Zhuo Li",
        "Hao Jiang",
        "Zhen Yu",
        "Yi-Qiang Lin",
        "Xin-Yu Zhao",
        "Qing-Chen Duan",
        "Wu-Zhang Yang",
        "Chong-Yao Zhao",
        "Zhi Ren",
        "Yu-Xue Mei",
        "Yong-Liang Chen",
        "Rui-Dan Zhong",
        "Qing-Xin Dong",
        "Peng-Tao Yang",
        "Shu-Gang Tan",
        "Bo-Sen Wang",
        "Huiqian Luo",
        "Jin-Guang Cheng",
        "Xue Ming",
        "Cao Wang",
        "Guang-Han Cao"
      ],
      "abstract": "We report the synthesis, structure and physical properties of a new quaternary nitride LaCr$_2$Ge$_2$N. The compound crystallizes in the CeCr$_2$Si$_2$C-type structure (P4/mmm), featuring distinctive Cr$_2$N square sheets within Cr$_2$Ge$_2$N block layers. Physical characterizations reveal enhanced electron correlations evidenced by a Sommerfeld coefficient substantially larger than band calculations and pressure-induced deviation from Fermi-liquid behavior. Magnetic measurements show short-range antiferromagnetic correlations developing around 460 K, followed by long-range magnetic ordering at 14 K. Additionally, subtle anomalies at 378 K suggest possible electronic ordering. First-principles calculations reveal nearly-flat Cr-3d bands near the Fermi level and predict a striped antiferromagnetic ground state. This work demonstrates how electron count variation in the CeCr$_2$Si$_2$C-type structure family leads to magnetic ordering in LaCr$_2$Ge$_2$N, contrasting with the paramagnetic behavior of LnCr$_2$Si$_2$C compounds.",
      "published": "2025-12-23",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.20843v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.19429v1",
      "title": "Semileptonic neutral currents decays of $\u039e_b$ with dileptons or dineutrinos in the final state",
      "authors": [
        "Zhou Rui",
        "Zhi-Tian Zou",
        "Ya Li",
        "Ying Li"
      ],
      "abstract": "We perform a detailed analysis of semileptonic $\u039e_b$ decays mediated by flavor-changing neutral currents ($b\\to s$ and $b\\to d$) with dilepton or dineutrino final states within the perturbative QCD framework. All independent form factors including vector, axial-vector, tensor, and pseudotensor currents are calculated and are used to analyze the decay branching fractions and angular distributions. Our numerical results for the branching fractions of $\u039e_b\\to \u039e\\ell^+\\ell^-$ decays suggest they are within measurable reach for the LHCb experiment in the near future. Furthermore, we show that a measurement of the ratio $\\mathcal{B}(\u039e_b^-\\to \u03a3^- \u03bc^+\u03bc^-) / \\mathcal{B}(\u039e_b^-\\to \u039e^- \u03bc^+\u03bc^-)$ will allow for an independent determination of $|V_{td}/V_{ts}|$. For the case of unpolarized $\u039e_b$ baryons, we derive several angular observables, which can provide new and complementary constraints on Wilson coefficients in semileptonic FCNC transitions compared to those from mesonic decays. Finally, we present a combined analysis of dilepton and dineutrino channels, comparing various observables in detail. Our results offer further insights into the long-standing anomalies observed in $B$ meson decays.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.19429v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.18993v1",
      "title": "Stoichiometry-Controlled Structural Order and Tunable Antiferromagnetism in $\\mathrm{Fe}_{x}\\mathrm{NbSe_2}$ ($0.05 \\le x \\le 0.38$)",
      "authors": [
        "Xiaotong Xu",
        "Bei Jiang",
        "Runze Wang",
        "Zhibin Qiu",
        "Shu Guo",
        "Baiqing Lv",
        "Ruidan Zhong"
      ],
      "abstract": "Transition metal dichalcogenides (TMDs) enable magnetic property engineering via intercalation, but stoichiometry-structure-magnetism correlations remain poorly defined for Fe-intercalated $\\mathrm{NbSe_2}$. Here, we report a systematic study of $\\mathrm{Fe}_{x}\\mathrm{NbSe_2}$ across an extended composition range $0.05 \\le x \\le 0.38$, synthesized via chemical vapor transport and verified by rigorous energy-dispersive X-ray spectroscopy (EDS) microanalysis. X-ray diffraction, magnetic, and transport measurements reveal an intrinsic correlation between Fe content, structural ordering, and magnetic ground states. With increasing $x$, the system undergoes a successive transition from paramagnetism to a spin-glass state, then to long-range antiferromagnetism (AFM), and ultimately to a reentrant spin-glass phase, with the transition temperatures exhibiting a non-monotonic dependence on Fe content. The maximum N\u00e9el temperature ($T_{\\mathrm{N}}$ = $\\mathrm{175K}$) and strongest AFM coupling occur at $x=0.25$, where Fe atoms form a well-ordered $2a_0 \\times 2a_0 $ superlattice within van der Waals gaps. Beyond $x = 0.25$, the superlattice transforms or disorders, weakening Ruderman-Kittel-Kasuya-Yosida (RKKY) interactions and reducing $T_{\\mathrm{N}}$ significantly. Electrical transport exhibits distinct anomalies at magnetic transition temperatures, corroborating the magnetic state evolution. Our work extends the compositional boundary of Fe-intercalated $\\mathrm{NbSe_2}$, establishes precise stoichiometry-structure-magnetism correlations, and identifies structural ordering as a key tuning parameter for AFM. These findings provide a quantitative framework for engineering altermagnetic or switchable antiferromagnetic states in van der Waals materials.",
      "published": "2025-12-22",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18993v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.18724v1",
      "title": "Spiral states, first-order transitions and specific heat multipeak phenomenon in $J_1$-$J_2$-$J_3$ model: A Wang-Landau algorithm study",
      "authors": [
        "Habib Ullah",
        "Kun Li",
        "Haoyu Lu",
        "Youjin Deng",
        "Wanzhou Zhang"
      ],
      "abstract": "The classical $J_1$-$J_2$-$J_3$ Ising model on the honeycomb lattice is important for understanding frustrated magnetic phenomena in materials such as $FePS_3$ and $Ba_2CoTeO_6$, where diverse phases (e.g., striped, zigzag, armchair) and magnetization plateaus have been experimentally observed. To explain the experimental results, previous mean-field studies have explored its thermal phase transitions, identifying armchair phases and striped phases, but their limitations call for more reliable numerical investigations. In this work, we systematically revisit the classical $J_1$-$J_2$-$J_3$ Ising model using the Wang-Landau algorithm. We find that the armchair (AC) phase, previously reported in mean-field and experimental studies, actually coexists with the spiral (SP) phase, with their combined degeneracy reaching 20-fold (4-fold for the AC states and 16-fold for the spiral states). The phase transitions and critical exponents are studied at different interaction values. We observe first-order phase transitions, continuous phase transitions, and even the multipeak phenomenon, i.e., Schottky-like specific-heat anomalies in frustrated systems. These results clarify the nature of phases and phase transitions in frustrated Ising systems and their exponents, and additionally provide inspiration for experimental efforts to search for the spiral state and Schottky-like anomalies.",
      "published": "2025-12-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.18724v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.17691v1",
      "title": "Bulk signatures of re-entrant superconductivity in UTe$_2$ from ultrasound measurements",
      "authors": [
        "N. Marquardt",
        "C. Duffy",
        "C. Proust",
        "S. Badoux",
        "M. Amano Patino",
        "G. Lapertot",
        "D. Aoki",
        "J. -P. Brison",
        "G. Knebel",
        "D. LeBoeuf"
      ],
      "abstract": "We report bulk ultrasound measurements up to 80 T and down to 0.5 K of the field re-entrant superconducting phase of the unconventional superconductor UTe$_2$. Clear bulk signatures of superconductivity are observed in the longitudinal elastic mode $c_{11}$ for fields applied at a tilt angle of $\u03b8_{b-c} =30^\\circ$ from $b$-axis. We confirm an upper critical field of $H_{\\rm c2}\\approx65$ T at 0.5 K and bulk superconductivity which survives up to $T\\approx 2$ K for fields above the metamagnetic transition. The $c_{11}$ mode has propagation and displacement vectors along the $a$-axis, and for fields applied at a tilt angle of $\u03b8_{b-c} =30^\\circ$, this mode is sensitive to the elasticity of the vortex lattice. The anomalies observed in $c_{11}$ are in part reminiscent of superconducting vortices pinned to lattice defects. Nonetheless, an excess attenuation, with respect to the normal state, is observed throughout the entire superconducting phase, suggesting unusual vortex dynamics and pinning in the field re-entrant superconducting phase of UTe$_2$.",
      "published": "2025-12-19",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17691v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.17018v1",
      "title": "Real-space Atomic Dynamics in Liquid Gallium Studied by Inelastic Neutron Scattering",
      "authors": [
        "Chengyun Hua",
        "Yadu K. Sarathchandran",
        "Eva Zarkadoula",
        "Wojciech Dmowski",
        "Douglas L. Abernathy",
        "Takeshi Egami",
        "Yuya Shinohara"
      ],
      "abstract": "Gallium is a prototypical liquid metal and has gained renewed attention due to its unique properties. Characterizing and elucidating its atomic dynamics remains elusive despite numerous studies, primarily due to the challenges of quantifying atomic-scale dynamics in liquids. Recent developments in inelastic neutron scattering enable us to measure the Van Hove correlation function that describes the real-space motion of liquid atoms. In this work, we use this approach to reveal the dynamics in gallium liquids and find the co-existence of two dynamical medium-range orders (MROs), which have a dynamical behavior distinct from that of the short-range order (SRO). We propose that these MROs are driven by global forces in the form of two density waves, as a direct consequence of the underlying competition between ionic core repulsion and valence electron cohesion. We suggest that the density wave approach is not only applicable to other metallic liquids exhibiting similar structural anomalies, but also offers a promising direction for elucidating the dynamics of complex liquids and glasses by linking electronic-state fluctuations to atomic dynamics.",
      "published": "2025-12-18",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.17018v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.12965v1",
      "title": "Challenges and Enablers: Remote Work for People with Disabilities in Software Development Teams",
      "authors": [
        "Thayssa Rocha",
        "Luciano Teran",
        "Marcelle Mota",
        "Cleidson de Souza",
        "Kiev Gama",
        "Gustavo Pinto"
      ],
      "abstract": "The increasing adoption of remote and hybrid work modalities in the technology sector has brought new opportunities and challenges for the inclusion of people with disabilities (PWD) in software development teams (SDT). This study investigates how remote work affects PWDs' experience in mixed-ability SDT, focusing on the unique challenges and strategies that emerge in remote environments. We conducted an online survey with \\totalSurveyResponses valid responses, encompassing PWD, their leaders, and teammates, to capture sociotechnical aspects of their experiences with remote collaboration. To deepen our understanding, we carried out 14 structured interviews with software developers who self-identified as having disabilities (six autistic individuals, six with physical disabilities, and two who are d/Deaf). Our analysis combines quantitative data with qualitative coding of open-ended survey responses and interview transcripts. The results reveal that, despite the barriers faced by team members with disabilities, their teammates and leaders have a limited perception of the daily challenges involved in sustaining collaborative remote work. These findings highlight opportunities for improvement in accessibility tools, communication strategies, and adaptive management approaches.",
      "published": "2025-12-15",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.12965v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2510.17130v1",
      "title": "SEER: Enhancing Chain-of-Thought Code Generation through Self-Exploring Deep Reasoning",
      "authors": [
        "Shuzheng Gao",
        "Chaozheng Wang",
        "Cuiyun Gao",
        "Michael R. Lyu"
      ],
      "abstract": "Code generation, the task of creating executable programs from natural language requirements, has recently seen tremendous advances through Chain-of-Thought (CoT) reasoning, which enables Large Language Models (LLMs) to develop high-level reasoning plans before writing code. Recent research has proposed various methods to enhance models' CoT reasoning for code generation such as prompt engineering and supervised fine-tuning. However, existing approaches still face three critical limitations: (1) limited exploration of diverse reasoning paths, which constrains generalization across various programming scenarios, (2) lack of quality assessment for intermediate reasoning steps, which hampers the reliability of the generated plans and code, and (3) the potential negative impact of \"overthinking\", potentially leading to unnecessarily complex and incorrect solutions. To address these limitations, we frame CoT code generation as a decision making problem and present SEER, a SElf-Exploring deep Reasoning framework that enables accurate and adaptive reasoning for code generation. SEER introduces three key components: (1) Diverse reasoning path exploration, which aims at exploring diverse reasoning paths and annotating intermediate steps without relying on manual experts or closed-source proprietary models; (2) Reasoning quality-aware model training, which trains a policy model for generating candidate reasoning steps and a value model for assessing their quality; and (3) Adaptive CoT reasoning, which dynamically switches between direct generation and step-by-step reasoning for different problems.",
      "published": "2025-10-20",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2510.17130v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2509.14093v1",
      "title": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework",
      "authors": [
        "Kerui Huang",
        "Shuhan Liu",
        "Xing Hu",
        "Tongtong Xu",
        "Lingfeng Bao",
        "Xin Xia"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by prompting intermediate steps, improving accuracy and robustness in arithmetic, logic, and commonsense tasks. However, this benefit comes with high computational costs: longer outputs increase latency, memory usage, and KV-cache demands. These issues are especially critical in software engineering tasks where concise and deterministic outputs are required. To investigate these trade-offs, we conduct an empirical study based on code generation benchmarks. The results reveal that longer CoT does not always help. Excessive reasoning often causes truncation, accuracy drops, and latency up to five times higher, with failed outputs consistently longer than successful ones. These findings challenge the assumption that longer reasoning is inherently better and highlight the need for adaptive CoT control. Motivated by this, we propose SEER (Self-Enhancing Efficient Reasoning), an adaptive framework that compresses CoT while preserving accuracy. SEER combines Best-of-N sampling with task-aware adaptive filtering, dynamically adjusting thresholds based on pre-inference outputs to reduce verbosity and computational overhead. We then evaluate SEER on three software engineering tasks and one math task. On average, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation, and eliminates most infinite loops. These results demonstrate SEER as a practical method to make CoT-enhanced LLMs more efficient and robust, even under resource constraints.",
      "published": "2025-09-17",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2509.14093v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2508.15411v2",
      "title": "Foundational Design Principles and Patterns for Building Robust and Adaptive GenAI-Native Systems",
      "authors": [
        "Frederik Vandeputte"
      ],
      "abstract": "Generative AI (GenAI) has emerged as a transformative technology, demonstrating remarkable capabilities across diverse application domains. However, GenAI faces several major challenges in developing reliable and efficient GenAI-empowered systems due to its unpredictability and inefficiency. This paper advocates for a paradigm shift: future GenAI-native systems should integrate GenAI's cognitive capabilities with traditional software engineering principles to create robust, adaptive, and efficient systems.   We introduce foundational GenAI-native design principles centered around five key pillars -- reliability, excellence, evolvability, self-reliance, and assurance -- and propose architectural patterns such as GenAI-native cells, organic substrates, and programmable routers to guide the creation of resilient and self-evolving systems. Additionally, we outline the key ingredients of a GenAI-native software stack and discuss the impact of these systems from technical, user adoption, economic, and legal perspectives, underscoring the need for further validation and experimentation. Our work aims to inspire future research and encourage relevant communities to implement and refine this conceptual framework.",
      "published": "2025-08-21",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2508.15411v2",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2504.18776v1",
      "title": "ThinkFL: Self-Refining Failure Localization for Microservice Systems via Reinforcement Fine-Tuning",
      "authors": [
        "Lingzhe Zhang",
        "Yunpeng Zhai",
        "Tong Jia",
        "Chiming Duan",
        "Siyu Yu",
        "Jinyang Gao",
        "Bolin Ding",
        "Zhonghai Wu",
        "Ying Li"
      ],
      "abstract": "As modern microservice systems grow increasingly popular and complex-often consisting of hundreds or even thousands of fine-grained, interdependent components-they are becoming more susceptible to frequent and subtle failures. Ensuring system reliability therefore hinges on accurate and efficient failure localization. Traditional failure localization approaches based on small models lack the flexibility to adapt to diverse failure scenarios, while recent LLM-based methods suffer from two major limitations: they often rely on rigid invocation workflows that constrain the model's ability to dynamically explore optimal localization paths, and they require resource-intensive inference, making them cost-prohibitive for real-world deployment. To address these challenges, we explore the use of reinforcement fine-tuning to equip lightweight LLMs with reasoning and self-refinement capabilities, significantly improving the cost-effectiveness and adaptability of LLM-based failure localization. We begin with an empirical study to identify three key capabilities essential for accurate localization. Building on these insights, we propose a progressive multi-stage GRPO fine-tuning framework, which integrates a multi-factor failure localization grader and a recursion-of-thought actor module. The resulting model, ThinkFL, not only outperforms existing state-of-the-art LLMs and baseline methods in localization accuracy but also reduces end-to-end localization latency from minutes to seconds, demonstrating strong potential for real-world applications.",
      "published": "2025-04-26",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2504.18776v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.13978v1",
      "title": "Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms",
      "authors": [
        "Yang Cao",
        "Yubin Chen",
        "Xuyang Guo",
        "Zhao Song",
        "Song Yue",
        "Jiahao Zhang",
        "Jiale Zhao"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has led to significant breakthroughs in automated mathematical reasoning and scientific discovery. Georgiev, G${\u00f3}$mez-Serrano, Tao, and Wagner [GGSTW+25] demonstrate that AI systems can explore new constructions and improve existing bounds, illustrating the growing potential of LLMs to accelerate mathematical discovery. Similarly, Bubeck et al. [BCE+25] show that GPT-5 can meaningfully contribute to scientific workflows, from proposing hypotheses to generating proofs and analyses. Despite these advances, a rigorous evaluation of these models on canonical, graduate-level mathematical theory remains necessary to understand their baseline reasoning capabilities. In this paper, we present a comprehensive benchmark of four frontier models: GPT-5-Thinking, Gemini-3-Pro, Claude-Sonnet-4.5-Thinking, and Grok-4 against the classic curriculum of Randomized Algorithms by Motwani and Raghavan [MR95].   We tasked each model with generating formal LaTeX proofs for a series of lemmas and exercises spanning the textbook. We find that while the top-tier models (Gemini, and Claude) achieve a high accuracy rate (approx. 66%), demonstrating a robust grasp of probabilistic method and formal logic, other models lag significantly in consistency (approx. 40%). We provide a qualitative analysis of the generated proofs, highlighting differences in conciseness, hallucination rates, and logical structure. Our results suggest that while frontier models have reached a threshold of proficiency suitable for graduate-level pedagogical assistance and formalization, significant variance exists in their reliability for rigorous mathematical derivation. The code and the full set of LLM-generated responses are open-sourced and publicly available at https://github.com/magiclinux/math_benchmark_probability.",
      "published": "2025-12-16",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.13978v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.06431v1",
      "title": "Smart Spatial Planning in Egypt: An Algorithm-Driven Approach to Public Service Evaluation in Qena City",
      "authors": [
        "Mohamed Shamroukh",
        "Mohamed Alkhuzamy Aziz"
      ],
      "abstract": "National planning standards for public services in Egypt often fail to align with unique local characteristics. Addressing this gap, this study develops a tailored planning model for Qena City. Using a hybrid methodology (descriptive, analytical, and experimental), the research utilizes Python programming to generate an intelligent spatial analysis algorithm based on Voronoi Diagrams. This approach creates city-specific planning criteria and evaluates the current coverage of public facilities. The primary contribution of this study is the successful derivation of a localized planning standards model and the deployment of an automated algorithm to assess service efficiency. Application of this model reveals a general service coverage average of 81.3%. Ambulance stations demonstrated the highest efficiency (99.8%) due to recent upgrades, while parks and open spaces recorded the lowest coverage (10%) caused by limited land availability. Spatial analysis indicates a high service density in midtown (>45 services/km^2), which diminishes significantly towards the outskirts (<5 services/km^2). Consequently, the Hajer Qena district contains the highest volume of unserved areas, while the First District (Qesm 1) exhibits the highest level of service coverage. This model offers a replicable framework for data-driven urban planning in Egyptian cities.",
      "published": "2025-12-06",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.06431v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.11865v1",
      "title": "Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation",
      "authors": [
        "Ju-Young Kim",
        "Ji-Hong Park",
        "Myeongjun Kim",
        "Gun-Woo Kim"
      ],
      "abstract": "Smart farming has emerged as a key technology for advancing modern agriculture through automation and intelligent control. However, systems relying on RGB cameras for perception and robotic manipulators for control, common in smart farming, are vulnerable to photometric perturbations such as hue, illumination, and noise changes, which can cause malfunction under adversarial attacks. To address this issue, we propose an explainable adversarial-robust Vision-Language-Action model based on the OpenVLA-OFT framework. The model integrates an Evidence-3 module that detects photometric perturbations and generates natural language explanations of their causes and effects. Experiments show that the proposed model reduces Current Action L1 loss by 21.7% and Next Actions L1 loss by 18.4% compared to the baseline, demonstrating improved action prediction accuracy and explainability under adversarial conditions.",
      "published": "2025-12-05",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.11865v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2512.02774v1",
      "title": "AI-Driven Document Redaction in UK Public Authorities: Implementation Gaps, Regulatory Challenges, and the Human Oversight Imperative",
      "authors": [
        "Yijun Chen"
      ],
      "abstract": "Document redaction in public authorities faces critical challenges as traditional manual approaches struggle to balance growing transparency demands with increasingly stringent data protection requirements. This study investigates the implementation of AI-driven document redaction within UK public authorities through Freedom of Information (FOI) requests. While AI technologies offer potential solutions to redaction challenges, their actual implementation within public sector organizations remains underexplored. Based on responses from 44 public authorities across healthcare, government, and higher education sectors, this study reveals significant gaps between technological possibilities and organizational realities. Findings show highly limited AI adoption (only one authority reported using AI tools), widespread absence of formal redaction policies (50 percent reported \"information not held\"), and deficiencies in staff training. The study identifies three key barriers to effective AI implementation: poor record-keeping practices, lack of standardized redaction guidelines, and insufficient specialized training for human oversight. These findings highlight the need for a socio-technical approach that balances technological automation with meaningful human expertise. This research provides the first empirical assessment of AI redaction practices in UK public authorities and contributes evidence to support policymakers navigating the complex interplay between transparency obligations, data protection requirements, and emerging AI technologies in public administration.",
      "published": "2025-12-02",
      "year": 2025,
      "pdf_url": "https://arxiv.org/pdf/2512.02774v1",
      "relevance_score": 5
    },
    {
      "arxiv_id": "2404.08509v2",
      "title": "Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction",
      "authors": [
        "Haoran Qiu",
        "Weichao Mao",
        "Archit Patke",
        "Shengkun Cui",
        "Saurabh Jha",
        "Chen Wang",
        "Hubertus Franke",
        "Zbigniew T. Kalbarczyk",
        "Tamer Ba\u015far",
        "Ravishankar K. Iyer"
      ],
      "abstract": "Large language models (LLMs) have been driving a new wave of interactive AI applications across numerous domains. However, efficiently serving LLM inference requests is challenging due to their unpredictable execution times originating from the autoregressive nature of generative models. Existing LLM serving systems exploit first-come-first-serve (FCFS) scheduling, suffering from head-of-line blocking issues. To address the non-deterministic nature of LLMs and enable efficient interactive LLM serving, we present a speculative shortest-job-first (SSJF) scheduler that uses a light proxy model to predict LLM output sequence lengths. Our open-source SSJF implementation does not require changes to memory management or batching strategies. Evaluations on real-world datasets and production workload traces show that SSJF reduces average job completion times by 30.5-39.6% and increases throughput by 2.2-3.6x compared to FCFS schedulers, across no batching, dynamic batching, and continuous batching settings.",
      "published": "2024-04-12",
      "year": 2024,
      "pdf_url": "https://arxiv.org/pdf/2404.08509v2",
      "relevance_score": 3
    }
  ]
}