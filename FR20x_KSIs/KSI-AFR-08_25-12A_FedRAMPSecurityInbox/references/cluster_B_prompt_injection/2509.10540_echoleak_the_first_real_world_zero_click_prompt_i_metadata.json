{
  "arxiv_id": "2509.10540",
  "title": "EchoLeak: The First Real-World Zero-Click Prompt Injection Exploit in a Production LLM System",
  "authors": [
    "Pavan Reddy",
    "Aditya Sanjay Gujral"
  ],
  "affiliation": "Pavan Reddy",
  "published_date": "2025-09",
  "url": "https://arxiv.org/abs/2509.10540",
  "pdf_url": "https://arxiv.org/pdf/2509.10540.pdf",
  "relevance_score": 76,
  "query_id": "B1",
  "pages": 7,
  "key_topics": [
    "LLM security",
    "prompt injection",
    "email processing"
  ],
  "summary": "Large language model (LLM) assistants are increasingly integrated into enterprise workflows, raising new security concerns as they bridge internal and external data sources. This paper presents an in-..."
}