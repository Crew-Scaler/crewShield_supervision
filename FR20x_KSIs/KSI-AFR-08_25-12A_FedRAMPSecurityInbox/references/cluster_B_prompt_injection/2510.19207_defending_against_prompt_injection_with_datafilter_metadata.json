{
  "arxiv_id": "2510.19207",
  "title": "Defending Against Prompt Injection with DataFilter",
  "authors": [
    "Yizhu Wang",
    "Sizhe Chen",
    "Raghad Alkhudair",
    "Basel Alomair",
    "David Wagner"
  ],
  "affiliation": "Yizhu Wang",
  "published_date": "2025-10",
  "url": "https://arxiv.org/abs/2510.19207",
  "pdf_url": "https://arxiv.org/pdf/2510.19207.pdf",
  "relevance_score": 76,
  "query_id": "B4",
  "pages": 7,
  "key_topics": [
    "threat modeling",
    "prompt injection",
    "agent systems"
  ],
  "summary": "When large language model (LLM) agents are increasingly deployed to automate tasks and interact with untrusted external data, prompt injection emerges as a significant security threat. By injecting ma..."
}