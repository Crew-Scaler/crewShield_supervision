{
  "arxiv_id": "2512.21911v1",
  "title": "Accelerate Speculative Decoding with Sparse Computation in Verification",
  "authors": [
    "Jikai Wang",
    "Jianchao Tan",
    "Yuxuan Hu",
    "Jiayu Qin",
    "Yerui Sun",
    "Yuchen Xie",
    "Xunliang Cai",
    "Juntao Li",
    "Min Zhang"
  ],
  "affiliation": "Jikai Wang",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.21911v1",
  "relevance_score": 65,
  "key_topics": [],
  "summary": "Speculative decoding accelerates autoregressive language model inference by verifying multiple draft tokens in parallel. However, the verification stage often becomes the dominant computational bottleneck, especially for long-context inputs and mixture-of-experts (MoE) models. Existing sparsificatio"
}