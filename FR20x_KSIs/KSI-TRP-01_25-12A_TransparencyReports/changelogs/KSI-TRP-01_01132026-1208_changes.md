# Extracted Metadata and Statistics

Extracted on: 01132026-1208

**Questions Moved to Other KSIs:** 19 questions
- Model Performance/Drift (Q013-Q015, Q034-Q035) → KSI-AIM-02
- Supply Chain/Third-Party Risk (Q007-Q008, Q031, Q067-Q069, Q071) → KSI-TPR-03/TPR-05
- Security Controls/Integrity (Q022-Q023, Q047, Q070) → KSI-SVC-05/SVC-09
- Federated Learning System Design (Q024) → AI Training KSI
- Regulatory/Certifications (Q043-Q045) → AI Governance KSI

**Consolidated Through De-duplication:** 15 questions
- Agent Registry Consolidation (Q001, Q061-Q063) → 2 consolidated questions
- Behavioral Monitoring Consolidation (Q010, Q012, Q064-Q066, Q058-Q060) → 2 consolidated questions
- Customer Trace/Replay Access (Q025-Q027, Q038, Q042) → 2 consolidated questions
- Removed near-duplicate customer/auditor pairs → 8 consolidated

**Final Question Count:** 38 questions (perspective-neutral format)

**Quality Assessment:**
- All remaining questions directly address transparency reporting and visibility requirements
- Perspective-neutral format supports multi-stakeholder assessment
- Questions focused on: what is observable about agents/models, how observability is exposed, how incidents are reported
- Questions removed due to: better fit in other KSIs, duplication, or deviation from transparency scope

---

## Core TRP-01 Discovery Questions: Transparency Reporting and Observability

These questions address what organizations observe about agents and models, how that observability is exposed to customers and auditors, and how incidents and policy violations are transparently reported and investigated.

**KSI-TRP-01-Q01:** Does the organization maintain a centralized agent registry documenting all deployed autonomous agents with metadata including purpose, developers, deployment dates, access levels, data access scope, approval dates, and lifecycle status? For each agent, can the organization produce documentation identifying architects, approved capabilities, and change history?

**KSI-TRP-01-Q02:** Does the organization implement change management procedures requiring approval before agents are deployed, capabilities are expanded, or data access is broadened? How is this approval history documented and made available for audit review?

**KSI-TRP-01-Q03:** How does the organization assign and document accountability for each deployed agent across development, deployment, monitoring, and retirement lifecycle phases?

**KSI-TRP-01-Q04:** Has the organization committed to transitioning from periodic transparency reporting (annual/semi-annual) to continuous, real-time transparency platforms where third-party integrations, security incidents, and compliance events are logged automatically?

**KSI-TRP-01-Q05:** What technological investments implement OpenTelemetry-compliant instrumentation for capturing agent interactions (prompts, API calls, tool invocations, data access), and what is the deployment timeline?

**KSI-TRP-01-Q06:** Does the observability infrastructure support automated PII redaction while maintaining audit trail completeness, and how is reversibility handled for authorized forensic investigations?

**KSI-TRP-01-Q07:** What mechanisms document whether transparency assessments, audit results, and independent certifications regarding agent transparency practices are available and communicated to stakeholders?

**KSI-TRP-01-Q08:** Does the organization provide customer-facing APIs or portals enabling stakeholders to query transparency information about data access, agent behavior, and tool invocations in real-time?

**KSI-TRP-01-Q09:** How is customer transparency information secured to prevent exposure of sensitive details in audit trails while maintaining sufficient granularity for security-conscious customers to verify compliance with data handling requirements?

**KSI-TRP-01-Q10:** What SLAs and retention policies govern transparency portal availability and historical data retention?

**KSI-TRP-01-Q11:** For multi-agent systems with emergent coordination behaviors and distributed decision-making, how does the organization establish and transparently document accountability for system-level outcomes when individual agents operate autonomously?

**KSI-TRP-01-Q12:** Does the observability infrastructure capture inter-agent communication, shared resource access patterns, and coordination decisions enabling forensic reconstruction of complex multi-agent interactions?

**KSI-TRP-01-Q13:** How does the organization transparently handle scenarios where agent-to-agent communication or emergent coordination behaviors violate security policies, and what investigation and remediation procedures are documented and disclosed?

**KSI-TRP-01-Q14:** What procedures document the assignment and enforcement of kill-switch mechanisms and rapid response procedures when agents exhibit unexpected behavior? How quickly can the organization disable agents and initiate forensic investigation?

**KSI-TRP-01-Q15:** Does the observability system support real-time alerting when agents access unauthorized data, invoke disallowed tools, exhibit prompt injection indicators, or exceed policy-defined rate limits?

**KSI-TRP-01-Q16:** Does the organization establish baseline behavioral profiles for critical agents and implement automated anomaly detection when agents deviate from expected patterns? What investigation procedures document whether detected anomalies are incidents, benign variations, or remain under investigation?

**KSI-TRP-01-Q17:** What mechanisms enable stakeholders to access historical agent behavior data spanning minimum 6-12 months for forensic investigation purposes, and what retention guarantees does the organization provide?

**KSI-TRP-01-Q18:** Before autonomous agents gain access to customer data or accounts, does the organization require explicit approval and provide information enabling stakeholders to understand what data agents can access and why access is necessary?

**KSI-TRP-01-Q19:** If agent capabilities or data access changes after initial approval, does the organization notify affected stakeholders and provide opportunity to approve or reject the change?

**KSI-TRP-01-Q20:** Does the organization provide mechanisms to revoke agent access to customer data or disable specific agents, and if so, what is the revocation timeframe?

**KSI-TRP-01-Q21:** Does the organization transparently document all third-party services that autonomous agents can access on behalf of customers, including SaaS vendors, APIs, data marketplaces, and plugin ecosystems?

**KSI-TRP-01-Q22:** For foundation models powering agents, does the organization disclose the model provider, training data composition (to the extent known), model version, and any known limitations or security considerations?

**KSI-TRP-01-Q23:** If the organization uses fine-tuning services or custom model adaptation, does it disclose whether these services are executed on organization-controlled infrastructure or outsourced, and how are intermediate model checkpoints secured?

**KSI-TRP-01-Q24:** What SLAs govern agent uptime, performance consistency, and incident notification timelines?

**KSI-TRP-01-Q25:** When security incidents affect agents or third-party services that customer data depends on, does the organization provide rapid notification and detailed investigation findings including which data was accessed, potential unauthorized actions, and remediation steps?

**KSI-TRP-01-Q26:** Does the organization provide forensic investigation access to agent traces, observability data, and decision logs enabling stakeholders to independently verify incident scope and confirm remediation effectiveness?

**KSI-TRP-01-Q27:** What compensation or service level credits does the organization provide when agent-related security incidents occur, and are these remedies documented in service level agreements?

**KSI-TRP-01-Q28:** For autonomous decisions agents make regarding customer data (access approval, action selection, tool invocation), does the organization provide explanations documenting key factors influencing the decision and alternative considerations evaluated?

**KSI-TRP-01-Q29:** Does the organization provide mechanisms to restrict agent autonomy for sensitive operations, such as requiring human approval before agents delete data, modify critical configurations, or invoke sensitive tools?

**KSI-TRP-01-Q30:** Does the organization provide replay capabilities enabling stakeholders to understand exactly how an agent processed specific data, including model reasoning, intermediate results, and decision chains?

**KSI-TRP-01-Q31:** Does the organization provide complete data lineage tracking showing which source datasets, transformation steps, and models contributed to outputs generated by agents processing customer data?

**KSI-TRP-01-Q32:** When agents are decommissioned or retired, does the organization notify relevant stakeholders and provide evidence that agent credentials have been revoked and customer data is no longer accessible to the retired agent?

**KSI-TRP-01-Q33:** Does the organization maintain comprehensive instrumentation and observability infrastructure capturing all agent interactions (prompts, API calls, tool invocations, data access) using standardized schemas (e.g., OpenTelemetry)?

**KSI-TRP-01-Q34:** For observability data spanning 6-12 months of historical operations, can the organization produce complete traces documenting specific agent interactions, including timestamps, parameters, results, and decision context?

**KSI-TRP-01-Q35:** What controls govern observability system access, data retention, and backup procedures, and how does the organization prevent unauthorized access to sensitive observability data containing customer information?

**KSI-TRP-01-Q36:** Does the organization maintain automated provenance systems establishing data lineage from final outputs backward to source datasets, transformation steps, and intermediate models?

**KSI-TRP-01-Q37:** Does the organization maintain automated policy violation detection systems that identify when agents access unauthorized data, invoke disallowed tools, exceed rate limits, or exhibit anomalous behavior?

**KSI-TRP-01-Q38:** When policy violations are detected, does the organization automatically compile incident reports including agent traces, observability data, event timeline, and impact assessment? What thresholds and criteria define policy violations, and are these criteria documented in written policies available for audit review?

---

## Document Information

- **KSI:** KSI-TRP-01 Transparency Reports (Retired - Superseded by KSI-AFR-01)
- **Document Version:** 2.0
- **Date:** 2026-01-13
- **Question Structure:**
  - All questions formatted as perspective-neutral discovery assessments
  - Questions focus on organizational capabilities, documentation, and disclosure mechanisms
  - Questions appropriate for CIOs, customers, and auditors without stakeholder designation
- **Questions Removed in Review:** 19 questions moved to other KSIs (model drift, supply chain risk, security controls, federated learning, governance)
- **Questions Consolidated:** 15 questions through de-duplication of overlapping themes
- **Scope:** Core transparency reporting capability assessment

---

## Focus Areas Coverage

**Transparency Governance and Architecture:**
- Centralized agent registry with complete lifecycle documentation (Q01-Q02, Q03)
- Continuous vs. periodic transparency reporting (Q04)
- OpenTelemetry instrumentation and standardized observability (Q05, Q33)
- PII redaction with forensic reversibility (Q06)

**Customer and Stakeholder Access:**
- Real-time transparency APIs and portals (Q08, Q10)
- Historical data access for forensic investigation (Q17)
- Agent approval and change notification mechanisms (Q18-Q20)
- Third-party service documentation (Q21)
- Foundation model disclosure (Q22-Q23)

**Agent Behavior and Accountability:**
- Agent registry and change management (Q01-Q02)
- Accountability assignment across lifecycle (Q03)
- Multi-agent coordination transparency (Q11-Q13)
- Kill-switch and rapid response procedures (Q14)
- Real-time policy violation alerting (Q15)
- Behavioral baseline monitoring and anomaly investigation (Q16)

**Incident Response and Investigation:**
- Security incident notification and investigation findings (Q25)
- Forensic investigation access and trace data (Q26)
- Service level credits for agent incidents (Q27)
- Automated incident report compilation (Q38)
- Policy violation definition and documentation (Q38)

**Decision Transparency and Explainability:**
- Decision reasoning and alternative consideration disclosure (Q28)
- Autonomy restriction for sensitive operations (Q29)
- Agent replay capabilities (Q30)
- Data lineage tracking (Q31)

**Observability Infrastructure:**
- Comprehensive instrumentation coverage (Q33)
- Historical trace production capability (Q34)
- Observability system access controls (Q35)
- Provenance system implementation (Q36)
- Policy violation detection automation (Q37)

**Agent Lifecycle:**
- Agent deprovisioning evidence and notification (Q32)

---

## Related KSIs for Moved Questions

The following questions were moved to other KSIs as better-aligned with those domains:

**Model Performance/Drift Monitoring** → KSI-AIM-02
- Continuous model performance monitoring (accuracy, F1-scores)
- Statistical drift detection methodology
- Baseline performance maintenance for performance degradation assessment
- Model retraining and rollback decision criteria

**Supply Chain Risk Management** → KSI-TPR-03/TPR-05
- Foundation model vendor assessment (update frequency, security patching, data handling)
- AI Component SBOM documentation (models, datasets, frameworks)
- Third-party plugin vetting and marketplace monitoring
- Upstream vulnerability monitoring in model providers and dependencies

**Security Controls and Integrity** → KSI-SVC-05/SVC-09
- Cryptographic signing and verification of models
- Agent sandboxing, resource isolation, and permission boundaries
- RAG data validation for injection prevention
- Cryptographic provenance of AI models and deployment verification

**Federated Learning System Design** → AI Training KSI (to be determined)
- Participant contribution transparency for federated learning
- Distributed training documentation (data sources, model updates, aggregation)
- Federated learning architecture transparency

**AI Governance and Executive Support** → KSI-PIY-08 or KSI-AIM-04
- Independent certifications for transparency practices
- Standards body participation and regulatory framework alignment
- Specialized transparency capabilities for regulated industries

---

## Usage Guidance

**For All Stakeholders:** Use questions KSI-TRP-01-Q01 through KSI-TRP-01-Q38 to assess organizational transparency reporting maturity for AI-driven systems. Questions address governance structures, technology investments, customer access mechanisms, and incident response procedures supporting continuous transparency.

**For CIOs/Technical Leaders:** Focus on Q04-Q06 (transparency architecture), Q33-Q36 (observability infrastructure), and Q37-Q38 (policy enforcement) to evaluate technology roadmap and governance implementation.

**For Customers/Auditors:** Focus on Q08-Q10 (access mechanisms), Q17-Q32 (data visibility and incident response), and Q25-Q27 (incident management) to validate CSP transparency capabilities meet requirements.

**For Governance/Risk Teams:** Focus on Q01-Q03 (agent governance), Q11-Q16 (behavioral monitoring), and Q37-Q38 (policy violation detection) to assess control adequacy.

---

## Quality Standards Applied

This question library follows quality standards:

1. **Relevance:** All questions directly address transparency reporting requirements for AI-driven systems
2. **Specificity:** Questions request concrete evidence, procedures, and documentation
3. **Actionability:** Questions enable auditors to validate controls and stakeholders to assess transparency
4. **Perspective-Neutral:** Questions formulated without stakeholder role designation
5. **Avoidance of Duplication:** Each question addresses distinct transparency aspect
6. **Completeness:** Questions cover transparency architecture, governance, access, and incident response