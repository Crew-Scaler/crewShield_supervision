{
  "arxiv_id": "2510.01359v1",
  "title": "Breaking the Code: Security Assessment of AI Code Agents Through Systematic Jailbreaking Attacks",
  "published": "2025-10-01T18:38:20Z",
  "summary": "Code-capable large language model (LLM) agents are increasingly embedded into software engineering workflows where they can read, write, and execute code, raising the stakes of safety-bypass (\"jailbreak\") attacks beyond text-only settings. Prior evaluations emphasize refusal or harmful-text detection, leaving open whether agents actually compile and run malicious programs. We present JAWS-BENCH (Jailbreaks Across WorkSpaces), a benchmark spanning three escalating workspace regimes that mirror at",
  "category": "cs.CR",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2510.01359v1",
  "cluster": 19,
  "issue": 170,
  "downloaded_at": "2026-01-11T10:27:53.529790"
}