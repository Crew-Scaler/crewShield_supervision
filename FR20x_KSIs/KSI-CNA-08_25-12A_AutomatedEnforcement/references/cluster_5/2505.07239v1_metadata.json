{
  "arxiv_id": "2505.07239v1",
  "title": "Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity",
  "published": "2025-05-12T05:29:30Z",
  "summary": "With the growing use of large language models (LLMs) hosted on cloud platforms to offer inference services, privacy concerns about the potential leakage of sensitive information are escalating. Secure multi-party computation (MPC) is a promising solution to protect the privacy in LLM inference. However, MPC requires frequent inter-server communication, causing high performance overhead.\n  Inspired by the prevalent activation sparsity of LLMs, where most neuron are not activated after non-linear ",
  "category": "cs.CR",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2505.07239v1",
  "cluster": 5,
  "issue": 170,
  "downloaded_at": "2026-01-11T10:27:53.497509"
}