{
  "arxiv_id": "2505.04592v1",
  "title": "AI Governance to Avoid Extinction: The Strategic Landscape and Actionable Research Questions",
  "published": "2025-05-07T17:35:36Z",
  "summary": "Humanity appears to be on course to soon develop AI systems that substantially outperform human experts in all cognitive domains and activities. We believe the default trajectory has a high likelihood of catastrophe, including human extinction. Risks come from failure to control powerful AI systems, misuse of AI by malicious rogue actors, war between great powers, and authoritarian lock-in. This research agenda has two aims: to describe the strategic landscape of AI development and to catalog im",
  "category": "cs.CY",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2505.04592v1",
  "cluster": 23,
  "issue": 170,
  "downloaded_at": "2026-01-11T10:27:53.536619"
}