{
  "arxiv_id": "2601.00213v1",
  "title": "Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak",
  "published": "2026-01-01T05:14:32Z",
  "summary": "The widespread deployment of large language models (LLMs) has raised growing concerns about their misuse risks and associated safety issues. While prior studies have examined the safety of LLMs in general usage, code generation, and agent-based applications, their vulnerabilities in automated algorithm design remain underexplored. To fill this gap, this study investigates this overlooked safety vulnerability, with a particular focus on intelligent optimization algorithm design, given its prevale",
  "category": "cs.CR",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2601.00213v1",
  "cluster": 14,
  "issue": 170,
  "downloaded_at": "2026-01-11T10:27:53.518192"
}