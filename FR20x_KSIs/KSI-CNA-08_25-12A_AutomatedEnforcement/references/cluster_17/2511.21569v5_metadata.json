{
  "arxiv_id": "2511.21569v5",
  "title": "Self-Transparency Failures in Expert-Persona LLMs: How Instruction-Following Overrides Disclosure",
  "published": "2025-11-26T16:41:49Z",
  "summary": "Self-transparency is a critical safety boundary, requiring language models to honestly disclose their limitations and artificial nature. This study stress-tests this capability, investigating whether models willingly disclose their identity when assigned professional personas that conflict with transparent self-representation. When models prioritize role consistency over this boundary disclosure, users may calibrate trust based on overstated competence claims, treating AI-generated guidance as e",
  "category": "cs.AI",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2511.21569v5",
  "cluster": 17,
  "issue": 170,
  "downloaded_at": "2026-01-11T10:27:53.524014"
}