{
  "arxiv_id": "2512.03047v1",
  "title": "Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models",
  "published": "2025-11-19T17:27:16Z",
  "summary": "Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate e",
  "category": "cs.CL",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2512.03047v1",
  "cluster": 17,
  "issue": 170,
  "downloaded_at": "2026-01-11T10:27:53.524766"
}