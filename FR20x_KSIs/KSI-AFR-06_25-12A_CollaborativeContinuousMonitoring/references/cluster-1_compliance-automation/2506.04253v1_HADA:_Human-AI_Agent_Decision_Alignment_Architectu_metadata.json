{
  "arxiv_id": "2506.04253v1",
  "title": "HADA: Human-AI Agent Decision Alignment Architecture",
  "authors": [
    "Tapio Pitk\u00e4ranta",
    "Leena Pitk\u00e4ranta"
  ],
  "affiliation": "",
  "published_date": "2025-06",
  "url": "https://arxiv.org/abs/2506.04253v1",
  "relevance_score": 100.0,
  "key_topics": [
    "compliance",
    "agents",
    "orchestration"
  ],
  "summary": "We present HADA (Human-AI Agent Decision Alignment), a protocol- and framework agnostic reference architecture that keeps both large language model (LLM) agents and legacy algorithms aligned with organizational targets and values. HADA wraps any algorithm or LLM in role-specific stakeholder agents -...",
  "category": "Unknown"
}