{
  "arxiv_id": "2512.23162v3",
  "title": "SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling",
  "authors": [
    "Yufan He",
    "Pengfei Guo",
    "Mengya Xu",
    "Zhaoshuo Li",
    "Andriy Myronenko"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23162v3",
  "relevance_score": 90.0,
  "estimated_pages": 12,
  "summary": "Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kine"
}