{
  "arxiv_id": "2512.16816v1",
  "title": "Toward Systematic Counterfactual Fairness Evaluation of Large Language Models: The CAFFE Framework",
  "authors": [
    "Alessandra Parziale",
    "Gianmario Voria",
    "Valeria Pontillo",
    "Gemma Catolino",
    "Andrea De Lucia"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.16816v1",
  "relevance_score": 91.5,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring"
  ],
  "summary": "Nowadays, Large Language Models (LLMs) are foundational components of modern software systems. As their influence grows, concerns about fairness have become increasingly pressing. Prior work has proposed metamorphic testing to detect fairness issues, applying input transformations to uncover inconsistencies in model behavior. This paper introduces an alternative perspective for testing counterfactual fairness in LLMs, proposing a structured and intent-aware framework coined CAFFE (Counterfactual..."
}