{
  "arxiv_id": "2512.23200v1",
  "title": "Energy and Memory-Efficient Federated Learning With Ordered Layer Freezing",
  "authors": [
    "Ziru Niu",
    "Hai Dong",
    "A. K. Qin",
    "Tao Gu",
    "Pengcheng Zhang"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23200v1",
  "relevance_score": 90.0,
  "estimated_pages": 12,
  "summary": "Federated Learning (FL) has emerged as a privacy-preserving paradigm for training machine learning models across distributed edge devices in the Internet of Things (IoT). By keeping data local and coordinating model training through a central server, FL effectively addresses privacy concerns and reduces communication overhead. However, the limited computational power, memory, and bandwidth of IoT "
}