{
  "arxiv_id": "2512.00218v2",
  "title": "Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?",
  "authors": [
    "Matt MacDermott",
    "Qiyao Wei",
    "Rada Djoneva",
    "Francis Rhys Ward"
  ],
  "affiliation": "See author list",
  "published_date": "2025-11",
  "url": "https://arxiv.org/abs/2512.00218v2",
  "relevance_score": 81.5,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness",
    "model monitoring"
  ],
  "summary": "AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \\emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process, and hence the extent to which it can be usefully monitored, may be influenced by certain aspects of training. We investigate how different \\emph{training incentives}, applied to a reasoning model, a..."
}