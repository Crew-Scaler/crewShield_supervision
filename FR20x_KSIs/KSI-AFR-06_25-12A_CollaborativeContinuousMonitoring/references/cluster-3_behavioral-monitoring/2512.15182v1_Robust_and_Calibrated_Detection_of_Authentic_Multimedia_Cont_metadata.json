{
  "arxiv_id": "2512.15182v1",
  "title": "Robust and Calibrated Detection of Authentic Multimedia Content",
  "authors": [
    "Sarim Hashmi",
    "Abdelrahman Elsayed",
    "Mohammed Talha Alam",
    "Samuele Poppi",
    "Nils Lukas"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.15182v1",
  "relevance_score": 94.5,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness"
  ],
  "summary": "Generative models can synthesize highly realistic content, so-called deepfakes, that are already being misused at scale to undermine digital media authenticity. Current deepfake detection methods are unreliable for two reasons: (i) distinguishing inauthentic content post-hoc is often impossible (e.g., with memorized samples), leading to an unbounded false positive rate (FPR); and (ii) detection lacks robustness, as adversaries can adapt to known detectors with near-perfect accuracy using minimal..."
}