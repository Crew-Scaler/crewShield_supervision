{
  "arxiv_id": "2506.10770v3",
  "title": "From Tea Leaves to System Maps: A Survey and Framework on Context-aware Machine Learning Monitoring",
  "authors": [
    "Joran Leest",
    "Claudia Raibulet",
    "Patricia Lago",
    "Ilias Gerostathopoulos"
  ],
  "affiliation": "See author list",
  "published_date": "2025-06",
  "url": "https://arxiv.org/abs/2506.10770v3",
  "relevance_score": 84.5,
  "estimated_pages": 10,
  "key_topics": [
    "anomaly detection",
    "model monitoring"
  ],
  "summary": "Machine learning (ML) models in production fail when their broader systems -- from data pipelines to deployment environments -- deviate from training assumptions, not merely due to statistical anomalies in input data. Despite extensive work on data drift, data validation, and out-of-distribution detection, ML monitoring research remains largely model-centric while neglecting contextual information: auxiliary signals about the system around the model (external factors, data pipelines, downstream ..."
}