{
  "arxiv_id": "2512.23453v1",
  "title": "CoFi-Dec: Hallucination-Resistant Decoding via Coarse-to-Fine Generative Feedback in Large Vision-Language Models",
  "authors": [
    "Zongsheng Cao",
    "Yangfan He",
    "Anran Liu",
    "Jun Xie",
    "Feng Chen"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23453v1",
  "relevance_score": 91.2,
  "estimated_pages": 12,
  "summary": "Large Vision-Language Models (LVLMs) have achieved impressive progress in multi-modal understanding and generation. However, they still tend to produce hallucinated content that is inconsistent with the visual input, which limits their reliability in real-world applications. We propose \\textbf{CoFi-Dec}, a training-free decoding framework that mitigates hallucinations by integrating generative sel"
}