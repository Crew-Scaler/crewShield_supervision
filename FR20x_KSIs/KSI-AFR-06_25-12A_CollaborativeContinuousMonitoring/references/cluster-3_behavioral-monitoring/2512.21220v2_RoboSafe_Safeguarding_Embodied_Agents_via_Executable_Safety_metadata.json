{
  "arxiv_id": "2512.21220v2",
  "title": "RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic",
  "authors": [
    "Le Wang",
    "Zonghao Ying",
    "Xiao Yang",
    "Quanchen Zou",
    "Zhenfei Yin"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.21220v2",
  "relevance_score": 86.0,
  "estimated_pages": 12,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness",
    "vulnerability management",
    "model monitoring",
    "autonomous systems"
  ],
  "summary": "Embodied agents powered by vision-language models (VLMs) are increasingly capable of executing complex real-world tasks, yet they remain vulnerable to hazardous instructions that may trigger unsafe behaviors. Runtime safety guardrails, which intercept hazardous actions during task execution, offer a promising solution due to their flexibility. However, existing defenses often rely on static rule filters or prompt-level control, which struggle to address implicit risks arising in dynamic, tempora..."
}