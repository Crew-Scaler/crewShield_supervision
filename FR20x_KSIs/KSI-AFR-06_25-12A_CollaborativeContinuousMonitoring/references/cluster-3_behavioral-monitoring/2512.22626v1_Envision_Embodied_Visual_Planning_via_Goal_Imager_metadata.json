{
  "arxiv_id": "2512.22626v1",
  "title": "Envision: Embodied Visual Planning via Goal-Imagery Video Diffusion",
  "authors": [
    "Yuming Gu",
    "Yizhi Wang",
    "Yining Hong",
    "Yipeng Gao",
    "Hao Jiang"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.22626v1",
  "relevance_score": 82.4,
  "estimated_pages": 12,
  "summary": "Embodied visual planning aims to enable manipulation tasks by imagining how a scene evolves toward a desired goal and using the imagined trajectories to guide actions. Video diffusion models, through their image-to-video generation capability, provide a promising foundation for such visual imagination. However, existing approaches are largely forward predictive, generating trajectories conditioned"
}