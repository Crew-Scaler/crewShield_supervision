{
  "arxiv_id": "2512.24227v1",
  "title": "Mirage: One-Step Video Diffusion for Photorealistic and Coherent Asset Editing in Driving Scenes",
  "authors": [
    "Shuyun Wang",
    "Haiyang Sun",
    "Bing Wang",
    "Hangjun Ye",
    "Xin Yu"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24227v1",
  "relevance_score": 92.4,
  "estimated_pages": 12,
  "summary": "Vision-centric autonomous driving systems rely on diverse and scalable training data to achieve robust performance. While video object editing offers a promising path for data augmentation, existing methods often struggle to maintain both high visual fidelity and temporal coherence. In this work, we propose \\textbf{Mirage}, a one-step video diffusion model for photorealistic and coherent asset edi"
}