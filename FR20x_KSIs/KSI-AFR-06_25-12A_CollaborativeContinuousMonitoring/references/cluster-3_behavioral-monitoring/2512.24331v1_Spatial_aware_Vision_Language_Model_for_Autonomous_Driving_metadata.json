{
  "arxiv_id": "2512.24331v1",
  "title": "Spatial-aware Vision Language Model for Autonomous Driving",
  "authors": [
    "Weijie Wei",
    "Zhipeng Luo",
    "Ling Feng",
    "Venice Erin Liong"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24331v1",
  "relevance_score": 91.5,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness",
    "model monitoring",
    "autonomous systems"
  ],
  "summary": "While Vision-Language Models (VLMs) show significant promise for end-to-end autonomous driving by leveraging the common sense embedded in language models, their reliance on 2D image cues for complex scene understanding and decision-making presents a critical bottleneck for safety and reliability. Current image-based methods struggle with accurate metric spatial reasoning and geometric inference, leading to unreliable driving policies. To bridge this gap, we propose LVLDrive (LiDAR-Vision-Languag..."
}