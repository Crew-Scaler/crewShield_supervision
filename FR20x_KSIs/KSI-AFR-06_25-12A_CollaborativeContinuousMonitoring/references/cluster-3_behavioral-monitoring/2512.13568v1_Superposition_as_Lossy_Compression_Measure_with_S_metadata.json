{
  "arxiv_id": "2512.13568v1",
  "title": "Superposition as Lossy Compression: Measure with Sparse Autoencoders and Connect to Adversarial Vulnerability",
  "authors": [
    "Leonard Bereska",
    "Zoe Tzifa-Kratira",
    "Reza Samavi",
    "Efstratios Gavves"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.13568v1",
  "relevance_score": 92.4,
  "estimated_pages": 12,
  "summary": "Neural networks achieve remarkable performance through superposition: encoding multiple features as overlapping directions in activation space rather than dedicating individual neurons to each feature. This challenges interpretability, yet we lack principled methods to measure superposition. We present an information-theoretic framework measuring a neural representation's effective degrees of free"
}