{
  "arxiv_id": "2512.16538v1",
  "title": "A Systematic Study of Code Obfuscation Against LLM-based Vulnerability Detection",
  "authors": [
    "Xiao Li",
    "Yue Li",
    "Hao Wu",
    "Yue Zhang",
    "Yechao Zhang"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.16538v1",
  "relevance_score": 93.6,
  "estimated_pages": 12,
  "summary": "As large language models (LLMs) are increasingly adopted for code vulnerability detection, their reliability and robustness across diverse vulnerability types have become a pressing concern. In traditional adversarial settings, code obfuscation has long been used as a general strategy to bypass auditing tools, preserving exploitability without tampering with the tools themselves. Numerous efforts "
}