{
  "arxiv_id": "2501.12521v1",
  "title": "An Empirically-grounded tool for Automatic Prompt Linting and Repair: A Case Study on Bias, Vulnerability, and Optimization in Developer Prompts",
  "authors": [
    "Dhia Elhaq Rzig",
    "Dhruba Jyoti Paul",
    "Kaiser Pister",
    "Jordan Henkel",
    "Foyzul Hassan"
  ],
  "affiliation": "See author list",
  "published_date": "2025-01",
  "url": "https://arxiv.org/abs/2501.12521v1",
  "relevance_score": 91.5,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness",
    "vulnerability management",
    "model monitoring"
  ],
  "summary": "The tidal wave of advancements in Large Language Models (LLMs) has led to their swift integration into application-level logic. Many software systems now use prompts to interact with these black-box models, combining natural language with dynamic values interpolated at runtime, to perform tasks ranging from sentiment analysis to question answering. Due to the programmatic and structured natural language aspects of these prompts, we refer to them as Developer Prompts. Unlike traditional software ..."
}