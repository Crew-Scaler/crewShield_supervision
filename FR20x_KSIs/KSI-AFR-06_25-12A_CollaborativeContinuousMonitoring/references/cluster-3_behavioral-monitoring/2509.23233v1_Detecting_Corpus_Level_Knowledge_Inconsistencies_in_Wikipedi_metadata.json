{
  "arxiv_id": "2509.23233v1",
  "title": "Detecting Corpus-Level Knowledge Inconsistencies in Wikipedia with Large Language Models",
  "authors": [
    "Sina J. Semnani",
    "Jirayu Burapacheep",
    "Arpandeep Khatua",
    "Thanawan Atchariyachanvanit",
    "Zheng Wang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-09",
  "url": "https://arxiv.org/abs/2509.23233v1",
  "relevance_score": 84.5,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring",
    "autonomous systems"
  ],
  "summary": "Wikipedia is the largest open knowledge corpus, widely used worldwide and serving as a key resource for training large language models (LLMs) and retrieval-augmented generation (RAG) systems. Ensuring its accuracy is therefore critical. But how accurate is Wikipedia, and how can we improve it?\n  We focus on inconsistencies, a specific type of factual inaccuracy, and introduce the task of corpus-level inconsistency detection. We present CLAIRE, an agentic system that combines LLM reasoning with r..."
}