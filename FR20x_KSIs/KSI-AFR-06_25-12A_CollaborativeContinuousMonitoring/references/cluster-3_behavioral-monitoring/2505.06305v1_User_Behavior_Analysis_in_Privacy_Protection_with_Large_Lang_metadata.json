{
  "arxiv_id": "2505.06305v1",
  "title": "User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data",
  "authors": [
    "Haowei Yang",
    "Qingyi Lu",
    "Yang Wang",
    "Sibei Liu",
    "Jiayun Zheng"
  ],
  "affiliation": "See author list",
  "published_date": "2025-05",
  "url": "https://arxiv.org/abs/2505.06305v1",
  "relevance_score": 90.0,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring",
    "vulnerability management",
    "model monitoring"
  ],
  "summary": "With the widespread application of large language models (LLMs), user privacy protection has become a significant research topic. Existing privacy preference modeling methods often rely on large-scale user data, making effective privacy preference analysis challenging in data-limited environments. This study explores how LLMs can analyze user behavior related to privacy protection in scenarios with limited data and proposes a method that integrates Few-shot Learning and Privacy Computing to mode..."
}