{
  "arxiv_id": "2504.21042v3",
  "title": "What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift",
  "authors": [
    "Jiamin Chang",
    "Haoyang Li",
    "Hammond Pearce",
    "Ruoxi Sun",
    "Bo Li"
  ],
  "affiliation": "See author list",
  "published_date": "2025-04",
  "url": "https://arxiv.org/abs/2504.21042v3",
  "relevance_score": 84.5,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness",
    "vulnerability management",
    "model monitoring"
  ],
  "summary": "The growing adoption of artificial intelligence (AI) has amplified concerns about trustworthiness, including integrity, privacy, robustness, and bias. To assess and attribute these threats, we propose ConceptLens, a generic framework that leverages pre-trained multimodal models to identify the root causes of integrity threats by analyzing Concept Shift in probing samples. ConceptLens demonstrates strong detection performance for vanilla data poisoning attacks and uncovers vulnerabilities to bias..."
}