{
  "arxiv_id": "2512.21526v1",
  "title": "Selective LLM-Guided Regularization for Enhancing Recommendation Models",
  "authors": [
    "Shanglin Yang",
    "Zhan Shi"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.21526v1",
  "relevance_score": 91.5,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring"
  ],
  "summary": "Large language models provide rich semantic priors and strong reasoning capabilities, making them promising auxiliary signals for recommendation. However, prevailing approaches either deploy LLMs as standalone recommender or apply global knowledge distillation, both of which suffer from inherent drawbacks. Standalone LLM recommender are costly, biased, and unreliable across large regions of the user item space, while global distillation forces the downstream model to imitate LLM predictions even..."
}