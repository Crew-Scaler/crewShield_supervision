{
  "arxiv_id": "2502.11090v3",
  "title": "SafeDialBench: A Fine-Grained Safety Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks",
  "authors": [
    "Hongye Cao",
    "Yanming Wang",
    "Sijia Jing",
    "Ziyue Peng",
    "Zhixin Bai"
  ],
  "affiliation": "See author list",
  "published_date": "2025-02",
  "url": "https://arxiv.org/abs/2502.11090v3",
  "relevance_score": 81.5,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness",
    "vulnerability management",
    "model monitoring"
  ],
  "summary": "With the rapid advancement of Large Language Models (LLMs), the safety of LLMs has been a critical concern requiring precise assessment. Current benchmarks primarily concentrate on single-turn dialogues or a single jailbreak attack method to assess the safety. Additionally, these benchmarks have not taken into account the LLM's capability of identifying and handling unsafe information in detail. To address these issues, we propose a fine-grained benchmark SafeDialBench for evaluating the safety ..."
}