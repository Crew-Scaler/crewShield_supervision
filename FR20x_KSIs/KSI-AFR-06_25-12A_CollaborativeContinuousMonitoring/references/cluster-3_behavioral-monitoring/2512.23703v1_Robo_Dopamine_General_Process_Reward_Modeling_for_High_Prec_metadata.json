{
  "arxiv_id": "2512.23703v1",
  "title": "Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation",
  "authors": [
    "Huajie Tan",
    "Sixiang Chen",
    "Yijie Xu",
    "Zixiao Wang",
    "Yuheng Ji"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23703v1",
  "relevance_score": 91.5,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness",
    "autonomous systems"
  ],
  "summary": "The primary obstacle for applying reinforcement learning (RL) to real-world robotics is the design of effective reward functions. While recently learning-based Process Reward Models (PRMs) are a promising direction, they are often hindered by two fundamental limitations: their reward models lack step-aware understanding and rely on single-view perception, leading to unreliable assessments of fine-grained manipulation progress; and their reward shaping procedures are theoretically unsound, often ..."
}