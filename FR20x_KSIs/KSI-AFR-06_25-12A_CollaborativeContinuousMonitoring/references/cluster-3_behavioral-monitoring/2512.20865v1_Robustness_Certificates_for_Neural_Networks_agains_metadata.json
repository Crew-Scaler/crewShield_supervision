{
  "arxiv_id": "2512.20865v1",
  "title": "Robustness Certificates for Neural Networks against Adversarial Attacks",
  "authors": [
    "Sara Taheri",
    "Mahalakshmi Sabanayagam",
    "Debarghya Ghoshdastidar",
    "Majid Zamani"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.20865v1",
  "relevance_score": 93.6,
  "estimated_pages": 12,
  "summary": "The increasing use of machine learning in safety-critical domains amplifies the risk of adversarial threats, especially data poisoning attacks that corrupt training data to degrade performance or induce unsafe behavior. Most existing defenses lack formal guarantees or rely on restrictive assumptions about the model class, attack type, extent of poisoning, or point-wise certification, limiting thei"
}