{
  "arxiv_id": "2501.12521v1",
  "title": "An Empirically-grounded tool for Automatic Prompt Linting and Repair: A Case Study on Bias, Vulnerability, and Optimization in Developer Prompts",
  "authors": [
    "Dhia Elhaq Rzig",
    "Dhruba Jyoti Paul",
    "Kaiser Pister",
    "Jordan Henkel",
    "Foyzul Hassan"
  ],
  "published_date": "2025-01",
  "url": "https://arxiv.org/abs/2501.12521v1",
  "relevance_score": 90.0,
  "estimated_pages": 12,
  "summary": "The tidal wave of advancements in Large Language Models (LLMs) has led to their swift integration into application-level logic. Many software systems now use prompts to interact with these black-box models, combining natural language with dynamic values interpolated at runtime, to perform tasks ranging from sentiment analysis to question answering. Due to the programmatic and structured natural la"
}