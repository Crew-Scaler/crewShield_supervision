{
  "arxiv_id": "2512.23769v1",
  "title": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
  "authors": [
    "Ranit Debnath Akash",
    "Ashish Kumar",
    "Verya Monjezi",
    "Ashutosh Trivedi",
    " Gang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23769v1",
  "relevance_score": 81.5,
  "estimated_pages": 12,
  "key_topics": [],
  "summary": "Fairness in algorithmic decision-making is often framed in terms of individual fairness, which requires that similar individuals receive similar outcomes. A system violates individual fairness if there exists a pair of inputs differing only in protected attributes (such as race or gender) that lead to significantly different outcomes-for example, one favorable and the other unfavorable. While this notion highlights isolated instances of unfairness, it fails to capture broader patterns of systema..."
}