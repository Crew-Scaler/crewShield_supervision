{
  "arxiv_id": "2512.20938v1",
  "title": "Pioneering Multimodal Emotion Recognition in the Era of Large Models: From Closed Sets to Open Vocabularies",
  "authors": [
    "Jing Han",
    "Zhiqiang Gao",
    "Shihao Gao",
    "Jialing Liu",
    "Hongyu Chen"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.20938v1",
  "relevance_score": 90.0,
  "estimated_pages": 10,
  "key_topics": [
    "model monitoring"
  ],
  "summary": "Recent advances in multimodal large language models (MLLMs) have demonstrated remarkable multi- and cross-modal integration capabilities. However, their potential for fine-grained emotion understanding remains systematically underexplored. While open-vocabulary multimodal emotion recognition (MER-OV) has emerged as a promising direction to overcome the limitations of closed emotion sets, no comprehensive evaluation of MLLMs in this context currently exists. To address this, our work presents the..."
}