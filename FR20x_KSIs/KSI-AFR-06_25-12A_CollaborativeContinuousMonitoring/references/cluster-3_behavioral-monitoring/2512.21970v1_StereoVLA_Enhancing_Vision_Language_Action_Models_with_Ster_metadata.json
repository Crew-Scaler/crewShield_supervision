{
  "arxiv_id": "2512.21970v1",
  "title": "StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision",
  "authors": [
    "Shengliang Deng",
    "Mi Yan",
    "Yixin Zheng",
    "Jiayi Su",
    "Wenhao Zhang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.21970v1",
  "relevance_score": 83.0,
  "estimated_pages": 8,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness"
  ],
  "summary": "Stereo cameras closely mimic human binocular vision, providing rich spatial cues critical for precise robotic manipulation. Despite their advantage, the adoption of stereo vision in vision-language-action models (VLAs) remains underexplored. In this work, we present StereoVLA, a VLA model that leverages rich geometric cues from stereo vision. We propose a novel Geometric-Semantic Feature Extraction module that utilizes vision foundation models to extract and fuse two key features: 1) geometric f..."
}