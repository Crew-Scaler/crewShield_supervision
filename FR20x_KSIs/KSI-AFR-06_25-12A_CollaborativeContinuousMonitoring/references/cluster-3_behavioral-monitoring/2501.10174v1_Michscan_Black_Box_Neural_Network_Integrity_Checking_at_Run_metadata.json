{
  "arxiv_id": "2501.10174v1",
  "title": "Michscan: Black-Box Neural Network Integrity Checking at Runtime Through Power Analysis",
  "authors": [
    "Robi Paul",
    "Michael Zuzak"
  ],
  "affiliation": "See author list",
  "published_date": "2025-01",
  "url": "https://arxiv.org/abs/2501.10174v1",
  "relevance_score": 81.5,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness",
    "supply chain"
  ],
  "summary": "As neural networks are increasingly used for critical decision-making tasks, the threat of integrity attacks, where an adversary maliciously alters a model, has become a significant security and safety concern. These concerns are compounded by the use of licensed models, where end-users purchase third-party models with only black-box access to protect model intellectual property (IP). In such scenarios, conventional approaches to verify model integrity require knowledge of model parameters or co..."
}