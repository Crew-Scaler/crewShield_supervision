{
  "arxiv_id": "2512.08329v1",
  "title": "Interpreting Structured Perturbations in Image Protection Methods for Diffusion Models",
  "authors": [
    "Michael R. Martin",
    "Garrick Chan",
    "Kwan-Liu Ma"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.08329v1",
  "relevance_score": 86.0,
  "estimated_pages": 12,
  "key_topics": [
    "anomaly detection",
    "behavioral monitoring",
    "adversarial robustness"
  ],
  "summary": "Recent image protection mechanisms such as Glaze and Nightshade introduce imperceptible, adversarially designed perturbations intended to disrupt downstream text-to-image generative models. While their empirical effectiveness is known, the internal structure, detectability, and representational behavior of these perturbations remain poorly understood. This study provides a systematic, explainable AI analysis using a unified framework that integrates white-box feature-space inspection and black-b..."
}