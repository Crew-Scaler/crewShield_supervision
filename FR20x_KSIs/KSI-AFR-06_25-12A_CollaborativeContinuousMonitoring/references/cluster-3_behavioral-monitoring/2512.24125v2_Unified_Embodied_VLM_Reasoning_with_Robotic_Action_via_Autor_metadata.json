{
  "arxiv_id": "2512.24125v2",
  "title": "Unified Embodied VLM Reasoning with Robotic Action via Autoregressive Discretized Pre-training",
  "authors": [
    "Yi Liu",
    "Sukai Wang",
    "Dafeng Wei",
    "Xiaowei Cai",
    "Linqing Zhong"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24125v2",
  "relevance_score": 83.0,
  "estimated_pages": 12,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness"
  ],
  "summary": "General-purpose robotic systems operating in open-world environments must achieve both broad generalization and high-precision action execution, a combination that remains challenging for existing Vision-Language-Action (VLA) models. While large Vision-Language Models (VLMs) improve semantic generalization, insufficient embodied reasoning leads to brittle behavior, and conversely, strong reasoning alone is inadequate without precise control. To provide a decoupled and quantitative assessment of ..."
}