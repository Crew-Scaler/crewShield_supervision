{
  "arxiv_id": "2512.16485v1",
  "title": "Smile on the Face, Sadness in the Eyes: Bridging the Emotion Gap with a Multimodal Dataset of Eye and Facial Behaviors",
  "authors": [
    "Kejun Liu",
    "Yuanyuan Liu",
    "Lin Wei",
    "Chang Tang",
    "Yibing Zhan"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.16485v1",
  "relevance_score": 83.6,
  "estimated_pages": 12,
  "summary": "Emotion Recognition (ER) is the process of analyzing and identifying human emotions from sensing data. Currently, the field heavily relies on facial expression recognition (FER) because visual channel conveys rich emotional cues. However, facial expressions are often used as social tools rather than manifestations of genuine inner emotions. To understand and bridge this gap between FER and ER, we "
}