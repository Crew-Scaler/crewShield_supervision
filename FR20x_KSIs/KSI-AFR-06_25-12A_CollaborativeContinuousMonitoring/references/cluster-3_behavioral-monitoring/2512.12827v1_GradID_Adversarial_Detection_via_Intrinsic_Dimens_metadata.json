{
  "arxiv_id": "2512.12827v1",
  "title": "GradID: Adversarial Detection via Intrinsic Dimensionality of Gradients",
  "authors": [
    "Mohammad Mahdi Razmjoo",
    "Mohammad Mahdi Sharifian",
    "Saeed Bagheri Shouraki"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.12827v1",
  "relevance_score": 83.6,
  "estimated_pages": 12,
  "summary": "Despite their remarkable performance, deep neural networks exhibit a critical vulnerability: small, often imperceptible, adversarial perturbations can lead to drastically altered model predictions. Given the stringent reliability demands of applications such as medical diagnosis and autonomous driving, robust detection of such adversarial attacks is paramount. In this paper, we investigate the geo"
}