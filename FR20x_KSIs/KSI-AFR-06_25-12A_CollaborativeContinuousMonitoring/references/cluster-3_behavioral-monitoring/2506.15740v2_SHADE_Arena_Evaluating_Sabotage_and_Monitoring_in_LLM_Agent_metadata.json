{
  "arxiv_id": "2506.15740v2",
  "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents",
  "authors": [
    "Jonathan Kutasov",
    "Yuqi Sun",
    "Paul Colognese",
    "Teun van der Weij",
    "Linda Petrini"
  ],
  "affiliation": "See author list",
  "published_date": "2025-06",
  "url": "https://arxiv.org/abs/2506.15740v2",
  "relevance_score": 86.0,
  "estimated_pages": 12,
  "key_topics": [
    "autonomous systems"
  ],
  "summary": "As Large Language Models (LLMs) are increasingly deployed as autonomous agents in complex and long horizon settings, it is critical to evaluate their ability to sabotage users by pursuing hidden objectives. We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks. We evaluate a broad range of frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena, the first highly diverse agent evaluation da..."
}