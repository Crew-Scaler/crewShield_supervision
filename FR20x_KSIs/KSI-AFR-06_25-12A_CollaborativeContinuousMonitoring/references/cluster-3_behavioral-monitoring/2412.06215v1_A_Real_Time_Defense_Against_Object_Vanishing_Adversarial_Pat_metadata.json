{
  "arxiv_id": "2412.06215v1",
  "title": "A Real-Time Defense Against Object Vanishing Adversarial Patch Attacks for Object Detection in Autonomous Vehicles",
  "authors": [
    "Jaden Mu"
  ],
  "affiliation": "See author list",
  "published_date": "2024-12",
  "url": "https://arxiv.org/abs/2412.06215v1",
  "relevance_score": 84.0,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness",
    "model monitoring",
    "autonomous systems"
  ],
  "summary": "Autonomous vehicles (AVs) increasingly use DNN-based object detection models in vision-based perception. Correct detection and classification of obstacles is critical to ensure safe, trustworthy driving decisions. Adversarial patches aim to fool a DNN with intentionally generated patterns concentrated in a localized region of an image. In particular, object vanishing patch attacks can cause object detection models to fail to detect most or all objects in a scene, posing a significant practical t..."
}