{
  "arxiv_id": "2508.10043v1",
  "title": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System",
  "authors": [
    "Pallavi Zambare",
    "Venkata Nikhil Thanikella",
    "Ying Liu"
  ],
  "affiliation": "See author list",
  "published_date": "2025-08",
  "url": "https://arxiv.org/abs/2508.10043v1",
  "relevance_score": 90.0,
  "estimated_pages": 12,
  "key_topics": [
    "anomaly detection",
    "adversarial robustness",
    "vulnerability management",
    "model monitoring",
    "autonomous systems"
  ],
  "summary": "When combining Large Language Models (LLMs) with autonomous agents, used in network monitoring and decision-making systems, this will create serious security issues. In this research, the MAESTRO framework consisting of the seven layers threat modeling architecture in the system was used to expose, evaluate, and eliminate vulnerabilities of agentic AI. The prototype agent system was constructed and implemented, using Python, LangChain, and telemetry in WebSockets, and deployed with inference, me..."
}