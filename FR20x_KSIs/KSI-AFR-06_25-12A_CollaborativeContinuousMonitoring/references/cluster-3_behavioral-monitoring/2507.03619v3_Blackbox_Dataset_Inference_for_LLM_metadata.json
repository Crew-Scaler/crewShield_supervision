{
  "arxiv_id": "2507.03619v3",
  "title": "Blackbox Dataset Inference for LLM",
  "authors": [
    "Ruikai Zhou",
    "Kang Yang",
    "Xun Chen",
    "Wendy Hui Wang",
    "Guanhong Tao"
  ],
  "published_date": "2025-07",
  "url": "https://arxiv.org/abs/2507.03619v3",
  "relevance_score": 91.2,
  "estimated_pages": 12,
  "summary": "Today, the training of large language models (LLMs) can involve personally identifiable information and copyrighted material, incurring dataset misuse. To mitigate the problem of dataset misuse, this paper explores \\textit{dataset inference}, which aims to detect if a suspect model $\\mathcal{M}$ used a victim dataset $\\mathcal{D}$ in training. Previous research tackles dataset inference by aggrega"
}