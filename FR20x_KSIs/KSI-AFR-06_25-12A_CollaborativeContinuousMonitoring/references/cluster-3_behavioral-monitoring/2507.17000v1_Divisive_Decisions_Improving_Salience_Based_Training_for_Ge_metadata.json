{
  "arxiv_id": "2507.17000v1",
  "title": "Divisive Decisions: Improving Salience-Based Training for Generalization in Binary Classification Tasks",
  "authors": [
    "Jacob Piland",
    "Chris Sweet",
    "Adam Czajka"
  ],
  "affiliation": "See author list",
  "published_date": "2025-07",
  "url": "https://arxiv.org/abs/2507.17000v1",
  "relevance_score": 93.0,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness"
  ],
  "summary": "Existing saliency-guided training approaches improve model generalization by incorporating a loss term that compares the model's class activation map (CAM) for a sample's true-class ({\\it i.e.}, correct-label class) against a human reference saliency map. However, prior work has ignored the false-class CAM(s), that is the model's saliency obtained for incorrect-label class. We hypothesize that in binary tasks the true and false CAMs should diverge on the important classification features identif..."
}