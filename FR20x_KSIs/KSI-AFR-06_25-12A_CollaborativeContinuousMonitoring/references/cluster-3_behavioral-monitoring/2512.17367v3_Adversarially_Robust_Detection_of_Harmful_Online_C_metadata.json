{
  "arxiv_id": "2512.17367v3",
  "title": "Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach",
  "authors": [
    "Yidong Chai",
    "Yi Liu",
    "Mohammadreza Ebrahimi",
    "Weifeng Li",
    "Balaji Padmanabhan"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.17367v3",
  "relevance_score": 93.6,
  "estimated_pages": 12,
  "summary": "Social media platforms are plagued by harmful content such as hate speech, misinformation, and extremist rhetoric. Machine learning (ML) models are widely adopted to detect such content; however, they remain highly vulnerable to adversarial attacks, wherein malicious users subtly modify text to evade detection. Enhancing adversarial robustness is therefore essential, requiring detectors that can d"
}