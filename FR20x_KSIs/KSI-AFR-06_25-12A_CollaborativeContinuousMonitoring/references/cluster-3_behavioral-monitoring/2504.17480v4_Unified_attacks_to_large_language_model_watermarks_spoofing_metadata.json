{
  "arxiv_id": "2504.17480v4",
  "title": "Unified attacks to large language model watermarks: spoofing and scrubbing in unauthorized knowledge distillation",
  "authors": [
    "Xin Yi",
    "Yue Li",
    "Shunfan Zheng",
    "Linlin Wang",
    "Xiaoling Wang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-04",
  "url": "https://arxiv.org/abs/2504.17480v4",
  "relevance_score": 84.5,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness",
    "model monitoring"
  ],
  "summary": "Watermarking has emerged as a critical technique for combating misinformation and protecting intellectual property in large language models (LLMs). A recent discovery, termed watermark radioactivity, reveals that watermarks embedded in teacher models can be inherited by student models through knowledge distillation. On the positive side, this inheritance allows for the detection of unauthorized knowledge distillation by identifying watermark traces in student models. However, the robustness of w..."
}