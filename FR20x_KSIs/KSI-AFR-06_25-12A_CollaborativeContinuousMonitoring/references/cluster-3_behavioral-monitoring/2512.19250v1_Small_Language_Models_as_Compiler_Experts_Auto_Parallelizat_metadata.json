{
  "arxiv_id": "2512.19250v1",
  "title": "Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems",
  "authors": [
    "Prathamesh Devadiga"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.19250v1",
  "relevance_score": 83.0,
  "estimated_pages": 8,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness",
    "model monitoring"
  ],
  "summary": "Traditional auto-parallelizing compilers, reliant on rigid heuristics, struggle with the complexity of modern heterogeneous systems. This paper presents a comprehensive evaluation of small (approximately 1B parameter) language-model-driven compiler auto-parallelization. We evaluate three models: gemma3, llama3.2, and qwen2.5, using six reasoning strategies across 11 real-world kernels drawn from scientific computing, graph algorithms, and machine learning. Our system is benchmarked against stron..."
}