{
  "arxiv_id": "2512.24661v1",
  "title": "Do Large Language Models Know What They Are Capable Of?",
  "authors": [
    "Casey O. Barkan",
    "Sid Black",
    "Oliver Sourbut"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24661v1",
  "relevance_score": 81.5,
  "estimated_pages": 10,
  "key_topics": [
    "autonomous systems"
  ],
  "summary": "We investigate whether large language models (LLMs) can predict whether they will succeed on a given task and whether their predictions improve as they progress through multi-step tasks. We also investigate whether LLMs can learn from in-context experiences to make better decisions about whether to pursue a task in scenarios where failure is costly. All LLMs we tested are overconfident, but most predict their success with better-than-random discriminatory power. We find that newer and larger LLM..."
}