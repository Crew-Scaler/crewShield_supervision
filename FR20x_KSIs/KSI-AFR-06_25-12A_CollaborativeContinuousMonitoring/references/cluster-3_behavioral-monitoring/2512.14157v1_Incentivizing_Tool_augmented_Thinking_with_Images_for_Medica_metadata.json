{
  "arxiv_id": "2512.14157v1",
  "title": "Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis",
  "authors": [
    "Yankai Jiang",
    "Yujie Zhang",
    "Peng Zhang",
    "Yichen Li",
    "Jintai Chen"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.14157v1",
  "relevance_score": 93.0,
  "estimated_pages": 12,
  "key_topics": [
    "behavioral monitoring",
    "model monitoring",
    "autonomous systems"
  ],
  "summary": "Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seam..."
}