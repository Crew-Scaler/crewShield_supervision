{
  "arxiv_id": "2509.23281v1",
  "title": "Preventing Robotic Jailbreaking via Multimodal Domain Adaptation",
  "authors": [
    "Francesco Marchiori",
    "Rohan Sinha",
    "Christopher Agia",
    "Alexander Robey",
    "George J. Pappas"
  ],
  "affiliation": "See author list",
  "published_date": "2025-09",
  "url": "https://arxiv.org/abs/2509.23281v1",
  "relevance_score": 96.0,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness",
    "vulnerability management",
    "autonomous systems"
  ],
  "summary": "Large Language Models (LLMs) and Vision-Language Models (VLMs) are increasingly deployed in robotic environments but remain vulnerable to jailbreaking attacks that bypass safety mechanisms and drive unsafe or physically harmful behaviors in the real world. Data-driven defenses such as jailbreak classifiers show promise, yet they struggle to generalize in domains where specialized datasets are scarce, limiting their effectiveness in robotics and other safety-critical contexts. To address this gap..."
}