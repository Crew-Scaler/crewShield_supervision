{
  "arxiv_id": "2508.20890v2",
  "title": "PromptSleuth: Detecting Prompt Injection via Semantic Intent Invariance",
  "authors": [
    "Mengxiao Wang",
    "Yuxuan Zhang",
    "Guofei Gu"
  ],
  "affiliation": "See author list",
  "published_date": "2025-08",
  "url": "https://arxiv.org/abs/2508.20890v2",
  "relevance_score": 87.5,
  "estimated_pages": 12,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness",
    "vulnerability management",
    "autonomous systems"
  ],
  "summary": "Large Language Models (LLMs) are increasingly integrated into real-world applications, from virtual assistants to autonomous agents. However, their flexibility also introduces new attack vectors-particularly Prompt Injection (PI), where adversaries manipulate model behavior through crafted inputs. As attackers continuously evolve with paraphrased, obfuscated, and even multi-task injection strategies, existing benchmarks are no longer sufficient to capture the full spectrum of emerging threats.\n ..."
}