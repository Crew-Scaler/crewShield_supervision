{
  "arxiv_id": "2501.12553v2",
  "title": "ViDDAR: Vision Language Model-Based Task-Detrimental Content Detection for Augmented Reality",
  "authors": [
    "Yanming Xiu",
    "Tim Scargill",
    "Maria Gorlatova"
  ],
  "affiliation": "See author list",
  "published_date": "2025-01",
  "url": "https://arxiv.org/abs/2501.12553v2",
  "relevance_score": 83.0,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness",
    "model monitoring"
  ],
  "summary": "In Augmented Reality (AR), virtual content enhances user experience by providing additional information. However, improperly positioned or designed virtual content can be detrimental to task performance, as it can impair users' ability to accurately interpret real-world information. In this paper we examine two types of task-detrimental virtual content: obstruction attacks, in which virtual content prevents users from seeing real-world objects, and information manipulation attacks, in which virt..."
}