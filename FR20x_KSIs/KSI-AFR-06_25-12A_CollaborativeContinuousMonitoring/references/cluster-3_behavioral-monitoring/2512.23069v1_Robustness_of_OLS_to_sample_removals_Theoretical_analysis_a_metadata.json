{
  "arxiv_id": "2512.23069v1",
  "title": "Robustness of OLS to sample removals: Theoretical analysis and implications",
  "authors": [
    "Eyar Azar",
    "Michael J. Feldman",
    "Boaz Nadler"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23069v1",
  "relevance_score": 81.5,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness"
  ],
  "summary": "For learned models to be trustworthy, it is essential to verify their robustness to perturbations in the training data. Classical approaches involve uncertainty quantification via confidence intervals and bootstrap methods. In contrast, recent work proposes a more stringent form of robustness: stability to the removal of any subset of $k$ samples from the training set. In this paper, we present a theoretical study of this criterion for ordinary least squares (OLS). Our contributions are as follo..."
}