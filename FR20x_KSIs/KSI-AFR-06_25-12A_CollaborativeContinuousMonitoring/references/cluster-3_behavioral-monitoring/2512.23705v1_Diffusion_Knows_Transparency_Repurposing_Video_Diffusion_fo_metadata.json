{
  "arxiv_id": "2512.23705v1",
  "title": "Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation",
  "authors": [
    "Shaocong Xu",
    "Songlin Wei",
    "Qizhe Wei",
    "Zheng Geng",
    "Hong Li"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23705v1",
  "relevance_score": 91.5,
  "estimated_pages": 12,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness",
    "AI governance"
  ],
  "summary": "Transparent objects remain notoriously hard for perception systems: refraction, reflection and transmission break the assumptions behind stereo, ToF and purely discriminative monocular depth, causing holes and temporally unstable estimates. Our key observation is that modern video diffusion models already synthesize convincing transparent phenomena, suggesting they have internalized the optical rules. We build TransPhy3D, a synthetic video corpus of transparent/reflective scenes: 11k sequences r..."
}