{
  "arxiv_id": "2510.20314v1",
  "title": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses",
  "authors": [
    "Wu Yichao",
    "Wang Yirui",
    "Ding Panpan",
    "Wang Hailong",
    "Zhu Bingqian"
  ],
  "affiliation": "See author list",
  "published_date": "2025-10",
  "url": "https://arxiv.org/abs/2510.20314v1",
  "relevance_score": 89.0,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness",
    "model monitoring",
    "autonomous systems"
  ],
  "summary": "With the wide application of deep reinforcement learning (DRL) techniques in complex fields such as autonomous driving, intelligent manufacturing, and smart healthcare, how to improve its security and robustness in dynamic and changeable environments has become a core issue in current research. Especially in the face of adversarial attacks, DRL may suffer serious performance degradation or even make potentially dangerous decisions, so it is crucial to ensure their stability in security-sensitive..."
}