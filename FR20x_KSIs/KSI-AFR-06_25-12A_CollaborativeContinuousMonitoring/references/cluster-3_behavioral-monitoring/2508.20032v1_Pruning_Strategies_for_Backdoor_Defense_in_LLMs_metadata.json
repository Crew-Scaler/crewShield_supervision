{
  "arxiv_id": "2508.20032v1",
  "title": "Pruning Strategies for Backdoor Defense in LLMs",
  "authors": [
    "Santosh Chapagain",
    "Shah Muhammad Hamdi",
    "Soukaina Filali Boubrahimi"
  ],
  "published_date": "2025-08",
  "url": "https://arxiv.org/abs/2508.20032v1",
  "relevance_score": 92.4,
  "estimated_pages": 10,
  "summary": "Backdoor attacks are a significant threat to the performance and integrity of pre-trained language models. Although such models are routinely fine-tuned for downstream NLP tasks, recent work shows they remain vulnerable to backdoor attacks that survive vanilla fine-tuning. These attacks are difficult to defend because end users typically lack knowledge of the attack triggers. Such attacks consist "
}