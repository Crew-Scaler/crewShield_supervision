{
  "arxiv_id": "2512.11865v1",
  "title": "Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation",
  "authors": [
    "Ju-Young Kim",
    "Ji-Hong Park",
    "Myeongjun Kim",
    "Gun-Woo Kim"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.11865v1",
  "relevance_score": 84.5,
  "estimated_pages": 8,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness",
    "vulnerability management"
  ],
  "summary": "Smart farming has emerged as a key technology for advancing modern agriculture through automation and intelligent control. However, systems relying on RGB cameras for perception and robotic manipulators for control, common in smart farming, are vulnerable to photometric perturbations such as hue, illumination, and noise changes, which can cause malfunction under adversarial attacks. To address this issue, we propose an explainable adversarial-robust Vision-Language-Action model based on the Open..."
}