{
  "arxiv_id": "2512.14938v1",
  "title": "TalkVerse: Democratizing Minute-Long Audio-Driven Video Generation",
  "authors": [
    "Zhenzhi Wang",
    "Jian Wang",
    "Ke Ma",
    "Dahua Lin",
    "Bing Zhou"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.14938v1",
  "relevance_score": 84.5,
  "estimated_pages": 10,
  "key_topics": [
    "anomaly detection",
    "behavioral monitoring"
  ],
  "summary": "We introduce TalkVerse, a large-scale, open corpus for single-person, audio-driven talking video generation designed to enable fair, reproducible comparison across methods. While current state-of-the-art systems rely on closed data or compute-heavy models, TalkVerse offers 2.3 million high-resolution (720p/1080p) audio-video synchronized clips totaling 6.3k hours. These are curated from over 60k hours of video via a transparent pipeline that includes scene-cut detection, aesthetic assessment, st..."
}