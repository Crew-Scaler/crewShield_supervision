{
  "arxiv_id": "2512.23959v2",
  "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
  "authors": [
    "Chulun Zhou",
    "Chunkang Zhang",
    "Guoxin Yu",
    "Fandong Meng",
    "Jie Zhou"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23959v2",
  "relevance_score": 90.0,
  "estimated_pages": 12,
  "key_topics": [
    "behavioral monitoring"
  ],
  "summary": "Multi-step retrieval-augmented generation (RAG) has become a widely adopted strategy for enhancing large language models (LLMs) on tasks that demand global comprehension and intensive reasoning. Many RAG systems incorporate a working memory module to consolidate retrieved information. However, existing memory designs function primarily as passive storage that accumulates isolated facts for the purpose of condensing the lengthy inputs and generating new sub-queries through deduction. This static ..."
}