{
  "arxiv_id": "2512.20520v1",
  "title": "Benchmarking LLMs for Predictive Applications in the Intensive Care Units",
  "authors": [
    "Chehak Malhotra",
    "Mehak Gopal",
    "Akshaya Devadiga",
    "Pradeep Singh",
    "Ridam Pal"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.20520v1",
  "relevance_score": 81.2,
  "estimated_pages": 10,
  "summary": "With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks f"
}