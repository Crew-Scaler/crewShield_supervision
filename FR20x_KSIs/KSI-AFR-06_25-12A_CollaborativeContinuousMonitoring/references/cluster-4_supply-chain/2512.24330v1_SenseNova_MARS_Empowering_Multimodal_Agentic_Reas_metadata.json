{
  "arxiv_id": "2512.24330v1",
  "title": "SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning",
  "authors": [
    "Yong Xien Chng",
    "Tao Hu",
    "Wenwen Tong",
    "Xueheng Li",
    "Jiandong Chen"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24330v1",
  "relevance_score": 81.2,
  "estimated_pages": 12,
  "summary": "While Vision-Language Models (VLMs) can solve complex tasks through agentic reasoning, their capabilities remain largely constrained to text-oriented chain-of-thought or isolated tool invocation. They fail to exhibit the human-like proficiency required to seamlessly interleave dynamic tool manipulation with continuous reasoning, particularly in knowledge-intensive and visually complex scenarios th"
}