{
  "arxiv_id": "2512.21964v1",
  "title": "Perceive and Calibrate: Analyzing and Enhancing Robustness of Medical Multi-Modal Large Language Models",
  "authors": [
    "Dunyuan XU",
    "Xikai Yang",
    "Yaoqian Li",
    "Juzheng Miao",
    "Jinpeng Li"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.21964v1",
  "relevance_score": 80.0,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness",
    "model monitoring",
    "autonomous systems"
  ],
  "summary": "Medical Multi-modal Large Language Models (MLLMs) have shown promising clinical performance. However, their sensitivity to real-world input perturbations, such as imaging artifacts and textual errors, critically undermines their clinical applicability. Systematic analysis of such noise impact on medical MLLMs remains largely unexplored. Furthermore, while several works have investigated the MLLMs' robustness in general domains, they primarily focus on text modality and rely on costly fine-tuning..."
}