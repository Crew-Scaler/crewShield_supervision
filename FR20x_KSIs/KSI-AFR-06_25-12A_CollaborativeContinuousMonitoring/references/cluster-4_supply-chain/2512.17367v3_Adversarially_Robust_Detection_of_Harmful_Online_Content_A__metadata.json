{
  "arxiv_id": "2512.17367v3",
  "title": "Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach",
  "authors": [
    "Yidong Chai",
    "Yi Liu",
    "Mohammadreza Ebrahimi",
    "Weifeng Li",
    "Balaji Padmanabhan"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.17367v3",
  "relevance_score": 90.0,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness",
    "vulnerability management"
  ],
  "summary": "Social media platforms are plagued by harmful content such as hate speech, misinformation, and extremist rhetoric. Machine learning (ML) models are widely adopted to detect such content; however, they remain highly vulnerable to adversarial attacks, wherein malicious users subtly modify text to evade detection. Enhancing adversarial robustness is therefore essential, requiring detectors that can defend against diverse attacks (generalizability) while maintaining high overall accuracy. However, s..."
}