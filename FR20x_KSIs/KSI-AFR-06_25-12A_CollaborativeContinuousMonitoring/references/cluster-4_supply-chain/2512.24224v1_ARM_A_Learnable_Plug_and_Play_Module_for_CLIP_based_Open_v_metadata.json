{
  "arxiv_id": "2512.24224v1",
  "title": "ARM: A Learnable, Plug-and-Play Module for CLIP-based Open-vocabulary Semantic Segmentation",
  "authors": [
    "Ziquan Liu",
    "Zhewei Zhu",
    "Xuyang Shi"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24224v1",
  "relevance_score": 81.5,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness",
    "model monitoring"
  ],
  "summary": "Open-vocabulary semantic segmentation (OVSS) is fundamentally hampered by the coarse, image-level representations of CLIP, which lack precise pixel-level details. Existing training-free methods attempt to resolve this by either importing priors from costly external foundation models (e.g., SAM, DINO) or by applying static, hand-crafted heuristics to CLIP's internal features. These approaches are either computationally expensive or sub-optimal. We propose the Attention Refinement Module (ARM), a ..."
}