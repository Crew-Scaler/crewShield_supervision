{
  "arxiv_id": "2601.00828v1",
  "title": "Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis",
  "authors": [
    "Yin Li"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2601.00828v1",
  "relevance_score": 81.2,
  "estimated_pages": 10,
  "summary": "Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. T"
}