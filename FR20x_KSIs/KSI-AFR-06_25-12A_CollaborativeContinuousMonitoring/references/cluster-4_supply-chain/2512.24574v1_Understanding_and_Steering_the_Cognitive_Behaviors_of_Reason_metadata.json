{
  "arxiv_id": "2512.24574v1",
  "title": "Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time",
  "authors": [
    "Zhenyu Zhang",
    "Xiaoxia Wu",
    "Zhongzhu Zhou",
    "Qingyang Wu",
    "Yineng Zhang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24574v1",
  "relevance_score": 80.0,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring"
  ],
  "summary": "Large Language Models (LLMs) often rely on long chain-of-thought (CoT) reasoning to solve complex tasks. While effective, these trajectories are frequently inefficient, leading to high latency from excessive token generation, or unstable reasoning that alternates between underthinking (shallow, inconsistent steps) and overthinking (repetitive, verbose reasoning). In this work, we study the structure of reasoning trajectories and uncover specialized attention heads that correlate with distinct co..."
}