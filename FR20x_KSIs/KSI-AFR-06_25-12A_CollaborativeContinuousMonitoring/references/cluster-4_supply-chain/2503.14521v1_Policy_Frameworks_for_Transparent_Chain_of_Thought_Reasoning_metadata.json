{
  "arxiv_id": "2503.14521v1",
  "title": "Policy Frameworks for Transparent Chain-of-Thought Reasoning in Large Language Models",
  "authors": [
    "Yihang Chen",
    "Haikang Deng",
    "Kaiqiao Han",
    "Qingyue Zhao"
  ],
  "affiliation": "See author list",
  "published_date": "2025-03",
  "url": "https://arxiv.org/abs/2503.14521v1",
  "relevance_score": 94.5,
  "estimated_pages": 10,
  "key_topics": [
    "AI governance",
    "model monitoring"
  ],
  "summary": "Chain-of-Thought (CoT) reasoning enhances large language models (LLMs) by decomposing complex problems into step-by-step solutions, improving performance on reasoning tasks. However, current CoT disclosure policies vary widely across different models in frontend visibility, API access, and pricing strategies, lacking a unified policy framework. This paper analyzes the dual-edged implications of full CoT disclosure: while it empowers small-model distillation, fosters trust, and enables error diag..."
}