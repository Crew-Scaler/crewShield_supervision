{
  "arxiv_id": "2512.22470v1",
  "title": "DarkPatterns-LLM: A Multi-Layer Benchmark for Detecting Manipulative and Harmful AI Behavior",
  "authors": [
    "Sadia Asif",
    "Israel Antonio Rosales Laguan",
    "Haris Khan",
    "Shumaila Asif",
    "Muneeb Asif"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.22470v1",
  "relevance_score": 81.5,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring",
    "vulnerability management",
    "model monitoring"
  ],
  "summary": "The proliferation of Large Language Models (LLMs) has intensified concerns about manipulative or deceptive behaviors that can undermine user autonomy, trust, and well-being. Existing safety benchmarks predominantly rely on coarse binary labels and fail to capture the nuanced psychological and social mechanisms constituting manipulation. We introduce \\textbf{DarkPatterns-LLM}, a comprehensive benchmark dataset and diagnostic framework for fine-grained assessment of manipulative content in LLM out..."
}