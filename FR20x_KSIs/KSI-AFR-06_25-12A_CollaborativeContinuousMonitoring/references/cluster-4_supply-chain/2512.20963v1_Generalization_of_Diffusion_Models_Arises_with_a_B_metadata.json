{
  "arxiv_id": "2512.20963v1",
  "title": "Generalization of Diffusion Models Arises with a Balanced Representation Space",
  "authors": [
    "Zekai Zhang",
    "Xiao Li",
    "Xiang Li",
    "Lianghe Shi",
    "Meng Wu"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.20963v1",
  "relevance_score": 82.4,
  "estimated_pages": 10,
  "summary": "Diffusion models excel at generating high-quality, diverse samples, yet they risk memorizing training data when overfit to the training objective. We analyze the distinctions between memorization and generalization in diffusion models through the lens of representation learning. By investigating a two-layer ReLU denoising autoencoder (DAE), we prove that (i) memorization corresponds to the model s"
}