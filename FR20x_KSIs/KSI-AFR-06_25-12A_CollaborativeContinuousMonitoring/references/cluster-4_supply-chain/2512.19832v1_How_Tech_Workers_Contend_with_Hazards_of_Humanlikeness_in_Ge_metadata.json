{
  "arxiv_id": "2512.19832v1",
  "title": "How Tech Workers Contend with Hazards of Humanlikeness in Generative AI",
  "authors": [
    "Mark D\u00edaz",
    "Renee Shelby",
    "Eric Corbett",
    "Andrew Smart"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.19832v1",
  "relevance_score": 91.5,
  "estimated_pages": 10,
  "key_topics": [],
  "summary": "Generative AI's humanlike qualities are driving its rapid adoption in professional domains. However, this anthropomorphic appeal raises concerns from HCI and responsible AI scholars about potential hazards and harms, such as overtrust in system outputs. To investigate how technology workers navigate these humanlike qualities and anticipate emergent harms, we conducted focus groups with 30 professionals across six job functions (ML engineering, product policy, UX research and design, product mana..."
}