{
  "arxiv_id": "2512.23430v1",
  "title": "C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs",
  "authors": [
    "Xuan Feng",
    "Bo An",
    "Tianlong Gu",
    "Liang Chang",
    "Fengrui Hao"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23430v1",
  "relevance_score": 92.4,
  "estimated_pages": 10,
  "summary": "Bias in Large Language Models (LLMs) poses significant risks to trustworthiness, manifesting primarily as stereotypical biases (e.g., gender or racial stereotypes) and structural biases (e.g., lexical overlap or position preferences). However, prior paradigms typically address these in isolation, often mitigating one at the expense of exacerbating the other. To address this, we conduct a systemati"
}