{
  "arxiv_id": "2512.20136v2",
  "title": "M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation",
  "authors": [
    "Hyeongcheol Park",
    "Jiyoung Seo",
    "Jaewon Mun",
    "Hogun Park",
    "Wonmin Byeon"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.20136v2",
  "relevance_score": 90.0,
  "estimated_pages": 10,
  "key_topics": [
    "autonomous systems"
  ],
  "summary": "Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to fi..."
}