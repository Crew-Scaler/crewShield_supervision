{
  "arxiv_id": "2512.23547v1",
  "title": "Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs",
  "authors": [
    "Sahil Kale",
    "Antonio Luca Alfeo"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23547v1",
  "relevance_score": 81.2,
  "estimated_pages": 10,
  "summary": "Hallucinations, the generation of apparently convincing yet false statements, remain a major barrier to the safe deployment of LLMs. Building on the strong performance of self-detection methods, we examine the use of structured knowledge representations, namely knowledge graphs, to improve hallucination self-detection. Specifically, we propose a simple yet powerful approach that enriches hallucina"
}