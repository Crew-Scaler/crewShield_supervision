{
  "arxiv_id": "2512.12443v1",
  "title": "AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline",
  "authors": [
    "Akhmadillo Mamirov",
    "Faiaz Azmain",
    "Hanyu Wang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.12443v1",
  "relevance_score": 96.0,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring",
    "AI governance",
    "autonomous systems"
  ],
  "summary": "AI model documentation is fragmented across platforms and inconsistent in structure, preventing policymakers, auditors, and users from reliably assessing safety claims, data provenance, and version-level changes. We analyzed documentation from five frontier models (Gemini 3, Grok 4.1, Llama 4, GPT-5, and Claude 4.5) and 100 Hugging Face model cards, identifying 947 unique section names with extreme naming variation. Usage information alone appeared under 97 distinct labels. Using the EU AI Act A..."
}