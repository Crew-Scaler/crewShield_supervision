{
  "arxiv_id": "2512.24058v1",
  "title": "Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models",
  "authors": [
    "Rohit Kumar Salla",
    "Manoj Saravanan",
    "Shrikar Reddy Kota"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24058v1",
  "relevance_score": 80.0,
  "estimated_pages": 8,
  "key_topics": [
    "behavioral monitoring",
    "adversarial robustness",
    "model monitoring"
  ],
  "summary": "Large Language Models (LLMs) like LLaMA, Mistral, and Gemma are increasingly used in decision-critical domains such as healthcare, law, and finance, yet their reliability remains uncertain. They often make overconfident errors, degrade under input shifts, and lack clear uncertainty estimates. Existing evaluations are fragmented, addressing only isolated aspects. We introduce the Composite Reliability Score (CRS), a unified framework that integrates calibration, robustness, and uncertainty quanti..."
}