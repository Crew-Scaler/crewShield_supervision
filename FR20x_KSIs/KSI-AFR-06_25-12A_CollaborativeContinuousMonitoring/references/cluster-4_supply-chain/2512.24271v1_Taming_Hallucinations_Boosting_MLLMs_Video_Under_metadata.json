{
  "arxiv_id": "2512.24271v1",
  "title": "Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation",
  "authors": [
    "Zhe Huang",
    "Hao Wen",
    "Aiming Hao",
    "Bingze Song",
    "Meiqi Wu"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24271v1",
  "relevance_score": 92.4,
  "estimated_pages": 12,
  "summary": "Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy common sense. This limitation, stemming from the intrinsic data imbalance between text and video, is chal"
}