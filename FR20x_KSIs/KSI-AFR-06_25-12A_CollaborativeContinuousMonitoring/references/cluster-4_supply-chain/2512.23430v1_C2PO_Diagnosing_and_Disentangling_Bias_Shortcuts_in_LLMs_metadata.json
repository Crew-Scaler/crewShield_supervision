{
  "arxiv_id": "2512.23430v1",
  "title": "C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs",
  "authors": [
    "Xuan Feng",
    "Bo An",
    "Tianlong Gu",
    "Liang Chang",
    "Fengrui Hao"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23430v1",
  "relevance_score": 91.5,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness"
  ],
  "summary": "Bias in Large Language Models (LLMs) poses significant risks to trustworthiness, manifesting primarily as stereotypical biases (e.g., gender or racial stereotypes) and structural biases (e.g., lexical overlap or position preferences). However, prior paradigms typically address these in isolation, often mitigating one at the expense of exacerbating the other. To address this, we conduct a systematic exploration of these reasoning failures and identify a primary inducement: the latent spurious fea..."
}