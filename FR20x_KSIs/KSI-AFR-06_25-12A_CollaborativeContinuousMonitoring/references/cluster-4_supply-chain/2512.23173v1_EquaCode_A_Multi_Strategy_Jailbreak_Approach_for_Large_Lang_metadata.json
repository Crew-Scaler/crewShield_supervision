{
  "arxiv_id": "2512.23173v1",
  "title": "EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion",
  "authors": [
    "Zhen Liang",
    "Hai Huang",
    "Zhengkui Chen"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23173v1",
  "relevance_score": 90.0,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness"
  ],
  "summary": "Large language models (LLMs), such as ChatGPT, have achieved remarkable success across a wide range of fields. However, their trustworthiness remains a significant concern, as they are still susceptible to jailbreak attacks aimed at eliciting inappropriate or harmful responses. However, existing jailbreak attacks mainly operate at the natural language level and rely on a single attack strategy, limiting their effectiveness in comprehensively assessing LLM robustness. In this paper, we propose Eq..."
}