{
  "arxiv_id": "2512.22780v1",
  "title": "Plug In, Grade Right: Psychology-Inspired AGIQA",
  "authors": [
    "Zhicheng Liao",
    "Baoliang Chen",
    "Hanwei Zhu",
    "Lingyu Zhu",
    "Shiqi Wang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.22780v1",
  "relevance_score": 90.0,
  "estimated_pages": 12,
  "key_topics": [
    "anomaly detection",
    "model monitoring"
  ],
  "summary": "Existing AGIQA models typically estimate image quality by measuring and aggregating the similarities between image embeddings and text embeddings derived from multi-grade quality descriptions. Although effective, we observe that such similarity distributions across grades usually exhibit multimodal patterns. For instance, an image embedding may show high similarity to both \"excellent\" and \"poor\" grade descriptions while deviating from the \"good\" one. We refer to this phenomenon as \"semantic drif..."
}