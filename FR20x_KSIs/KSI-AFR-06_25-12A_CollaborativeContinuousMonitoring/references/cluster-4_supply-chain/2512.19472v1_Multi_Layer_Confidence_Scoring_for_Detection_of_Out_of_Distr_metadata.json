{
  "arxiv_id": "2512.19472v1",
  "title": "Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications",
  "authors": [
    "Lorenzo Capelli",
    "Leandro de Souza Rosa",
    "Gianluca Setti",
    "Mauro Mangia",
    "Riccardo Rovatti"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.19472v1",
  "relevance_score": 90.0,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness",
    "model monitoring"
  ],
  "summary": "The recent explosive growth in Deep Neural Networks applications raises concerns about the black-box usage of such models, with limited trasparency and trustworthiness in high-stakes domains, which have been crystallized as regulatory requirements such as the European Union Artificial Intelligence Act. While models with embedded confidence metrics have been proposed, such approaches cannot be applied to already existing models without retraining, limiting their broad application. On the other ha..."
}