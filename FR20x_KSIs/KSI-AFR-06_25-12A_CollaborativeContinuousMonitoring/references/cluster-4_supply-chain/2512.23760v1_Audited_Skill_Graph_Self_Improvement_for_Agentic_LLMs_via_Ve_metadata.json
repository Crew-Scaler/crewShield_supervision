{
  "arxiv_id": "2512.23760v1",
  "title": "Audited Skill-Graph Self-Improvement for Agentic LLMs via Verifiable Rewards, Experience Synthesis, and Continual Memory",
  "authors": [
    "Ken Huang",
    "Jerry Huang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23760v1",
  "relevance_score": 84.5,
  "estimated_pages": 12,
  "key_topics": [
    "anomaly detection",
    "behavioral monitoring",
    "AI governance",
    "model monitoring",
    "autonomous systems"
  ],
  "summary": "Reinforcement learning is increasingly used to transform large language models into agentic systems that act over long horizons, invoke tools, and manage memory under partial observability. While recent work has demonstrated performance gains through tool learning, verifiable rewards, and continual training, deployed self-improving agents raise unresolved security and governance challenges: optimization pressure can incentivize reward hacking, behavioral drift is difficult to audit or reproduce,..."
}