{
  "arxiv_id": "2512.22631v1",
  "title": "Evaluating GRPO and DPO for Faithful Chain-of-Thought Reasoning in LLMs",
  "authors": [
    "Hadi Mohammadi",
    "Tamas Kozak",
    "Anastasia Giachanou"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.22631v1",
  "relevance_score": 90.0,
  "estimated_pages": 10,
  "key_topics": [
    "behavioral monitoring",
    "model monitoring"
  ],
  "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful technique for improving the problem-solving capabilities of large language models (LLMs), particularly for tasks requiring multi-step reasoning. However, recent studies show that CoT explanations often fail to reflect the model's actual reasoning process, as models may produce coherent yet misleading justifications or modify answers without acknowledging external cues. Such discrepancies undermine the reliability of CoT-based methods for..."
}