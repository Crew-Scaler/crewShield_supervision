{
  "arxiv_id": "2512.22278v1",
  "title": "FETAL-GAUGE: A Benchmark for Assessing Vision-Language Models in Fetal Ultrasound",
  "authors": [
    "Hussain Alasmawi",
    "Numan Saeed",
    "Mohammad Yaqub"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.22278v1",
  "relevance_score": 91.5,
  "estimated_pages": 12,
  "key_topics": [
    "supply chain",
    "model monitoring"
  ],
  "summary": "The growing demand for prenatal ultrasound imaging has intensified a global shortage of trained sonographers, creating barriers to essential fetal health monitoring. Deep learning has the potential to enhance sonographers' efficiency and support the training of new practitioners. Vision-Language Models (VLMs) are particularly promising for ultrasound interpretation, as they can jointly process images and text to perform multiple clinical tasks within a single framework. However, despite the expa..."
}