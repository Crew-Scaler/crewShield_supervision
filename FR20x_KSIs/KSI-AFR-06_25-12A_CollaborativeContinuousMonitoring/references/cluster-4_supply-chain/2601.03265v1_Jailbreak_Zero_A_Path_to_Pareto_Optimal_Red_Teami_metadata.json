{
  "arxiv_id": "2601.03265v1",
  "title": "Jailbreak-Zero: A Path to Pareto Optimal Red Teaming for Large Language Models",
  "authors": [
    "Kai Hu",
    "Abhinav Aggarwal",
    "Mehran Khodabandeh",
    "David Zhang",
    "Eric Hsin"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2601.03265v1",
  "relevance_score": 92.4,
  "estimated_pages": 10,
  "summary": "This paper introduces Jailbreak-Zero, a novel red teaming methodology that shifts the paradigm of Large Language Model (LLM) safety evaluation from a constrained example-based approach to a more expansive and effective policy-based framework. By leveraging an attack LLM to generate a high volume of diverse adversarial prompts and then fine-tuning this attack model with a preference dataset, Jailbr"
}