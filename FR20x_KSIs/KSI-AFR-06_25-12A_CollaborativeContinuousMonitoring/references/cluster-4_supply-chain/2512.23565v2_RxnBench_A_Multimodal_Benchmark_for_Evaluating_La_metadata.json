{
  "arxiv_id": "2512.23565v2",
  "title": "RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature",
  "authors": [
    "Hanzheng Li",
    "Xi Fang",
    "Yixuan Li",
    "Chaozheng Huang",
    "Junjie Wang"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.23565v2",
  "relevance_score": 81.2,
  "estimated_pages": 10,
  "summary": "The integration of Multimodal Large Language Models (MLLMs) into chemistry promises to revolutionize scientific discovery, yet their ability to comprehend the dense, graphical language of reactions within authentic literature remains underexplored. Here, we introduce RxnBench, a multi-tiered benchmark designed to rigorously evaluate MLLMs on chemical reaction understanding from scientific PDFs. Rx"
}