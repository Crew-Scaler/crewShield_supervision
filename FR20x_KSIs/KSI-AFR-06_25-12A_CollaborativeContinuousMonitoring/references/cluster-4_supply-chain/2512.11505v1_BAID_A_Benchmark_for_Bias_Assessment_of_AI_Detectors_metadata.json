{
  "arxiv_id": "2512.11505v1",
  "title": "BAID: A Benchmark for Bias Assessment of AI Detectors",
  "authors": [
    "Priyam Basu",
    "Yunfeng Zhang",
    "Vipul Raheja"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.11505v1",
  "relevance_score": 81.5,
  "estimated_pages": 10,
  "key_topics": [
    "AI governance",
    "model monitoring"
  ],
  "summary": "AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 ..."
}