{
  "arxiv_id": "2512.22539v1",
  "title": "VLA-Arena: An Open-Source Framework for Benchmarking Vision-Language-Action Models",
  "authors": [
    "Borong Zhang",
    "Jiahao Li",
    "Jiachen Shen",
    "Yishuai Cai",
    "Yuhao Zhang"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.22539v1",
  "relevance_score": 90.0,
  "estimated_pages": 12,
  "key_topics": [
    "adversarial robustness"
  ],
  "summary": "While Vision-Language-Action models (VLAs) are rapidly advancing towards generalist robot policies, it remains difficult to quantitatively understand their limits and failure modes. To address this, we introduce a comprehensive benchmark called VLA-Arena. We propose a novel structured task design framework to quantify difficulty across three orthogonal axes: (1) Task Structure, (2) Language Command, and (3) Visual Observation. This allows us to systematically design tasks with fine-grained diffi..."
}