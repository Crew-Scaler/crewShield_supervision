{
  "arxiv_id": "2512.20136v2",
  "title": "M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation",
  "authors": [
    "Hyeongcheol Park",
    "Jiyoung Seo",
    "Jaewon Mun",
    "Hogun Park",
    "Wonmin Byeon"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.20136v2",
  "relevance_score": 91.2,
  "estimated_pages": 10,
  "summary": "Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, a"
}