{
  "arxiv_id": "2512.19286v2",
  "title": "GShield: Mitigating Poisoning Attacks in Federated Learning",
  "authors": [
    "Sameera K. M.",
    "Serena Nicolazzo",
    "Antonino Nocera",
    "Vinod P.",
    "Rafidha Rehiman K. A"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.19286v2",
  "relevance_score": 92.4,
  "estimated_pages": 10,
  "summary": "Federated Learning (FL) has recently emerged as a revolutionary approach to collaborative training Machine Learning models. In particular, it enables decentralized model training while preserving data privacy, but its distributed nature makes it highly vulnerable to a severe attack known as Data Poisoning. In such scenarios, malicious clients inject manipulated data into the training process, ther"
}