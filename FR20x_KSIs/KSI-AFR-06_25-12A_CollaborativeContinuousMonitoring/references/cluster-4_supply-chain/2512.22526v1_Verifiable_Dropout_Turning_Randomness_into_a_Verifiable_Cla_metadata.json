{
  "arxiv_id": "2512.22526v1",
  "title": "Verifiable Dropout: Turning Randomness into a Verifiable Claim",
  "authors": [
    "Kichang Lee",
    "Sungmin Lee",
    "Jaeho Jin",
    "JeongGil Ko"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.22526v1",
  "relevance_score": 81.5,
  "estimated_pages": 10,
  "key_topics": [
    "adversarial robustness",
    "AI governance"
  ],
  "summary": "Modern cloud-based AI training relies on extensive telemetry and logs to ensure accountability. While these audit trails enable retrospective inspection, they struggle to address the inherent non-determinism of deep learning. Stochastic operations, such as dropout, create an ambiguity surface where attackers can mask malicious manipulations as natural random variance, granting them plausible deniability. Consequently, existing logging mechanisms cannot verify whether stochastic values were gener..."
}