{
  "arxiv_id": "2511.22889v1",
  "title": "The Immutable Tensor Architecture: A Pure Dataflow Approach for Secure, Energy-Efficient AI Inference",
  "authors": [
    "Fang Li"
  ],
  "published_date": "2025-11",
  "url": "https://arxiv.org/abs/2511.22889v1",
  "relevance_score": 91.2,
  "estimated_pages": 8,
  "summary": "The deployment of Large Language Models (LLMs) on consumer edge devices is throttled by the \"Memory Wall\" -- the prohibitive bandwidth and energy cost of fetching gigabytes of model weights from DRAM for every token generated. Current architectures (GPUs, NPUs) treat model weights as mutable software data, incurring massive energy penalties to maintain general-purpose programmability. We propose T"
}