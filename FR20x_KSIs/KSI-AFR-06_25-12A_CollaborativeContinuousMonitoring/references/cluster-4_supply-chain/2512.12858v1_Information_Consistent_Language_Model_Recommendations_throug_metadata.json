{
  "arxiv_id": "2512.12858v1",
  "title": "Information-Consistent Language Model Recommendations through Group Relative Policy Optimization",
  "authors": [
    "Sonal Prabhune",
    "Balaji Padmanabhan",
    "Kaushik Dutta"
  ],
  "affiliation": "See author list",
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.12858v1",
  "relevance_score": 91.5,
  "estimated_pages": 12,
  "key_topics": [
    "behavioral monitoring",
    "AI governance"
  ],
  "summary": "Large Language Models (LLMs) are increasingly deployed in business-critical domains such as finance, education, healthcare, and customer support, where users expect consistent and reliable recommendations. Yet LLMs often exhibit variability when prompts are phrased with minor differences, even when semantically equivalent. Such inconsistency undermines trust, complicates compliance, and disrupts user experience. While personalization is desirable in certain contexts, many enterprise scenarios-su..."
}