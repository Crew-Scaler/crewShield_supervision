{
  "arxiv_id": "2512.24503v1",
  "title": "Can Small Training Runs Reliably Guide Data Curation? Rethinking Proxy-Model Practice",
  "authors": [
    "Jiachen T. Wang",
    "Tong Wu",
    "Kaifeng Lyu",
    "James Zou",
    "Dawn Song"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.24503v1",
  "relevance_score": 91.2,
  "estimated_pages": 12,
  "summary": "Data teams at frontier AI companies routinely train small proxy models to make critical decisions about pretraining data recipes for full-scale training runs. However, the community has a limited understanding of whether and when conclusions drawn from small-scale experiments reliably transfer to full-scale model training. In this work, we uncover a subtle yet critical issue in the standard experi"
}