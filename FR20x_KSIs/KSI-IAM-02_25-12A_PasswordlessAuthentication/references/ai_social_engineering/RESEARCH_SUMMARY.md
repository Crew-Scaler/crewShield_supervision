# AI-Powered Social Engineering & Credential Theft Research

**Research Date:** 2025-12-11

**Total Papers:** 45

## Distribution by Year

- 2025: 45 papers
- 2024: 0 papers

## Distribution by Topic

- LLM/Language Models: 44 papers
- Deepfakes/Synthetic Media: 1 papers
- Phishing/Social Engineering: 42 papers

## Research Focus Areas

1. **LLM-Based Social Engineering**
   - LLM-generated phishing campaigns
   - Automated social engineering attacks
   - Prompt injection and jailbreaking

2. **Deepfake & Impersonation Attacks**
   - Voice cloning for authentication bypass
   - Video deepfakes for credential theft
   - AI-powered impersonation techniques

3. **Personalization & Targeting**
   - ML-driven spear phishing
   - Behavioral analysis for targeting
   - Trust exploitation using AI

4. **Automated Attack Campaigns**
   - Generative AI for attack scaling
   - Autonomous social engineering systems
   - Campaign optimization using ML

## Downloaded Papers

### [2025] Improving Phishing Resilience with AI-Generated Training: Evidence on Prompting, Personalization, and Duration

**Authors:** Francesco Greco, Giuseppe Desolda, Cesare Tucci et al. (6 total)

**ArXiv ID:** 2512.01893v1

**Categories:** cs.CR

**Estimated Pages:** 8

**Abstract:** Phishing remains a persistent cybersecurity threat; however, developing scalable and effective user training is labor-intensive and challenging to maintain. Generative Artificial Intelligence offers an interesting opportunity, but empirical evidence on its instructional efficacy remains scarce. This...

**PDF:** 2512.01893v1.pdf

---

### [2025] Constructing and Benchmarking: a Labeled Email Dataset for Text-Based Phishing and Spam Detection Framework

**Authors:** Rebeka Toth, Tamas Bisztray, Richard Dubniczky

**ArXiv ID:** 2511.21448v1

**Categories:** cs.CR, cs.AI, cs.DB

**Estimated Pages:** 8

**Abstract:** Phishing and spam emails remain a major cybersecurity threat, with attackers increasingly leveraging Large Language Models (LLMs) to craft highly deceptive content. This study presents a comprehensive email dataset containing phishing, spam, and legitimate messages, explicitly distinguishing between...

**PDF:** 2511.21448v1.pdf

---

### [2025] Small Language Models for Phishing Website Detection: Cost, Performance, and Privacy Trade-Offs

**Authors:** Georg Goldenits, Philip Koenig, Sebastian Raubitzek et al. (4 total)

**ArXiv ID:** 2511.15434v1

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 10

**Abstract:** Phishing websites pose a major cybersecurity threat, exploiting unsuspecting users and causing significant financial and organisational harm. Traditional machine learning approaches for phishing detection often require extensive feature engineering, continuous retraining, and costly infrastructure m...

**PDF:** 2511.15434v1.pdf

---

### [2025] How Can We Effectively Use LLMs for Phishing Detection?: Evaluating the Effectiveness of Large Language Model-based Phishing Detection Models

**Authors:** Fujiao Ji, Doowon Kim

**ArXiv ID:** 2511.09606v2

**Categories:** cs.CR

**Estimated Pages:** 10

**Abstract:** Large language models (LLMs) have emerged as a promising phishing detection mechanism, addressing the limitations of traditional deep learning-based detectors, including poor generalization to previously unseen websites and a lack of interpretability. However, LLMs' effectiveness for phishing detect...

**PDF:** 2511.09606v2.pdf

---

### [2025] Trustworthiness Calibration Framework for Phishing Email Detection Using Large Language Models

**Authors:** Daniyal Ganiuly, Assel Smaiyl

**ArXiv ID:** 2511.04728v1

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 10

**Abstract:** Phishing emails continue to pose a persistent challenge to online communication, exploiting human trust and evading automated filters through realistic language and adaptive tactics. While large language models (LLMs) such as GPT-4 and LLaMA-3-8B achieve strong accuracy in text classification, their...

**PDF:** 2511.04728v1.pdf

---

### [2025] Network Intrusion Detection: Evolution from Conventional Approaches to LLM Collaboration and Emerging Risks

**Authors:** Yaokai Feng, Kouichi Sakurai

**ArXiv ID:** 2510.23313v2

**Categories:** cs.CR

**Estimated Pages:** 29

**Abstract:** This survey systematizes the evolution of network intrusion detection systems (NIDS), from conventional methods such as signature-based and neural network (NN)-based approaches to recent integrations with large language models (LLMs). It clearly and concisely summarizes the current status, strengths...

**PDF:** 2510.23313v2.pdf

---

### [2025] CLASP: Cost-Optimized LLM-based Agentic System for Phishing Detection

**Authors:** Fouad Trad, Ali Chehab

**ArXiv ID:** 2510.18585v1

**Categories:** cs.CR

**Estimated Pages:** 10

**Abstract:** Phishing websites remain a significant cybersecurity threat, necessitating accurate and cost-effective detection mechanisms. In this paper, we present CLASP, a novel system that effectively identifies phishing websites by leveraging multiple intelligent agents, built using large language models (LLM...

**PDF:** 2510.18585v1.pdf

---

### [2025] Robust ML-based Detection of Conventional, LLM-Generated, and Adversarial Phishing Emails Using Advanced Text Preprocessing

**Authors:** Deeksha Hareesha Kulal, Chidozie Princewill Arannonu, Afsah Anwar et al. (5 total)

**ArXiv ID:** 2510.11915v1

**Categories:** cs.CR

**Estimated Pages:** 10

**Abstract:** Phishing remains a critical cybersecurity threat, especially with the advent of large language models (LLMs) capable of generating highly convincing malicious content. Unlike earlier phishing attempts which are identifiable by grammatical errors, misspellings, incorrect phrasing, and inconsistent fo...

**PDF:** 2510.11915v1.pdf

---

### [2025] "Your AI, My Shell": Demystifying Prompt Injection Attacks on Agentic AI Coding Editors

**Authors:** Yue Liu, Yanjie Zhao, Yunbo Lyu et al. (6 total)

**ArXiv ID:** 2509.22040v1

**Categories:** cs.CR, cs.SE

**Estimated Pages:** 10

**Abstract:** Agentic AI coding editors driven by large language models have recently become more popular due to their ability to improve developer productivity during software development. Modern editors such as Cursor are designed not just for code completion, but also with more system privileges for complex co...

**PDF:** 2509.22040v1.pdf

---

### [2025] EvoMail: Self-Evolving Cognitive Agents for Adaptive Spam and Phishing Email Defense

**Authors:** Wei Huang, De-Tian Chu, Lin-Yuan Bai et al. (9 total)

**ArXiv ID:** 2509.21129v1

**Categories:** cs.LG, cs.CR

**Estimated Pages:** 10

**Abstract:** Modern email spam and phishing attacks have evolved far beyond keyword blacklists or simple heuristics. Adversaries now craft multi-modal campaigns that combine natural-language text with obfuscated URLs, forged headers, and malicious attachments, adapting their strategies within days to bypass filt...

**PDF:** 2509.21129v1.pdf

---

### [2025] Send to which account? Evaluation of an LLM-based Scambaiting System

**Authors:** Hossein Siadati, Haadi Jafarian, Sima Jafarikhah

**ArXiv ID:** 2509.08493v1

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 10

**Abstract:** Scammers are increasingly harnessing generative AI(GenAI) technologies to produce convincing phishing content at scale, amplifying financial fraud and undermining public trust. While conventional defenses, such as detection algorithms, user training, and reactive takedown efforts remain important, t...

**PDF:** 2509.08493v1.pdf

---

### [2025] A Decade-long Landscape of Advanced Persistent Threats: Longitudinal Analysis and Global Trends

**Authors:** Shakhzod Yuldoshkhujaev, Mijin Jeon, Doowon Kim et al. (5 total)

**ArXiv ID:** 2509.07457v1

**Categories:** cs.CR

**Estimated Pages:** 18

**Abstract:** An advanced persistent threat (APT) refers to a covert, long-term cyberattack, typically conducted by state-sponsored actors, targeting critical sectors and often remaining undetected for long periods. In response, collective intelligence from around the globe collaborates to identify and trace surr...

**PDF:** 2509.07457v1.pdf

---

### [2025] Paladin: Defending LLM-enabled Phishing Emails with a New Trigger-Tag Paradigm

**Authors:** Yan Pang, Wenlong Meng, Xiaojing Liao et al. (4 total)

**ArXiv ID:** 2509.07287v1

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 20

**Abstract:** With the rapid development of large language models, the potential threat of their malicious use, particularly in generating phishing content, is becoming increasingly prevalent. Leveraging the capabilities of LLMs, malicious users can synthesize phishing emails that are free from spelling mistakes ...

**PDF:** 2509.07287v1.pdf

---

### [2025] Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs

**Authors:** Ilham Wicaksono, Zekun Wu, Rahul Patel et al. (6 total)

**ArXiv ID:** 2509.04802v2

**Categories:** cs.CL

**Estimated Pages:** 10

**Abstract:** As large language models transition to agentic systems, current safety evaluation frameworks face critical gaps in assessing deployment-specific risks. We introduce AgentSeer, an observability-based evaluation framework that decomposes agentic executions into granular action and component graphs, en...

**PDF:** 2509.04802v2.pdf

---

### [2025] E-PhishGen: Unlocking Novel Research in Phishing Email Detection

**Authors:** Luca Pajola, Eugenio Caripoti, Stefan Banzer et al. (6 total)

**ArXiv ID:** 2509.01791v2

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 10

**Abstract:** Every day, our inboxes are flooded with unsolicited emails, ranging between annoying spam to more subtle phishing scams. Unfortunately, despite abundant prior efforts proposing solutions achieving near-perfect accuracy, the reality is that countering malicious emails still remains an unsolved dilemm...

**PDF:** 2509.01791v2.pdf

---

### [2025] SoK: Exposing the Generation and Detection Gaps in LLM-Generated Phishing Through Examination of Generation Methods, Content Characteristics, and Countermeasures

**Authors:** Fengchao Chen, Tingmin Wu, Van Nguyen et al. (4 total)

**ArXiv ID:** 2508.21457v2

**Categories:** cs.CR

**Estimated Pages:** 18

**Abstract:** Phishing campaigns involve adversaries masquerading as trusted vendors trying to trigger user behavior that enables them to exfiltrate private data. While URLs are an important part of phishing campaigns, communicative elements like text and images are central in triggering the required user behavio...

**PDF:** 2508.21457v2.pdf

---

### [2025] CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments

**Authors:** Nitish Jaipuria, Lorenzo Gatto, Zijun Kan et al. (9 total)

**ArXiv ID:** 2508.19932v1

**Categories:** cs.AI

**Estimated Pages:** 10

**Abstract:** The proliferation of digital payment platforms has transformed commerce, offering unmatched convenience and accessibility globally. However, this growth has also attracted malicious actors, leading to a corresponding increase in sophisticated social engineering scams. These scams are often initiated...

**PDF:** 2508.19932v1.pdf

---

### [2025] Invitation Is All You Need! Promptware Attacks Against LLM-Powered Assistants in Production Are Practical and Dangerous

**Authors:** Ben Nassi, Stav Cohen, Or Yair

**ArXiv ID:** 2508.12175v1

**Categories:** cs.CR

**Estimated Pages:** 10

**Abstract:** The growing integration of LLMs into applications has introduced new security risks, notably known as Promptware - maliciously engineered prompts designed to manipulate LLMs to compromise the CIA triad of these applications. While prior research warned about a potential shift in the threat landscape...

**PDF:** 2508.12175v1.pdf

---

### [2025] Per-sender neural network classifiers for email authorship validation

**Authors:** Rohit Dube

**ArXiv ID:** 2509.00005v1

**Categories:** cs.CR, cs.AI, stat.AP

**Estimated Pages:** 11

**Abstract:** Business email compromise and lateral spear phishing attacks are among modern organizations' most costly and damaging threats. While inbound phishing defenses have improved significantly, most organizations still trust internal emails by default, leaving themselves vulnerable to attacks from comprom...

**PDF:** 2509.00005v1.pdf

---

### [2025] PhishParrot: LLM-Driven Adaptive Crawling to Unveil Cloaked Phishing Sites

**Authors:** Hiroki Nakano, Takashi Koide, Daiki Chiba

**ArXiv ID:** 2508.02035v1

**Categories:** cs.CR

**Estimated Pages:** 8

**Abstract:** Phishing attacks continue to evolve, with cloaking techniques posing a significant challenge to detection efforts. Cloaking allows attackers to display phishing sites only to specific users while presenting legitimate pages to security crawlers, rendering traditional detection systems ineffective. T...

**PDF:** 2508.02035v1.pdf

---

### [2025] LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora

**Authors:** Estelle Ruellan, Eric Clay, Nicholas Ascoli

**ArXiv ID:** 2507.23611v1

**Categories:** cs.CR, cs.AI, cs.CV

**Estimated Pages:** 10

**Abstract:** Infostealers exfiltrate credentials, session cookies, and sensitive data from infected systems. With over 29 million stealer logs reported in 2024, manual analysis and mitigation at scale are virtually unfeasible/unpractical. While most research focuses on proactive malware detection, a significant ...

**PDF:** 2507.23611v1.pdf

---

### [2025] Can We End the Cat-and-Mouse Game? Simulating Self-Evolving Phishing Attacks with LLMs and Genetic Algorithms

**Authors:** Seiji Sato, Tetsushi Ohki, Masakatsu Nishigaki

**ArXiv ID:** 2507.21538v1

**Categories:** cs.CR

**Estimated Pages:** 8

**Abstract:** Anticipating emerging attack methodologies is crucial for proactive cybersecurity. Recent advances in Large Language Models (LLMs) have enabled the automated generation of phishing messages and accelerated research into potential attack techniques. However, predicting future threats remains challeng...

**PDF:** 2507.21538v1.pdf

---

### [2025] Talking Like a Phisher: LLM-Based Attacks on Voice Phishing Classifiers

**Authors:** Wenhao Li, Selvakumar Manickam, Yung-wey Chong et al. (4 total)

**ArXiv ID:** 2507.16291v1

**Categories:** cs.CR

**Estimated Pages:** 8

**Abstract:** Voice phishing (vishing) remains a persistent threat in cybersecurity, exploiting human trust through persuasive speech. While machine learning (ML)-based classifiers have shown promise in detecting malicious call transcripts, they remain vulnerable to adversarial manipulations that preserve semanti...

**PDF:** 2507.16291v1.pdf

---

### [2025] PhishIntentionLLM: Uncovering Phishing Website Intentions through Multi-Agent Retrieval-Augmented Generation

**Authors:** Wenhao Li, Selvakumar Manickam, Yung-wey Chong et al. (4 total)

**ArXiv ID:** 2507.15419v1

**Categories:** cs.CR

**Estimated Pages:** 8

**Abstract:** Phishing websites remain a major cybersecurity threat, yet existing methods primarily focus on detection, while the recognition of underlying malicious intentions remains largely unexplored. To address this gap, we propose PhishIntentionLLM, a multi-agent retrieval-augmented generation (RAG) framewo...

**PDF:** 2507.15419v1.pdf

---

### [2025] PiMRef: Detecting and Explaining Ever-evolving Spear Phishing Emails with Knowledge Base Invariants

**Authors:** Ruofan Liu, Yun Lin, Silas Yeo Shuen Yu et al. (6 total)

**ArXiv ID:** 2507.15393v1

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 10

**Abstract:** Phishing emails are a critical component of the cybercrime kill chain due to their wide reach and low cost. Their ever-evolving nature renders traditional rule-based and feature-engineered detectors ineffective in the ongoing arms race between attackers and defenders. The rise of large language mode...

**PDF:** 2507.15393v1.pdf

---

### [2025] Exploiting Jailbreaking Vulnerabilities in Generative AI to Bypass Ethical Safeguards for Facilitating Phishing Attacks

**Authors:** Rina Mishra, Gaurav Varshney

**ArXiv ID:** 2507.12185v1

**Categories:** cs.CR

**Estimated Pages:** 10

**Abstract:** The advent of advanced Generative AI (GenAI) models such as DeepSeek and ChatGPT has significantly reshaped the cybersecurity landscape, introducing both promising opportunities and critical risks. This study investigates how GenAI powered chatbot services can be exploited via jailbreaking technique...

**PDF:** 2507.12185v1.pdf

---

### [2025] Can Large Language Models Improve Phishing Defense? A Large-Scale Controlled Experiment on Warning Dialogue Explanations

**Authors:** Federico Maria Cau, Giuseppe Desolda, Francesco Greco et al. (5 total)

**ArXiv ID:** 2507.07916v1

**Categories:** cs.CR, cs.HC

**Estimated Pages:** 10

**Abstract:** Phishing has become a prominent risk in modern cybersecurity, often used to bypass technological defences by exploiting predictable human behaviour. Warning dialogues are a standard mitigation measure, but the lack of explanatory clarity and static content limits their effectiveness. In this paper, ...

**PDF:** 2507.07916v1.pdf

---

### [2025] Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models

**Authors:** Jikesh Thapa, Gurrehmat Chahal, Serban Voinea Gabreanu et al. (4 total)

**ArXiv ID:** 2507.07406v1

**Categories:** cs.CR, cs.AI, cs.LG

**Estimated Pages:** 8

**Abstract:** Phishing attacks are becoming increasingly sophisticated, underscoring the need for detection systems that strike a balance between high accuracy and computational efficiency. This paper presents a comparative evaluation of traditional Machine Learning (ML), Deep Learning (DL), and quantized small-p...

**PDF:** 2507.07406v1.pdf

---

### [2025] AI Generated Text Detection Using Instruction Fine-tuned Large Language and Transformer-Based Models

**Authors:** Chinnappa Guggilla, Budhaditya Roy, Trupti Ramdas Chavan et al. (5 total)

**ArXiv ID:** 2507.05157v1

**Categories:** cs.CL, cs.AI

**Estimated Pages:** 7

**Abstract:** Large Language Models (LLMs) possess an extraordinary capability to produce text that is not only coherent and contextually relevant but also strikingly similar to human writing. They adapt to various styles and genres, producing content that is both grammatically correct and semantically meaningful...

**PDF:** 2507.05157v1.pdf

---

### [2025] From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows

**Authors:** Mohamed Amine Ferrag, Norbert Tihanyi, Djallel Hamouda et al. (5 total)

**ArXiv ID:** 2506.23260v1

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 29

**Abstract:** Autonomous AI agents powered by large language models (LLMs) with structured function-calling interfaces have dramatically expanded capabilities for real-time data retrieval, complex computation, and multi-step orchestration. Yet, the explosive proliferation of plugins, connectors, and inter-agent p...

**PDF:** 2506.23260v1.pdf

---

### [2025] Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models

**Authors:** Atharva Bhargude, Ishan Gonehal, Dave Yoon et al. (7 total)

**ArXiv ID:** 2507.13357v2

**Categories:** cs.CL

**Estimated Pages:** 9

**Abstract:** Phishing attacks represent a significant cybersecurity threat, necessitating adaptive detection techniques. This study explores few-shot Adaptive Linguistic Prompting (ALP) in detecting phishing webpages through the multimodal capabilities of state-of-the-art large language models (LLMs) such as GPT...

**PDF:** 2507.13357v2.pdf

---

### [2025] PhishDebate: An LLM-Based Multi-Agent Framework for Phishing Website Detection

**Authors:** Wenhao Li, Selvakumar Manickam, Yung-wey Chong et al. (4 total)

**ArXiv ID:** 2506.15656v1

**Categories:** cs.CR

**Estimated Pages:** 8

**Abstract:** Phishing websites continue to pose a significant cybersecurity threat, often leveraging deceptive structures, brand impersonation, and social engineering tactics to evade detection. While recent advances in large language models (LLMs) have enabled improved phishing detection through contextual unde...

**PDF:** 2506.15656v1.pdf

---

### [2025] LLM-Powered Intent-Based Categorization of Phishing Emails

**Authors:** Even Eilertsen, Vasileios Mavroeidis, Gudmund Grov

**ArXiv ID:** 2506.14337v1

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 8

**Abstract:** Phishing attacks remain a significant threat to modern cybersecurity, as they successfully deceive both humans and the defense mechanisms intended to protect them. Traditional detection systems primarily focus on email metadata that users cannot see in their inboxes. Additionally, these systems stru...

**PDF:** 2506.14337v1.pdf

---

### [2025] Evaluating Large Language Models for Phishing Detection, Self-Consistency, Faithfulness, and Explainability

**Authors:** Shova Kuikel, Aritran Piplai, Palvi Aggarwal

**ArXiv ID:** 2506.13746v1

**Categories:** cs.CR, cs.AI, cs.LG

**Estimated Pages:** 10

**Abstract:** Phishing attacks remain one of the most prevalent and persistent cybersecurity threat with attackers continuously evolving and intensifying tactics to evade the general detection system. Despite significant advances in artificial intelligence and machine learning, faithfully reproducing the interpre...

**PDF:** 2506.13746v1.pdf

---

### [2025] From Promise to Peril: Rethinking Cybersecurity Red and Blue Teaming in the Age of LLMs

**Authors:** Alsharif Abuadbba, Chris Hicks, Kristen Moore et al. (7 total)

**ArXiv ID:** 2506.13434v1

**Categories:** cs.CR

**Estimated Pages:** 10

**Abstract:** Large Language Models (LLMs) are set to reshape cybersecurity by augmenting red and blue team operations. Red teams can exploit LLMs to plan attacks, craft phishing content, simulate adversaries, and generate exploit code. Conversely, blue teams may deploy them for threat intelligence synthesis, roo...

**PDF:** 2506.13434v1.pdf

---

### [2025] ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams

**Authors:** Freddie Grabovski, Gilad Gressel, Yisroel Mirsky

**ArXiv ID:** 2506.11125v1

**Categories:** cs.CL, cs.AI

**Estimated Pages:** 8

**Abstract:** Large Language Models (LLMs), combined with Text-to-Speech (TTS) and Automatic Speech Recognition (ASR), are increasingly used to automate voice phishing (vishing) scams. These systems are scalable and convincing, posing a significant security threat. We identify the ASR transcription step as the mo...

**PDF:** 2506.11125v1.pdf

---

### [2025] Mind the Web: The Security of Web Use Agents

**Authors:** Avishag Shapira, Parth Atulbhai Gandhi, Edan Habler et al. (4 total)

**ArXiv ID:** 2506.07153v2

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 10

**Abstract:** Web-use agents are rapidly being deployed to automate complex web tasks with extensive browser capabilities. However, these capabilities create a critical and previously unexplored attack surface. This paper demonstrates how attackers can exploit web-use agents by embedding malicious content in web ...

**PDF:** 2506.07153v2.pdf

---

### [2025] Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text

**Authors:** Yize Cheng, Vinu Sankar Sadasivan, Mehrdad Saberi et al. (5 total)

**ArXiv ID:** 2506.07001v2

**Categories:** cs.CL

**Estimated Pages:** 10

**Abstract:** The increasing capabilities of Large Language Models (LLMs) have raised concerns about their misuse in AI-generated plagiarism and social engineering. While various AI-generated text detectors have been proposed to mitigate these risks, many remain vulnerable to simple evasion techniques such as par...

**PDF:** 2506.07001v2.pdf

---

### [2025] Client-Side Zero-Shot LLM Inference for Comprehensive In-Browser URL Analysis

**Authors:** Avihay Cohen

**ArXiv ID:** 2506.03656v1

**Categories:** cs.CR

**Estimated Pages:** 46

**Abstract:** Malicious websites and phishing URLs pose an ever-increasing cybersecurity risk, with phishing attacks growing by 40% in a single year. Traditional detection approaches rely on machine learning classifiers or rule-based scanners operating in the cloud, but these face significant challenges in genera...

**PDF:** 2506.03656v1.pdf

---

### [2025] Cascading Adversarial Bias from Injection to Distillation in Language Models

**Authors:** Harsh Chaudhari, Jamie Hayes, Matthew Jagielski et al. (6 total)

**ArXiv ID:** 2505.24842v2

**Categories:** cs.LG, cs.CR

**Estimated Pages:** 10

**Abstract:** Model distillation has become essential for creating smaller, deployable language models that retain larger system capabilities. However, widespread deployment raises concerns about resilience to adversarial manipulation. This paper investigates vulnerability of distilled models to adversarial injec...

**PDF:** 2505.24842v2.pdf

---

### [2025] MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment

**Authors:** John Halloran

**ArXiv ID:** 2505.23634v1

**Categories:** cs.LG, cs.CR

**Estimated Pages:** 27

**Abstract:** The model context protocol (MCP) has been widely adapted as an open standard enabling the seamless integration of generative AI agents. However, recent work has shown the MCP is susceptible to retrieval-based "falsely benign" attacks (FBAs), allowing malicious system access and credential theft, but...

**PDF:** 2505.23634v1.pdf

---

### [2025] MultiPhishGuard: An LLM-based Multi-Agent System for Phishing Email Detection

**Authors:** Yinuo Xue, Eric Spero, Yun Sing Koh et al. (4 total)

**ArXiv ID:** 2505.23803v1

**Categories:** cs.CR, cs.AI

**Estimated Pages:** 10

**Abstract:** Phishing email detection faces critical challenges from evolving adversarial tactics and heterogeneous attack patterns. Traditional detection methods, such as rule-based filters and denylists, often struggle to keep pace with these evolving tactics, leading to false negatives and compromised securit...

**PDF:** 2505.23803v1.pdf

---

### [2025] Cracking Aegis: An Adversarial LLM-based Game for Raising Awareness of Vulnerabilities in Privacy Protection

**Authors:** Jiaying Fu, Yiyang Lu, Zehua Yang et al. (5 total)

**ArXiv ID:** 2505.16954v1

**Categories:** cs.HC

**Estimated Pages:** 24

**Abstract:** Traditional methods for raising awareness of privacy protection often fail to engage users or provide hands-on insights into how privacy vulnerabilities are exploited. To address this, we incorporate an adversarial mechanic in the design of the dialogue-based serious game Cracking Aegis. Leveraging ...

**PDF:** 2505.16954v1.pdf

---

### [2025] The Impact of Emerging Phishing Threats: Assessing Quishing and LLM-generated Phishing Emails against Organizations

**Authors:** Marie Weinz, Nicola Zannone, Luca Allodi et al. (4 total)

**ArXiv ID:** 2505.12104v1

**Categories:** cs.CR

**Estimated Pages:** 10

**Abstract:** Modern organizations are persistently targeted by phishing emails. Despite advances in detection systems and widespread employee training, attackers continue to innovate, posing ongoing threats. Two emerging vectors stand out in the current landscape: QR-code baits and LLM-enabled pretexting. Yet, l...

**PDF:** 2505.12104v1.pdf

---

### [2025] Joint Detection of Fraud and Concept Drift inOnline Conversations with LLM-Assisted Judgment

**Authors:** Ali Senol, Garima Agrawal, Huan Liu

**ArXiv ID:** 2505.07852v1

**Categories:** cs.CL, cs.AI, cs.LG

**Estimated Pages:** 10

**Abstract:** Detecting fake interactions in digital communication platforms remains a challenging and insufficiently addressed problem. These interactions may appear as harmless spam or escalate into sophisticated scam attempts, making it difficult to flag malicious intent early. Traditional detection methods of...

**PDF:** 2505.07852v1.pdf

---

