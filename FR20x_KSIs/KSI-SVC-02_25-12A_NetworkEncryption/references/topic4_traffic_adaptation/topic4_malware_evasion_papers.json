[
  {
    "id": "http://arxiv.org/abs/2510.12310v1",
    "arxiv_id": "2510.12310v1",
    "title": "DeepTrust: Multi-Step Classification through Dissimilar Adversarial Representations for Robust Android Malware Detection",
    "summary": "Over the last decade, machine learning has been extensively applied to identify malicious Android applications. However, such approaches remain vulnerable against adversarial examples, i.e., examples that are subtly manipulated to fool a machine learning model into making incorrect predictions. This research presents DeepTrust, a novel metaheuristic that arranges flexible classifiers, like deep neural networks, into an ordered sequence where the final decision is made by a single internal model based on conditions activated in cascade. In the Robust Android Malware Detection competition at the 2025 IEEE Conference SaTML, DeepTrust secured the first place and achieved state-of-the-art results, outperforming the next-best competitor by up to 266% under feature-space evasion attacks. This is accomplished while maintaining the highest detection rate on non-adversarial malware and a false positive rate below 1%. The method's efficacy stems from maximizing the divergence of the learned representations among the internal models. By using classifiers inducing fundamentally dissimilar embeddings of the data, the decision space becomes unpredictable for an attacker. This frustrates the iterative perturbation process inherent to evasion attacks, enhancing system robustness without compromising accuracy on clean examples.",
    "published": "2025-10-14T09:10:23Z",
    "updated": "2025-10-14T09:10:23Z",
    "authors": [
      "Daniel Pulido-Cort\u00e1zar",
      "Daniel Gibert",
      "Felip Many\u00e0"
    ],
    "affiliations": [],
    "first_author": "Daniel Pulido-Cort\u00e1zar",
    "pdf_url": "https://arxiv.org/pdf/2510.12310v1",
    "primary_category": "cs.CR",
    "relevance_score": 14.0
  },
  {
    "id": "http://arxiv.org/abs/2501.10996v1",
    "arxiv_id": "2501.10996v1",
    "title": "Effectiveness of Adversarial Benign and Malware Examples in Evasion and Poisoning Attacks",
    "summary": "Adversarial attacks present significant challenges for malware detection systems. This research investigates the effectiveness of benign and malicious adversarial examples (AEs) in evasion and poisoning attacks on the Portable Executable file domain. A novel focus of this study is on benign AEs, which, although not directly harmful, can increase false positives and undermine trust in antivirus solutions. We propose modifying existing adversarial malware generators to produce benign AEs and show they are as successful as malware AEs in evasion attacks. Furthermore, our data show that benign AEs have a more decisive influence in poisoning attacks than standard malware AEs, demonstrating their superior ability to decrease the model's performance. Our findings introduce new opportunities for adversaries and further increase the attack surface that needs to be protected by security researchers.",
    "published": "2025-01-19T09:44:58Z",
    "updated": "2025-01-19T09:44:58Z",
    "authors": [
      "Matou\u0161 Koz\u00e1k",
      "Martin Jure\u010dek"
    ],
    "affiliations": [],
    "first_author": "Matou\u0161 Koz\u00e1k",
    "pdf_url": "https://arxiv.org/pdf/2501.10996v1",
    "primary_category": "cs.CR",
    "relevance_score": 14.0
  },
  {
    "id": "http://arxiv.org/abs/2511.17761v1",
    "arxiv_id": "2511.17761v1",
    "title": "StealthCup: Realistic, Multi-Stage, Evasion-Focused CTF for Benchmarking IDS",
    "summary": "Intrusion Detection Systems (IDS) are critical to defending enterprise and industrial control environments, yet evaluating their effectiveness under realistic conditions remains an open challenge. Existing benchmarks rely on synthetic datasets (e.g., NSL-KDD, CICIDS2017) or scripted replay frameworks, which fail to capture adaptive adversary behavior. Even MITRE ATT&CK Evaluations, while influential, are host-centric and assume malware-driven compromise, thereby under-representing stealthy, multi-stage intrusions across IT and OT domains. We present StealthCup, a novel evaluation methodology that operationalizes IDS benchmarking as an evasion-focused Capture-the-Flag competition. Professional penetration testers engaged in multi-stage attack chains on a realistic IT/OT testbed, with scoring penalizing IDS detections. The event generated structured attacker writeups, validated detections, and PCAPs, host logs, and alerts. Our results reveal that out of 32 exercised attack techniques, 11 were not detected by any IDS configuration. Open-source systems (Wazuh, Suricata) produced high false-positive rates >90%, while commercial tools generated fewer false positives but also missed more attacks. Comparison with the Volt Typhoon APT advisory confirmed strong realism: all 28 applicable techniques were exercised, 19 appeared in writeups, and 9 in forensic traces. These findings demonstrate that StealthCup elicits attacker behavior closely aligned with state-sponsored TTPs, while exposing blind spots across both open-source and commercial IDS. The resulting datasets and methodology provide a reproducible foundation for future stealth-focused IDS evaluation.",
    "published": "2025-11-21T20:17:59Z",
    "updated": "2025-11-21T20:17:59Z",
    "authors": [
      "Manuel Kern",
      "Dominik Steffan",
      "Felix Schuster",
      "Florian Skopik",
      "Max Landauer",
      "David Allison",
      "Simon Freudenthaler",
      "Edgar Weippl"
    ],
    "affiliations": [],
    "first_author": "Manuel Kern",
    "pdf_url": "https://arxiv.org/pdf/2511.17761v1",
    "primary_category": "cs.CR",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2511.04440v1",
    "arxiv_id": "2511.04440v1",
    "title": "Adversarially Robust and Interpretable Magecart Malware Detection",
    "summary": "Magecart skimming attacks have emerged as a significant threat to client-side security and user trust in online payment systems. This paper addresses the challenge of achieving robust and explainable detection of Magecart attacks through a comparative study of various Machine Learning (ML) models with a real-world dataset. Tree-based, linear, and kernel-based models were applied, further enhanced through hyperparameter tuning and feature selection, to distinguish between benign and malicious scripts. Such models are supported by a Behavior Deterministic Finite Automaton (DFA) which captures structural behavior patterns in scripts, helping to analyze and classify client-side script execution logs. To ensure robustness against adversarial evasion attacks, the ML models were adversarially trained and evaluated using attacks from the Adversarial Robustness Toolbox and the Adaptative Perturbation Pattern Method. In addition, concise explanations of ML model decisions are provided, supporting transparency and user trust. Experimental validation demonstrated high detection performance and interpretable reasoning, demonstrating that traditional ML models can be effective in real-world web security contexts.",
    "published": "2025-11-06T15:13:29Z",
    "updated": "2025-11-06T15:13:29Z",
    "authors": [
      "Pedro Pereira",
      "Jos\u00e9 Gouveia",
      "Jo\u00e3o Vitorino",
      "Eva Maia",
      "Isabel Pra\u00e7a"
    ],
    "affiliations": [],
    "first_author": "Pedro Pereira",
    "pdf_url": "https://arxiv.org/pdf/2511.04440v1",
    "primary_category": "cs.CR",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2508.08656v1",
    "arxiv_id": "2508.08656v1",
    "title": "Evasive Ransomware Attacks Using Low-level Behavioral Adversarial Examples",
    "summary": "Protecting state-of-the-art AI-based cybersecurity defense systems from cyber attacks is crucial. Attackers create adversarial examples by adding small changes (i.e., perturbations) to the attack features to evade or fool the deep learning model. This paper introduces the concept of low-level behavioral adversarial examples and its threat model of evasive ransomware. We formulate the method and the threat model to generate the optimal source code of evasive malware. We then examine the method using the leaked source code of Conti ransomware with the micro-behavior control function. The micro-behavior control function is our test component to simulate changing source code in ransomware; ransomware's behavior can be changed by specifying the number of threads, file encryption ratio, and delay after file encryption at the boot time. We evaluated how much an attacker can control the behavioral features of ransomware using the micro-behavior control function to decrease the detection rate of a ransomware detector.",
    "published": "2025-08-12T05:45:28Z",
    "updated": "2025-08-12T05:45:28Z",
    "authors": [
      "Manabu Hirano",
      "Ryotaro Kobayashi"
    ],
    "affiliations": [],
    "first_author": "Manabu Hirano",
    "pdf_url": "https://arxiv.org/pdf/2508.08656v1",
    "primary_category": "cs.CR",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2505.09342v2",
    "arxiv_id": "2505.09342v2",
    "title": "Evaluating the robustness of adversarial defenses in malware detection systems",
    "summary": "Machine learning is a key tool for Android malware detection, effectively identifying malicious patterns in apps. However, ML-based detectors are vulnerable to evasion attacks, where small, crafted changes bypass detection. Despite progress in adversarial defenses, the lack of comprehensive evaluation frameworks in binary-constrained domains limits understanding of their robustness. We introduce two key contributions. First, Prioritized Binary Rounding, a technique to convert continuous perturbations into binary feature spaces while preserving high attack success and low perturbation size. Second, the sigma-binary attack, a novel adversarial method for binary domains, designed to achieve attack goals with minimal feature changes. Experiments on the Malscan dataset show that sigma-binary outperforms existing attacks and exposes key vulnerabilities in state-of-the-art defenses. Defenses equipped with adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant brittleness, with attack success rates exceeding 90% using fewer than 10 feature modifications and reaching 100% with just 20. Adversarially trained defenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small budgets but remains vulnerable to unrestricted perturbations, with attack success rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates strong robustness against state-of-the-art gradient-based adversarial attacks by maintaining an attack success rate below 16.55%, the sigma-binary attack significantly outperforms these methods, achieving a 94.56% success rate under unrestricted perturbations. These findings highlight the critical need for precise method like sigma-binary to expose hidden vulnerabilities in existing defenses and support the development of more resilient malware detection systems.",
    "published": "2025-05-14T12:38:43Z",
    "updated": "2025-12-08T15:56:17Z",
    "authors": [
      "Mostafa Jafari",
      "Alireza Shameli-Sendi"
    ],
    "affiliations": [],
    "first_author": "Mostafa Jafari",
    "pdf_url": "https://arxiv.org/pdf/2505.09342v2",
    "primary_category": "cs.CR",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2504.14886v1",
    "arxiv_id": "2504.14886v1",
    "title": "Zero Day Malware Detection with Alpha: Fast DBI with Transformer Models for Real World Application",
    "summary": "The effectiveness of an AI model in accurately classifying novel malware hinges on the quality of the features it is trained on, which in turn depends on the effectiveness of the analysis tool used. Peekaboo, a Dynamic Binary Instrumentation (DBI) tool, defeats malware evasion techniques to capture authentic behavior at the Assembly (ASM) instruction level. This behavior exhibits patterns consistent with Zipf's law, a distribution commonly seen in natural languages, making Transformer models particularly effective for binary classification tasks. We introduce Alpha, a framework for zero day malware detection that leverages Transformer models and ASM language. Alpha is trained on malware and benign software data collected through Peekaboo, enabling it to identify entirely new samples with exceptional accuracy. Alpha eliminates any common functions from the test samples that are in the training dataset. This forces the model to rely on contextual patterns and novel ASM instruction combinations to detect malicious behavior, rather than memorizing familiar features. By combining the strengths of DBI, ASM analysis, and Transformer architectures, Alpha offers a powerful approach to proactively addressing the evolving threat of malware. Alpha demonstrates perfect accuracy for Ransomware, Worms and APTs with flawless classification for both malicious and benign samples. The results highlight the model's exceptional performance in detecting truly new malware samples.",
    "published": "2025-04-21T06:30:21Z",
    "updated": "2025-04-21T06:30:21Z",
    "authors": [
      "Matthew Gaber",
      "Mohiuddin Ahmed",
      "Helge Janicke"
    ],
    "affiliations": [],
    "first_author": "Matthew Gaber",
    "pdf_url": "https://arxiv.org/pdf/2504.14886v1",
    "primary_category": "cs.CR",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2510.18324v1",
    "arxiv_id": "2510.18324v1",
    "title": "CryptoGuard: Lightweight Hybrid Detection and Response to Host-based Cryptojackers in Linux Cloud Environments",
    "summary": "Host-based cryptomining malware, commonly known as cryptojackers, have gained notoriety for their stealth and the significant financial losses they cause in Linux-based cloud environments. Existing solutions often struggle with scalability due to high monitoring overhead, low detection accuracy against obfuscated behavior, and lack of integrated remediation. We present CryptoGuard, a lightweight hybrid solution that combines detection and remediation strategies to counter cryptojackers. To ensure scalability, CryptoGuard uses sketch- and sliding window-based syscall monitoring to collect behavior patterns with minimal overhead. It decomposes the classification task into a two-phase process, leveraging deep learning models to identify suspicious activity with high precision. To counter evasion techniques such as entry point poisoning and PID manipulation, CryptoGuard integrates targeted remediation mechanisms based on eBPF, a modern Linux kernel feature deployable on any compatible host. Evaluated on 123 real-world cryptojacker samples, it achieves average F1-scores of 96.12% and 92.26% across the two phases, and outperforms state-of-the-art baselines in terms of true and false positive rates, while incurring only 0.06% CPU overhead per host.",
    "published": "2025-10-21T06:15:48Z",
    "updated": "2025-10-21T06:15:48Z",
    "authors": [
      "Gyeonghoon Park",
      "Jaehan Kim",
      "Jinu Choi",
      "Jinwoo Kim"
    ],
    "affiliations": [],
    "first_author": "Gyeonghoon Park",
    "pdf_url": "https://arxiv.org/pdf/2510.18324v1",
    "primary_category": "cs.CR",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2510.16251v1",
    "arxiv_id": "2510.16251v1",
    "title": "LibIHT: A Hardware-Based Approach to Efficient and Evasion-Resistant Dynamic Binary Analysis",
    "summary": "Dynamic program analysis is invaluable for malware detection, debugging, and performance profiling. However, software-based instrumentation incurs high overhead and can be evaded by anti-analysis techniques. In this paper, we propose LibIHT, a hardware-assisted tracing framework that leverages on-CPU branch tracing features (Intel Last Branch Record and Branch Trace Store) to efficiently capture program control-flow with minimal performance impact. Our approach reconstructs control-flow graphs (CFGs) by collecting hardware generated branch execution data in the kernel, preserving program behavior against evasive malware. We implement LibIHT as an OS kernel module and user-space library, and evaluate it on both benign benchmark programs and adversarial anti-instrumentation samples. Our results indicate that LibIHT reduces runtime overhead by over 150x compared to Intel Pin (7x vs 1,053x slowdowns), while achieving high fidelity in CFG reconstruction (capturing over 99% of execution basic blocks and edges). Although this hardware-assisted approach sacrifices the richer semantic detail available from full software instrumentation by capturing only branch addresses, this trade-off is acceptable for many applications where performance and low detectability are paramount. Our findings show that hardware-based tracing captures control flow information significantly faster, reduces detection risk and performs dynamic analysis with minimal interference.",
    "published": "2025-10-17T22:42:33Z",
    "updated": "2025-10-17T22:42:33Z",
    "authors": [
      "Changyu Zhao",
      "Yohan Beugin",
      "Jean-Charles Noirot Ferrand",
      "Quinn Burke",
      "Guancheng Li",
      "Patrick McDaniel"
    ],
    "affiliations": [],
    "first_author": "Changyu Zhao",
    "pdf_url": "https://arxiv.org/pdf/2510.16251v1",
    "primary_category": "cs.CR",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2509.22113v2",
    "arxiv_id": "2509.22113v2",
    "title": "Countering adversarial evasion in regression analysis",
    "summary": "Adversarial machine learning challenges the assumption that the underlying distribution remains consistent throughout the training and implementation of a prediction model. In particular, adversarial evasion considers scenarios where adversaries adapt their data to influence particular outcomes from established prediction models, such scenarios arise in applications such as spam email filtering, malware detection and fake-image generation, where security methods must be actively updated to keep up with the ever-improving generation of malicious data. Game theoretic models have been shown to be effective at modelling these scenarios and hence training resilient predictors against such adversaries. Recent advancements in the use of pessimistic bilevel optimsiation which remove assumptions about the convexity and uniqueness of the adversary's optimal strategy have proved to be particularly effective at mitigating threats to classifiers due to its ability to capture the antagonistic nature of the adversary. However, this formulation has not yet been adapted to regression scenarios. This article serves to propose a pessimistic bilevel optimisation program for regression scenarios which makes no assumptions on the convexity or uniqueness of the adversary's solutions.",
    "published": "2025-09-26T09:35:26Z",
    "updated": "2025-11-29T22:37:32Z",
    "authors": [
      "David Benfield",
      "Phan Tu Vuong",
      "Alain Zemkoho"
    ],
    "affiliations": [],
    "first_author": "David Benfield",
    "pdf_url": "https://arxiv.org/pdf/2509.22113v2",
    "primary_category": "cs.LG",
    "relevance_score": 10.0
  }
]