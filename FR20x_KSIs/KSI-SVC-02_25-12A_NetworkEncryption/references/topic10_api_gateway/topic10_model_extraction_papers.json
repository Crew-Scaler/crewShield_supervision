[
  {
    "id": "http://arxiv.org/abs/2512.20619v1",
    "arxiv_id": "2512.20619v1",
    "title": "SemanticGen: Video Generation in Semantic Space",
    "summary": "State-of-the-art video generative models typically learn the distribution of video latents in the VAE space and map them to pixels using a VAE decoder. While this approach can generate high-quality videos, it suffers from slow convergence and is computationally expensive when generating long videos. In this paper, we introduce SemanticGen, a novel solution to address these limitations by generating videos in the semantic space. Our main insight is that, due to the inherent redundancy in videos, the generation process should begin in a compact, high-level semantic space for global planning, followed by the addition of high-frequency details, rather than directly modeling a vast set of low-level video tokens using bi-directional attention. SemanticGen adopts a two-stage generation process. In the first stage, a diffusion model generates compact semantic video features, which define the global layout of the video. In the second stage, another diffusion model generates VAE latents conditioned on these semantic features to produce the final output. We observe that generation in the semantic space leads to faster convergence compared to the VAE latent space. Our method is also effective and computationally efficient when extended to long video generation. Extensive experiments demonstrate that SemanticGen produces high-quality videos and outperforms state-of-the-art approaches and strong baselines.",
    "published": "2025-12-23T18:59:56Z",
    "updated": "2025-12-23T18:59:56Z",
    "authors": [
      "Jianhong Bai",
      "Xiaoshi Wu",
      "Xintao Wang",
      "Fu Xiao",
      "Yuanxing Zhang",
      "Qinghe Wang",
      "Xiaoyu Shi",
      "Menghan Xia",
      "Zuozhu Liu",
      "Haoji Hu",
      "Pengfei Wan",
      "Kun Gai"
    ],
    "affiliations": [],
    "first_author": "Jianhong Bai",
    "pdf_url": "https://arxiv.org/pdf/2512.20619v1",
    "primary_category": "cs.CV",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20618v1",
    "arxiv_id": "2512.20618v1",
    "title": "LongVideoAgent: Multi-Agent Reasoning with Long Videos",
    "summary": "Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.",
    "published": "2025-12-23T18:59:49Z",
    "updated": "2025-12-23T18:59:49Z",
    "authors": [
      "Runtao Liu",
      "Ziyi Liu",
      "Jiaqi Tang",
      "Yue Ma",
      "Renjie Pi",
      "Jipeng Zhang",
      "Qifeng Chen"
    ],
    "affiliations": [],
    "first_author": "Runtao Liu",
    "pdf_url": "https://arxiv.org/pdf/2512.20618v1",
    "primary_category": "cs.AI",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20617v1",
    "arxiv_id": "2512.20617v1",
    "title": "SpatialTree: How Spatial Abilities Branch Out in MLLMs",
    "summary": "Cognitive science suggests that spatial ability develops progressively-from perception to reasoning and interaction. Yet in multimodal LLMs (MLLMs), this hierarchy remains poorly understood, as most studies focus on a narrow set of tasks. We introduce SpatialTree, a cognitive-science-inspired hierarchy that organizes spatial abilities into four levels: low-level perception (L1), mental mapping (L2), simulation (L3), and agentic competence (L4). Based on this taxonomy, we construct the first capability-centric hierarchical benchmark, thoroughly evaluating mainstream MLLMs across 27 sub-abilities. The evaluation results reveal a clear structure: L1 skills are largely orthogonal, whereas higher-level skills are strongly correlated, indicating increasing interdependency. Through targeted supervised fine-tuning, we uncover a surprising transfer dynamic-negative transfer within L1, but strong cross-level transfer from low- to high-level abilities with notable synergy. Finally, we explore how to improve the entire hierarchy. We find that naive RL that encourages extensive \"thinking\" is unreliable: it helps complex reasoning but hurts intuitive perception. We propose a simple auto-think strategy that suppresses unnecessary deliberation, enabling RL to consistently improve performance across all levels. By building SpatialTree, we provide a proof-of-concept framework for understanding and systematically scaling spatial abilities in MLLMs.",
    "published": "2025-12-23T18:59:46Z",
    "updated": "2025-12-23T18:59:46Z",
    "authors": [
      "Yuxi Xiao",
      "Longfei Li",
      "Shen Yan",
      "Xinhang Liu",
      "Sida Peng",
      "Yunchao Wei",
      "Xiaowei Zhou",
      "Bingyi Kang"
    ],
    "affiliations": [],
    "first_author": "Yuxi Xiao",
    "pdf_url": "https://arxiv.org/pdf/2512.20617v1",
    "primary_category": "cs.CV",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20616v1",
    "arxiv_id": "2512.20616v1",
    "title": "Dynamical Dark Energy models in light of the latest observations",
    "summary": "In this paper, we study several models and parameterizations of dynamical dark energy (DE) that have been studied already in the past, in conjunction with the recently proposed model $w$XCDM, the running vacuum model (RVM) with and without a threshold at $z=1$ and two variants of it, the RRVM and the ``flipped RVM'', and compare them all with the concordance $\u039b$CDM model and the popular $w_0w_a$CDM parameterization. We use two standard sets of cosmological data, one including distant supernovae from Pantheon$+$ and the other from DES-Y5. The rest of the data (BAO from DESI DR2 and CMB from Planck PR4) are shared by the two sets. They are analyzed with the help of \\texttt{CLASS}. No structure formation data are utilized for this analysis and no use is made of the SH0ES calibration of $H_0$. Even so, we find that the flipped RVM and to a lesser extent the $w$XCDM and the RVM with threshold, point to significant evidence of dynamical DE, at a level comparable to $w_0w_a$CDM, more conspicuously for the dataset that involves DES-Y5 observations. We also find that while more traditional models studied in the past, in which there is an exchange between vacuum energy and cold dark matter (through e.g. an interactive source proportional either to the density of dark matter or to that of vacuum) still hint at dynamical DE, the strength of the statistical signal (which we assess through information criteria and other estimators) is nevertheless less pronounced. Finally, we discuss the ability of the various models to explain the data by performing an analysis of their effective equation-of-state parameters and corresponding evolution of their dark energy densities.",
    "published": "2025-12-23T18:59:29Z",
    "updated": "2025-12-23T18:59:29Z",
    "authors": [
      "Javier de Cruz P\u00e9rez",
      "Adri\u00e0 G\u00f3mez-Valent",
      "Joan Sol\u00e0 Peracaula"
    ],
    "affiliations": [],
    "first_author": "Javier de Cruz P\u00e9rez",
    "pdf_url": "https://arxiv.org/pdf/2512.20616v1",
    "primary_category": "astro-ph.CO",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20615v1",
    "arxiv_id": "2512.20615v1",
    "title": "Active Intelligence in Video Avatars via Closed-loop World Modeling",
    "summary": "Current video avatar generation methods excel at identity preservation and motion alignment but lack genuine agency, they cannot autonomously pursue long-term goals through adaptive environmental interaction. We address this by introducing L-IVA (Long-horizon Interactive Visual Avatar), a task and benchmark for evaluating goal-directed planning in stochastic generative environments, and ORCA (Online Reasoning and Cognitive Architecture), the first framework enabling active intelligence in video avatars. ORCA embodies Internal World Model (IWM) capabilities through two key innovations: (1) a closed-loop OTAR cycle (Observe-Think-Act-Reflect) that maintains robust state tracking under generative uncertainty by continuously verifying predicted outcomes against actual generations, and (2) a hierarchical dual-system architecture where System 2 performs strategic reasoning with state prediction while System 1 translates abstract plans into precise, model-specific action captions. By formulating avatar control as a POMDP and implementing continuous belief updating with outcome verification, ORCA enables autonomous multi-step task completion in open-domain scenarios. Extensive experiments demonstrate that ORCA significantly outperforms open-loop and non-reflective baselines in task success rate and behavioral coherence, validating our IWM-inspired design for advancing video avatar intelligence from passive animation to active, goal-oriented behavior.",
    "published": "2025-12-23T18:59:16Z",
    "updated": "2025-12-23T18:59:16Z",
    "authors": [
      "Xuanhua He",
      "Tianyu Yang",
      "Ke Cao",
      "Ruiqi Wu",
      "Cheng Meng",
      "Yong Zhang",
      "Zhuoliang Kang",
      "Xiaoming Wei",
      "Qifeng Chen"
    ],
    "affiliations": [],
    "first_author": "Xuanhua He",
    "pdf_url": "https://arxiv.org/pdf/2512.20615v1",
    "primary_category": "cs.CV",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20614v1",
    "arxiv_id": "2512.20614v1",
    "title": "Tunably realizing flat-bands and exceptional points in kinetically frustrated systems: An example on the non-Hermitian Creutz ladder",
    "summary": "We study a non-Hermitian extension of the Creutz ladder with generic non-reciprocal hopping. By mapping the ladder onto two decoupled non-Hermitian Su--Schrieffer--Heeger (SSH) chains, we uncover a rich structure in parameter space under different boundary conditions. Under periodic boundary conditions, the spectrum admits a fine-tuned line in parameter space with entirely real eigenvalues, while deviations from this line induce a real--complex spectral transition without crossing exceptional points. In contrast, an exact analytical diagonalization under open boundary conditions reveals extended regions in parameter space with purely real or purely imaginary spectra, separated from complex spectral domains by exceptional lines. The intersections of these exceptional lines define triple-junction points where distinct spectral regimes meet, giving rise to a structured phase diagram that is absent under periodic boundary conditions. We further show that flat bands in this system can occur both as Hermitian diabolical points and as non-Hermitian exceptional points, known as exceptional flat bands, where the dynamics is more stringent than in the Hermitian case, leading to distinct spectral and dynamical signatures.",
    "published": "2025-12-23T18:58:36Z",
    "updated": "2025-12-23T18:58:36Z",
    "authors": [
      "Debashish Dutta",
      "Sayan Choudhury"
    ],
    "affiliations": [],
    "first_author": "Debashish Dutta",
    "pdf_url": "https://arxiv.org/pdf/2512.20614v1",
    "primary_category": "quant-ph",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20613v1",
    "arxiv_id": "2512.20613v1",
    "title": "Variational (matrix) product states for combinatorial optimization",
    "summary": "To compute approximate solutions for combinatorial optimization problems, we describe variational methods based on the product state (PS) and matrix product state (MPS) ansatzes. We perform variational energy minimization with respect to a quantum annealing Hamiltonian and utilize randomness by embedding the approaches in the metaheuristic iterated local search (ILS). The resulting quantum-inspired ILS algorithms are benchmarked on maximum cut problems of up to 50000 variables. We show that they can outperform traditional (M)PS methods, classical ILS, the quantum approximate optimization algorithm and other variational quantum-inspired solvers.",
    "published": "2025-12-23T18:58:35Z",
    "updated": "2025-12-23T18:58:35Z",
    "authors": [
      "Guillermo Preisser",
      "Conor Mc Keever",
      "Michael Lubasch"
    ],
    "affiliations": [],
    "first_author": "Guillermo Preisser",
    "pdf_url": "https://arxiv.org/pdf/2512.20613v1",
    "primary_category": "quant-ph",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20612v1",
    "arxiv_id": "2512.20612v1",
    "title": "Making Large Language Models Efficient Dense Retrievers",
    "summary": "Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.",
    "published": "2025-12-23T18:58:25Z",
    "updated": "2025-12-23T18:58:25Z",
    "authors": [
      "Yibin Lei",
      "Shwai He",
      "Ang Li",
      "Andrew Yates"
    ],
    "affiliations": [],
    "first_author": "Yibin Lei",
    "pdf_url": "https://arxiv.org/pdf/2512.20612v1",
    "primary_category": "cs.IR",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20611v1",
    "arxiv_id": "2512.20611v1",
    "title": "Single-LED-pumped, room-temperature, solid-state maser",
    "summary": "Through their ability to achieve `cryogenic' levels of noise performance while operating at room temperature, optically-pumped, solid-state (OPSS) masers show great promise as quantum sensors, oscillators, and amplifiers. We here demonstrate maser oscillation in a microwave cavity containing a crystal of pentacene-doped \\textit{para}-terphenyl (ptc:ptp) pumped by a single, chip-scale LED. Here, unlike previous work, the size of the pump source no longer dominates the size of the maser system as a whole. This miniaturization is achieved through invasive optical pumping in the form of a waveguide, the tip of which is embedded into the maser crystal. Combining experimental measurements with ray-tracing analysis, we find that our approach offers at least a factor of 2 enhancement in the cooperativity over end-on optical excitation.",
    "published": "2025-12-23T18:58:21Z",
    "updated": "2025-12-23T18:58:21Z",
    "authors": [
      "Michael Newns",
      "Shirley Xu",
      "Mingyang Liu",
      "Zike Cheng",
      "Zike Cheng",
      "Ziqiu Huang",
      "Max Attwood",
      "Mark Oxborrow"
    ],
    "affiliations": [],
    "first_author": "Michael Newns",
    "pdf_url": "https://arxiv.org/pdf/2512.20611v1",
    "primary_category": "quant-ph",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20610v1",
    "arxiv_id": "2512.20610v1",
    "title": "FedPOD: the deployable units of training for federated learning",
    "summary": "This paper proposes FedPOD (Proportionally Orchestrated Derivative) for optimizing learning efficiency and communication cost in federated learning among multiple clients. Inspired by FedPIDAvg, we define a round-wise task for FedPOD to enhance training efficiency. FedPIDAvg achieved performance improvement by incorporating the training loss reduction for prediction entropy as weights using differential terms. Furthermore, by modeling data distribution with a Poisson distribution and using a PID controller, it reduced communication costs even in skewed data distribution. However, excluding participants classified as outliers based on the Poisson distribution can limit data utilization. Additionally, PID controller requires the same participants to be maintained throughout the federated learning process as it uses previous rounds' learning information in the current round. In our approach, FedPOD addresses these issues by including participants excluded as outliers, eliminating dependency on previous rounds' learning information, and applying a method for calculating validation loss at each round. In this challenge, FedPOD presents comparable performance to FedPIDAvg in metrics of Dice score, 0.78, 0.71 and 0.72 for WT, ET and TC in average, and projected convergence score, 0.74 in average. Furthermore, the concept of FedPOD draws inspiration from Kubernetes' smallest computing unit, POD, designed to be compatible with Kubernetes auto-scaling. Extending round-wise tasks of FedPOD to POD units allows flexible design by applying scale-out similar to Kubernetes' auto-scaling. This work demonstrated the potentials of FedPOD to enhance federated learning by improving efficiency, flexibility, and performance in metrics.",
    "published": "2025-12-23T18:57:53Z",
    "updated": "2025-12-23T18:57:53Z",
    "authors": [
      "Daewoon Kim",
      "Si Young Yie",
      "Jae Sung Lee"
    ],
    "affiliations": [],
    "first_author": "Daewoon Kim",
    "pdf_url": "https://arxiv.org/pdf/2512.20610v1",
    "primary_category": "cs.CV",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20609v1",
    "arxiv_id": "2512.20609v1",
    "title": "Revealing Electron-Ytterbium Interactions through Rydberg Molecular Spectroscopy",
    "summary": "Divalent atoms have emerged as powerful alternatives to alkalis in ultracold atom platforms, offering unique advantages arising from their two-electron structure. Among these species, ytterbium (Yb) is especially promising, yet its anionic properties and its Rydberg spectrum remain comparatively unexplored. In this work, we perform a first and comprehensive experimental and theoretical investigation of ultralong-range Rydberg molecules (ULRMs) of $^{174}$Yb in $6sns\\,^1S_0$ Rydberg states across nearly two decades in principal quantum number $n$ and three orders of magnitude in molecular binding energy. Using the Coulomb Green's function formalism, we compute Born-Oppenheimer molecular potentials describing the Rydberg atom in the presence of a ground-state perturber and achieve quantitative agreement with high-resolution molecular spectra. This enables the extraction of low-energy electron-Yb scattering phase shifts, including the zero-energy $s$-wave scattering length and the positions of two spin-orbit split $p$-wave shape resonances. Our results provide strong evidence that the Yb$^{-}$ anion exists only as a metastable resonance. We additionally show the sensitivity of ULRM spectra to the atomic quantum defects, using this to refine the value for the $6s23f\\, ^1F_3$ quantum defect. Together, these findings establish Yb ULRMs as a powerful probe of electron-Yb interactions and lay essential groundwork for future Rydberg experiments with divalent atoms.",
    "published": "2025-12-23T18:55:58Z",
    "updated": "2025-12-23T18:55:58Z",
    "authors": [
      "Tangi Legrand",
      "Xin Wang",
      "Milena Simi\u0107",
      "Florian Pausewang",
      "Wolfgang Alt",
      "Eduardo Uru\u00f1uela",
      "Matthew T. Eiles",
      "Sebastian Hofferberth"
    ],
    "affiliations": [],
    "first_author": "Tangi Legrand",
    "pdf_url": "https://arxiv.org/pdf/2512.20609v1",
    "primary_category": "physics.atom-ph",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20608v1",
    "arxiv_id": "2512.20608v1",
    "title": "R\u00e9nyi-like entanglement probe of the chiral central charge",
    "summary": "We propose a ground state entanglement probe for gapped, two-dimensional quantum many-body systems that involves taking powers of reduced density matrices in a particular geometric configuration. This quantity, which we denote by $\u03c9_{\u03b1,\u03b2}$, is parameterized by two positive real numbers $\u03b1, \u03b2$, and can be seen as a ``R\u00e9nyi-like\" generalization of the modular commutator -- another entanglement probe proposed as a way to compute the chiral central charge from a bulk wave function. We obtain analytic expressions for $\u03c9_{\u03b1,\u03b2}$ for gapped ground states of non-interacting fermion Hamiltonians as well as ground states of string-net models. In both cases, we find that $\u03c9_{\u03b1,\u03b2}$ takes a universal value related to the chiral central charge. For integer values of $\u03b1$ and $\u03b2$, our quantity $\u03c9_{\u03b1,\u03b2}$ can be expressed as an expectation value of permutation operators acting on an appropriate replica system, providing a natural route to measuring $\u03c9_{\u03b1,\u03b2}$ in numerical simulations and potentially, experiments.",
    "published": "2025-12-23T18:55:34Z",
    "updated": "2025-12-23T18:55:34Z",
    "authors": [
      "Julian Gass",
      "Michael Levin"
    ],
    "affiliations": [],
    "first_author": "Julian Gass",
    "pdf_url": "https://arxiv.org/pdf/2512.20608v1",
    "primary_category": "cond-mat.str-el",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20607v1",
    "arxiv_id": "2512.20607v1",
    "title": "Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures",
    "summary": "Neural networks trained with gradient descent often learn solutions of increasing complexity over time, a phenomenon known as simplicity bias. Despite being widely observed across architectures, existing theoretical treatments lack a unifying framework. We present a theoretical framework that explains a simplicity bias arising from saddle-to-saddle learning dynamics for a general class of neural networks, incorporating fully-connected, convolutional, and attention-based architectures. Here, simple means expressible with few hidden units, i.e., hidden neurons, convolutional kernels, or attention heads. Specifically, we show that linear networks learn solutions of increasing rank, ReLU networks learn solutions with an increasing number of kinks, convolutional networks learn solutions with an increasing number of convolutional kernels, and self-attention models learn solutions with an increasing number of attention heads. By analyzing fixed points, invariant manifolds, and dynamics of gradient descent learning, we show that saddle-to-saddle dynamics operates by iteratively evolving near an invariant manifold, approaching a saddle, and switching to another invariant manifold. Our analysis also illuminates the effects of data distribution and weight initialization on the duration and number of plateaus in learning, dissociating previously confounding factors. Overall, our theory offers a framework for understanding when and why gradient descent progressively learns increasingly complex solutions.",
    "published": "2025-12-23T18:55:30Z",
    "updated": "2025-12-23T18:55:30Z",
    "authors": [
      "Yedi Zhang",
      "Andrew Saxe",
      "Peter E. Latham"
    ],
    "affiliations": [],
    "first_author": "Yedi Zhang",
    "pdf_url": "https://arxiv.org/pdf/2512.20607v1",
    "primary_category": "cs.LG",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20606v1",
    "arxiv_id": "2512.20606v1",
    "title": "Repurposing Video Diffusion Transformers for Robust Point Tracking",
    "summary": "Point tracking aims to localize corresponding points across video frames, serving as a fundamental task for 4D reconstruction, robotics, and video editing. Existing methods commonly rely on shallow convolutional backbones such as ResNet that process frames independently, lacking temporal coherence and producing unreliable matching costs under challenging conditions. Through systematic analysis, we find that video Diffusion Transformers (DiTs), pre-trained on large-scale real-world videos with spatio-temporal attention, inherently exhibit strong point tracking capability and robustly handle dynamic motions and frequent occlusions. We propose DiTracker, which adapts video DiTs through: (1) query-key attention matching, (2) lightweight LoRA tuning, and (3) cost fusion with a ResNet backbone. Despite training with 8 times smaller batch size, DiTracker achieves state-of-the-art performance on challenging ITTO benchmark and matches or outperforms state-of-the-art models on TAP-Vid benchmarks. Our work validates video DiT features as an effective and efficient foundation for point tracking.",
    "published": "2025-12-23T18:54:10Z",
    "updated": "2025-12-23T18:54:10Z",
    "authors": [
      "Soowon Son",
      "Honggyu An",
      "Chaehyun Kim",
      "Hyunah Ko",
      "Jisu Nam",
      "Dahyun Chung",
      "Siyoon Jin",
      "Jung Yi",
      "Jaewon Min",
      "Junhwa Hur",
      "Seungryong Kim"
    ],
    "affiliations": [],
    "first_author": "Soowon Son",
    "pdf_url": "https://arxiv.org/pdf/2512.20606v1",
    "primary_category": "cs.CV",
    "relevance_score": 10.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20605v1",
    "arxiv_id": "2512.20605v1",
    "title": "Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning",
    "summary": "Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term \"internal RL\", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.",
    "published": "2025-12-23T18:51:50Z",
    "updated": "2025-12-23T18:51:50Z",
    "authors": [
      "Seijin Kobayashi",
      "Yanick Schimpf",
      "Maximilian Schlegel",
      "Angelika Steger",
      "Maciej Wolczyk",
      "Johannes von Oswald",
      "Nino Scherre",
      "Kaitlin Maile",
      "Guillaume Lajoie",
      "Blake A. Richards",
      "Rif A. Saurous",
      "James Manyika",
      "Blaise Ag\u00fcera y Arcas",
      "Alexander Meulemans",
      "Jo\u00e3o Sacramento"
    ],
    "affiliations": [],
    "first_author": "Seijin Kobayashi",
    "pdf_url": "https://arxiv.org/pdf/2512.20605v1",
    "primary_category": "cs.LG",
    "relevance_score": 10.0
  }
]