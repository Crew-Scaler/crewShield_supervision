[
  {
    "id": "http://arxiv.org/abs/2512.20615v1",
    "arxiv_id": "2512.20615v1",
    "title": "Active Intelligence in Video Avatars via Closed-loop World Modeling",
    "summary": "Current video avatar generation methods excel at identity preservation and motion alignment but lack genuine agency, they cannot autonomously pursue long-term goals through adaptive environmental interaction. We address this by introducing L-IVA (Long-horizon Interactive Visual Avatar), a task and benchmark for evaluating goal-directed planning in stochastic generative environments, and ORCA (Online Reasoning and Cognitive Architecture), the first framework enabling active intelligence in video avatars. ORCA embodies Internal World Model (IWM) capabilities through two key innovations: (1) a closed-loop OTAR cycle (Observe-Think-Act-Reflect) that maintains robust state tracking under generative uncertainty by continuously verifying predicted outcomes against actual generations, and (2) a hierarchical dual-system architecture where System 2 performs strategic reasoning with state prediction while System 1 translates abstract plans into precise, model-specific action captions. By formulating avatar control as a POMDP and implementing continuous belief updating with outcome verification, ORCA enables autonomous multi-step task completion in open-domain scenarios. Extensive experiments demonstrate that ORCA significantly outperforms open-loop and non-reflective baselines in task success rate and behavioral coherence, validating our IWM-inspired design for advancing video avatar intelligence from passive animation to active, goal-oriented behavior.",
    "published": "2025-12-23T18:59:16Z",
    "updated": "2025-12-23T18:59:16Z",
    "authors": [
      "Xuanhua He",
      "Tianyu Yang",
      "Ke Cao",
      "Ruiqi Wu",
      "Cheng Meng",
      "Yong Zhang",
      "Zhuoliang Kang",
      "Xiaoming Wei",
      "Qifeng Chen"
    ],
    "affiliations": [],
    "first_author": "Xuanhua He",
    "pdf_url": "https://arxiv.org/pdf/2512.20615v1",
    "primary_category": "cs.CV",
    "relevance_score": 14.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20589v1",
    "arxiv_id": "2512.20589v1",
    "title": "Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information",
    "summary": "As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME. To that end, this paper proposes an intelligent mission coordination methodology that integrates digital mission models with Reinforcement Learning (RL), that specifically addresses the need for adaptive task allocation and reconfiguration. More specifically, we are leveraging a Digital Engineering (DE) based infrastructure that is composed of a high-fidelity digital mission model and agent-based simulation; and then we formulate the mission tactics management problem as a Markov Decision Process (MDP), and employ an RL agent trained via Proximal Policy Optimization. By leveraging the simulation as a sandbox, we map the system states to actions, refining the policy based on realized mission outcomes. The utility of the RL-based intelligent mission coordinator is demonstrated through an aerial firefighting case study. Our findings indicate that the RL-based intelligent mission coordinator not only surpasses baseline performance but also significantly reduces the variability in mission performance. Thus, this study serves as a proof of concept demonstrating that DE-enabled mission simulations combined with advanced analytical tools offer a mission-agnostic framework for improving ME practice; which can be extended to more complicated fleet design and selection problems in the future from a mission-first perspective.",
    "published": "2025-12-23T18:36:07Z",
    "updated": "2025-12-23T18:36:07Z",
    "authors": [
      "\u0130brahim O\u011fuz \u00c7etinkaya",
      "Sajad Khodadadian",
      "Taylan G. Top\u00e7u"
    ],
    "affiliations": [],
    "first_author": "\u0130brahim O\u011fuz \u00c7etinkaya",
    "pdf_url": "https://arxiv.org/pdf/2512.20589v1",
    "primary_category": "cs.CY",
    "relevance_score": 14.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20586v1",
    "arxiv_id": "2512.20586v1",
    "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
    "summary": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.",
    "published": "2025-12-23T18:32:17Z",
    "updated": "2025-12-23T18:32:17Z",
    "authors": [
      "Humza Nusrat",
      "Luke Francisco",
      "Bing Luo",
      "Hassan Bagher-Ebadian",
      "Joshua Kim",
      "Karen Chin-Snyder",
      "Salim Siddiqui",
      "Mira Shah",
      "Eric Mellon",
      "Mohammad Ghassemi",
      "Anthony Doemer",
      "Benjamin Movsas",
      "Kundan Thind"
    ],
    "affiliations": [],
    "first_author": "Humza Nusrat",
    "pdf_url": "https://arxiv.org/pdf/2512.20586v1",
    "primary_category": "cs.AI",
    "relevance_score": 14.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20618v1",
    "arxiv_id": "2512.20618v1",
    "title": "LongVideoAgent: Multi-Agent Reasoning with Long Videos",
    "summary": "Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.",
    "published": "2025-12-23T18:59:49Z",
    "updated": "2025-12-23T18:59:49Z",
    "authors": [
      "Runtao Liu",
      "Ziyi Liu",
      "Jiaqi Tang",
      "Yue Ma",
      "Renjie Pi",
      "Jipeng Zhang",
      "Qifeng Chen"
    ],
    "affiliations": [],
    "first_author": "Runtao Liu",
    "pdf_url": "https://arxiv.org/pdf/2512.20618v1",
    "primary_category": "cs.AI",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20617v1",
    "arxiv_id": "2512.20617v1",
    "title": "SpatialTree: How Spatial Abilities Branch Out in MLLMs",
    "summary": "Cognitive science suggests that spatial ability develops progressively-from perception to reasoning and interaction. Yet in multimodal LLMs (MLLMs), this hierarchy remains poorly understood, as most studies focus on a narrow set of tasks. We introduce SpatialTree, a cognitive-science-inspired hierarchy that organizes spatial abilities into four levels: low-level perception (L1), mental mapping (L2), simulation (L3), and agentic competence (L4). Based on this taxonomy, we construct the first capability-centric hierarchical benchmark, thoroughly evaluating mainstream MLLMs across 27 sub-abilities. The evaluation results reveal a clear structure: L1 skills are largely orthogonal, whereas higher-level skills are strongly correlated, indicating increasing interdependency. Through targeted supervised fine-tuning, we uncover a surprising transfer dynamic-negative transfer within L1, but strong cross-level transfer from low- to high-level abilities with notable synergy. Finally, we explore how to improve the entire hierarchy. We find that naive RL that encourages extensive \"thinking\" is unreliable: it helps complex reasoning but hurts intuitive perception. We propose a simple auto-think strategy that suppresses unnecessary deliberation, enabling RL to consistently improve performance across all levels. By building SpatialTree, we provide a proof-of-concept framework for understanding and systematically scaling spatial abilities in MLLMs.",
    "published": "2025-12-23T18:59:46Z",
    "updated": "2025-12-23T18:59:46Z",
    "authors": [
      "Yuxi Xiao",
      "Longfei Li",
      "Shen Yan",
      "Xinhang Liu",
      "Sida Peng",
      "Yunchao Wei",
      "Xiaowei Zhou",
      "Bingyi Kang"
    ],
    "affiliations": [],
    "first_author": "Yuxi Xiao",
    "pdf_url": "https://arxiv.org/pdf/2512.20617v1",
    "primary_category": "cs.CV",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20610v1",
    "arxiv_id": "2512.20610v1",
    "title": "FedPOD: the deployable units of training for federated learning",
    "summary": "This paper proposes FedPOD (Proportionally Orchestrated Derivative) for optimizing learning efficiency and communication cost in federated learning among multiple clients. Inspired by FedPIDAvg, we define a round-wise task for FedPOD to enhance training efficiency. FedPIDAvg achieved performance improvement by incorporating the training loss reduction for prediction entropy as weights using differential terms. Furthermore, by modeling data distribution with a Poisson distribution and using a PID controller, it reduced communication costs even in skewed data distribution. However, excluding participants classified as outliers based on the Poisson distribution can limit data utilization. Additionally, PID controller requires the same participants to be maintained throughout the federated learning process as it uses previous rounds' learning information in the current round. In our approach, FedPOD addresses these issues by including participants excluded as outliers, eliminating dependency on previous rounds' learning information, and applying a method for calculating validation loss at each round. In this challenge, FedPOD presents comparable performance to FedPIDAvg in metrics of Dice score, 0.78, 0.71 and 0.72 for WT, ET and TC in average, and projected convergence score, 0.74 in average. Furthermore, the concept of FedPOD draws inspiration from Kubernetes' smallest computing unit, POD, designed to be compatible with Kubernetes auto-scaling. Extending round-wise tasks of FedPOD to POD units allows flexible design by applying scale-out similar to Kubernetes' auto-scaling. This work demonstrated the potentials of FedPOD to enhance federated learning by improving efficiency, flexibility, and performance in metrics.",
    "published": "2025-12-23T18:57:53Z",
    "updated": "2025-12-23T18:57:53Z",
    "authors": [
      "Daewoon Kim",
      "Si Young Yie",
      "Jae Sung Lee"
    ],
    "affiliations": [],
    "first_author": "Daewoon Kim",
    "pdf_url": "https://arxiv.org/pdf/2512.20610v1",
    "primary_category": "cs.CV",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20606v1",
    "arxiv_id": "2512.20606v1",
    "title": "Repurposing Video Diffusion Transformers for Robust Point Tracking",
    "summary": "Point tracking aims to localize corresponding points across video frames, serving as a fundamental task for 4D reconstruction, robotics, and video editing. Existing methods commonly rely on shallow convolutional backbones such as ResNet that process frames independently, lacking temporal coherence and producing unreliable matching costs under challenging conditions. Through systematic analysis, we find that video Diffusion Transformers (DiTs), pre-trained on large-scale real-world videos with spatio-temporal attention, inherently exhibit strong point tracking capability and robustly handle dynamic motions and frequent occlusions. We propose DiTracker, which adapts video DiTs through: (1) query-key attention matching, (2) lightweight LoRA tuning, and (3) cost fusion with a ResNet backbone. Despite training with 8 times smaller batch size, DiTracker achieves state-of-the-art performance on challenging ITTO benchmark and matches or outperforms state-of-the-art models on TAP-Vid benchmarks. Our work validates video DiT features as an effective and efficient foundation for point tracking.",
    "published": "2025-12-23T18:54:10Z",
    "updated": "2025-12-23T18:54:10Z",
    "authors": [
      "Soowon Son",
      "Honggyu An",
      "Chaehyun Kim",
      "Hyunah Ko",
      "Jisu Nam",
      "Dahyun Chung",
      "Siyoon Jin",
      "Jung Yi",
      "Jaewon Min",
      "Junhwa Hur",
      "Seungryong Kim"
    ],
    "affiliations": [],
    "first_author": "Soowon Son",
    "pdf_url": "https://arxiv.org/pdf/2512.20606v1",
    "primary_category": "cs.CV",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20600v1",
    "arxiv_id": "2512.20600v1",
    "title": "Modeling Economic Systems as Multiport Networks",
    "summary": "In this paper, we demonstrate how multiport network theory can be used as a powerful modeling tool in economics. The critical insight is using the port concept to pair the flow of goods (the electrical current) with the agent's incentive (the voltage) in an economic interaction. By building networks of agents interacting through ports, we create models with multiple levels of abstraction, from the macro level down to the micro level. We are thereby able to model complex macroeconomic systems whose dynamical behavior is emergent from the micro level. Using the LTSpice circuit simulator, we then design and analyze a series of example systems that range in complexity from the textbook Robinson Crusoe economy to a model of an entire economy.",
    "published": "2025-12-23T18:47:32Z",
    "updated": "2025-12-23T18:47:32Z",
    "authors": [
      "Coen Hutters",
      "Max B. Mendel"
    ],
    "affiliations": [],
    "first_author": "Coen Hutters",
    "pdf_url": "https://arxiv.org/pdf/2512.20600v1",
    "primary_category": "eess.SY",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20584v1",
    "arxiv_id": "2512.20584v1",
    "title": "A human-centered approach to reframing job satisfaction in the BIM-enabled construction industry",
    "summary": "As the construction industry undergoes rapid digital transformation, ensuring that new technologies enhance rather than hinder human experience has become essential. The inclusion of Building Information Modeling (BIM) plays a central role in this shift, yet its influence on job satisfaction remains underexplored. In response, this study developed a human-centered measurement model for evaluating job satisfaction in BIM work environments by adapting Hackman and Oldham's Job Characteristics Model for the architecture, engineering, and construction (AEC) industry to create a survey that captured industry perspectives on BIM use and job satisfaction. The model uses Partial Least Squares Structural Equation Modeling to analyze the survey results and identify what dimensions of BIM-related work affect job satisfaction. While it was hypothesized that BIM use increases job satisfaction, the results show that only some dimensions of BIM use positively impact BIM job satisfaction; the use of BIM does not guarantee an increase in overall job satisfaction. Additionally, more frequent BIM use was not associated with higher satisfaction levels. These findings suggest that in the AEC industry, sustainable job satisfaction depends less on technological autonomy and more on human-centric factors, particularly collaboration and meaningful engagement within digital workflows.",
    "published": "2025-12-23T18:29:51Z",
    "updated": "2025-12-23T18:29:51Z",
    "authors": [
      "Sharareh Mirzaei",
      "Stephanie Bunt",
      "Susan M Bogus"
    ],
    "affiliations": [],
    "first_author": "Sharareh Mirzaei",
    "pdf_url": "https://arxiv.org/pdf/2512.20584v1",
    "primary_category": "cs.HC",
    "relevance_score": 12.0
  },
  {
    "id": "http://arxiv.org/abs/2512.20574v1",
    "arxiv_id": "2512.20574v1",
    "title": "Revisiting the near infrared Calcium triplet as metallicity indicator",
    "summary": "The near-infrared Calcium II Triplet (CaT), around 850nm, is a key metallicity indicator for red giant stars. We present a revised [Fe/H] calibration as a function of CaT line strengths and four luminosity indicators, including the $Gaia$ $G$-band, together with the classical $V$, $I$, and $K_s$ bandpasses. For this purpose, we used a sample of 366 red giant stars belonging to 25 globular and open clusters, complemented by 52 extremely metal-poor field giant stars. The CaT line strengths are determined by fitting Gaussian-Lorentzian combination profiles using the Python lmfit package, which utilises the algorithms implemented therein. The derived calibration is valid for a wide metallicity range, $-4$\\,dex$ \\lesssim \\mathrm{[Fe/H]} \\lesssim +0.15$, and for ages older than $\\sim$200 Myr. In addition, we performed a detailed assessment of how factors such as spectral resolution, spectral quality (expressed through the signal-to-noise ratio), and the algorithms used to constrain the line profiles affect the measured line strengths and the resulting metallicities.",
    "published": "2025-12-23T18:17:25Z",
    "updated": "2025-12-23T18:17:25Z",
    "authors": [
      "M. Navabi",
      "R. Carrera",
      "N. E. D. No\u00ebl",
      "C. Gallart",
      "E. Pancino",
      "M. De Leo"
    ],
    "affiliations": [],
    "first_author": "M. Navabi",
    "pdf_url": "https://arxiv.org/pdf/2512.20574v1",
    "primary_category": "astro-ph.SR",
    "relevance_score": 12.0
  }
]