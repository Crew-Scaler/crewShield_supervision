{
  "cluster": "cluster_f_training",
  "execution_date": "2026-01-11T09:14:45.665868",
  "total_papers": 397,
  "green_papers_count": 13,
  "papers": [
    {
      "arxiv_id": "2501.08292v1",
      "title": "HALoGEN: Fantastic LLM Hallucinations and Where to Find Them",
      "authors": [
        "Abhilasha Ravichander",
        "Shrusti Ghela",
        "David Wadden",
        "Yejin Choi"
      ],
      "published": "2025-01-14T18:13:08Z",
      "categories": "",
      "summary": "Despite their impressive ability to generate high-quality and fluent text, generative large language models (LLMs) also produce hallucinations: statements that are misaligned with established world knowledge or provided input context. However, measuring hallucination can be challenging, as having humans verify model generations on-the-fly is both expensive and time-consuming. In this work, we release HALoGEN, a comprehensive hallucination benchmark consisting of: (1) 10,923 prompts for generative models spanning nine domains including programming, scientific attribution, and summarization, and...",
      "pdf_url": "https://arxiv.org/pdf/2501.08292v1.pdf",
      "relevance_score": 97,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2501.08292v1_paper.pdf"
    },
    {
      "arxiv_id": "2412.02980v2",
      "title": "Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models",
      "authors": [
        "Alex Havrilla",
        "Andrew Dai",
        "Laura O'Mahony",
        "Koen Oostermeijer",
        "Vera Zisler",
        "Alon Albalak",
        "Fabrizio Milo",
        "Sharath Chandra Raparthy",
        "Kanishk Gandhi",
        "Baber Abbasi",
        "Duy Phung",
        "Maia Iyer",
        "Dakota Mahan",
        "Chase Blagden",
        "Srishti Gureja",
        "Mohammed Hamdy",
        "Wen-Ding Li",
        "Giovanni Paolini",
        "Pawan Sasanka Ammanamanchi",
        "Elliot Meyerson"
      ],
      "published": "2024-12-04T02:47:45Z",
      "categories": "",
      "summary": "Synthetic data generation with Large Language Models is a promising paradigm for augmenting natural data over a nearly infinite range of tasks. Given this variety, direct comparisons among synthetic data generation algorithms are scarce, making it difficult to understand where improvement comes from and what bottlenecks exist. We propose to evaluate algorithms via the makeup of synthetic data generated by each algorithm in terms of data quality, diversity, and complexity. We choose these three characteristics for their significance in open-ended processes and the impact each has on the capabil...",
      "pdf_url": "https://arxiv.org/pdf/2412.02980v2.pdf",
      "relevance_score": 97,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2412.02980v2_paper.pdf"
    },
    {
      "arxiv_id": "2406.09358v2",
      "title": "Understanding Hallucinations in Diffusion Models through Mode Interpolation",
      "authors": [
        "Sumukh K Aithal",
        "Pratyush Maini",
        "Zachary C. Lipton",
        "J. Zico Kolter"
      ],
      "published": "2024-06-13T17:43:41Z",
      "categories": "",
      "summary": "Colloquially speaking, image generation models based upon diffusion processes are frequently said to exhibit \"hallucinations,\" samples that could never occur in the training data. But where do such hallucinations come from? In this paper, we study a particular failure mode in diffusion models, which we term mode interpolation. Specifically, we find that diffusion models smoothly \"interpolate\" between nearby data modes in the training set, to generate samples that are completely outside the support of the original training distribution; this phenomenon leads diffusion models to generate artifac...",
      "pdf_url": "https://arxiv.org/pdf/2406.09358v2.pdf",
      "relevance_score": 93,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2406.09358v2_paper.pdf"
    },
    {
      "arxiv_id": "2509.11273v1",
      "title": "Synthetic Dataset Evaluation Based on Generalized Cross Validation",
      "authors": [
        "Zhihang Song",
        "Dingyi Yao",
        "Ruibo Ming",
        "Lihui Peng",
        "Danya Yao",
        "Yi Zhang"
      ],
      "published": "2025-09-14T13:57:33Z",
      "categories": "",
      "summary": "With the rapid advancement of synthetic dataset generation techniques, evaluating the quality of synthetic data has become a critical research focus. Robust evaluation not only drives innovations in data generation methods but also guides researchers in optimizing the utilization of these synthetic resources. However, current evaluation studies for synthetic datasets remain limited, lacking a universally accepted standard framework. To address this, this paper proposes a novel evaluation framework integrating generalized cross-validation experiments and domain transfer learning principles, ena...",
      "pdf_url": "https://arxiv.org/pdf/2509.11273v1.pdf",
      "relevance_score": 89,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2509.11273v1_paper.pdf"
    },
    {
      "arxiv_id": "2510.24052v1",
      "title": "SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration",
      "authors": [
        "Jongsuk Kim",
        "Jaeyoung Lee",
        "Gyojin Han",
        "Dongjae Lee",
        "Minki Jeong",
        "Junmo Kim"
      ],
      "published": "2025-10-28T04:22:02Z",
      "categories": "",
      "summary": "Recent advancements in deep learning and the availability of high-quality real-world driving datasets have propelled end-to-end autonomous driving. Despite this progress, relying solely on real-world data limits the variety of driving scenarios for training. Synthetic scenario generation has emerged as a promising solution to enrich the diversity of training data; however, its application within E2E AD models remains largely unexplored. This is primarily due to the absence of a designated ego vehicle and the associated sensor inputs, such as camera or LiDAR, typically provided in real-world sc...",
      "pdf_url": "https://arxiv.org/pdf/2510.24052v1.pdf",
      "relevance_score": 89,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2510.24052v1_paper.pdf"
    },
    {
      "arxiv_id": "2211.09878v2",
      "title": "Reducing Hallucinations in Neural Machine Translation with Feature Attribution",
      "authors": [
        "Jo\u00ebl Tang",
        "Marina Fomicheva",
        "Lucia Specia"
      ],
      "published": "2022-11-17T20:33:56Z",
      "categories": "",
      "summary": "Neural conditional language generation models achieve the state-of-the-art in Neural Machine Translation (NMT) but are highly dependent on the quality of parallel training dataset. When trained on low-quality datasets, these models are prone to various error types, including hallucinations, i.e. outputs that are fluent, but unrelated to the source sentences. These errors are particularly dangerous, because on the surface the translation can be perceived as a correct output, especially if the reader does not understand the source language. We present a case study focusing on model understanding...",
      "pdf_url": "https://arxiv.org/pdf/2211.09878v2.pdf",
      "relevance_score": 87,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2211.09878v2_paper.pdf"
    },
    {
      "arxiv_id": "2510.06596v1",
      "title": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation",
      "authors": [
        "Ayush Zenith",
        "Arnold Zumbrun",
        "Neel Raut",
        "Jing Lin"
      ],
      "published": "2025-10-08T03:01:26Z",
      "categories": "",
      "summary": "The performance of machine learning models depends heavily on training data. The scarcity of large-scale, well-annotated datasets poses significant challenges in creating robust models. To address this, synthetic data generated through simulations and generative models has emerged as a promising solution, enhancing dataset diversity and improving the performance, reliability, and resilience of models. However, evaluating the quality of this generated data requires an effective metric. This paper introduces the Synthetic Dataset Quality Metric (SDQM) to assess data quality for object detection ...",
      "pdf_url": "https://arxiv.org/pdf/2510.06596v1.pdf",
      "relevance_score": 87,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2510.06596v1_paper.pdf"
    },
    {
      "arxiv_id": "2403.03307v1",
      "title": "Book2Dial: Generating Teacher-Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots",
      "authors": [
        "Junling Wang",
        "Jakub Macina",
        "Nico Daheim",
        "Sankalan Pal Chowdhury",
        "Mrinmaya Sachan"
      ],
      "published": "2024-03-05T20:12:05Z",
      "categories": "",
      "summary": "Educational chatbots are a promising tool for assisting student learning. However, the development of effective chatbots in education has been challenging, as high-quality data is seldom available in this domain. In this paper, we propose a framework for generating synthetic teacher-student interactions grounded in a set of textbooks. Our approaches capture one aspect of learning interactions where curious students with partial knowledge interactively ask a teacher questions about the material in the textbook. We highlight various quality criteria that such dialogues should fulfill and compare...",
      "pdf_url": "https://arxiv.org/pdf/2403.03307v1.pdf",
      "relevance_score": 82,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2403.03307v1_paper.pdf"
    },
    {
      "arxiv_id": "2410.19217v1",
      "title": "No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models",
      "authors": [
        "Changlong Wu",
        "Ananth Grama",
        "Wojciech Szpankowski"
      ],
      "published": "2024-10-24T23:57:11Z",
      "categories": "",
      "summary": "Generative models have shown impressive capabilities in synthesizing high-quality outputs across various domains. However, a persistent challenge is the occurrence of \"hallucinations\", where the model produces outputs that are plausible but invalid. While empirical strategies have been explored to mitigate this issue, a rigorous theoretical understanding remains elusive. In this paper, we develop a theoretical framework to analyze the learnability of non-hallucinating generative models from a learning-theoretic perspective. Our results reveal that non-hallucinating learning is statistically im...",
      "pdf_url": "https://arxiv.org/pdf/2410.19217v1.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2410.19217v1_paper.pdf"
    },
    {
      "arxiv_id": "2410.16326v2",
      "title": "Synthetic Network Traffic Data Generation: A Comparative Study",
      "authors": [
        "Dure Adan Ammara",
        "Jianguo Ding",
        "Kurt Tutschku"
      ],
      "published": "2024-10-18T14:19:25Z",
      "categories": "",
      "summary": "The generation of synthetic network traffic data is essential for network security testing, machine learning model training, and performance analysis. However, existing methods for synthetic data generation differ significantly in their ability to maintain statistical fidelity, utility for classification tasks, and class balance. This study presents a comparative analysis of twelve synthetic network traffic data generation methods, encompassing non-AI (statistical), classical AI, and generative AI techniques. Using NSL-KDD and CIC-IDS2017 datasets, we evaluate the fidelity, utility, class bala...",
      "pdf_url": "https://arxiv.org/pdf/2410.16326v2.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2410.16326v2_paper.pdf"
    },
    {
      "arxiv_id": "2510.13080v2",
      "title": "Counting Hallucinations in Diffusion Models",
      "authors": [
        "Shuai Fu",
        "Jian Zhou",
        "Qi Chen",
        "Huang Jing",
        "Huy Anh Nguyen",
        "Xiaohan Liu",
        "Zhixiong Zeng",
        "Lin Ma",
        "Quanshi Zhang",
        "Qi Wu"
      ],
      "published": "2025-10-15T01:48:04Z",
      "categories": "",
      "summary": "Diffusion probabilistic models (DPMs) have demonstrated remarkable progress in generative tasks, such as image and video synthesis. However, they still often produce hallucinated samples (hallucinations) that conflict with real-world knowledge, such as generating an implausible duplicate cup floating beside another cup. Despite their prevalence, the lack of feasible methodologies for systematically quantifying such hallucinations hinders progress in addressing this challenge and obscures potential pathways for designing next-generation generative models under factual constraints. In this work,...",
      "pdf_url": "https://arxiv.org/pdf/2510.13080v2.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2510.13080v2_paper.pdf"
    },
    {
      "arxiv_id": "2203.03429v1",
      "title": "Synthetic Defect Generation for Display Front-of-Screen Quality Inspection: A Survey",
      "authors": [
        "Shancong Mou",
        "Meng Cao",
        "Zhendong Hong",
        "Ping Huang",
        "Jiulong Shan",
        "Jianjun Shi"
      ],
      "published": "2022-03-03T20:56:28Z",
      "categories": "",
      "summary": "Display front-of-screen (FOS) quality inspection is essential for the mass production of displays in the manufacturing process. However, the severe imbalanced data, especially the limited number of defect samples, has been a long-standing problem that hinders the successful application of deep learning algorithms. Synthetic defect data generation can help address this issue. This paper reviews the state-of-the-art synthetic data generation methods and the evaluation metrics that can potentially be applied to display FOS quality inspection tasks.",
      "pdf_url": "https://arxiv.org/pdf/2203.03429v1.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2203.03429v1_paper.pdf"
    },
    {
      "arxiv_id": "2507.11687v2",
      "title": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization",
      "authors": [
        "Atharva Naik",
        "Lawanya Baghel",
        "Dhakshin Govindarajan",
        "Darsh Agrawal",
        "Daniel Fried",
        "Carolyn Rose"
      ],
      "published": "2025-07-15T19:44:20Z",
      "categories": "",
      "summary": "Large Language Models, though successful in code generation, struggle with code quality analysis because they are limited by static training data and can't easily adapt to evolving best practices. We introduce MetaLint, an instruction-following framework that formulates code quality analysis as the task of detecting and fixing problematic semantic code fragments or code idioms based on high-level specifications. Unlike conventional approaches that train models on static code quality conventions, MetaLint employs instruction tuning on synthetic linter-generated data with dynamic conventions to ...",
      "pdf_url": "https://arxiv.org/pdf/2507.11687v2.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2507.11687v2_paper.pdf"
    },
    {
      "arxiv_id": "2501.16616v1",
      "title": "Few-Shot Optimized Framework for Hallucination Detection in Resource-Limited NLP Systems",
      "authors": [
        "Baraa Hikal",
        "Ahmed Nasreldin",
        "Ali Hamdi",
        "Ammar Mohammed"
      ],
      "published": "2025-01-28T01:26:22Z",
      "categories": "",
      "summary": "Hallucination detection in text generation remains an ongoing struggle for natural language processing (NLP) systems, frequently resulting in unreliable outputs in applications such as machine translation and definition modeling. Existing methods struggle with data scarcity and the limitations of unlabeled datasets, as highlighted by the SHROOM shared task at SemEval-2024. In this work, we propose a novel framework to address these challenges, introducing DeepSeek Few-shot optimization to enhance weak label generation through iterative prompt engineering. We achieved high-quality annotations t...",
      "pdf_url": "https://arxiv.org/pdf/2501.16616v1.pdf",
      "relevance_score": 79,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.19744v1",
      "title": "DeepBridge: A Unified and Production-Ready Framework for Multi-Dimensional Machine Learning Validation",
      "authors": [
        "Gustavo Coelho Haase",
        "Paulo Henrique Dourado da Silva"
      ],
      "published": "2025-12-18T01:32:32Z",
      "categories": "",
      "summary": "We present DeepBridge, an 80K-line Python library that unifies multi-dimensional validation, automatic compliance verification, knowledge distillation, and synthetic data generation. DeepBridge offers: (i) 5 validation suites (fairness with 15 metrics, robustness with weakness detection, uncertainty via conformal prediction, resilience with 5 drift types, hyperparameter sensitivity), (ii) automatic EEOC/ECOA/GDPR verification, (iii) multi-format reporting system (interactive/static HTML, PDF, JSON), (iv) HPM-KD framework for knowledge distillation with meta-learning, and (v) scalable synthetic...",
      "pdf_url": "https://arxiv.org/pdf/2512.19744v1.pdf",
      "relevance_score": 79,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.05929v2",
      "title": "Towards Reliable Generative AI-Driven Scaffolding: Reducing Hallucinations and Enhancing Quality in Self-Regulated Learning Support",
      "authors": [
        "Keyang Qian",
        "Shiqi Liu",
        "Tongguang Li",
        "Mladen Rakovi\u0107",
        "Xinyu Li",
        "Rui Guan",
        "Inge Molenaar",
        "Sadia Nawaz",
        "Zachari Swiecki",
        "Lixiang Yan",
        "Dragan Ga\u0161evi\u0107"
      ],
      "published": "2025-08-08T01:40:10Z",
      "categories": "",
      "summary": "Generative Artificial Intelligence (GenAI) holds a potential to advance existing educational technologies with capabilities to automatically generate personalised scaffolds that support students' self-regulated learning (SRL). While advancements in large language models (LLMs) promise improvements in the adaptability and quality of educational technologies for SRL, there remain concerns about the hallucinations in content generated by LLMs, which can compromise both the learning experience and ethical standards. To address these challenges, we proposed GenAI-enabled approaches for evaluating p...",
      "pdf_url": "https://arxiv.org/pdf/2508.05929v2.pdf",
      "relevance_score": 78,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.15804v1",
      "title": "Insights from Verification: Training a Verilog Generation LLM with Reinforcement Learning with Testbench Feedback",
      "authors": [
        "Ning Wang",
        "Bingkun Yao",
        "Jie Zhou",
        "Yuchen Hu",
        "Xi Wang",
        "Nan Guan",
        "Zhe Jiang"
      ],
      "published": "2025-04-22T11:38:14Z",
      "categories": "",
      "summary": "Large language models (LLMs) have shown strong performance in Verilog generation from natural language description. However, ensuring the functional correctness of the generated code remains a significant challenge. This paper introduces a method that integrates verification insights from testbench into the training of Verilog generation LLMs, aligning the training with the fundamental goal of hardware design: functional correctness. The main obstacle in using LLMs for Verilog code generation is the lack of sufficient functional verification data, particularly testbenches paired with design sp...",
      "pdf_url": "https://arxiv.org/pdf/2504.15804v1.pdf",
      "relevance_score": 78,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.12784v7",
      "title": "Evaluating Image Hallucination in Text-to-Image Generation with Question-Answering",
      "authors": [
        "Youngsun Lim",
        "Hojun Choi",
        "Hyunjung Shim"
      ],
      "published": "2024-09-19T13:51:21Z",
      "categories": "",
      "summary": "Despite the impressive success of text-to-image (TTI) generation models, existing studies overlook the issue of whether these models accurately convey factual information. In this paper, we focus on the problem of image hallucination, where images created by generation models fail to faithfully depict factual content. To address this, we introduce I-HallA (Image Hallucination evaluation with Question Answering), a novel automated evaluation metric that measures the factuality of generated images through visual question answering (VQA). We also introduce I-HallA v1.0, a curated benchmark datase...",
      "pdf_url": "https://arxiv.org/pdf/2409.12784v7.pdf",
      "relevance_score": 78,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.13300v1",
      "title": "PASE: Leveraging the Phonological Prior of WavLM for Low-Hallucination Generative Speech Enhancement",
      "authors": [
        "Xiaobin Rong",
        "Qinwen Hu",
        "Mansur Yesilbursa",
        "Kamil Wojcicki",
        "Jing Lu"
      ],
      "published": "2025-11-17T12:24:35Z",
      "categories": "",
      "summary": "Generative models have shown remarkable performance in speech enhancement (SE), achieving superior perceptual quality over traditional discriminative approaches. However, existing generative SE approaches often overlook the risk of hallucination under severe noise, leading to incorrect spoken content or inconsistent speaker characteristics, which we term linguistic and acoustic hallucinations, respectively. We argue that linguistic hallucination stems from models' failure to constrain valid phonological structures and it is a more fundamental challenge. While language models (LMs) are well-sui...",
      "pdf_url": "https://arxiv.org/pdf/2511.13300v1.pdf",
      "relevance_score": 77,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2110.15914v1",
      "title": "Improving the quality of generative models through Smirnov transformation",
      "authors": [
        "\u00c1ngel Gonz\u00e1lez-Prieto",
        "Alberto Mozo",
        "Sandra G\u00f3mez-Canaval",
        "Edgar Talavera"
      ],
      "published": "2021-10-29T17:01:06Z",
      "categories": "",
      "summary": "Solving the convergence issues of Generative Adversarial Networks (GANs) is one of the most outstanding problems in generative models. In this work, we propose a novel activation function to be used as output of the generator agent. This activation function is based on the Smirnov probabilistic transformation and it is specifically designed to improve the quality of the generated data. In sharp contrast with previous works, our activation function provides a more general approach that deals not only with the replication of categorical variables but with any type of data distribution (continuou...",
      "pdf_url": "https://arxiv.org/pdf/2110.15914v1.pdf",
      "relevance_score": 77,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.14994v1",
      "title": "Non-Reference Quality Assessment for Medical Imaging: Application to Synthetic Brain MRIs",
      "authors": [
        "Karl Van Eeden Risager",
        "Torkan Gholamalizadeh",
        "Mostafa Mehdipour Ghazi"
      ],
      "published": "2024-07-20T22:05:30Z",
      "categories": "",
      "summary": "Generating high-quality synthetic data is crucial for addressing challenges in medical imaging, such as domain adaptation, data scarcity, and privacy concerns. Existing image quality metrics often rely on reference images, are tailored for group comparisons, or are intended for 2D natural images, limiting their efficacy in complex domains like medical imaging. This study introduces a novel deep learning-based non-reference approach to assess brain MRI quality by training a 3D ResNet. The network is designed to estimate quality across six distinct artifacts commonly encountered in MRI scans. Ad...",
      "pdf_url": "https://arxiv.org/pdf/2407.14994v1.pdf",
      "relevance_score": 77,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.03739v1",
      "title": "A Unified Virtual Mixture-of-Experts Framework:Enhanced Inference and Hallucination Mitigation in Single-Model System",
      "authors": [
        "Mingyan Liu"
      ],
      "published": "2025-04-01T11:38:01Z",
      "categories": "",
      "summary": "Generative models, such as GPT and BERT, have significantly improved performance in tasks like text generation and summarization. However, hallucinations \"where models generate non-factual or misleading content\" are especially problematic in smaller-scale architectures, limiting their real-world applicability.In this paper, we propose a unified Virtual Mixture-of-Experts (MoE) fusion strategy that enhances inference performance and mitigates hallucinations in a single Qwen 1.5 0.5B model without increasing the parameter count. Our method leverages multiple domain-specific expert prompts (with ...",
      "pdf_url": "https://arxiv.org/pdf/2504.03739v1.pdf",
      "relevance_score": 76,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.19360v2",
      "title": "SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation",
      "authors": [
        "Yunsung Chung",
        "Yunbei Zhang",
        "Nassir Marrouche",
        "Jihun Hamm"
      ],
      "published": "2025-06-24T06:41:34Z",
      "categories": "",
      "summary": "Advances in generative models have transformed the field of synthetic image generation for privacy-preserving data synthesis (PPDS). However, the field lacks a comprehensive survey and comparison of synthetic image generation methods across diverse settings. In particular, when we generate synthetic images for the purpose of training a classifier, there is a pipeline of generation-sampling-classification which takes private training as input and outputs the final classifier of interest. In this survey, we systematically categorize existing image synthesis methods, privacy attacks, and mitigati...",
      "pdf_url": "https://arxiv.org/pdf/2506.19360v2.pdf",
      "relevance_score": 75,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.00379v2",
      "title": "Improving clustering quality evaluation in noisy Gaussian mixtures",
      "authors": [
        "Renato Cordeiro de Amorim",
        "Vladimir Makarenkov"
      ],
      "published": "2025-03-01T07:11:30Z",
      "categories": "",
      "summary": "Clustering is a well-established technique in machine learning and data analysis, widely used across various domains. Cluster validity indices, such as the Average Silhouette Width, Calinski-Harabasz, and Davies-Bouldin indices, play a crucial role in assessing clustering quality when external ground truth labels are unavailable. However, these measures can be affected by the feature relevance issue, potentially leading to unreliable evaluations in high-dimensional or noisy data sets.   We introduce a theoretically grounded Feature Importance Rescaling (FIR) method that enhances the quality of...",
      "pdf_url": "https://arxiv.org/pdf/2503.00379v2.pdf",
      "relevance_score": 75,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2601.02947v1",
      "title": "Quality Degradation Attack in Synthetic Data",
      "authors": [
        "Qinyi Liu",
        "Dong Liu",
        "Farhad Vadiee",
        "Mohammad Khalil",
        "Pedro P. Vergara Barrios"
      ],
      "published": "2026-01-06T11:43:31Z",
      "categories": "",
      "summary": "Synthetic Data Generation (SDG) can be used to facilitate privacy-preserving data sharing. However, most existing research focuses on privacy attacks where the adversary is the recipient of the released synthetic data and attempts to infer sensitive information from it. This study investigates quality degradation attacks initiated by adversaries who possess access to the real dataset or control over the generation process, such as the data owner, the synthetic data provider, or potential intruders. We formalize a corresponding threat model and empirically evaluate the effectiveness of targeted...",
      "pdf_url": "https://arxiv.org/pdf/2601.02947v1.pdf",
      "relevance_score": 75,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.19941v3",
      "title": "Alleviating Distribution Shift in Synthetic Data for Machine Translation Quality Estimation",
      "authors": [
        "Xiang Geng",
        "Zhejian Lai",
        "Jiajun Chen",
        "Hao Yang",
        "Shujian Huang"
      ],
      "published": "2025-02-27T10:11:53Z",
      "categories": "",
      "summary": "Quality Estimation (QE) models evaluate the quality of machine translations without reference translations, serving as the reward models for the translation task. Due to the data scarcity, synthetic data generation has emerged as a promising solution. However, synthetic QE data often suffers from distribution shift, which can manifest as discrepancies between pseudo and real translations, or in pseudo labels that do not align with human preferences. To tackle this issue, we introduce DCSQE, a novel framework for alleviating distribution shift in synthetic QE data. To reduce the difference betw...",
      "pdf_url": "https://arxiv.org/pdf/2502.19941v3.pdf",
      "relevance_score": 75,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.06499v2",
      "title": "SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms",
      "authors": [
        "Alex Havrilla",
        "Edward Hughes",
        "Mikayel Samvelyan",
        "Jacob Abernethy"
      ],
      "published": "2025-06-06T19:49:42Z",
      "categories": "",
      "summary": "Large language model (LLM) driven synthetic data generation has emerged as a powerful method for improving model reasoning capabilities. However, most methods either distill large state-of-the-art models into small students or use natural ground-truth problem statements to guarantee problem statement quality. This limits the scalability of these approaches to more complex and diverse problem domains. To address this, we present SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms, a novel approach for generating high-quality and diverse synthetic math problem and ...",
      "pdf_url": "https://arxiv.org/pdf/2506.06499v2.pdf",
      "relevance_score": 75,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.01237v1",
      "title": "Confidence-Aware Routing for Large Language Model Reliability Enhancement: A Multi-Signal Approach to Pre-Generation Hallucination Mitigation",
      "authors": [
        "Nandakishor M"
      ],
      "published": "2025-09-23T18:34:20Z",
      "categories": "",
      "summary": "Large Language Models suffer from hallucination, generating plausible yet factually incorrect content. Current mitigation strategies focus on post-generation correction, which is computationally expensive and fails to prevent unreliable content generation. We propose a confidence-aware routing system that proactively assesses model uncertainty before generation and redirects queries based on estimated reliability. Our approach combines three complementary signals: semantic alignment between internal representations and reference embeddings, internal convergence analysis across model layers, an...",
      "pdf_url": "https://arxiv.org/pdf/2510.01237v1.pdf",
      "relevance_score": 75,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.12003v2",
      "title": "RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization",
      "authors": [
        "Jinhu Qi",
        "Shuai Yan",
        "Yibo Zhang",
        "Wentao Zhang",
        "Rong Jin",
        "Yuwei Hu",
        "Ke Wang"
      ],
      "published": "2024-08-21T21:34:01Z",
      "categories": "",
      "summary": "With the development of the modern social economy, tourism has become an important way to meet people's spiritual needs, bringing development opportunities to the tourism industry. However, existing large language models (LLMs) face challenges in personalized recommendation capabilities and the generation of content that can sometimes produce hallucinations. This study proposes an optimization scheme for Tibet tourism LLMs based on retrieval-augmented generation (RAG) technology. By constructing a database of tourist viewpoints and processing the data using vectorization techniques, we have si...",
      "pdf_url": "https://arxiv.org/pdf/2408.12003v2.pdf",
      "relevance_score": 75,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.08758v1",
      "title": "Hyper-RAG: Combating LLM Hallucinations using Hypergraph-Driven Retrieval-Augmented Generation",
      "authors": [
        "Yifan Feng",
        "Hao Hu",
        "Xingliang Hou",
        "Shiquan Liu",
        "Shihui Ying",
        "Shaoyi Du",
        "Han Hu",
        "Yue Gao"
      ],
      "published": "2025-03-30T12:39:14Z",
      "categories": "",
      "summary": "Large language models (LLMs) have transformed various sectors, including education, finance, and medicine, by enhancing content generation and decision-making processes. However, their integration into the medical field is cautious due to hallucinations, instances where generated content deviates from factual accuracy, potentially leading to adverse outcomes. To address this, we introduce Hyper-RAG, a hypergraph-driven Retrieval-Augmented Generation method that comprehensively captures both pairwise and beyond-pairwise correlations in domain-specific knowledge, thereby mitigating hallucination...",
      "pdf_url": "https://arxiv.org/pdf/2504.08758v1.pdf",
      "relevance_score": 75,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1910.04731v1",
      "title": "Automatic Quality Estimation for Natural Language Generation: Ranting (Jointly Rating and Ranking)",
      "authors": [
        "Ond\u0159ej Du\u0161ek",
        "Karin Sevegnani",
        "Ioannis Konstas",
        "Verena Rieser"
      ],
      "published": "2019-10-10T17:43:31Z",
      "categories": "",
      "summary": "We present a recurrent neural network based system for automatic quality estimation of natural language generation (NLG) outputs, which jointly learns to assign numerical ratings to individual outputs and to provide pairwise rankings of two different outputs. The latter is trained using pairwise hinge loss over scores from two copies of the rating network.   We use learning to rank and synthetic data to improve the quality of ratings assigned by our system: we synthesise training pairs of distorted system outputs and train the system to rank the less distorted one higher. This leads to a 12% i...",
      "pdf_url": "https://arxiv.org/pdf/1910.04731v1.pdf",
      "relevance_score": 74,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2402.14594v1",
      "title": "Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation",
      "authors": [
        "Zifei FeiFei Han",
        "Jionghao Lin",
        "Ashish Gurung",
        "Danielle R. Thomas",
        "Eason Chen",
        "Conrad Borchers",
        "Shivang Gupta",
        "Kenneth R. Koedinger"
      ],
      "published": "2024-02-04T20:42:30Z",
      "categories": "",
      "summary": "One-on-one tutoring is an effective instructional method for enhancing learning, yet its efficacy hinges on tutor competencies. Novice math tutors often prioritize content-specific guidance, neglecting aspects such as social-emotional learning. Social-emotional learning promotes equity and inclusion and nurturing relationships with students, which is crucial for holistic student development. Assessing the competencies of tutors accurately and efficiently can drive the development of tailored tutor training programs. However, evaluating novice tutor ability during real-time tutoring remains cha...",
      "pdf_url": "https://arxiv.org/pdf/2402.14594v1.pdf",
      "relevance_score": 73,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.13906v1",
      "title": "ConVis: Contrastive Decoding with Hallucination Visualization for Mitigating Hallucinations in Multimodal Large Language Models",
      "authors": [
        "Yeji Park",
        "Deokyeong Lee",
        "Junsuk Choe",
        "Buru Chang"
      ],
      "published": "2024-08-25T18:02:36Z",
      "categories": "",
      "summary": "Hallucinations in Multimodal Large Language Models (MLLMs) where generated responses fail to accurately reflect the given image pose a significant challenge to their reliability. To address this, we introduce ConVis, a novel training-free contrastive decoding method. ConVis leverages a text-to-image (T2I) generation model to semantically reconstruct the given image from hallucinated captions. By comparing the contrasting probability distributions produced by the original and reconstructed images, ConVis enables MLLMs to capture visual contrastive signals that penalize hallucination generation....",
      "pdf_url": "https://arxiv.org/pdf/2408.13906v1.pdf",
      "relevance_score": 73,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.03491v1",
      "title": "A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded Dialogue Generation",
      "authors": [
        "Jifan Yu",
        "Xiaohan Zhang",
        "Yifan Xu",
        "Xuanyu Lei",
        "Zijun Yao",
        "Jing Zhang",
        "Lei Hou",
        "Juanzi Li"
      ],
      "published": "2024-04-04T14:45:26Z",
      "categories": "",
      "summary": "Empowered by the large-scale pretrained language models, existing dialogue systems have demonstrated impressive performance conducting fluent and natural-sounding conversations. However, they are still plagued by the hallucination problem, causing unpredictable factual errors in the generated responses. Recently, knowledge-grounded dialogue generation models, that intentionally invoke external knowledge resources to more informative responses, are also proven to be effective in reducing hallucination. Following the idea of getting high-quality knowledge, a few efforts have achieved pretty good...",
      "pdf_url": "https://arxiv.org/pdf/2404.03491v1.pdf",
      "relevance_score": 73,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.17075v3",
      "title": "SAFETY-J: Evaluating Safety with Critique",
      "authors": [
        "Yixiu Liu",
        "Yuxiang Zheng",
        "Shijie Xia",
        "Jiajun Li",
        "Yi Tu",
        "Chaoling Song",
        "Pengfei Liu"
      ],
      "published": "2024-07-24T08:04:00Z",
      "categories": "",
      "summary": "The deployment of Large Language Models (LLMs) in content generation raises significant safety concerns, particularly regarding the transparency and interpretability of content evaluations. Current methods, primarily focused on binary safety classifications, lack mechanisms for detailed critique, limiting their utility for model improvement and user trust. To address these limitations, we introduce SAFETY-J, a bilingual generative safety evaluator for English and Chinese with critique-based judgment. SAFETY-J utilizes a robust training dataset that includes diverse dialogues and augmented quer...",
      "pdf_url": "https://arxiv.org/pdf/2407.17075v3.pdf",
      "relevance_score": 73,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.05952v1",
      "title": "Dean of LLM Tutors: Exploring Comprehensive and Automated Evaluation of LLM-generated Educational Feedback via LLM Feedback Evaluators",
      "authors": [
        "Keyang Qian",
        "Yixin Cheng",
        "Rui Guan",
        "Wei Dai",
        "Flora Jin",
        "Kaixun Yang",
        "Sadia Nawaz",
        "Zachari Swiecki",
        "Guanliang Chen",
        "Lixiang Yan",
        "Dragan Ga\u0161evi\u0107"
      ],
      "published": "2025-08-08T02:36:23Z",
      "categories": "",
      "summary": "The use of LLM tutors to provide automated educational feedback to students on student assignment submissions has received much attention in the AI in Education field. However, the stochastic nature and tendency for hallucinations in LLMs can undermine both quality of learning experience and adherence to ethical standards. To address this concern, we propose a method that uses LLM feedback evaluators (DeanLLMs) to automatically and comprehensively evaluate feedback generated by LLM tutor for submissions on university assignments before it is delivered to students. This allows low-quality feedb...",
      "pdf_url": "https://arxiv.org/pdf/2508.05952v1.pdf",
      "relevance_score": 72,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2210.13918v2",
      "title": "Differentially Private Language Models for Secure Data Sharing",
      "authors": [
        "Justus Mattern",
        "Zhijing Jin",
        "Benjamin Weggenmann",
        "Bernhard Schoelkopf",
        "Mrinmaya Sachan"
      ],
      "published": "2022-10-25T11:12:56Z",
      "categories": "",
      "summary": "To protect the privacy of individuals whose data is being shared, it is of high importance to develop methods allowing researchers and companies to release textual data while providing formal privacy guarantees to its originators. In the field of NLP, substantial efforts have been directed at building mechanisms following the framework of local differential privacy, thereby anonymizing individual text samples before releasing them. In practice, these approaches are often dissatisfying in terms of the quality of their output language due to the strong noise required for local differential priva...",
      "pdf_url": "https://arxiv.org/pdf/2210.13918v2.pdf",
      "relevance_score": 71,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.12201v2",
      "title": "RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models",
      "authors": [
        "Yiqi Tian",
        "Pengfei Jin",
        "Mingze Yuan",
        "Na Li",
        "Bo Zeng",
        "Quanzheng Li"
      ],
      "published": "2025-07-16T12:55:58Z",
      "categories": "",
      "summary": "Diffusion models have achieved state-of-the-art performance in generative modeling, yet their sampling procedures remain vulnerable to hallucinations-often stemming from inaccuracies in score approximation. In this work, we reinterpret diffusion sampling through the lens of optimization and introduce RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that detects and corrects high-risk sampling steps using geometric cues from the loss landscape. RODS enforces smoother sampling trajectories and adaptively adjusts perturbations, reducing hallucinations without retraining and a...",
      "pdf_url": "https://arxiv.org/pdf/2507.12201v2.pdf",
      "relevance_score": 71,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.17642v2",
      "title": "Banishing LLM Hallucinations Requires Rethinking Generalization",
      "authors": [
        "Johnny Li",
        "Saksham Consul",
        "Eda Zhou",
        "James Wong",
        "Naila Farooqui",
        "Yuxin Ye",
        "Nithyashree Manohar",
        "Zhuxiaona Wei",
        "Tian Wu",
        "Ben Echols",
        "Sharon Zhou",
        "Gregory Diamos"
      ],
      "published": "2024-06-25T15:31:01Z",
      "categories": "",
      "summary": "Despite their powerful chat, coding, and reasoning abilities, Large Language Models (LLMs) frequently hallucinate. Conventional wisdom suggests that hallucinations are a consequence of a balance between creativity and factuality, which can be mitigated, but not eliminated, by grounding the LLM in external knowledge sources. Through extensive systematic experiments, we show that these traditional approaches fail to explain why LLMs hallucinate in practice. Specifically, we show that LLMs augmented with a massive Mixture of Memory Experts (MoME) can easily memorize large datasets of random numbe...",
      "pdf_url": "https://arxiv.org/pdf/2406.17642v2.pdf",
      "relevance_score": 71,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.20921v1",
      "title": "Leveraging Generative AI Through Prompt Engineering and Rigorous Validation to Create Comprehensive Synthetic Datasets for AI Training in Healthcare",
      "authors": [
        "Polycarp Nalela"
      ],
      "published": "2025-04-29T16:37:34Z",
      "categories": "",
      "summary": "Access to high-quality medical data is often restricted due to privacy concerns, posing significant challenges for training artificial intelligence (AI) algorithms within Electronic Health Record (EHR) applications. In this study, prompt engineering with the GPT-4 API was employed to generate high-quality synthetic datasets aimed at overcoming this limitation. The generated data encompassed a comprehensive array of patient admission information, including healthcare provider details, hospital departments, wards, bed assignments, patient demographics, emergency contacts, vital signs, immunizati...",
      "pdf_url": "https://arxiv.org/pdf/2504.20921v1.pdf",
      "relevance_score": 71,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2401.13716v1",
      "title": "Can I trust my fake data -- A comprehensive quality assessment framework for synthetic tabular data in healthcare",
      "authors": [
        "Vibeke Binz Vallevik",
        "Aleksandar Babic",
        "Serena Elizabeth Marshall",
        "Severin Elvatun",
        "Helga Br\u00f8gger",
        "Sharmini Alagaratnam",
        "Bj\u00f8rn Edwin",
        "Narasimha Raghavan Veeraragavan",
        "Anne Kjersti Befring",
        "Jan Franz Nyg\u00e5rd"
      ],
      "published": "2024-01-24T08:14:20Z",
      "categories": "",
      "summary": "Ensuring safe adoption of AI tools in healthcare hinges on access to sufficient data for training, testing and validation. In response to privacy concerns and regulatory requirements, using synthetic data has been suggested. Synthetic data is created by training a generator on real data to produce a dataset with similar statistical properties. Competing metrics with differing taxonomies for quality evaluation have been suggested, resulting in a complex landscape. Optimising quality entails balancing considerations that make the data fit for use, yet relevant dimensions are left out of existing...",
      "pdf_url": "https://arxiv.org/pdf/2401.13716v1.pdf",
      "relevance_score": 71,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.16341v2",
      "title": "Quality Matters: Evaluating Synthetic Data for Tool-Using LLMs",
      "authors": [
        "Shadi Iskander",
        "Nachshon Cohen",
        "Zohar Karnin",
        "Ori Shapira",
        "Sofia Tolmach"
      ],
      "published": "2024-09-24T17:20:02Z",
      "categories": "",
      "summary": "Training large language models (LLMs) for external tool usage is a rapidly expanding field, with recent research focusing on generating synthetic data to address the shortage of available data. However, the absence of systematic data quality checks poses complications for properly training and testing models. To that end, we propose two approaches for assessing the reliability of data for training LLMs to use external tools. The first approach uses intuitive, human-defined correctness criteria. The second approach uses a model-driven assessment with in-context evaluation. We conduct a thorough...",
      "pdf_url": "https://arxiv.org/pdf/2409.16341v2.pdf",
      "relevance_score": 71,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.23174v1",
      "title": "Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data",
      "authors": [
        "Chen Gong",
        "Bo Liang",
        "Wei Gao",
        "Chenren Xu"
      ],
      "published": "2025-06-29T10:17:39Z",
      "categories": "",
      "summary": "Generative models have gained significant attention for their ability to produce realistic synthetic data that supplements the quantity of real-world datasets. While recent studies show performance improvements in wireless sensing tasks by incorporating all synthetic data into training sets, the quality of synthetic data remains unpredictable and the resulting performance gains are not guaranteed. To address this gap, we propose tractable and generalizable metrics to quantify quality attributes of synthetic data - affinity and diversity. Our assessment reveals prevalent affinity limitation in ...",
      "pdf_url": "https://arxiv.org/pdf/2506.23174v1.pdf",
      "relevance_score": 71,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.00701v2",
      "title": "D3: Training-Free AI-Generated Video Detection Using Second-Order Features",
      "authors": [
        "Chende Zheng",
        "Ruiqi suo",
        "Chenhao Lin",
        "Zhengyu Zhao",
        "Le Yang",
        "Shuai Liu",
        "Minghui Yang",
        "Cong Wang",
        "Chao Shen"
      ],
      "published": "2025-08-01T15:17:51Z",
      "categories": "",
      "summary": "The evolution of video generation techniques, such as Sora, has made it increasingly easy to produce high-fidelity AI-generated videos, raising public concern over the dissemination of synthetic content. However, existing detection methodologies remain limited by their insufficient exploration of temporal artifacts in synthetic videos. To bridge this gap, we establish a theoretical framework through second-order dynamical analysis under Newtonian mechanics, subsequently extending the Second-order Central Difference features tailored for temporal artifact detection. Building on this theoretical...",
      "pdf_url": "https://arxiv.org/pdf/2508.00701v2.pdf",
      "relevance_score": 70,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.10652v2",
      "title": "TriDF: Evaluating Perception, Detection, and Hallucination for Interpretable DeepFake Detection",
      "authors": [
        "Jian-Yu Jiang-Lin",
        "Kang-Yang Huang",
        "Ling Zou",
        "Ling Lo",
        "Sheng-Ping Yang",
        "Yu-Wen Tseng",
        "Kun-Hsiang Lin",
        "Chia-Ling Chen",
        "Yu-Ting Ta",
        "Yan-Tsung Wang",
        "Po-Ching Chen",
        "Hongxia Xie",
        "Hong-Han Shuai",
        "Wen-Huang Cheng"
      ],
      "published": "2025-12-11T14:01:01Z",
      "categories": "",
      "summary": "Advances in generative modeling have made it increasingly easy to fabricate realistic portrayals of individuals, creating serious risks for security, communication, and public trust. Detecting such person-driven manipulations requires systems that not only distinguish altered content from authentic media but also provide clear and reliable reasoning. In this paper, we introduce TriDF, a comprehensive benchmark for interpretable DeepFake detection. TriDF contains high-quality forgeries from advanced synthesis models, covering 16 DeepFake types across image, video, and audio modalities. The benc...",
      "pdf_url": "https://arxiv.org/pdf/2512.10652v2.pdf",
      "relevance_score": 70,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2307.07146v1",
      "title": "Federated Learning-Empowered AI-Generated Content in Wireless Networks",
      "authors": [
        "Xumin Huang",
        "Peichun Li",
        "Hongyang Du",
        "Jiawen Kang",
        "Dusit Niyato",
        "Dong In Kim",
        "Yuan Wu"
      ],
      "published": "2023-07-14T04:13:11Z",
      "categories": "",
      "summary": "Artificial intelligence generated content (AIGC) has emerged as a promising technology to improve the efficiency, quality, diversity and flexibility of the content creation process by adopting a variety of generative AI models. Deploying AIGC services in wireless networks has been expected to enhance the user experience. However, the existing AIGC service provision suffers from several limitations, e.g., the centralized training in the pre-training, fine-tuning and inference processes, especially their implementations in wireless networks with privacy preservation. Federated learning (FL), as ...",
      "pdf_url": "https://arxiv.org/pdf/2307.07146v1.pdf",
      "relevance_score": 69,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.03345v1",
      "title": "HalluGen: Synthesizing Realistic and Controllable Hallucinations for Evaluating Image Restoration",
      "authors": [
        "Seunghoi Kim",
        "Henry F. J. Tregidgo",
        "Chen Jin",
        "Matteo Figini",
        "Daniel C. Alexander"
      ],
      "published": "2025-12-03T01:20:00Z",
      "categories": "",
      "summary": "Generative models are prone to hallucinations: plausible but incorrect structures absent in the ground truth. This issue is problematic in image restoration for safety-critical domains such as medical imaging, industrial inspection, and remote sensing, where such errors undermine reliability and trust. For example, in low-field MRI, widely used in resource-limited settings, restoration models are essential for enhancing low-quality scans, yet hallucinations can lead to serious diagnostic errors. Progress has been hindered by a circular dependency: evaluating hallucinations requires labeled dat...",
      "pdf_url": "https://arxiv.org/pdf/2512.03345v1.pdf",
      "relevance_score": 69,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.09871v1",
      "title": "Content-Aware Preserving Image Generation",
      "authors": [
        "Giang H. Le",
        "Anh Q. Nguyen",
        "Byeongkeun Kang",
        "Yeejin Lee"
      ],
      "published": "2024-11-15T01:32:19Z",
      "categories": "",
      "summary": "Remarkable progress has been achieved in image generation with the introduction of generative models. However, precisely controlling the content in generated images remains a challenging task due to their fundamental training objective. This paper addresses this challenge by proposing a novel image generation framework explicitly designed to incorporate desired content in output images. The framework utilizes advanced encoding techniques, integrating subnetworks called content fusion and frequency encoding modules. The frequency encoding module first captures features and structures of referen...",
      "pdf_url": "https://arxiv.org/pdf/2411.09871v1.pdf",
      "relevance_score": 69,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.12522v1",
      "title": "Evaluating the Diversity and Quality of LLM Generated Content",
      "authors": [
        "Alexander Shypula",
        "Shuo Li",
        "Botong Zhang",
        "Vishakh Padmakumar",
        "Kayo Yin",
        "Osbert Bastani"
      ],
      "published": "2025-04-16T23:02:23Z",
      "categories": "",
      "summary": "Recent work suggests that preference-tuning techniques--including Reinforcement Learning from Human Preferences (RLHF) methods like PPO and GRPO, as well as alternatives like DPO--reduce diversity, creating a dilemma given that such models are widely deployed in applications requiring diverse outputs. To address this, we introduce a framework for measuring effective semantic diversity--diversity among outputs that meet quality thresholds--which better reflects the practical utility of large language models (LLMs). Using open-ended tasks that require no human intervention, we find counterintuit...",
      "pdf_url": "https://arxiv.org/pdf/2504.12522v1.pdf",
      "relevance_score": 69,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.22166v1",
      "title": "Expert Validation of Synthetic Cervical Spine Radiographs Generated with a Denoising Diffusion Probabilistic Model",
      "authors": [
        "Austin A. Barr",
        "Brij S. Karmur",
        "Anthony J. Winder",
        "Eddie Guo",
        "John T. Lysack",
        "James N. Scott",
        "William F. Morrish",
        "Muneer Eesa",
        "Morgan Willson",
        "David W. Cadotte",
        "Michael M. H. Yang",
        "Ian Y. M. Chan",
        "Sanju Lama",
        "Garnette R. Sutherland"
      ],
      "published": "2025-10-25T05:25:37Z",
      "categories": "",
      "summary": "Machine learning in neurosurgery is limited by challenges in assembling large, high-quality imaging datasets. Synthetic data offers a scalable, privacy-preserving solution. We evaluated the feasibility of generating realistic lateral cervical spine radiographs using a denoising diffusion probabilistic model (DDPM) trained on 4,963 images from the Cervical Spine X-ray Atlas. Model performance was monitored via training/validation loss and Frechet inception distance, and synthetic image quality was assessed in a blinded \"clinical Turing test\" with six neuroradiologists and two spine-fellowship t...",
      "pdf_url": "https://arxiv.org/pdf/2510.22166v1.pdf",
      "relevance_score": 69,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.02326v1",
      "title": "Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining",
      "authors": [
        "Yuxiang Wei",
        "Hojae Han",
        "Rajhans Samdani"
      ],
      "published": "2024-09-03T22:36:42Z",
      "categories": "",
      "summary": "Recent studies have been increasingly demonstrating that high-quality data is crucial for effective pretraining of language models. However, the precise definition of \"high-quality\" remains underexplored. Focusing on the code domain, we introduce Arctic-SnowCoder-1.3B, a data-efficient base code model pretrained on 555B tokens through three phases of progressively refined data: (1) general pretraining with 500B standard-quality code tokens, preprocessed through basic filtering, deduplication, and decontamination, (2) continued pretraining with 50B high-quality tokens, selected from phase one b...",
      "pdf_url": "https://arxiv.org/pdf/2409.02326v1.pdf",
      "relevance_score": 69,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.12574v3",
      "title": "ForgetMe: Evaluating Selective Forgetting in Generative Models",
      "authors": [
        "Zhenyu Yu",
        "Mohd Yamani Inda Idris",
        "Pei Wang"
      ],
      "published": "2025-04-17T01:44:57Z",
      "categories": "",
      "summary": "The widespread adoption of diffusion models in image generation has increased the demand for privacy-compliant unlearning. However, due to the high-dimensional nature and complex feature representations of diffusion models, achieving selective unlearning remains challenging, as existing methods struggle to remove sensitive information while preserving the consistency of non-sensitive regions. To address this, we propose an Automatic Dataset Creation Framework based on prompt-based layered editing and training-free local feature removal, constructing the ForgetMe dataset and introducing the Ent...",
      "pdf_url": "https://arxiv.org/pdf/2504.12574v3.pdf",
      "relevance_score": 69,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.18564v1",
      "title": "VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning",
      "authors": [
        "Xuanyu Zhang",
        "Weiqi Li",
        "Shijie Zhao",
        "Junlin Li",
        "Li Zhang",
        "Jian Zhang"
      ],
      "published": "2025-06-23T12:20:14Z",
      "categories": "",
      "summary": "Recent advances in AI-generated content (AIGC) have led to the emergence of powerful text-to-video generation models. Despite these successes, evaluating the quality of AIGC-generated videos remains challenging due to limited generalization, lack of temporal awareness, heavy reliance on large-scale annotated datasets, and the lack of effective interaction with generation models. Most current approaches rely on supervised finetuning of vision-language models (VLMs), which often require large-scale annotated datasets and tend to decouple understanding and generation. To address these shortcoming...",
      "pdf_url": "https://arxiv.org/pdf/2506.18564v1.pdf",
      "relevance_score": 68,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2310.20062v2",
      "title": "Scalable and Privacy-Preserving Synthetic Data Generation on Decentralised Web",
      "authors": [
        "Vishal Ramesh",
        "Rui Zhao",
        "Naman Goel"
      ],
      "published": "2023-10-30T22:27:32Z",
      "categories": "",
      "summary": "Data on the Web has fueled much of the recent progress in AI. As more high-quality data becomes difficult to access, synthetic data is emerging as a promising solution for privacy-friendly data release and complementing real datasets in developing robust and safe AI. But there is limited work on decentralised, scalable and contributor-centric synthetic data generation systems. A recent proposal, called Libertas, allows data contributors to autonomously participate in joint computations over their Web data without relying on a trusted centre. Libertas uses Solid (Social Linked Data) and MPC (Se...",
      "pdf_url": "https://arxiv.org/pdf/2310.20062v2.pdf",
      "relevance_score": 67,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.17573v3",
      "title": "Securing Federated Learning against Backdoor Threats with Foundation Model Integration",
      "authors": [
        "Xiaohuan Bi",
        "Xi Li"
      ],
      "published": "2024-10-23T05:54:41Z",
      "categories": "",
      "summary": "Federated Learning (FL) enables decentralized model training while preserving privacy. Recently, the integration of Foundation Models (FMs) into FL has enhanced performance but introduced a novel backdoor attack mechanism. Attackers can exploit FM vulnerabilities to embed backdoors into synthetic data generated by FMs. During global model fusion, these backdoors are transferred to the global model through compromised synthetic data, subsequently infecting all client models. Existing FL backdoor defenses are ineffective against this novel attack due to its fundamentally different mechanism comp...",
      "pdf_url": "https://arxiv.org/pdf/2410.17573v3.pdf",
      "relevance_score": 67,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.16541v2",
      "title": "Supervised Contrastive Learning for Few-Shot AI-Generated Image Detection and Attribution",
      "authors": [
        "Jaime \u00c1lvarez Urue\u00f1a",
        "David Camacho",
        "Javier Huertas Tato"
      ],
      "published": "2025-11-20T16:53:24Z",
      "categories": "",
      "summary": "The rapid advancement of generative artificial intelligence has enabled the creation of synthetic images that are increasingly indistinguishable from authentic content, posing significant challenges for digital media integrity. This problem is compounded by the accelerated release cycle of novel generative models, which renders traditional detection approaches (reliant on periodic retraining) computationally infeasible and operationally impractical.   This work proposes a novel two-stage detection framework designed to address the generalization challenge inherent in synthetic image detection....",
      "pdf_url": "https://arxiv.org/pdf/2511.16541v2.pdf",
      "relevance_score": 67,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.01789v2",
      "title": "Datasheets Aren't Enough: DataRubrics for Automated Quality Metrics and Accountability",
      "authors": [
        "Genta Indra Winata",
        "David Anugraha",
        "Emmy Liu",
        "Alham Fikri Aji",
        "Shou-Yi Hung",
        "Aditya Parashar",
        "Patrick Amadeus Irawan",
        "Ruochen Zhang",
        "Zheng-Xin Yong",
        "Jan Christian Blaise Cruz",
        "Niklas Muennighoff",
        "Seungone Kim",
        "Hanyang Zhao",
        "Sudipta Kar",
        "Kezia Erina Suryoraharjo",
        "M. Farid Adilazuarda",
        "En-Shiun Annie Lee",
        "Ayu Purwarianti",
        "Derry Tanti Wijaya",
        "Monojit Choudhury"
      ],
      "published": "2025-06-02T15:31:52Z",
      "categories": "",
      "summary": "High-quality datasets are fundamental to training and evaluating machine learning models, yet their creation-especially with accurate human annotations-remains a significant challenge. Many dataset paper submissions lack originality, diversity, or rigorous quality control, and these shortcomings are often overlooked during peer review. Submissions also frequently omit essential details about dataset construction and properties. While existing tools such as datasheets aim to promote transparency, they are largely descriptive and do not provide standardized, measurable methods for evaluating dat...",
      "pdf_url": "https://arxiv.org/pdf/2506.01789v2.pdf",
      "relevance_score": 67,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.17231v2",
      "title": "Dyna-LfLH: Learning Agile Navigation in Dynamic Environments from Learned Hallucination",
      "authors": [
        "Saad Abdul Ghani",
        "Zizhao Wang",
        "Peter Stone",
        "Xuesu Xiao"
      ],
      "published": "2024-03-25T22:17:51Z",
      "categories": "",
      "summary": "This paper introduces Dynamic Learning from Learned Hallucination (Dyna-LfLH), a self-supervised method for training motion planners to navigate environments with dense and dynamic obstacles. Classical planners struggle with dense, unpredictable obstacles due to limited computation, while learning-based planners face challenges in acquiring high-quality demonstrations for imitation learning or dealing with exploration inefficiencies in reinforcement learning. Building on Learning from Hallucination (LfH), which synthesizes training data from past successful navigation experiences in simpler en...",
      "pdf_url": "https://arxiv.org/pdf/2403.17231v2.pdf",
      "relevance_score": 66,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.08802v1",
      "title": "Democratizing ML for Enterprise Security: A Self-Sustained Attack Detection Framework",
      "authors": [
        "Sadegh Momeni",
        "Ge Zhang",
        "Birkett Huber",
        "Hamza Harkous",
        "Sam Lipton",
        "Benoit Seguin",
        "Yanis Pavlidis"
      ],
      "published": "2025-12-09T16:58:08Z",
      "categories": "",
      "summary": "Despite advancements in machine learning for security, rule-based detection remains prevalent in Security Operations Centers due to the resource intensiveness and skill gap associated with ML solutions. While traditional rule-based methods offer efficiency, their rigidity leads to high false positives or negatives and requires continuous manual maintenance. This paper proposes a novel, two-stage hybrid framework to democratize ML-based threat detection. The first stage employs intentionally loose YARA rules for coarse-grained filtering, optimized for high recall. The second stage utilizes an M...",
      "pdf_url": "https://arxiv.org/pdf/2512.08802v1.pdf",
      "relevance_score": 65,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2311.15460v1",
      "title": "Privacy-Preserving Data Sharing in Agriculture: Enforcing Policy Rules for Secure and Confidential Data Synthesis",
      "authors": [
        "Anantaa Kotal",
        "Lavanya Elluri",
        "Deepti Gupta",
        "Varun Mandalapu",
        "Anupam Joshi"
      ],
      "published": "2023-11-27T00:12:47Z",
      "categories": "",
      "summary": "Big Data empowers the farming community with the information needed to optimize resource usage, increase productivity, and enhance the sustainability of agricultural practices. The use of Big Data in farming requires the collection and analysis of data from various sources such as sensors, satellites, and farmer surveys. While Big Data can provide the farming community with valuable insights and improve efficiency, there is significant concern regarding the security of this data as well as the privacy of the participants. Privacy regulations, such as the EU GDPR, the EU Code of Conduct on agri...",
      "pdf_url": "https://arxiv.org/pdf/2311.15460v1.pdf",
      "relevance_score": 65,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.23041v2",
      "title": "Virus Infection Attack on LLMs: Your Poisoning Can Spread \"VIA\" Synthetic Data",
      "authors": [
        "Zi Liang",
        "Qingqing Ye",
        "Xuan Liu",
        "Yanyun Wang",
        "Jianliang Xu",
        "Haibo Hu"
      ],
      "published": "2025-09-27T01:39:41Z",
      "categories": "",
      "summary": "Synthetic data refers to artificial samples generated by models. While it has been validated to significantly enhance the performance of large language models (LLMs) during training and has been widely adopted in LLM development, potential security risks it may introduce remain uninvestigated. This paper systematically evaluates the resilience of synthetic-data-integrated training paradigm for LLMs against mainstream poisoning and backdoor attacks. We reveal that such a paradigm exhibits strong resistance to existing attacks, primarily thanks to the different distribution patterns between pois...",
      "pdf_url": "https://arxiv.org/pdf/2509.23041v2.pdf",
      "relevance_score": 65,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.19482v2",
      "title": "KSHSeek: Data-Driven Approaches to Mitigating and Detecting Knowledge-Shortcut Hallucinations in Generative Models",
      "authors": [
        "Zhongxin Liu",
        "Zhiwei Wang",
        "Jun Niu",
        "Ying Li",
        "Hongyu Sun",
        "Meng Xu",
        "He Wang",
        "Gaofei Wu",
        "Yuqing Zhang"
      ],
      "published": "2025-03-25T09:18:27Z",
      "categories": "",
      "summary": "The emergence of large language models (LLMs) has significantly advanced the development of natural language processing (NLP), especially in text generation tasks like question answering. However, model hallucinations remain a major challenge in natural language generation (NLG) tasks due to their complex causes. We systematically expand on the causes of factual hallucinations from the perspective of knowledge shortcuts, analyzing hallucinations arising from correct and defect-free data and demonstrating that knowledge-shortcut hallucinations are prevalent in generative models. To mitigate thi...",
      "pdf_url": "https://arxiv.org/pdf/2503.19482v2.pdf",
      "relevance_score": 65,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.17783v1",
      "title": "Leveraging the Domain Adaptation of Retrieval Augmented Generation Models for Question Answering and Reducing Hallucination",
      "authors": [
        "Salman Rakin",
        "Md. A. R. Shibly",
        "Zahin M. Hossain",
        "Zeeshan Khan",
        "Md. Mostofa Akbar"
      ],
      "published": "2024-10-23T11:32:46Z",
      "categories": "",
      "summary": "While ongoing advancements in Large Language Models have demonstrated remarkable success across various NLP tasks, Retrieval Augmented Generation Model stands out to be highly effective on downstream applications like Question Answering. Recently, RAG-end2end model further optimized the architecture and achieved notable performance improvements on domain adaptation. However, the effectiveness of these RAG-based architectures remains relatively unexplored when fine-tuned on specialized domains such as customer service for building a reliable conversational AI system. Furthermore, a critical cha...",
      "pdf_url": "https://arxiv.org/pdf/2410.17783v1.pdf",
      "relevance_score": 65,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.17730v1",
      "title": "AdaptPrompt: Parameter-Efficient Adaptation of VLMs for Generalizable Deepfake Detection",
      "authors": [
        "Yichen Jiang",
        "Mohammed Talha Alam",
        "Sohail Ahmed Khan",
        "Duc-Tien Dang-Nguyen",
        "Fakhri Karray"
      ],
      "published": "2025-12-19T16:06:03Z",
      "categories": "",
      "summary": "Recent advances in image generation have led to the widespread availability of highly realistic synthetic media, increasing the difficulty of reliable deepfake detection. A key challenge is generalization, as detectors trained on a narrow class of generators often fail when confronted with unseen models. In this work, we address the pressing need for generalizable detection by leveraging large vision-language models, specifically CLIP, to identify synthetic content across diverse generative techniques. First, we introduce Diff-Gen, a large-scale benchmark dataset comprising 100k diffusion-gene...",
      "pdf_url": "https://arxiv.org/pdf/2512.17730v1.pdf",
      "relevance_score": 65,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2312.15561v5",
      "title": "README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP",
      "authors": [
        "Zonghai Yao",
        "Nandyala Siddharth Kantu",
        "Guanghao Wei",
        "Hieu Tran",
        "Zhangqi Duan",
        "Sunjae Kwon",
        "Zhichao Yang",
        "README annotation team",
        "Hong Yu"
      ],
      "published": "2023-12-24T23:01:00Z",
      "categories": "",
      "summary": "The advancement in healthcare has shifted focus toward patient-centric approaches, particularly in self-care and patient education, facilitated by access to Electronic Health Records (EHR). However, medical jargon in EHRs poses significant challenges in patient comprehension. To address this, we introduce a new task of automatically generating lay definitions, aiming to simplify complex medical terms into patient-friendly lay language. We first created the README dataset, an extensive collection of over 50,000 unique (medical term, lay definition) pairs and 300,000 mentions, each offering cont...",
      "pdf_url": "https://arxiv.org/pdf/2312.15561v5.pdf",
      "relevance_score": 64,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.06663v1",
      "title": "SecureNet: A Comparative Study of DeBERTa and Large Language Models for Phishing Detection",
      "authors": [
        "Sakshi Mahendru",
        "Tejul Pandit"
      ],
      "published": "2024-06-10T13:13:39Z",
      "categories": "",
      "summary": "Phishing, whether through email, SMS, or malicious websites, poses a major threat to organizations by using social engineering to trick users into revealing sensitive information. It not only compromises company's data security but also incurs significant financial losses. In this paper, we investigate whether the remarkable performance of Large Language Models (LLMs) can be leveraged for particular task like text classification, particularly detecting malicious content and compare its results with state-of-the-art Deberta V3 (DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled...",
      "pdf_url": "https://arxiv.org/pdf/2406.06663v1.pdf",
      "relevance_score": 64,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.22037v1",
      "title": "Secure Tug-of-War (SecTOW): Iterative Defense-Attack Training with Reinforcement Learning for Multimodal Model Security",
      "authors": [
        "Muzhi Dai",
        "Shixuan Liu",
        "Zhiyuan Zhao",
        "Junyu Gao",
        "Hao Sun",
        "Xuelong Li"
      ],
      "published": "2025-07-29T17:39:48Z",
      "categories": "",
      "summary": "The rapid advancement of multimodal large language models (MLLMs) has led to breakthroughs in various applications, yet their security remains a critical challenge. One pressing issue involves unsafe image-query pairs--jailbreak inputs specifically designed to bypass security constraints and elicit unintended responses from MLLMs. Compared to general multimodal data, such unsafe inputs are relatively sparse, which limits the diversity and richness of training samples available for developing robust defense models. Meanwhile, existing guardrail-type methods rely on external modules to enforce s...",
      "pdf_url": "https://arxiv.org/pdf/2507.22037v1.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2402.18329v2",
      "title": "Robust Synthetic Data-Driven Detection of Living-Off-the-Land Reverse Shells",
      "authors": [
        "Dmitrijs Trizna",
        "Luca Demetrio",
        "Battista Biggio",
        "Fabio Roli"
      ],
      "published": "2024-02-28T13:49:23Z",
      "categories": "",
      "summary": "Living-off-the-land (LOTL) techniques pose a significant challenge to security operations, exploiting legitimate tools to execute malicious commands that evade traditional detection methods. To address this, we present a robust augmentation framework for cyber defense systems as Security Information and Event Management (SIEM) solutions, enabling the detection of LOTL attacks such as reverse shells through machine learning. Leveraging real-world threat intelligence and adversarial training, our framework synthesizes diverse malicious datasets while preserving the variability of legitimate acti...",
      "pdf_url": "https://arxiv.org/pdf/2402.18329v2.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2405.04180v1",
      "title": "Sora Detector: A Unified Hallucination Detection for Large Text-to-Video Models",
      "authors": [
        "Zhixuan Chu",
        "Lei Zhang",
        "Yichen Sun",
        "Siqiao Xue",
        "Zhibo Wang",
        "Zhan Qin",
        "Kui Ren"
      ],
      "published": "2024-05-07T10:39:14Z",
      "categories": "",
      "summary": "The rapid advancement in text-to-video (T2V) generative models has enabled the synthesis of high-fidelity video content guided by textual descriptions. Despite this significant progress, these models are often susceptible to hallucination, generating contents that contradict the input text, which poses a challenge to their reliability and practical deployment. To address this critical issue, we introduce the SoraDetector, a novel unified framework designed to detect hallucinations across diverse large T2V models, including the cutting-edge Sora model. Our framework is built upon a comprehensiv...",
      "pdf_url": "https://arxiv.org/pdf/2405.04180v1.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.07457v5",
      "title": "Estimating the Hallucination Rate of Generative AI",
      "authors": [
        "Andrew Jesson",
        "Nicolas Beltran-Velez",
        "Quentin Chu",
        "Sweta Karlekar",
        "Jannik Kossen",
        "Yarin Gal",
        "John P. Cunningham",
        "David Blei"
      ],
      "published": "2024-06-11T17:01:52Z",
      "categories": "",
      "summary": "This paper presents a method for estimating the hallucination rate for in-context learning (ICL) with generative AI. In ICL, a conditional generative model (CGM) is prompted with a dataset and a prediction question and asked to generate a response. One interpretation of ICL assumes that the CGM computes the posterior predictive of an unknown Bayesian model, which implicitly defines a joint distribution over observable datasets and latent mechanisms. This joint distribution factorizes into two components: the model prior over mechanisms and the model likelihood of datasets given a mechanism. Wi...",
      "pdf_url": "https://arxiv.org/pdf/2406.07457v5.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.02730v1",
      "title": "MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context",
      "authors": [
        "Zishan Gu",
        "Changchang Yin",
        "Fenglin Liu",
        "Ping Zhang"
      ],
      "published": "2024-07-03T00:59:03Z",
      "categories": "",
      "summary": "Large Vision Language Models (LVLMs) have recently achieved superior performance in various tasks on natural image and text data, which inspires a large amount of studies for LVLMs fine-tuning and training. Despite their advancements, there has been scant research on the robustness of these models against hallucination when fine-tuned on smaller datasets. In this study, we introduce a new benchmark dataset, the Medical Visual Hallucination Test (MedVH), to evaluate the hallucination of domain-specific LVLMs. MedVH comprises five tasks to evaluate hallucinations in LVLMs within the medical cont...",
      "pdf_url": "https://arxiv.org/pdf/2407.02730v1.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2211.04590v1",
      "title": "LGSQE: Lightweight Generated Sample Quality Evaluatoin",
      "authors": [
        "Ganning Zhao",
        "Vasileios Magoulianitis",
        "Suya You",
        "C. -C. Jay Kuo"
      ],
      "published": "2022-11-08T22:10:57Z",
      "categories": "",
      "summary": "Despite prolific work on evaluating generative models, little research has been done on the quality evaluation of an individual generated sample. To address this problem, a lightweight generated sample quality evaluation (LGSQE) method is proposed in this work. In the training stage of LGSQE, a binary classifier is trained on real and synthetic samples, where real and synthetic data are labeled by 0 and 1, respectively. In the inference stage, the classifier assigns soft labels (ranging from 0 to 1) to each generated sample. The value of soft label indicates the quality level; namely, the qual...",
      "pdf_url": "https://arxiv.org/pdf/2211.04590v1.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1708.01759v1",
      "title": "Referenceless Quality Estimation for Natural Language Generation",
      "authors": [
        "Ond\u0159ej Du\u0161ek",
        "Jekaterina Novikova",
        "Verena Rieser"
      ],
      "published": "2017-08-05T12:24:04Z",
      "categories": "",
      "summary": "Traditional automatic evaluation measures for natural language generation (NLG) use costly human-authored references to estimate the quality of a system output. In this paper, we propose a referenceless quality estimation (QE) approach based on recurrent neural networks, which predicts a quality score for a NLG system output by comparing it to the source meaning representation only. Our method outperforms traditional metrics and a constant baseline in most respects; we also show that synthetic data helps to increase correlation results by 21% compared to the base system. Our results are compar...",
      "pdf_url": "https://arxiv.org/pdf/1708.01759v1.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.21566v1",
      "title": "The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation",
      "authors": [
        "Arwa Arif"
      ],
      "published": "2025-06-12T09:02:53Z",
      "categories": "",
      "summary": "Backtranslation BT is widely used in low resource machine translation MT to generate additional synthetic training data using monolingual corpora. While this approach has shown strong improvements for many language pairs, its effectiveness in high quality, low resource settings remains unclear. In this work, we explore the effectiveness of backtranslation for English Gujarati translation using the multilingual pretrained MBART50 model. Our baseline system, trained on a high quality parallel corpus of approximately 50,000 sentence pairs, achieves a BLEU score of 43.8 on a validation set. We aug...",
      "pdf_url": "https://arxiv.org/pdf/2506.21566v1.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2308.12060v3",
      "title": "FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering",
      "authors": [
        "Zhenyu Li",
        "Sunqi Fan",
        "Yu Gu",
        "Xiuxing Li",
        "Zhichao Duan",
        "Bowen Dong",
        "Ning Liu",
        "Jianyong Wang"
      ],
      "published": "2023-08-23T11:00:36Z",
      "categories": "",
      "summary": "Knowledge base question answering (KBQA) is a critical yet challenging task due to the vast number of entities within knowledge bases and the diversity of natural language questions posed by users. Unfortunately, the performance of most KBQA models tends to decline significantly in real-world scenarios where high-quality annotated data is insufficient. To mitigate the burden associated with manual annotation, we introduce FlexKBQA by utilizing Large Language Models (LLMs) as program translators for addressing the challenges inherent in the few-shot KBQA task. Specifically, FlexKBQA leverages a...",
      "pdf_url": "https://arxiv.org/pdf/2308.12060v3.pdf",
      "relevance_score": 63,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.20369v1",
      "title": "AI-driven formative assessment and adaptive learning in data-science education: Evaluating an LLM-powered virtual teaching assistant",
      "authors": [
        "Fadjimata I Anaroua",
        "Qing Li",
        "Yan Tang",
        "Hong P. Liu"
      ],
      "published": "2025-09-17T11:27:45Z",
      "categories": "",
      "summary": "This paper presents VITA (Virtual Teaching Assistants), an adaptive distributed learning (ADL) platform that embeds a large language model (LLM)-powered chatbot (BotCaptain) to provide dialogic support, interoperable analytics, and integrity-aware assessment for workforce preparation in data science. The platform couples context-aware conversational tutoring with formative-assessment patterns designed to promote reflective reasoning. The paper describes an end-to-end data pipeline that transforms chat logs into Experience API (xAPI) statements, instructor dashboards that surface outliers for j...",
      "pdf_url": "https://arxiv.org/pdf/2509.20369v1.pdf",
      "relevance_score": 62,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.00160v2",
      "title": "Improving Quality Control Of MRI Images Using Synthetic Motion Data",
      "authors": [
        "Charles Bricout",
        "Kang Ik K. Cho",
        "Michael Harms",
        "Ofer Pasternak",
        "Carrie E. Bearden",
        "Patrick D. McGorry",
        "Rene S. Kahn",
        "John Kane",
        "Barnaby Nelson",
        "Scott W. Woods",
        "Martha E. Shenton",
        "Sylvain Bouix",
        "Samira Ebrahimi Kahou"
      ],
      "published": "2025-01-31T20:50:55Z",
      "categories": "",
      "summary": "MRI quality control (QC) is challenging due to unbalanced and limited datasets, as well as subjective scoring, which hinder the development of reliable automated QC systems. To address these issues, we introduce an approach that pretrains a model on synthetically generated motion artifacts before applying transfer learning for QC classification. This method not only improves the accuracy in identifying poor-quality scans but also reduces training time and resource requirements compared to training from scratch. By leveraging synthetic data, we provide a more robust and resource-efficient solut...",
      "pdf_url": "https://arxiv.org/pdf/2502.00160v2.pdf",
      "relevance_score": 62,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.14191v2",
      "title": "Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education",
      "authors": [
        "Chengshuai Zhao",
        "Garima Agrawal",
        "Fan Zhang",
        "Tharindu Kumarage",
        "Zhen Tan",
        "Yuli Deng",
        "Ying-Chih Chen",
        "Huan Liu"
      ],
      "published": "2024-12-10T21:52:35Z",
      "categories": "",
      "summary": "Integrating AI into education has the potential to transform the teaching of science and technology courses, particularly in the field of cybersecurity. AI-driven question-answering (QA) systems can actively manage uncertainty in cybersecurity problem-solving, offering interactive, inquiry-based learning experiences. Recently, Large language models (LLMs) have gained prominence in AI-driven QA systems, enabling advanced language understanding and user engagement. However, they face challenges like hallucinations and limited domain-specific knowledge, which reduce their reliability in education...",
      "pdf_url": "https://arxiv.org/pdf/2412.14191v2.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2401.07358v2",
      "title": "Harnessing Machine Learning for Discerning AI-Generated Synthetic Images",
      "authors": [
        "Yuyang Wang",
        "Yizhi Hao",
        "Amando Xu Cong"
      ],
      "published": "2024-01-14T20:00:37Z",
      "categories": "",
      "summary": "In the realm of digital media, the advent of AI-generated synthetic images has introduced significant challenges in distinguishing between real and fabricated visual content. These images, often indistinguishable from authentic ones, pose a threat to the credibility of digital media, with potential implications for disinformation and fraud. Our research addresses this challenge by employing machine learning techniques to discern between AI-generated and genuine images. Central to our approach is the CIFAKE dataset, a comprehensive collection of images labeled as \"Real\" and \"Fake\". We refine an...",
      "pdf_url": "https://arxiv.org/pdf/2401.07358v2.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.01396v2",
      "title": "All Patches Matter, More Patches Better: Enhance AI-Generated Image Detection via Panoptic Patch Learning",
      "authors": [
        "Zheng Yang",
        "Ruoxin Chen",
        "Zhiyuan Yan",
        "Ke-Yue Zhang",
        "Xinghe Fu",
        "Shuang Wu",
        "Xiujun Shu",
        "Taiping Yao",
        "Shouhong Ding",
        "Xi Li"
      ],
      "published": "2025-04-02T06:32:09Z",
      "categories": "",
      "summary": "The exponential growth of AI-generated images (AIGIs) underscores the urgent need for robust and generalizable detection methods. In this paper, we establish two key principles for AIGI detection through systematic analysis: (1) All Patches Matter: Unlike conventional image classification where discriminative features concentrate on object-centric regions, each patch in AIGIs inherently contains synthetic artifacts due to the uniform generation process, suggesting that every patch serves as an important artifact source for detection. (2) More Patches Better: Leveraging distributed artifacts ac...",
      "pdf_url": "https://arxiv.org/pdf/2504.01396v2.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.14367v1",
      "title": "Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution",
      "authors": [
        "Weiming Ren",
        "Raghav Goyal",
        "Zhiming Hu",
        "Tristan Ty Aumentado-Armstrong",
        "Iqbal Mohomed",
        "Alex Levinshtein"
      ],
      "published": "2025-07-18T21:13:50Z",
      "categories": "",
      "summary": "Generative super-resolution (GSR) currently sets the state-of-the-art in terms of perceptual image quality, overcoming the \"regression-to-the-mean\" blur of prior non-generative models. However, from a human perspective, such models do not fully conform to the optimal balance between quality and fidelity. Instead, a different class of artifacts, in which generated details fail to perceptually match the low resolution image (LRI) or ground-truth image (GTI), is a critical but under studied issue in GSR, limiting its practical deployments. In this work, we focus on measuring, analyzing, and mitig...",
      "pdf_url": "https://arxiv.org/pdf/2507.14367v1.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2601.00269v1",
      "title": "FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering",
      "authors": [
        "Chaodong Tong",
        "Qi Zhang",
        "Chen Li",
        "Lei Jiang",
        "Yanbing Liu"
      ],
      "published": "2026-01-01T09:19:39Z",
      "categories": "",
      "summary": "Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficientl...",
      "pdf_url": "https://arxiv.org/pdf/2601.00269v1.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2310.16052v1",
      "title": "Synthetic Data as Validation",
      "authors": [
        "Qixin Hu",
        "Alan Yuille",
        "Zongwei Zhou"
      ],
      "published": "2023-10-24T17:59:55Z",
      "categories": "",
      "summary": "This study leverages synthetic data as a validation set to reduce overfitting and ease the selection of the best model in AI development. While synthetic data have been used for augmenting the training set, we find that synthetic data can also significantly diversify the validation set, offering marked advantages in domains like healthcare, where data are typically limited, sensitive, and from out-domain sources (i.e., hospitals). In this study, we illustrate the effectiveness of synthetic data for early cancer detection in computed tomography (CT) volumes, where synthetic tumors are generated...",
      "pdf_url": "https://arxiv.org/pdf/2310.16052v1.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2308.03740v1",
      "title": "A Cost Analysis of Generative Language Models and Influence Operations",
      "authors": [
        "Micah Musser"
      ],
      "published": "2023-08-07T17:38:41Z",
      "categories": "",
      "summary": "Despite speculation that recent large language models (LLMs) are likely to be used maliciously to improve the quality or scale of influence operations, uncertainty persists regarding the economic value that LLMs offer propagandists. This research constructs a model of costs facing propagandists for content generation at scale and analyzes (1) the potential savings that LLMs could offer propagandists, (2) the potential deterrent effect of monitoring controls on API-accessible LLMs, and (3) the optimal strategy for propagandists choosing between multiple private and/or open source LLMs when cond...",
      "pdf_url": "https://arxiv.org/pdf/2308.03740v1.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.08273v1",
      "title": "AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content",
      "authors": [
        "Thanh Vu",
        "Richi Nayak",
        "Thiru Balasubramaniam"
      ],
      "published": "2025-12-09T06:03:25Z",
      "categories": "",
      "summary": "Modern businesses are increasingly challenged by the time and expense required to generate and assess high-quality content. Human writers face time constraints, and extrinsic evaluations can be costly. While Large Language Models (LLMs) offer potential in content creation, concerns about the quality of AI-generated content persist. Traditional evaluation methods, like human surveys, further add operational costs, highlighting the need for efficient, automated solutions. This research introduces Generative Agents as a means to tackle these challenges. These agents can rapidly and cost-effective...",
      "pdf_url": "https://arxiv.org/pdf/2512.08273v1.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2109.12211v1",
      "title": "Style Control for Schema-Guided Natural Language Generation",
      "authors": [
        "Alicia Y. Tsai",
        "Shereen Oraby",
        "Vittorio Perera",
        "Jiun-Yu Kao",
        "Yuheng Du",
        "Anjali Narayan-Chen",
        "Tagyoung Chung",
        "Dilek Hakkani-Tur"
      ],
      "published": "2021-09-24T21:47:58Z",
      "categories": "",
      "summary": "Natural Language Generation (NLG) for task-oriented dialogue systems focuses on communicating specific content accurately, fluently, and coherently. While these attributes are crucial for a successful dialogue, it is also desirable to simultaneously accomplish specific stylistic goals, such as response length, point-of-view, descriptiveness, sentiment, formality, and empathy. In this work, we focus on stylistic control and evaluation for schema-guided NLG, with joint goals of achieving both semantic and stylistic control. We experiment in detail with various controlled generation methods for l...",
      "pdf_url": "https://arxiv.org/pdf/2109.12211v1.pdf",
      "relevance_score": 61,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2306.13865v1",
      "title": "IERL: Interpretable Ensemble Representation Learning -- Combining CrowdSourced Knowledge and Distributed Semantic Representations",
      "authors": [
        "Yuxin Zi",
        "Kaushik Roy",
        "Vignesh Narayanan",
        "Manas Gaur",
        "Amit Sheth"
      ],
      "published": "2023-06-24T05:02:34Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) encode meanings of words in the form of distributed semantics. Distributed semantics capture common statistical patterns among language tokens (words, phrases, and sentences) from large amounts of data. LLMs perform exceedingly well across General Language Understanding Evaluation (GLUE) tasks designed to test a model's understanding of the meanings of the input tokens. However, recent studies have shown that LLMs tend to generate unintended, inconsistent, or wrong texts as outputs when processing inputs that were seen rarely during training, or inputs that are ass...",
      "pdf_url": "https://arxiv.org/pdf/2306.13865v1.pdf",
      "relevance_score": 60,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2104.08704v2",
      "title": "A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation",
      "authors": [
        "Tianyu Liu",
        "Yizhe Zhang",
        "Chris Brockett",
        "Yi Mao",
        "Zhifang Sui",
        "Weizhu Chen",
        "Bill Dolan"
      ],
      "published": "2021-04-18T04:09:48Z",
      "categories": "",
      "summary": "Large pretrained generative models like GPT-3 often suffer from hallucinating non-existent or incorrect content, which undermines their potential merits in real applications. Existing work usually attempts to detect these hallucinations based on a corresponding oracle reference at a sentence or document level. However ground-truth references may not be readily available for many free-form text generation applications, and sentence- or document-level detection may fail to provide the fine-grained signals that would prevent fallacious content in real time. As a first step to addressing these iss...",
      "pdf_url": "https://arxiv.org/pdf/2104.08704v2.pdf",
      "relevance_score": 60,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.04676v1",
      "title": "Gen-n-Val: Agentic Image Data Generation and Validation",
      "authors": [
        "Jing-En Huang",
        "I-Sheng Fang",
        "Tzuhsuan Huang",
        "Chih-Yu Wang",
        "Jun-Cheng Chen"
      ],
      "published": "2025-06-05T06:52:26Z",
      "categories": "",
      "summary": "Recently, Large Language Models (LLMs) and Vision Large Language Models (VLLMs) have demonstrated impressive performance as agents across various tasks while data scarcity and label noise remain significant challenges in computer vision tasks, such as object detection and instance segmentation. A common solution for resolving these issues is to generate synthetic data. However, current synthetic data generation methods struggle with issues, such as multiple objects per mask, inaccurate segmentation, and incorrect category labels, limiting their effectiveness. To address these issues, we introd...",
      "pdf_url": "https://arxiv.org/pdf/2506.04676v1.pdf",
      "relevance_score": 60,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.02949v2",
      "title": "RADIANT: Retrieval AugmenteD entIty-context AligNmenT -- Introducing RAG-ability and Entity-Context Divergence",
      "authors": [
        "Vipula Rawte",
        "Rajarshi Roy",
        "Gurpreet Singh",
        "Danush Khanna",
        "Yaswanth Narsupalli",
        "Basab Ghosh",
        "Abhay Gupta",
        "Argha Kamal Samanta",
        "Aditya Shingote",
        "Aadi Krishna Vikram",
        "Vinija Jain",
        "Aman Chadha",
        "Amit Sheth",
        "Amitava Das"
      ],
      "published": "2025-06-28T21:40:35Z",
      "categories": "",
      "summary": "As Large Language Models (LLMs) continue to advance, Retrieval-Augmented Generation (RAG) has emerged as a vital technique to enhance factual accuracy by integrating external knowledge into the generation process. However, LLMs often fail to faithfully integrate retrieved evidence into their generated responses, leading to factual inconsistencies. To quantify this gap, we introduce Entity-Context Divergence (ECD), a metric that measures the extent to which retrieved information is accurately reflected in model outputs. We systematically evaluate contemporary LLMs on their ability to preserve f...",
      "pdf_url": "https://arxiv.org/pdf/2507.02949v2.pdf",
      "relevance_score": 60,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.10596v2",
      "title": "Post-training an LLM for RAG? Train on Self-Generated Demonstrations",
      "authors": [
        "Matthew Finlayson",
        "Ilia Kulikov",
        "Daniel M. Bikel",
        "Barlas Oguz",
        "Xilun Chen",
        "Aasish Pappu"
      ],
      "published": "2025-02-14T23:00:49Z",
      "categories": "",
      "summary": "Large language models (LLMs) often struggle with knowledge intensive NLP tasks, such as answering \"Who won the latest World Cup?\" because the knowledge they learn during training may be insufficient or outdated. Conditioning generation on retrieved documents -- a technique known as retrieval augmented generation (RAG) -- mitigates these shortcomings by allowing the model to leverage in-context information. Practitioners can improve LLM RAG performance by fine-tuning on retrieval-augmented instructions, but must beware that this can cause undesirable model behaviors like hallucinations. We attr...",
      "pdf_url": "https://arxiv.org/pdf/2502.10596v2.pdf",
      "relevance_score": 59,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.10489v1",
      "title": "SynthGuard: Redefining Synthetic Data Generation with a Scalable and Privacy-Preserving Workflow Framework",
      "authors": [
        "Eduardo Brito",
        "Mahmoud Shoush",
        "Kristian Tamm",
        "Paula Etti",
        "Liina Kamm"
      ],
      "published": "2025-07-14T17:11:20Z",
      "categories": "",
      "summary": "The growing reliance on data-driven applications in sectors such as healthcare, finance, and law enforcement underscores the need for secure, privacy-preserving, and scalable mechanisms for data generation and sharing. Synthetic data generation (SDG) has emerged as a promising approach but often relies on centralized or external processing, raising concerns about data sovereignty, domain ownership, and compliance with evolving regulatory standards. To overcome these issues, we introduce SynthGuard, a framework designed to ensure computational governance by enabling data owners to maintain cont...",
      "pdf_url": "https://arxiv.org/pdf/2507.10489v1.pdf",
      "relevance_score": 59,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2405.10994v1",
      "title": "\"What do you want from theory alone?\" Experimenting with Tight Auditing of Differentially Private Synthetic Data Generation",
      "authors": [
        "Meenatchi Sundaram Muthu Selva Annamalai",
        "Georgi Ganev",
        "Emiliano De Cristofaro"
      ],
      "published": "2024-05-16T14:23:48Z",
      "categories": "",
      "summary": "Differentially private synthetic data generation (DP-SDG) algorithms are used to release datasets that are structurally and statistically similar to sensitive data while providing formal bounds on the information they leak. However, bugs in algorithms and implementations may cause the actual information leakage to be higher. This prompts the need to verify whether the theoretical guarantees of state-of-the-art DP-SDG implementations also hold in practice. We do so via a rigorous auditing process: we compute the information leakage via an adversary playing a distinguishing game and running memb...",
      "pdf_url": "https://arxiv.org/pdf/2405.10994v1.pdf",
      "relevance_score": 59,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.20800v1",
      "title": "Evidencing Unauthorized Training Data from AI Generated Content using Information Isotopes",
      "authors": [
        "Qi Tao",
        "Yin Jinhua",
        "Cai Dongqi",
        "Xie Yueqi",
        "Wang Huili",
        "Hu Zhiyang",
        "Yang Peiru",
        "Nan Guoshun",
        "Zhou Zhili",
        "Wang Shangguang",
        "Lyu Lingjuan",
        "Huang Yongfeng",
        "Lane Nicholas"
      ],
      "published": "2025-03-24T07:35:59Z",
      "categories": "",
      "summary": "In light of scaling laws, many AI institutions are intensifying efforts to construct advanced AIs on extensive collections of high-quality human data. However, in a rush to stay competitive, some institutions may inadvertently or even deliberately include unauthorized data (like privacy- or intellectual property-sensitive content) for AI training, which infringes on the rights of data owners. Compounding this issue, these advanced AI services are typically built on opaque cloud platforms, which restricts access to internal information during AI training and inference, leaving only the generate...",
      "pdf_url": "https://arxiv.org/pdf/2503.20800v1.pdf",
      "relevance_score": 59,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.13224v1",
      "title": "Leveraging Pre-Trained Visual Models for AI-Generated Video Detection",
      "authors": [
        "Keerthi Veeramachaneni",
        "Praveen Tirupattur",
        "Amrit Singh Bedi",
        "Mubarak Shah"
      ],
      "published": "2025-07-17T15:36:39Z",
      "categories": "",
      "summary": "Recent advances in Generative AI (GenAI) have led to significant improvements in the quality of generated visual content. As AI-generated visual content becomes increasingly indistinguishable from real content, the challenge of detecting the generated content becomes critical in combating misinformation, ensuring privacy, and preventing security threats. Although there has been substantial progress in detecting AI-generated images, current methods for video detection are largely focused on deepfakes, which primarily involve human faces. However, the field of video generation has advanced beyon...",
      "pdf_url": "https://arxiv.org/pdf/2507.13224v1.pdf",
      "relevance_score": 59,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.24116v2",
      "title": "AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization",
      "authors": [
        "Amir Kazemi",
        "Qurat ul ain Fatima",
        "Volodymyr Kindratenko",
        "Christopher Tessum"
      ],
      "published": "2024-10-31T16:46:23Z",
      "categories": "",
      "summary": "Image labeling is a critical bottleneck in the development of computer vision technologies, often constraining the potential of machine learning models due to the time-intensive nature of manual annotations. This work introduces a novel approach that leverages outpainting to mitigate the problem of annotated data scarcity by generating artificial contexts and annotations, significantly reducing manual labeling efforts. We apply this technique to a particularly acute challenge in autonomous driving, urban planning, and environmental monitoring: the lack of diverse, eye-level vehicle images in d...",
      "pdf_url": "https://arxiv.org/pdf/2410.24116v2.pdf",
      "relevance_score": 59,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.00866v2",
      "title": "The Data-Quality Illusion: Rethinking Classifier-Based Quality Filtering for LLM Pretraining",
      "authors": [
        "Thiziri Nait Saada",
        "Louis Bethune",
        "Michal Klein",
        "David Grangier",
        "Marco Cuturi",
        "Pierre Ablin"
      ],
      "published": "2025-10-01T13:15:15Z",
      "categories": "",
      "summary": "Large-scale models are pretrained on massive web-crawled datasets containing documents of mixed quality, making data filtering essential. A popular method is Classifier-based Quality Filtering (CQF), which trains a binary classifier to distinguish between pretraining data and a small, high-quality set. It assigns each pretraining document a quality score defined as the classifier's score and retains only the top-scoring ones. We provide an in-depth analysis of CQF. We show that while CQF improves downstream task performance, it does not necessarily enhance language modeling on the high-quality...",
      "pdf_url": "https://arxiv.org/pdf/2510.00866v2.pdf",
      "relevance_score": 59,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2102.04020v1",
      "title": "Quality Estimation without Human-labeled Data",
      "authors": [
        "Yi-Lin Tuan",
        "Ahmed El-Kishky",
        "Adithya Renduchintala",
        "Vishrav Chaudhary",
        "Francisco Guzm\u00e1n",
        "Lucia Specia"
      ],
      "published": "2021-02-08T06:25:46Z",
      "categories": "",
      "summary": "Quality estimation aims to measure the quality of translated content without access to a reference translation. This is crucial for machine translation systems in real-world scenarios where high-quality translation is needed. While many approaches exist for quality estimation, they are based on supervised machine learning requiring costly human labelled data. As an alternative, we propose a technique that does not rely on examples from human-annotators and instead uses synthetic training data. We train off-the-shelf architectures for supervised quality estimation on our synthetic data and show...",
      "pdf_url": "https://arxiv.org/pdf/2102.04020v1.pdf",
      "relevance_score": 59,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2210.13591v2",
      "title": "Learning by Hallucinating: Vision-Language Pre-training with Weak Supervision",
      "authors": [
        "Tzu-Jui Julius Wang",
        "Jorma Laaksonen",
        "Tomas Langer",
        "Heikki Arponen",
        "Tom E. Bishop"
      ],
      "published": "2022-10-24T20:30:55Z",
      "categories": "",
      "summary": "Weakly-supervised vision-language (V-L) pre-training (W-VLP) aims at learning cross-modal alignment with little or no paired data, such as aligned images and captions. Recent W-VLP methods, which pair visual features with object tags, help achieve performances comparable with some VLP models trained with aligned pairs in various V-L downstream tasks. This, however, is not the case in cross-modal retrieval (XMR). We argue that the learning of such a W-VLP model is curbed and biased by the object tags of limited semantics.   We address the lack of paired V-L data for model supervision with a nov...",
      "pdf_url": "https://arxiv.org/pdf/2210.13591v2.pdf",
      "relevance_score": 58,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.10490v4",
      "title": "Learning Dynamics of LLM Finetuning",
      "authors": [
        "Yi Ren",
        "Danica J. Sutherland"
      ],
      "published": "2024-07-15T07:30:28Z",
      "categories": "",
      "summary": "Learning dynamics, which describes how the learning of specific training examples influences the model's predictions on other examples, gives us a powerful tool for understanding the behavior of deep learning systems. We study the learning dynamics of large language models during different types of finetuning, by analyzing the step-wise decomposition of how influence accumulates among different potential responses. Our framework allows a uniform interpretation of many interesting observations about the training of popular algorithms for both instruction tuning and preference tuning. In particu...",
      "pdf_url": "https://arxiv.org/pdf/2407.10490v4.pdf",
      "relevance_score": 58,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2301.07779v2",
      "title": "Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection",
      "authors": [
        "Weijia Xu",
        "Sweta Agrawal",
        "Eleftheria Briakou",
        "Marianna J. Martindale",
        "Marine Carpuat"
      ],
      "published": "2023-01-18T20:43:13Z",
      "categories": "",
      "summary": "Neural sequence generation models are known to \"hallucinate\", by producing outputs that are unrelated to the source text. These hallucinations are potentially harmful, yet it remains unclear in what conditions they arise and how to mitigate their impact. In this work, we first identify internal model symptoms of hallucinations by analyzing the relative token contributions to the generation in contrastive hallucinated vs. non-hallucinated outputs generated via source perturbations. We then show that these symptoms are reliable indicators of natural hallucinations, by using them to design a ligh...",
      "pdf_url": "https://arxiv.org/pdf/2301.07779v2.pdf",
      "relevance_score": 58,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.00299v2",
      "title": "RadFlag: A Black-Box Hallucination Detection Method for Medical Vision Language Models",
      "authors": [
        "Serena Zhang",
        "Sraavya Sambara",
        "Oishi Banerjee",
        "Julian Acosta",
        "L. John Fahrner",
        "Pranav Rajpurkar"
      ],
      "published": "2024-11-01T01:38:42Z",
      "categories": "",
      "summary": "Generating accurate radiology reports from medical images is a clinically important but challenging task. While current Vision Language Models (VLMs) show promise, they are prone to generating hallucinations, potentially compromising patient care. We introduce RadFlag, a black-box method to enhance the accuracy of radiology report generation. Our method uses a sampling-based flagging technique to find hallucinatory generations that should be removed. We first sample multiple reports at varying temperatures and then use a Large Language Model (LLM) to identify claims that are not consistently s...",
      "pdf_url": "https://arxiv.org/pdf/2411.00299v2.pdf",
      "relevance_score": 58,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.18672v3",
      "title": "FactCheXcker: Mitigating Measurement Hallucinations in Chest X-ray Report Generation Models",
      "authors": [
        "Alice Heiman",
        "Xiaoman Zhang",
        "Emma Chen",
        "Sung Eun Kim",
        "Pranav Rajpurkar"
      ],
      "published": "2024-11-27T18:29:46Z",
      "categories": "",
      "summary": "Medical vision-language models often struggle with generating accurate quantitative measurements in radiology reports, leading to hallucinations that undermine clinical reliability. We introduce FactCheXcker, a modular framework that de-hallucinates radiology report measurements by leveraging an improved query-code-update paradigm. Specifically, FactCheXcker employs specialized modules and the code generation capabilities of large language models to solve measurement queries generated based on the original report. After extracting measurable findings, the results are incorporated into an updat...",
      "pdf_url": "https://arxiv.org/pdf/2411.18672v3.pdf",
      "relevance_score": 58,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.12079v1",
      "title": "Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks",
      "authors": [
        "Ningzhe Shi",
        "Yiqing Zhou",
        "Ling Liu",
        "Jinglin Shi",
        "Yihao Wu",
        "Haiwei Shi",
        "Hanxiao Yu"
      ],
      "published": "2025-08-16T15:29:59Z",
      "categories": "",
      "summary": "Integrated sensing and communication (ISAC) can enhance artificial intelligence-generated content (AIGC) networks by providing efficient sensing and transmission. Existing AIGC services usually assume that the accuracy of the generated content can be ensured, given accurate input data and prompt, thus only the content generation quality (CGQ) is concerned. However, it is not applicable in ISAC-based AIGC networks, where content generation is based on inaccurate sensed data. Moreover, the AIGC model itself introduces generation errors, which depend on the number of generating steps (i.e., compu...",
      "pdf_url": "https://arxiv.org/pdf/2508.12079v1.pdf",
      "relevance_score": 58,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.01955v2",
      "title": "The use of large language models to enhance cancer clinical trial educational materials",
      "authors": [
        "Mingye Gao",
        "Aman Varshney",
        "Shan Chen",
        "Vikram Goddla",
        "Jack Gallifant",
        "Patrick Doyle",
        "Claire Novack",
        "Maeve Dillon-Martin",
        "Teresia Perkins",
        "Xinrong Correia",
        "Erik Duhaime",
        "Howard Isenstein",
        "Elad Sharon",
        "Lisa Soleymani Lehmann",
        "David Kozono",
        "Brian Anthony",
        "Dmitriy Dligach",
        "Danielle S. Bitterman"
      ],
      "published": "2024-12-02T20:31:27Z",
      "categories": "",
      "summary": "Cancer clinical trials often face challenges in recruitment and engagement due to a lack of participant-facing informational and educational resources. This study investigated the potential of Large Language Models (LLMs), specifically GPT4, in generating patient-friendly educational content from clinical trial informed consent forms. Using data from ClinicalTrials.gov, we employed zero-shot learning for creating trial summaries and one-shot learning for developing multiple-choice questions, evaluating their effectiveness through patient surveys and crowdsourced annotation. Results showed that...",
      "pdf_url": "https://arxiv.org/pdf/2412.01955v2.pdf",
      "relevance_score": 57,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1911.07759v1",
      "title": "A gamified simulator and physical platform for self-driving algorithm training and validation",
      "authors": [
        "Joshua E. Siegel",
        "Georgios Pappas",
        "Konstantinos Politopoulos",
        "Yongbin Sun"
      ],
      "published": "2019-11-18T16:44:57Z",
      "categories": "",
      "summary": "We identify the need for a gamified self-driving simulator where game mechanics encourage high-quality data capture, and design and apply such a simulator to collecting lane-following training data. The resulting synthetic data enables a Convolutional Neural Network (CNN) to drive an in-game vehicle. We simultaneously develop a physical test platform based on a radio-controlled vehicle and the Robotic Operating System (ROS) and successfully transfer the simulation-trained model to the physical domain without modification. The cross-platform simulator facilitates unsupervised crowdsourcing, hel...",
      "pdf_url": "https://arxiv.org/pdf/1911.07759v1.pdf",
      "relevance_score": 57,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.09804v1",
      "title": "SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations",
      "authors": [
        "Eric Xie",
        "Danielle Waterfield",
        "Michael Kennedy",
        "Aidong Zhang"
      ],
      "published": "2025-11-12T23:12:05Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) have shown immense potential in education, automating tasks like quiz generation and content summarization. However, generating effective presentation slides introduces unique challenges due to the complexity of multimodal content creation and the need for precise, domain-specific information. Existing LLM-based solutions often fail to produce reliable and informative outputs, limiting their educational value. To address these limitations, we introduce SlideBot - a modular, multi-agent slide generation framework that integrates LLMs with retrieval, structured plann...",
      "pdf_url": "https://arxiv.org/pdf/2511.09804v1.pdf",
      "relevance_score": 57,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.07149v1",
      "title": "Glocalizing Generative AI in Education for the Global South: The Design Case of 21st Century Teacher Educator AI for Ghana",
      "authors": [
        "Matthew Nyaaba"
      ],
      "published": "2025-04-09T03:28:35Z",
      "categories": "",
      "summary": "This study presents the design and development of the 21st Century Teacher Educator for Ghana GPT, a customized Generative AI (GenAI) tool created using OpenAI's Retrieval-Augmented Generation (RAG) and Interactive Semi-Automated Prompting Strategy (ISA). Anchored in a Glocalized design approach, this tool supports pre-service teachers (PSTs) in Ghana by embedding localized linguistic, cultural, and curricular content within globally aligned principles of ethical and responsible AI use. The model utilizes structured, preloaded datasets-including Ghana's National Teacher Education Curriculum Fr...",
      "pdf_url": "https://arxiv.org/pdf/2504.07149v1.pdf",
      "relevance_score": 56,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2305.14224v1",
      "title": "mmT5: Modular Multilingual Pre-Training Solves Source Language Hallucinations",
      "authors": [
        "Jonas Pfeiffer",
        "Francesco Piccinno",
        "Massimo Nicosia",
        "Xinyi Wang",
        "Machel Reid",
        "Sebastian Ruder"
      ],
      "published": "2023-05-23T16:38:01Z",
      "categories": "",
      "summary": "Multilingual sequence-to-sequence models perform poorly with increased language coverage and fail to consistently generate text in the correct target language in few-shot settings. To address these challenges, we propose mmT5, a modular multilingual sequence-to-sequence model. mmT5 utilizes language-specific modules during pre-training, which disentangle language-specific information from language-agnostic information. We identify representation drift during fine-tuning as a key limitation of modular generative models and develop strategies that enable effective zero-shot transfer. Our model o...",
      "pdf_url": "https://arxiv.org/pdf/2305.14224v1.pdf",
      "relevance_score": 56,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.03083v1",
      "title": "Scaling Parameter-Constrained Language Models with Quality Data",
      "authors": [
        "Ernie Chang",
        "Matteo Paltenghi",
        "Yang Li",
        "Pin-Jie Lin",
        "Changsheng Zhao",
        "Patrick Huber",
        "Zechun Liu",
        "Rastislav Rabatin",
        "Yangyang Shi",
        "Vikas Chandra"
      ],
      "published": "2024-10-04T02:07:17Z",
      "categories": "",
      "summary": "Scaling laws in language modeling traditionally quantify training loss as a function of dataset size and model parameters, providing compute-optimal estimates but often neglecting the impact of data quality on model generalization. In this paper, we extend the conventional understanding of scaling law by offering a microscopic view of data quality within the original formulation -- effective training tokens -- which we posit to be a critical determinant of performance for parameter-constrained language models. Specifically, we formulate the proposed term of effective training tokens to be a co...",
      "pdf_url": "https://arxiv.org/pdf/2410.03083v1.pdf",
      "relevance_score": 56,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.09354v1",
      "title": "Fully-Synthetic Training for Visual Quality Inspection in Automotive Production",
      "authors": [
        "Christoph Huber",
        "Dino Knoll",
        "Michael Guthe"
      ],
      "published": "2025-03-12T12:58:30Z",
      "categories": "",
      "summary": "Visual Quality Inspection plays a crucial role in modern manufacturing environments as it ensures customer safety and satisfaction. The introduction of Computer Vision (CV) has revolutionized visual quality inspection by improving the accuracy and efficiency of defect detection. However, traditional CV models heavily rely on extensive datasets for training, which can be costly, time-consuming, and error-prone. To overcome these challenges, synthetic images have emerged as a promising alternative. They offer a cost-effective solution with automatically generated labels. In this paper, we propos...",
      "pdf_url": "https://arxiv.org/pdf/2503.09354v1.pdf",
      "relevance_score": 56,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2011.13996v4",
      "title": "Training a quantum annealing based restricted Boltzmann machine on cybersecurity data",
      "authors": [
        "Vivek Dixit",
        "Raja Selvarajan",
        "Tamer Aldwairi",
        "Yaroslav Koshka",
        "Mark A. Novotny",
        "Travis S. Humble",
        "Muhammad A. Alam",
        "Sabre Kais"
      ],
      "published": "2020-11-24T21:18:45Z",
      "categories": "",
      "summary": "We present a real-world application that uses a quantum computer. Specifically, we train a RBM using QA for cybersecurity applications. The D-Wave 2000Q has been used to implement QA. RBMs are trained on the ISCX data, which is a benchmark dataset for cybersecurity. For comparison, RBMs are also trained using CD. CD is a commonly used method for RBM training. Our analysis of the ISCX data shows that the dataset is imbalanced. We present two different schemes to balance the training dataset before feeding it to a classifier. The first scheme is based on the undersampling of benign instances. Th...",
      "pdf_url": "https://arxiv.org/pdf/2011.13996v4.pdf",
      "relevance_score": 55,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.01893v1",
      "title": "Improving Phishing Resilience with AI-Generated Training: Evidence on Prompting, Personalization, and Duration",
      "authors": [
        "Francesco Greco",
        "Giuseppe Desolda",
        "Cesare Tucci",
        "Andrea Esposito",
        "Antonio Curci",
        "Antonio Piccinno"
      ],
      "published": "2025-12-01T17:13:09Z",
      "categories": "",
      "summary": "Phishing remains a persistent cybersecurity threat; however, developing scalable and effective user training is labor-intensive and challenging to maintain. Generative Artificial Intelligence offers an interesting opportunity, but empirical evidence on its instructional efficacy remains scarce. This paper provides an experimental validation of Large Language Models (LLMs) as autonomous engines for generating phishing resilience training. Across two controlled studies (N=480), we demonstrate that AI-generated content yields significant pre-post learning gains regardless of the specific promptin...",
      "pdf_url": "https://arxiv.org/pdf/2512.01893v1.pdf",
      "relevance_score": 55,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.24278v1",
      "title": "Training-free Source Attribution of AI-generated Images via Resynthesis",
      "authors": [
        "Pietro Bongini",
        "Valentina Molinari",
        "Andrea Costanzo",
        "Benedetta Tondi",
        "Mauro Barni"
      ],
      "published": "2025-10-28T10:39:04Z",
      "categories": "",
      "summary": "Synthetic image source attribution is a challenging task, especially in data scarcity conditions requiring few-shot or zero-shot classification capabilities. We present a new training-free one-shot attribution method based on image resynthesis. A prompt describing the image under analysis is generated, then it is used to resynthesize the image with all the candidate sources. The image is attributed to the model which produced the resynthesis closest to the original image in a proper feature space. We also introduce a new dataset for synthetic image attribution consisting of face images from co...",
      "pdf_url": "https://arxiv.org/pdf/2510.24278v1.pdf",
      "relevance_score": 55,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.04845v2",
      "title": "SLPL SHROOM at SemEval2024 Task 06: A comprehensive study on models ability to detect hallucination",
      "authors": [
        "Pouya Fallah",
        "Soroush Gooran",
        "Mohammad Jafarinasab",
        "Pouya Sadeghi",
        "Reza Farnia",
        "Amirreza Tarabkhah",
        "Zainab Sadat Taghavi",
        "Hossein Sameti"
      ],
      "published": "2024-04-07T07:34:49Z",
      "categories": "",
      "summary": "Language models, particularly generative models, are susceptible to hallucinations, generating outputs that contradict factual knowledge or the source text. This study explores methods for detecting hallucinations in three SemEval-2024 Task 6 tasks: Machine Translation, Definition Modeling, and Paraphrase Generation. We evaluate two methods: semantic similarity between the generated text and factual references, and an ensemble of language models that judge each other's outputs. Our results show that semantic similarity achieves moderate accuracy and correlation scores in trial data, while the ...",
      "pdf_url": "https://arxiv.org/pdf/2404.04845v2.pdf",
      "relevance_score": 55,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2110.11425v1",
      "title": "A Machine Learning Framework Towards Transparency in Experts' Decision Quality",
      "authors": [
        "Wanxue Dong",
        "Maytal Saar-Tsechansky",
        "Tomer Geva"
      ],
      "published": "2021-10-21T18:50:40Z",
      "categories": "",
      "summary": "Expert workers make non-trivial decisions with significant implications. Experts' decision accuracy is thus a fundamental aspect of their judgment quality, key to both management and consumers of experts' services. Yet, in many important settings, transparency in experts' decision quality is rarely possible because ground truth data for evaluating the experts' decisions is costly and available only for a limited set of decisions. Furthermore, different experts typically handle exclusive sets of decisions, and thus prior solutions that rely on the aggregation of multiple experts' decisions for ...",
      "pdf_url": "https://arxiv.org/pdf/2110.11425v1.pdf",
      "relevance_score": 55,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1810.11212v2",
      "title": "Third Generation MEEG Source Connectivity Analysis Toolbox (BC-VARETA 1.0) and Validation Benchmark",
      "authors": [
        "Eduardo Gonzalez-Moreira",
        "Deirel Paz-Linares",
        "Ariosky Areces-Gonzalez",
        "Rigel Wang",
        "Pedro A. Valdes-Sosa"
      ],
      "published": "2018-10-26T07:47:04Z",
      "categories": "",
      "summary": "This paper presents a new toolbox for MEEG source activity and connectivity estimation: Brain Connectivity Variable Resolution Tomographic Analysis version 1.0 (BC-VARETA 1.0). It relies on the third generation of nonlinear methods for the analysis of resting state MEEG Time Series. Into the state of the art of MEEG analysis, the methodology underlying our tool (BC-VARETA) brings out several assets. First: Constitutes a Bayesian Identification approach of Linear Dynamical Systems in the Frequency Domain, grounded in more consistent models (third generation). Second: Achieves Super-Resolution, ...",
      "pdf_url": "https://arxiv.org/pdf/1810.11212v2.pdf",
      "relevance_score": 55,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.13757v1",
      "title": "Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models",
      "authors": [
        "Zhuo Chen",
        "Jiawei Liu",
        "Haotan Liu",
        "Qikai Cheng",
        "Fan Zhang",
        "Wei Lu",
        "Xiaozhong Liu"
      ],
      "published": "2024-07-18T17:55:55Z",
      "categories": "",
      "summary": "Retrieval-Augmented Generation (RAG) is applied to solve hallucination problems and real-time constraints of large language models, but it also induces vulnerabilities against retrieval corruption attacks. Existing research mainly explores the unreliability of RAG in white-box and closed-domain QA tasks. In this paper, we aim to reveal the vulnerabilities of Retrieval-Enhanced Generative (RAG) models when faced with black-box attacks for opinion manipulation. We explore the impact of such attacks on user cognition and decision-making, providing new insight to enhance the reliability and securi...",
      "pdf_url": "https://arxiv.org/pdf/2407.13757v1.pdf",
      "relevance_score": 55,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2103.06710v1",
      "title": "Deep Transfer Learning for Infectious Disease Case Detection Using Electronic Medical Records",
      "authors": [
        "Ye Ye",
        "Andrew Gu"
      ],
      "published": "2021-03-08T01:53:29Z",
      "categories": "",
      "summary": "During an infectious disease pandemic, it is critical to share electronic medical records or models (learned from these records) across regions. Applying one region's data/model to another region often have distribution shift issues that violate the assumptions of traditional machine learning techniques. Transfer learning can be a solution. To explore the potential of deep transfer learning algorithms, we applied two data-based algorithms (domain adversarial neural networks and maximum classifier discrepancy) and model-based transfer learning algorithms to infectious disease detection tasks. W...",
      "pdf_url": "https://arxiv.org/pdf/2103.06710v1.pdf",
      "relevance_score": 55,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2302.06549v1",
      "title": "Between Generating Noise and Generating Images: Noise in the Correct Frequency Improves the Quality of Synthetic Histopathology Images for Digital Pathology",
      "authors": [
        "Nati Daniel",
        "Eliel Aknin",
        "Ariel Larey",
        "Yoni Peretz",
        "Guy Sela",
        "Yael Fisher",
        "Yonatan Savir"
      ],
      "published": "2023-02-13T17:49:24Z",
      "categories": "",
      "summary": "Artificial intelligence and machine learning techniques have the promise to revolutionize the field of digital pathology. However, these models demand considerable amounts of data, while the availability of unbiased training data is limited. Synthetic images can augment existing datasets, to improve and validate AI algorithms. Yet, controlling the exact distribution of cellular features within them is still challenging. One of the solutions is harnessing conditional generative adversarial networks that take a semantic mask as an input rather than a random noise. Unlike other domains, outlining...",
      "pdf_url": "https://arxiv.org/pdf/2302.06549v1.pdf",
      "relevance_score": 54,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2212.09803v3",
      "title": "Training Trajectories of Language Models Across Scales",
      "authors": [
        "Mengzhou Xia",
        "Mikel Artetxe",
        "Chunting Zhou",
        "Xi Victoria Lin",
        "Ramakanth Pasunuru",
        "Danqi Chen",
        "Luke Zettlemoyer",
        "Ves Stoyanov"
      ],
      "published": "2022-12-19T19:16:29Z",
      "categories": "",
      "summary": "Scaling up language models has led to unprecedented performance gains, but little is understood about how the training dynamics change as models get larger. How do language models of different sizes learn during pre-training? Why do larger language models demonstrate more desirable behaviors? In this paper, we analyze the intermediate training checkpoints of differently sized OPT models (Zhang et al.,2022)--from 125M to 175B parameters--on next-token prediction, sequence-level generation, and downstream tasks. We find that 1) at a given perplexity and independent of model sizes, a similar subs...",
      "pdf_url": "https://arxiv.org/pdf/2212.09803v3.pdf",
      "relevance_score": 53,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.20488v1",
      "title": "Generative AI for Vulnerability Detection in 6G Wireless Networks: Advances, Case Study, and Future Directions",
      "authors": [
        "Shuo Yang",
        "Xinran Zheng",
        "Jinfeng Xu",
        "Jinze Li",
        "Danyang Song",
        "Zheyu Chen",
        "Edith C. H. Ngai"
      ],
      "published": "2025-06-25T14:36:31Z",
      "categories": "",
      "summary": "The rapid advancement of 6G wireless networks, IoT, and edge computing has significantly expanded the cyberattack surface, necessitating more intelligent and adaptive vulnerability detection mechanisms. Traditional security methods, while foundational, struggle with zero-day exploits, adversarial threats, and context-dependent vulnerabilities in highly dynamic network environments. Generative AI (GAI) emerges as a transformative solution, leveraging synthetic data generation, multimodal reasoning, and adaptive learning to enhance security frameworks. This paper explores the integration of GAI-...",
      "pdf_url": "https://arxiv.org/pdf/2506.20488v1.pdf",
      "relevance_score": 53,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.18189v1",
      "title": "ClassComet: Exploring and Designing AI-generated Danmaku in Educational Videos to Enhance Online Learning",
      "authors": [
        "Zipeng Ji",
        "Pengcheng An",
        "Jian Zhao"
      ],
      "published": "2025-04-25T09:09:27Z",
      "categories": "",
      "summary": "Danmaku, users' live comments synchronized with, and overlaying on videos, has recently shown potential in promoting online video-based learning. However, user-generated danmaku can be scarce-especially in newer or less viewed videos and its quality is unpredictable, limiting its educational impact. This paper explores how large multimodal models (LMM) can be leveraged to automatically generate effective, high-quality danmaku. We first conducted a formative study to identify the desirable characteristics of content- and emotion-related danmaku in educational videos. Based on the obtained insig...",
      "pdf_url": "https://arxiv.org/pdf/2504.18189v1.pdf",
      "relevance_score": 53,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2306.10509v2",
      "title": "Can We Trust AI-Generated Educational Content? Comparative Analysis of Human and AI-Generated Learning Resources",
      "authors": [
        "Paul Denny",
        "Hassan Khosravi",
        "Arto Hellas",
        "Juho Leinonen",
        "Sami Sarsa"
      ],
      "published": "2023-06-18T09:49:21Z",
      "categories": "",
      "summary": "As an increasing number of students move to online learning platforms that deliver personalized learning experiences, there is a great need for the production of high-quality educational content. Large language models (LLMs) appear to offer a promising solution to the rapid creation of learning materials at scale, reducing the burden on instructors. In this study, we investigated the potential for LLMs to produce learning resources in an introductory programming context, by comparing the quality of the resources generated by an LLM with those created by students as part of a learnersourcing ac...",
      "pdf_url": "https://arxiv.org/pdf/2306.10509v2.pdf",
      "relevance_score": 53,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.16497v2",
      "title": "Establishing Validity for Distance Functions and Internal Clustering Validity Indices in Correlation Space",
      "authors": [
        "Isabella Degen",
        "Zahraa S Abdallah",
        "Kate Robson Brown",
        "Henry W J Reeve"
      ],
      "published": "2025-07-22T11:51:48Z",
      "categories": "",
      "summary": "Internal clustering validity indices (ICVIs) assess clustering quality without ground truth labels. Comparative studies consistently find that no single ICVI outperforms others across datasets, leaving practitioners without principled ICVI selection. We argue that inconsistent ICVI performance arises because studies evaluate them based on matching human labels rather than measuring the quality of the discovered structure in the data, using datasets without formally quantifying the structure type and quality. Structure type refers to the mathematical organisation in data that clustering aims to...",
      "pdf_url": "https://arxiv.org/pdf/2507.16497v2.pdf",
      "relevance_score": 53,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.17050v2",
      "title": "Towards Robust Evaluation of STEM Education: Leveraging MLLMs in Project-Based Learning",
      "authors": [
        "Xinyi Wu",
        "Yanhao Jia",
        "Qinglin Zhang",
        "Yiran Qin",
        "Luwei Xiao",
        "Shuai Zhao"
      ],
      "published": "2025-05-16T11:01:01Z",
      "categories": "",
      "summary": "Project-Based Learning (PBL) involves a variety of highly correlated multimodal data, making it a vital educational approach within STEM disciplines. With the rapid development of multimodal large language models (MLLMs), researchers have begun exploring their potential to enhance tasks such as information retrieval, knowledge comprehension, and data generation in educational settings. However, existing benchmarks fall short in providing both a free-form output structure and a rigorous human expert validation process, limiting their effectiveness in evaluating real-world educational tasks. Add...",
      "pdf_url": "https://arxiv.org/pdf/2505.17050v2.pdf",
      "relevance_score": 52,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.18603v1",
      "title": "Toward Personalizing Quantum Computing Education: An Evolutionary LLM-Powered Approach",
      "authors": [
        "Iizalaarab Elhaimeur",
        "Nikos Chrisochoides"
      ],
      "published": "2025-04-24T21:53:34Z",
      "categories": "",
      "summary": "Quantum computing education faces significant challenges due to its complexity and the limitations of current tools; this paper introduces a novel Intelligent Teaching Assistant for quantum computing education and details its evolutionary design process. The system combines a knowledge-graph-augmented architecture with two specialized Large Language Model (LLM) agents: a Teaching Agent for dynamic interaction, and a Lesson Planning Agent for lesson plan generation. The system is designed to adapt to individual student needs, with interactions meticulously tracked and stored in a knowledge grap...",
      "pdf_url": "https://arxiv.org/pdf/2504.18603v1.pdf",
      "relevance_score": 52,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.08093v2",
      "title": "Training LLMs for Honesty via Confessions",
      "authors": [
        "Manas Joglekar",
        "Jeremy Chen",
        "Gabriel Wu",
        "Jason Yosinski",
        "Jasmine Wang",
        "Boaz Barak",
        "Amelia Glaese"
      ],
      "published": "2025-12-08T23:05:52Z",
      "categories": "",
      "summary": "Large language models (LLMs) can be dishonest when reporting on their actions and beliefs -- for example, they may overstate their confidence in factual claims or cover up evidence of covert actions. Such dishonesty may arise due to the effects of reinforcement learning (RL), where challenges with reward shaping can result in a training process that inadvertently incentivizes the model to lie or misrepresent its actions.   In this work we propose a method for eliciting an honest expression of an LLM's shortcomings via a self-reported *confession*. A confession is an output, provided upon reque...",
      "pdf_url": "https://arxiv.org/pdf/2512.08093v2.pdf",
      "relevance_score": 52,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.13859v1",
      "title": "SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection",
      "authors": [
        "Aleksandr Gashkov",
        "Aleksandr Perevalov",
        "Maria Eltsova",
        "Andreas Both"
      ],
      "published": "2025-07-18T12:28:08Z",
      "categories": "",
      "summary": "Nowadays, the importance of software with natural-language user interfaces cannot be underestimated. In particular, in Question Answering (QA) systems, generating a SPARQL query for a given natural-language question (often named Query Building) from the information retrieved from the same question is the central task of QA systems working over Knowledge Graphs (KGQA). Due to the rise of Large Language Models (LLMs), they are considered a well-suited method to increase the quality of the question-answering functionality, as there is still a lot of room for improvement, aiming for enhanced quali...",
      "pdf_url": "https://arxiv.org/pdf/2507.13859v1.pdf",
      "relevance_score": 52,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1905.11757v1",
      "title": "Evaluation of Machine Learning-based Anomaly Detection Algorithms on an Industrial Modbus/TCP Data Set",
      "authors": [
        "Simon Duque Anton",
        "Suneetha Kanoor",
        "Daniel Fraunholz",
        "Hans Dieter Schotten"
      ],
      "published": "2019-05-28T11:52:25Z",
      "categories": "",
      "summary": "In the context of the Industrial Internet of Things, communication technology, originally used in home and office environments, is introduced into industrial applications. Commercial off-the-shelf products, as well as unified and well-established communication protocols make this technology easy to integrate and use. Furthermore, productivity is increased in comparison to classic industrial control by making systems easier to manage, set up and configure. Unfortunately, most attack surfaces of home and office environments are introduced into industrial applications as well, which usually have ...",
      "pdf_url": "https://arxiv.org/pdf/1905.11757v1.pdf",
      "relevance_score": 51,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.16641v1",
      "title": "Vision-Language Consistency Guided Multi-modal Prompt Learning for Blind AI Generated Image Quality Assessment",
      "authors": [
        "Jun Fu",
        "Wei Zhou",
        "Qiuping Jiang",
        "Hantao Liu",
        "Guangtao Zhai"
      ],
      "published": "2024-06-24T13:45:31Z",
      "categories": "",
      "summary": "Recently, textual prompt tuning has shown inspirational performance in adapting Contrastive Language-Image Pre-training (CLIP) models to natural image quality assessment. However, such uni-modal prompt learning method only tunes the language branch of CLIP models. This is not enough for adapting CLIP models to AI generated image quality assessment (AGIQA) since AGIs visually differ from natural images. In addition, the consistency between AGIs and user input text prompts, which correlates with the perceptual quality of AGIs, is not investigated to guide AGIQA. In this letter, we propose vision...",
      "pdf_url": "https://arxiv.org/pdf/2406.16641v1.pdf",
      "relevance_score": 51,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.10384v1",
      "title": "Adult learners recall and recognition performance and affective feedback when learning from an AI-generated synthetic video",
      "authors": [
        "Zoe Ruo-Yu Li",
        "Caswell Barry",
        "Mutlu Cukurova"
      ],
      "published": "2024-11-28T21:40:28Z",
      "categories": "",
      "summary": "The widespread use of generative AI has led to multiple applications of AI-generated text and media to potentially enhance learning outcomes. However, there are a limited number of well-designed experimental studies investigating the impact of learning gains and affective feedback from AI-generated media compared to traditional media (e.g., text from documents and human recordings of video). The current study recruited 500 participants to investigate adult learners recall and recognition performances as well as their affective feedback on the AI-generated synthetic video, using a mixed-methods...",
      "pdf_url": "https://arxiv.org/pdf/2412.10384v1.pdf",
      "relevance_score": 51,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2501.00794v1",
      "title": "VoiceRestore: Flow-Matching Transformers for Speech Recording Quality Restoration",
      "authors": [
        "Stanislav Kirdey"
      ],
      "published": "2025-01-01T10:13:19Z",
      "categories": "",
      "summary": "We present VoiceRestore, a novel approach to restoring the quality of speech recordings using flow-matching Transformers trained in a self-supervised manner on synthetic data. Our method tackles a wide range of degradations frequently found in both short and long-form speech recordings, including background noise, reverberation, compression artifacts, and bandwidth limitations - all within a single, unified model. Leveraging conditional flow matching and classifier free guidance, the model learns to map degraded speech to high quality recordings without requiring paired clean and degraded data...",
      "pdf_url": "https://arxiv.org/pdf/2501.00794v1.pdf",
      "relevance_score": 51,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2311.17898v3",
      "title": "Contextual Knowledge Pursuit for Faithful Visual Synthesis",
      "authors": [
        "Jinqi Luo",
        "Kwan Ho Ryan Chan",
        "Dimitris Dimos",
        "Ren\u00e9 Vidal"
      ],
      "published": "2023-11-29T18:51:46Z",
      "categories": "",
      "summary": "Modern text-to-vision generative models often hallucinate when the prompt describing the scene to be generated is underspecified. In large language models (LLMs), a prevalent strategy to reduce hallucinations is to retrieve factual knowledge from an external database. While such retrieval augmentation strategies have great potential to enhance text-to-vision generators, existing static top-K retrieval methods explore the knowledge pool once, missing the broader context necessary for high-quality generation. Furthermore, LLMs internally possess rich world knowledge learned during large-scale tr...",
      "pdf_url": "https://arxiv.org/pdf/2311.17898v3.pdf",
      "relevance_score": 51,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2405.11724v2",
      "title": "Token-wise Influential Training Data Retrieval for Large Language Models",
      "authors": [
        "Huawei Lin",
        "Jikai Long",
        "Zhaozhuo Xu",
        "Weijie Zhao"
      ],
      "published": "2024-05-20T01:57:34Z",
      "categories": "",
      "summary": "Given a Large Language Model (LLM) generation, how can we identify which training data led to this generation? In this paper, we proposed RapidIn, a scalable framework adapting to LLMs for estimating the influence of each training data. The proposed framework consists of two stages: caching and retrieval. First, we compress the gradient vectors by over 200,000x, allowing them to be cached on disk or in GPU/CPU memory. Then, given a generation, RapidIn efficiently traverses the cached gradients to estimate the influence within minutes, achieving over a 6,326x speedup. Moreover, RapidIn supports...",
      "pdf_url": "https://arxiv.org/pdf/2405.11724v2.pdf",
      "relevance_score": 51,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.17943v1",
      "title": "Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches",
      "authors": [
        "Saman Sarraf"
      ],
      "published": "2024-11-26T23:34:07Z",
      "categories": "",
      "summary": "Generative AI (GenAI) has revolutionized content generation, offering transformative capabilities for improving language coherence, readability, and overall quality. This manuscript explores the application of qualitative, quantitative, and mixed-methods research approaches to evaluate the performance of GenAI models in enhancing scientific writing. Using a hypothetical use case involving a collaborative medical imaging manuscript, we demonstrate how each method provides unique insights into the impact of GenAI. Qualitative methods gather in-depth feedback from expert reviewers, analyzing thei...",
      "pdf_url": "https://arxiv.org/pdf/2411.17943v1.pdf",
      "relevance_score": 51,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.17671v2",
      "title": "A Bias-Free Training Paradigm for More General AI-generated Image Detection",
      "authors": [
        "Fabrizio Guillaro",
        "Giada Zingarini",
        "Ben Usman",
        "Avneesh Sud",
        "Davide Cozzolino",
        "Luisa Verdoliva"
      ],
      "published": "2024-12-23T15:54:32Z",
      "categories": "",
      "summary": "Successful forensic detectors can produce excellent results in supervised learning benchmarks but struggle to transfer to real-world applications. We believe this limitation is largely due to inadequate training data quality. While most research focuses on developing new algorithms, less attention is given to training data selection, despite evidence that performance can be strongly impacted by spurious correlations such as content, format, or resolution. A well-designed forensic detector should detect generator specific artifacts rather than reflect data biases. To this end, we propose B-Free...",
      "pdf_url": "https://arxiv.org/pdf/2412.17671v2.pdf",
      "relevance_score": 50,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2305.00644v1",
      "title": "Procedural Content Generation via Knowledge Transformation (PCG-KT)",
      "authors": [
        "Anurag Sarkar",
        "Matthew Guzdial",
        "Sam Snodgrass",
        "Adam Summerville",
        "Tiago Machado",
        "Gillian Smith"
      ],
      "published": "2023-05-01T03:31:22Z",
      "categories": "",
      "summary": "We introduce the concept of Procedural Content Generation via Knowledge Transformation (PCG-KT), a new lens and framework for characterizing PCG methods and approaches in which content generation is enabled by the process of knowledge transformation -- transforming knowledge derived from one domain in order to apply it in another. Our work is motivated by a substantial number of recent PCG works that focus on generating novel content via repurposing derived knowledge. Such works have involved, for example, performing transfer learning on models trained on one game's content to adapt to another...",
      "pdf_url": "https://arxiv.org/pdf/2305.00644v1.pdf",
      "relevance_score": 50,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.21257v2",
      "title": "Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation",
      "authors": [
        "Seyed Amir Kasaei",
        "Mohammad Hossein Rohban"
      ],
      "published": "2025-09-25T14:50:21Z",
      "categories": "",
      "summary": "In language and vision-language models, hallucination is broadly understood as content generated from a model's prior knowledge or biases rather than from the given input. While this phenomenon has been studied in those domains, it has not been clearly framed for text-to-image (T2I) generative models. Existing evaluations mainly focus on alignment, checking whether prompt-specified elements appear, but overlook what the model generates beyond the prompt. We argue for defining hallucination in T2I as bias-driven deviations and propose a taxonomy with three categories: attribute, relation, and o...",
      "pdf_url": "https://arxiv.org/pdf/2509.21257v2.pdf",
      "relevance_score": 50,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.02772v1",
      "title": "Towards Unification of Hallucination Detection and Fact Verification for Large Language Models",
      "authors": [
        "Weihang Su",
        "Jianming Long",
        "Changyue Wang",
        "Shiyu Lin",
        "Jingyan Xu",
        "Ziyi Ye",
        "Qingyao Ai",
        "Yiqun Liu"
      ],
      "published": "2025-12-02T13:51:01Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) frequently exhibit hallucinations, generating content that appears fluent and coherent but is factually incorrect. Such errors undermine trust and hinder their adoption in real-world applications. To address this challenge, two distinct research paradigms have emerged: model-centric Hallucination Detection (HD) and text-centric Fact Verification (FV). Despite sharing the same goal, these paradigms have evolved in isolation, using distinct assumptions, datasets, and evaluation protocols. This separation has created a research schism that hinders their collective pro...",
      "pdf_url": "https://arxiv.org/pdf/2512.02772v1.pdf",
      "relevance_score": 50,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2310.15319v1",
      "title": "Hallucination Detection for Grounded Instruction Generation",
      "authors": [
        "Lingjun Zhao",
        "Khanh Nguyen",
        "Hal Daum\u00e9"
      ],
      "published": "2023-10-23T19:36:28Z",
      "categories": "",
      "summary": "We investigate the problem of generating instructions to guide humans to navigate in simulated residential environments. A major issue with current models is hallucination: they generate references to actions or objects that are inconsistent with what a human follower would perform or encounter along the described path. We develop a model that detects these hallucinated references by adopting a model pre-trained on a large corpus of image-text pairs, and fine-tuning it with a contrastive loss that separates correct instructions from instructions containing synthesized hallucinations. Our final...",
      "pdf_url": "https://arxiv.org/pdf/2310.15319v1.pdf",
      "relevance_score": 50,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.04184v1",
      "title": "Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains",
      "authors": [
        "Mohammed Musthafa Rafi",
        "Adarsh Krishnamurthy",
        "Aditya Balu"
      ],
      "published": "2025-11-06T08:36:42Z",
      "categories": "",
      "summary": "The proliferation of AI-generated content has created an absurd communication theater where senders use LLMs to inflate simple ideas into verbose content, recipients use LLMs to compress them back into summaries, and as a consequence neither party engage with authentic content. LAAC (LLM as a Communicator) proposes a paradigm shift - positioning LLMs as intelligent communication intermediaries that capture the sender's intent through structured dialogue and facilitate genuine knowledge exchange with recipients. Rather than perpetuating cycles of AI-generated inflation and compression, LAAC ena...",
      "pdf_url": "https://arxiv.org/pdf/2511.04184v1.pdf",
      "relevance_score": 50,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.06092v3",
      "title": "Taming Data Challenges in ML-based Security Tasks: Lessons from Integrating Generative AI",
      "authors": [
        "Shravya Kanchi",
        "Neal Mangaokar",
        "Aravind Cheruvu",
        "Sifat Muhammad Abdullah",
        "Shirin Nilizadeh",
        "Atul Prakash",
        "Bimal Viswanath"
      ],
      "published": "2025-07-08T15:34:45Z",
      "categories": "",
      "summary": "Machine learning-based supervised classifiers are widely used for security tasks, and their improvement has been largely focused on algorithmic advancements. We argue that data challenges that negatively impact the performance of these classifiers have received limited attention. We address the following research question: Can developments in Generative AI (GenAI) address these data challenges and improve classifier performance? We propose augmenting training datasets with synthetic data generated using GenAI techniques to improve classifier generalization. We evaluate this approach across 7 d...",
      "pdf_url": "https://arxiv.org/pdf/2507.06092v3.pdf",
      "relevance_score": 49,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1907.05276v2",
      "title": "Human detection of machine manipulated media",
      "authors": [
        "Matthew Groh",
        "Ziv Epstein",
        "Nick Obradovich",
        "Manuel Cebrian",
        "Iyad Rahwan"
      ],
      "published": "2019-07-06T02:52:42Z",
      "categories": "",
      "summary": "Recent advances in neural networks for content generation enable artificial intelligence (AI) models to generate high-quality media manipulations. Here we report on a randomized experiment designed to study the effect of exposure to media manipulations on over 15,000 individuals' ability to discern machine-manipulated media. We engineer a neural network to plausibly and automatically remove objects from images, and we deploy this neural network online with a randomized experiment where participants can guess which image out of a pair of images has been manipulated. The system provides particip...",
      "pdf_url": "https://arxiv.org/pdf/1907.05276v2.pdf",
      "relevance_score": 49,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2402.07371v1",
      "title": "Real-World Atmospheric Turbulence Correction via Domain Adaptation",
      "authors": [
        "Xijun Wang",
        "Santiago L\u00f3pez-Tapia",
        "Aggelos K. Katsaggelos"
      ],
      "published": "2024-02-12T02:09:08Z",
      "categories": "",
      "summary": "Atmospheric turbulence, a common phenomenon in daily life, is primarily caused by the uneven heating of the Earth's surface. This phenomenon results in distorted and blurred acquired images or videos and can significantly impact downstream vision tasks, particularly those that rely on capturing clear, stable images or videos from outdoor environments, such as accurately detecting or recognizing objects. Therefore, people have proposed ways to simulate atmospheric turbulence and designed effective deep learning-based methods to remove the atmospheric turbulence effect. However, these synthesize...",
      "pdf_url": "https://arxiv.org/pdf/2402.07371v1.pdf",
      "relevance_score": 49,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2304.14774v3",
      "title": "A feature selection method based on Shapley values robust to concept shift in regression",
      "authors": [
        "Carlos Sebasti\u00e1n",
        "Carlos E. Gonz\u00e1lez-Guill\u00e9n"
      ],
      "published": "2023-04-28T11:34:59Z",
      "categories": "",
      "summary": "Feature selection is one of the most relevant processes in any methodology for creating a statistical learning model. Usually, existing algorithms establish some criterion to select the most influential variables, discarding those that do not contribute to the model with any relevant information. This methodology makes sense in a static situation where the joint distribution of the data does not vary over time. However, when dealing with real data, it is common to encounter the problem of the dataset shift and, specifically, changes in the relationships between variables (concept shift). In th...",
      "pdf_url": "https://arxiv.org/pdf/2304.14774v3.pdf",
      "relevance_score": 49,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2310.14564v2",
      "title": "Language Models Hallucinate, but May Excel at Fact Verification",
      "authors": [
        "Jian Guan",
        "Jesse Dodge",
        "David Wadden",
        "Minlie Huang",
        "Hao Peng"
      ],
      "published": "2023-10-23T04:39:01Z",
      "categories": "",
      "summary": "Recent progress in natural language processing (NLP) owes much to remarkable advances in large language models (LLMs). Nevertheless, LLMs frequently \"hallucinate,\" resulting in non-factual outputs. Our carefully-designed human evaluation substantiates the serious hallucination issue, revealing that even GPT-3.5 produces factual outputs less than 25% of the time. This underscores the importance of fact verifiers in order to measure and incentivize progress. Our systematic investigation affirms that LLMs can be repurposed as effective fact verifiers with strong correlations with human judgments....",
      "pdf_url": "https://arxiv.org/pdf/2310.14564v2.pdf",
      "relevance_score": 48,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2004.07740v2",
      "title": "Really Useful Synthetic Data -- A Framework to Evaluate the Quality of Differentially Private Synthetic Data",
      "authors": [
        "Christian Arnold",
        "Marcel Neunhoeffer"
      ],
      "published": "2020-04-16T16:24:22Z",
      "categories": "",
      "summary": "Recent advances in generating synthetic data that allow to add principled ways of protecting privacy -- such as Differential Privacy -- are a crucial step in sharing statistical information in a privacy preserving way. But while the focus has been on privacy guarantees, the resulting private synthetic data is only useful if it still carries statistical information from the original data. To further optimise the inherent trade-off between data privacy and data quality, it is necessary to think closely about the latter. What is it that data analysts want? Acknowledging that data quality is a sub...",
      "pdf_url": "https://arxiv.org/pdf/2004.07740v2.pdf",
      "relevance_score": 48,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2108.13087v1",
      "title": "InSE-NET: A Perceptually Coded Audio Quality Model based on CNN",
      "authors": [
        "Guanxin Jiang",
        "Arijit Biswas",
        "Christian Bergler",
        "Andreas Maier"
      ],
      "published": "2021-08-30T09:51:39Z",
      "categories": "",
      "summary": "Automatic coded audio quality assessment is an important task whose progress is hampered by the scarcity of human annotations, poor generalization to unseen codecs, bitrates, content-types, and a lack of flexibility of existing approaches. One of the typical human-perception-related metrics, ViSQOL v3 (ViV3), has been proven to provide a high correlation to the quality scores rated by humans. In this study, we take steps to tackle problems of predicting coded audio quality by completely utilizing programmatically generated data that is informed with expert domain knowledge. We propose a learna...",
      "pdf_url": "https://arxiv.org/pdf/2108.13087v1.pdf",
      "relevance_score": 48,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2207.01798v2",
      "title": "GSMFlow: Generation Shifts Mitigating Flow for Generalized Zero-Shot Learning",
      "authors": [
        "Zhi Chen",
        "Yadan Luo",
        "Sen Wang",
        "Jingjing Li",
        "Zi Huang"
      ],
      "published": "2022-07-05T04:04:37Z",
      "categories": "",
      "summary": "Generalized Zero-Shot Learning (GZSL) aims to recognize images from both the seen and unseen classes by transferring semantic knowledge from seen to unseen classes. It is a promising solution to take the advantage of generative models to hallucinate realistic unseen samples based on the knowledge learned from the seen classes. However, due to the generation shifts, the synthesized samples by most existing methods may drift from the real distribution of the unseen data. To address this issue, we propose a novel flow-based generative framework that consists of multiple conditional affine couplin...",
      "pdf_url": "https://arxiv.org/pdf/2207.01798v2.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1810.11730v3",
      "title": "Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks",
      "authors": [
        "Hang Gao",
        "Zheng Shou",
        "Alireza Zareian",
        "Hanwang Zhang",
        "Shih-Fu Chang"
      ],
      "published": "2018-10-27T23:09:10Z",
      "categories": "",
      "summary": "Deep neural networks suffer from over-fitting and catastrophic forgetting when trained with small data. One natural remedy for this problem is data augmentation, which has been recently shown to be effective. However, previous works either assume that intra-class variances can always be generalized to new classes, or employ naive generation methods to hallucinate finite examples without modeling their latent distributions. In this work, we propose Covariance-Preserving Adversarial Augmentation Networks to overcome existing limits of low-shot learning. Specifically, a novel Generative Adversari...",
      "pdf_url": "https://arxiv.org/pdf/1810.11730v3.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2405.10521v1",
      "title": "Generative AI for Secure and Privacy-Preserving Mobile Crowdsensing",
      "authors": [
        "Yaoqi Yang",
        "Bangning Zhang",
        "Daoxing Guo",
        "Hongyang Du",
        "Zehui Xiong",
        "Dusit Niyato",
        "Zhu Han"
      ],
      "published": "2024-05-17T04:00:58Z",
      "categories": "",
      "summary": "Recently, generative AI has attracted much attention from both academic and industrial fields, which has shown its potential, especially in the data generation and synthesis aspects. Simultaneously, secure and privacy-preserving mobile crowdsensing (SPPMCS) has been widely applied in data collection/ acquirement due to an advantage on low deployment cost, flexible implementation, and high adaptability. Since generative AI can generate new synthetic data to replace the original data to be analyzed and processed, it can lower data attacks and privacy leakage risks for the original data. Therefor...",
      "pdf_url": "https://arxiv.org/pdf/2405.10521v1.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.02572v4",
      "title": "GenDFIR: Advancing Cyber Incident Timeline Analysis Through Retrieval Augmented Generation and Large Language Models",
      "authors": [
        "Fatma Yasmine Loumachi",
        "Mohamed Chahine Ghanem",
        "Mohamed Amine Ferrag"
      ],
      "published": "2024-09-04T09:46:33Z",
      "categories": "",
      "summary": "Cyber timeline analysis, or forensic timeline analysis, is crucial in Digital Forensics and Incident Response (DFIR). It examines artefacts and events particularly timestamps and metadata to detect anomalies, establish correlations, and reconstruct incident timelines. Traditional methods rely on structured artefacts, such as logs and filesystem metadata, using specialised tools for evidence identification and feature extraction. This paper introduces GenDFIR, a framework leveraging large language models (LLMs), specifically Llama 3.1 8B in zero shot mode, integrated with a Retrieval-Augmented ...",
      "pdf_url": "https://arxiv.org/pdf/2409.02572v4.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.13859v1",
      "title": "Benchmarking Correctness and Security in Multi-Turn Code Generation",
      "authors": [
        "Ruchit Rawal",
        "Jeffrey Yang Fan Chiang",
        "Chihao Shen",
        "Jeffery Siyuan Tian",
        "Aastha Mahajan",
        "Tom Goldstein",
        "Yizheng Chen"
      ],
      "published": "2025-10-13T01:20:46Z",
      "categories": "",
      "summary": "AI coding assistants powered by large language models (LLMs) have transformed software development, significantly boosting productivity. While existing benchmarks evaluate the correctness and security of LLM-generated code, they are typically limited to single-turn tasks that do not reflect the iterative nature of real-world development. We introduce MT-Sec, the first benchmark to systematically evaluate both correctness and security in multi-turn coding scenarios. We construct this using a synthetic data pipeline that transforms existing single-turn tasks into semantically aligned multi-turn ...",
      "pdf_url": "https://arxiv.org/pdf/2510.13859v1.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2401.10765v2",
      "title": "Starlit: Privacy-Preserving Federated Learning to Enhance Financial Fraud Detection",
      "authors": [
        "Aydin Abadi",
        "Bradley Doyle",
        "Francesco Gini",
        "Kieron Guinamard",
        "Sasi Kumar Murakonda",
        "Jack Liddell",
        "Paul Mellor",
        "Steven J. Murdoch",
        "Mohammad Naseri",
        "Hector Page",
        "George Theodorakopoulos",
        "Suzanne Weller"
      ],
      "published": "2024-01-19T15:37:11Z",
      "categories": "",
      "summary": "Federated Learning (FL) is a data-minimization approach enabling collaborative model training across diverse clients with local data, avoiding direct data exchange. However, state-of-the-art FL solutions to identify fraudulent financial transactions exhibit a subset of the following limitations. They (1) lack a formal security definition and proof, (2) assume prior freezing of suspicious customers' accounts by financial institutions (limiting the solutions' adoption), (3) scale poorly, involving either $O(n^2)$ computationally expensive modular exponentiation (where $n$ is the total number of ...",
      "pdf_url": "https://arxiv.org/pdf/2401.10765v2.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2501.03203v1",
      "title": "Detecting AI-Generated Text in Educational Content: Leveraging Machine Learning and Explainable AI for Academic Integrity",
      "authors": [
        "Ayat A. Najjar",
        "Huthaifa I. Ashqar",
        "Omar A. Darwish",
        "Eman Hammad"
      ],
      "published": "2025-01-06T18:34:20Z",
      "categories": "",
      "summary": "This study seeks to enhance academic integrity by providing tools to detect AI-generated content in student work using advanced technologies. The findings promote transparency and accountability, helping educators maintain ethical standards and supporting the responsible integration of AI in education. A key contribution of this work is the generation of the CyberHumanAI dataset, which has 1000 observations, 500 of which are written by humans and the other 500 produced by ChatGPT. We evaluate various machine learning (ML) and deep learning (DL) algorithms on the CyberHumanAI dataset comparing ...",
      "pdf_url": "https://arxiv.org/pdf/2501.03203v1.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2303.13052v3",
      "title": "Diffusion-based Reinforcement Learning for Edge-enabled AI-Generated Content Services",
      "authors": [
        "Hongyang Du",
        "Zonghang Li",
        "Dusit Niyato",
        "Jiawen Kang",
        "Zehui Xiong",
        "Huawei Huang",
        "Shiwen Mao"
      ],
      "published": "2023-03-23T05:54:45Z",
      "categories": "",
      "summary": "As Metaverse emerges as the next-generation Internet paradigm, the ability to efficiently generate content is paramount. AIGenerated Content (AIGC) emerges as a key solution, yet the resource intensive nature of large Generative AI (GAI) models presents challenges. To address this issue, we introduce an AIGC-as-a-Service (AaaS) architecture, which deploys AIGC models in wireless edge networks to ensure broad AIGC services accessibility for Metaverse users. Nonetheless, an important aspect of providing personalized user experiences requires carefully selecting AIGC Service Providers (ASPs) capa...",
      "pdf_url": "https://arxiv.org/pdf/2303.13052v3.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.19565v3",
      "title": "Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training",
      "authors": [
        "Meng Xiao",
        "Xunxin Cai",
        "Qingqing Long",
        "Chengrui Wang",
        "Yuanchun Zhou",
        "Hengshu Zhu"
      ],
      "published": "2025-04-28T08:18:24Z",
      "categories": "",
      "summary": "Corpus distillation for biomedical large language models (LLMs) seeks to address the pressing challenge of insufficient quantity and quality in open-source annotated scientific corpora, which remains a bottleneck for effective LLM training in biomedical research. This paper proposes a knowledge-driven, agentic framework for scientific corpus distillation, tailored explicitly for LLM training in the biomedical domain, addressing the challenge posed by the complex hierarchy of biomedical knowledge. Central to our approach is a collaborative multi-agent architecture, where specialized agents, eac...",
      "pdf_url": "https://arxiv.org/pdf/2504.19565v3.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2204.05543v2",
      "title": "Towards Reliable Image Outpainting: Learning Structure-Aware Multimodal Fusion with Depth Guidance",
      "authors": [
        "Lei Zhang",
        "Kang Liao",
        "Chunyu Lin",
        "Yao Zhao"
      ],
      "published": "2022-04-12T06:06:50Z",
      "categories": "",
      "summary": "Image outpainting technology generates visually plausible content regardless of authenticity, making it unreliable to be applied in practice. Thus, we propose a reliable image outpainting task, introducing the sparse depth from LiDARs to extrapolate authentic RGB scenes. The large field view of LiDARs allows it to serve for data enhancement and further multimodal tasks. Concretely, we propose a Depth-Guided Outpainting Network to model different feature representations of two modalities and learn the structure-aware cross-modal fusion. And two components are designed: 1) The Multimodal Learnin...",
      "pdf_url": "https://arxiv.org/pdf/2204.05543v2.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2207.09777v2",
      "title": "AU-Supervised Convolutional Vision Transformers for Synthetic Facial Expression Recognition",
      "authors": [
        "Shuyi Mao",
        "Xinpeng Li",
        "Junyao Chen",
        "Xiaojiang Peng"
      ],
      "published": "2022-07-20T09:33:39Z",
      "categories": "",
      "summary": "The paper describes our proposed methodology for the six basic expression classification track of Affective Behavior Analysis in-the-wild (ABAW) Competition 2022. In Learing from Synthetic Data(LSD) task, facial expression recognition (FER) methods aim to learn the representation of expression from the artificially generated data and generalise to real data. Because of the ambiguous of the synthetic data and the objectivity of the facial Action Unit (AU), we resort to the AU information for performance boosting, and make contributions as follows. First, to adapt the model to synthetic scenario...",
      "pdf_url": "https://arxiv.org/pdf/2207.09777v2.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2003.12222v6",
      "title": "Voice activity detection in the wild via weakly supervised sound event detection",
      "authors": [
        "Heinrich Dinkel",
        "Yefei Chen",
        "Mengyue Wu",
        "Kai Yu"
      ],
      "published": "2020-03-27T03:47:12Z",
      "categories": "",
      "summary": "Traditional supervised voice activity detection (VAD) methods work well in clean and controlled scenarios, with performance severely degrading in real-world applications. One possible bottleneck is that speech in the wild contains unpredictable noise types, hence frame-level label prediction is difficult, which is required for traditional supervised VAD training. In contrast, we propose a general-purpose VAD (GPVAD) framework, which can be easily trained from noisy data in a weakly supervised fashion, requiring only clip-level labels. We proposed two GPVAD models, one full (GPV-F), trained on ...",
      "pdf_url": "https://arxiv.org/pdf/2003.12222v6.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.18088v1",
      "title": "Strategic Coordination for Evolving Multi-agent Systems: A Hierarchical Reinforcement and Collective Learning Approach",
      "authors": [
        "Chuhao Qin",
        "Evangelos Pournaras"
      ],
      "published": "2025-09-22T17:58:45Z",
      "categories": "",
      "summary": "Decentralized combinatorial optimization in evolving multi-agent systems poses significant challenges, requiring agents to balance long-term decision-making, short-term optimized collective outcomes, while preserving autonomy of interactive agents under unanticipated changes. Reinforcement learning offers a way to model sequential decision-making through dynamic programming to anticipate future environmental changes. However, applying multi-agent reinforcement learning (MARL) to decentralized combinatorial optimization problems remains an open challenge due to the exponential growth of the joi...",
      "pdf_url": "https://arxiv.org/pdf/2509.18088v1.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2201.04051v3",
      "title": "LOKO: Localization-aware Roll-out Planning for Future Mobile Networks",
      "authors": [
        "Antonio Albanese",
        "Vincenzo Sciancalepore",
        "Albert Banchs",
        "Xavier Costa-P\u00e9rez"
      ],
      "published": "2022-01-11T16:53:27Z",
      "categories": "",
      "summary": "The roll-out phase of the next generation of mobile networks (5G) has started and operators are required to devise deployment solutions while pursuing localization accuracy maximization. Enabling location-based services is expected to be a unique selling point for service providers now able to deliver critical mobile services, e.g., autonomous driving, public safety, remote operations. In this paper, we propose a novel roll-out base station placement solution that, given a Throughput-Positioning Ratio (TPR) target, selects the location of new-generation base stations (among available candidate...",
      "pdf_url": "https://arxiv.org/pdf/2201.04051v3.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.17514v1",
      "title": "Speaker Distance Estimation in Enclosures from Single-Channel Audio",
      "authors": [
        "Michael Neri",
        "Archontis Politis",
        "Daniel Krause",
        "Marco Carli",
        "Tuomas Virtanen"
      ],
      "published": "2024-03-26T09:16:21Z",
      "categories": "",
      "summary": "Distance estimation from audio plays a crucial role in various applications, such as acoustic scene analysis, sound source localization, and room modeling. Most studies predominantly center on employing a classification approach, where distances are discretized into distinct categories, enabling smoother model training and achieving higher accuracy but imposing restrictions on the precision of the obtained sound source position. Towards this direction, in this paper we propose a novel approach for continuous distance estimation from audio signals using a convolutional recurrent neural network ...",
      "pdf_url": "https://arxiv.org/pdf/2403.17514v1.pdf",
      "relevance_score": 47,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2306.03823v1",
      "title": "Transformative Effects of ChatGPT on Modern Education: Emerging Era of AI Chatbots",
      "authors": [
        "Sukhpal Singh Gill",
        "Minxian Xu",
        "Panos Patros",
        "Huaming Wu",
        "Rupinder Kaur",
        "Kamalpreet Kaur",
        "Stephanie Fuller",
        "Manmeet Singh",
        "Priyansh Arora",
        "Ajith Kumar Parlikad",
        "Vlado Stankovski",
        "Ajith Abraham",
        "Soumya K. Ghosh",
        "Hanan Lutfiyya",
        "Salil S. Kanhere",
        "Rami Bahsoon",
        "Omer Rana",
        "Schahram Dustdar",
        "Rizos Sakellariou",
        "Steve Uhlig",
        "Rajkumar Buyya"
      ],
      "published": "2023-05-25T17:35:57Z",
      "categories": "",
      "summary": "ChatGPT, an AI-based chatbot, was released to provide coherent and useful replies based on analysis of large volumes of data. In this article, leading scientists, researchers and engineers discuss the transformative effects of ChatGPT on modern education. This research seeks to improve our knowledge of ChatGPT capabilities and its use in the education sector, identifying potential concerns and challenges. Our preliminary evaluation concludes that ChatGPT performed differently in each subject area including finance, coding and maths. While ChatGPT has the ability to help educators by creating i...",
      "pdf_url": "https://arxiv.org/pdf/2306.03823v1.pdf",
      "relevance_score": 46,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2304.11957v4",
      "title": "Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology",
      "authors": [
        "Yixing Huang",
        "Ahmed Gomaa",
        "Sabine Semrau",
        "Marlen Haderlein",
        "Sebastian Lettmaier",
        "Thomas Weissmann",
        "Johanna Grigo",
        "Hassen Ben Tkhayat",
        "Benjamin Frey",
        "Udo S. Gaipl",
        "Luitpold V. Distel",
        "Andreas Maier",
        "Rainer Fietkau",
        "Christoph Bert",
        "Florian Putz"
      ],
      "published": "2023-04-24T09:50:39Z",
      "categories": "",
      "summary": "The potential of large language models in medicine for education and decision making purposes has been demonstrated as they achieve decent scores on medical exams such as the United States Medical Licensing Exam (USMLE) and the MedQA exam. In this work, we evaluate the performance of ChatGPT-4 in the specialized field of radiation oncology using the 38th American College of Radiology (ACR) radiation oncology in-training (TXIT) exam and the 2022 Red Journal Gray Zone cases. For the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of 63.65% and 74.57%, respectively, highlighting the...",
      "pdf_url": "https://arxiv.org/pdf/2304.11957v4.pdf",
      "relevance_score": 46,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.04851v1",
      "title": "Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights",
      "authors": [
        "Giorgio Biancini",
        "Alessio Ferrato",
        "Carla Limongelli"
      ],
      "published": "2025-06-05T10:21:49Z",
      "categories": "",
      "summary": "Integrating Artificial Intelligence (AI) in educational settings has brought new learning approaches, transforming the practices of both students and educators. Among the various technologies driving this transformation, Large Language Models (LLMs) have emerged as powerful tools for creating educational materials and question answering, but there are still space for new applications. Educators commonly use Multiple-Choice Questions (MCQs) to assess student knowledge, but manually generating these questions is resource-intensive and requires significant time and cognitive effort. In our opinio...",
      "pdf_url": "https://arxiv.org/pdf/2506.04851v1.pdf",
      "relevance_score": 46,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2405.20112v1",
      "title": "RIGID: A Training-free and Model-Agnostic Framework for Robust AI-Generated Image Detection",
      "authors": [
        "Zhiyuan He",
        "Pin-Yu Chen",
        "Tsung-Yi Ho"
      ],
      "published": "2024-05-30T14:49:54Z",
      "categories": "",
      "summary": "The rapid advances in generative AI models have empowered the creation of highly realistic images with arbitrary content, raising concerns about potential misuse and harm, such as Deepfakes. Current research focuses on training detectors using large datasets of generated images. However, these training-based solutions are often computationally expensive and show limited generalization to unseen generated images. In this paper, we propose a training-free method to distinguish between real and AI-generated images. We first observe that real images are more robust to tiny noise perturbations than...",
      "pdf_url": "https://arxiv.org/pdf/2405.20112v1.pdf",
      "relevance_score": 46,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2405.16422v1",
      "title": "AI-Generated Text Detection and Classification Based on BERT Deep Learning Algorithm",
      "authors": [
        "Hao Wang",
        "Jianwei Li",
        "Zhengyu Li"
      ],
      "published": "2024-05-26T04:26:07Z",
      "categories": "",
      "summary": "AI-generated text detection plays an increasingly important role in various fields. In this study, we developed an efficient AI-generated text detection model based on the BERT algorithm, which provides new ideas and methods for solving related problems. In the data preprocessing stage, a series of steps were taken to process the text, including operations such as converting to lowercase, word splitting, removing stop words, stemming extraction, removing digits, and eliminating redundant spaces, to ensure data quality and accuracy. By dividing the dataset into a training set and a test set in ...",
      "pdf_url": "https://arxiv.org/pdf/2405.16422v1.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.21473v1",
      "title": "Are Hallucinations Bad Estimations?",
      "authors": [
        "Hude Liu",
        "Jerry Yao-Chieh Hu",
        "Jennifer Yuntong Zhang",
        "Zhao Song",
        "Han Liu"
      ],
      "published": "2025-09-25T19:39:09Z",
      "categories": "",
      "summary": "We formalize hallucinations in generative models as failures to link an estimate to any plausible cause. Under this interpretation, we show that even loss-minimizing optimal estimators still hallucinate. We confirm this with a general high probability lower bound on hallucinate rate for generic data distributions. This reframes hallucination as structural misalignment between loss minimization and human-acceptable outputs, and hence estimation errors induced by miscalibration. Experiments on coin aggregation, open-ended QA, and text-to-image support our theory.",
      "pdf_url": "https://arxiv.org/pdf/2509.21473v1.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2601.01401v1",
      "title": "LANCET: Neural Intervention via Structural Entropy for Mitigating Faithfulness Hallucinations in LLMs",
      "authors": [
        "Chenxu Wang",
        "Chaozhuo Li",
        "Pengbo Wang",
        "Litian Zhang",
        "Songyang Liu",
        "Ji Qi",
        "Jiahui Hu",
        "Yushan Cai",
        "Hao Zhao",
        "Rui Pu"
      ],
      "published": "2026-01-04T06:41:28Z",
      "categories": "",
      "summary": "Large Language Models have revolutionized information processing, yet their reliability is severely compromised by faithfulness hallucinations. While current approaches attempt to mitigate this issue through node-level adjustments or coarse suppression, they often overlook the distributed nature of neural information, leading to imprecise interventions. Recognizing that hallucinations propagate through specific forward transmission pathways like an infection, we aim to surgically block this flow using precise structural analysis. To leverage this, we propose Lancet, a novel framework that achi...",
      "pdf_url": "https://arxiv.org/pdf/2601.01401v1.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.03502v2",
      "title": "CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model",
      "authors": [
        "Yuxuan Chen",
        "Haipeng Xie"
      ],
      "published": "2025-06-04T02:34:09Z",
      "categories": "",
      "summary": "The denoising diffusion probabilistic model has become a mainstream generative model, achieving significant success in various computer vision tasks. Recently, there has been initial exploration of applying diffusion models to time series tasks. However, existing studies still face challenges in multi-scale feature alignment and generative capabilities across different entities and long-time scales. In this paper, we propose CHIME, a conditional hallucination and integrated multi-scale enhancement framework for time series diffusion models. By employing multi-scale decomposition and integratio...",
      "pdf_url": "https://arxiv.org/pdf/2506.03502v2.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2011.14615v2",
      "title": "SoMin.ai: Personality-Driven Content Generation Platform",
      "authors": [
        "Aleksandr Farseev",
        "Qi Yang",
        "Andrey Filchenkov",
        "Kirill Lepikhin",
        "Yu-Yi Chu-Farseeva",
        "Daron-Benjamin Loo"
      ],
      "published": "2020-11-30T08:33:39Z",
      "categories": "",
      "summary": "In this technical demonstration, we showcase the World's first personality-driven marketing content generation platform, called SoMin.ai. The platform combines deep multi-view personality profiling framework and style generative adversarial networks facilitating the automatic creation of content that appeals to different human personality types. The platform can be used for the enhancement of the social networking user experience as well as for content marketing routines. Guided by the MBTI personality type, automatically derived from a user social network content, SoMin.ai generates new socia...",
      "pdf_url": "https://arxiv.org/pdf/2011.14615v2.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.18480v2",
      "title": "Content-Based Collaborative Generation for Recommender Systems",
      "authors": [
        "Yidan Wang",
        "Zhaochun Ren",
        "Weiwei Sun",
        "Jiyuan Yang",
        "Zhixiang Liang",
        "Xin Chen",
        "Ruobing Xie",
        "Su Yan",
        "Xu Zhang",
        "Pengjie Ren",
        "Zhumin Chen",
        "Xin Xin"
      ],
      "published": "2024-03-27T11:49:58Z",
      "categories": "",
      "summary": "Generative models have emerged as a promising utility to enhance recommender systems. It is essential to model both item content and user-item collaborative interactions in a unified generative framework for better recommendation. Although some existing large language model (LLM)-based methods contribute to fusing content information and collaborative signals, they fundamentally rely on textual language generation, which is not fully aligned with the recommendation task. How to integrate content knowledge and collaborative interaction signals in a generative framework tailored for item recomme...",
      "pdf_url": "https://arxiv.org/pdf/2403.18480v2.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.10467v1",
      "title": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs",
      "authors": [
        "Xueli Pan",
        "Victor de Boer",
        "Jacco van Ossenbruggen"
      ],
      "published": "2025-08-14T09:08:50Z",
      "categories": "",
      "summary": "Question answering over Scholarly Knowledge Graphs (SKGs) remains a challenging task due to the complexity of scholarly content and the intricate structure of these graphs. Large Language Model (LLM) approaches could be used to translate natural language questions (NLQs) into SPARQL queries; however, these LLM-based approaches struggle with SPARQL query generation due to limited exposure to SKG-specific content and the underlying schema. We identified two main types of errors in the LLM-generated SPARQL queries: (i) structural inconsistencies, such as missing or redundant triples in the querie...",
      "pdf_url": "https://arxiv.org/pdf/2508.10467v1.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.09326v1",
      "title": "Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks",
      "authors": [
        "Kexin Chen",
        "Yi Liu",
        "Dongxia Wang",
        "Jiaying Chen",
        "Wenhai Wang"
      ],
      "published": "2024-08-18T01:58:03Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) have increasingly become pivotal in content generation with notable societal impact. These models hold the potential to generate content that could be deemed harmful.Efforts to mitigate this risk include implementing safeguards to ensure LLMs adhere to social ethics.However, despite such measures, the phenomenon of \"jailbreaking\" -- where carefully crafted prompts elicit harmful responses from models -- persists as a significant challenge. Recognizing the continuous threat posed by jailbreaking tactics and their repercussions for the trustworthy use of LLMs, a rigo...",
      "pdf_url": "https://arxiv.org/pdf/2408.09326v1.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.11365v4",
      "title": "Phare: A Safety Probe for Large Language Models",
      "authors": [
        "Pierre Le Jeune",
        "Beno\u00eet Mal\u00e9zieux",
        "Weixuan Xiao",
        "Matteo Dora"
      ],
      "published": "2025-05-16T15:31:08Z",
      "categories": "",
      "summary": "Ensuring the safety of large language models (LLMs) is critical for responsible deployment, yet existing evaluations often prioritize performance over identifying failure modes. We introduce Phare, a multilingual diagnostic framework to probe and evaluate LLM behavior across three critical dimensions: hallucination and reliability, social biases, and harmful content generation. Our evaluation of 17 state-of-the-art LLMs reveals patterns of systematic vulnerabilities across all safety dimensions, including sycophancy, prompt sensitivity, and stereotype reproduction. By highlighting these specif...",
      "pdf_url": "https://arxiv.org/pdf/2505.11365v4.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.06872v1",
      "title": "Towards Trustworthy Retrieval Augmented Generation for Large Language Models: A Survey",
      "authors": [
        "Bo Ni",
        "Zheyuan Liu",
        "Leyao Wang",
        "Yongjia Lei",
        "Yuying Zhao",
        "Xueqi Cheng",
        "Qingkai Zeng",
        "Luna Dong",
        "Yinglong Xia",
        "Krishnaram Kenthapadi",
        "Ryan Rossi",
        "Franck Dernoncourt",
        "Md Mehrab Tanjim",
        "Nesreen Ahmed",
        "Xiaorui Liu",
        "Wenqi Fan",
        "Erik Blasch",
        "Yu Wang",
        "Meng Jiang",
        "Tyler Derr"
      ],
      "published": "2025-02-08T06:50:47Z",
      "categories": "",
      "summary": "Retrieval-Augmented Generation (RAG) is an advanced technique designed to address the challenges of Artificial Intelligence-Generated Content (AIGC). By integrating context retrieval into content generation, RAG provides reliable and up-to-date external knowledge, reduces hallucinations, and ensures relevant context across a wide range of tasks. However, despite RAG's success and potential, recent studies have shown that the RAG paradigm also introduces new risks, including robustness issues, privacy concerns, adversarial attacks, and accountability issues. Addressing these risks is critical f...",
      "pdf_url": "https://arxiv.org/pdf/2502.06872v1.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.05563v2",
      "title": "A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions",
      "authors": [
        "Ola Shorinwa",
        "Zhiting Mei",
        "Justin Lidard",
        "Allen Z. Ren",
        "Anirudha Majumdar"
      ],
      "published": "2024-12-07T06:56:01Z",
      "categories": "",
      "summary": "The remarkable performance of large language models (LLMs) in content generation, coding, and common-sense reasoning has spurred widespread integration into many facets of society. However, integration of LLMs raises valid questions on their reliability and trustworthiness, given their propensity to generate hallucinations: plausible, factually-incorrect responses, which are expressed with striking confidence. Previous work has shown that hallucinations and other non-factual responses generated by LLMs can be detected by examining the uncertainty of the LLM in its response to the pertinent pro...",
      "pdf_url": "https://arxiv.org/pdf/2412.05563v2.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.16810v5",
      "title": "AI Realtor: Towards Grounded Persuasive Language Generation for Automated Copywriting",
      "authors": [
        "Jibang Wu",
        "Chenghao Yang",
        "Yi Wu",
        "Simon Mahns",
        "Chaoqi Wang",
        "Hao Zhu",
        "Fei Fang",
        "Haifeng Xu"
      ],
      "published": "2025-02-24T03:36:57Z",
      "categories": "",
      "summary": "This paper develops an agentic framework that employs large language models (LLMs) for grounded persuasive language generation in automated copywriting, with real estate marketing as a focal application. Our method is designed to align the generated content with user preferences while highlighting useful factual attributes. This agent consists of three key modules: (1) Grounding Module, mimicking expert human behavior to predict marketable features; (2) Personalization Module, aligning content with user preferences; (3) Marketing Module, ensuring factual accuracy and the inclusion of localized...",
      "pdf_url": "https://arxiv.org/pdf/2502.16810v5.pdf",
      "relevance_score": 45,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.13685v1",
      "title": "Using AI Large Language Models for Grading in Education: A Hands-On Test for Physics",
      "authors": [
        "Ryan Mok",
        "Faraaz Akhtar",
        "Louis Clare",
        "Christine Li",
        "Jun Ida",
        "Lewis Ross",
        "Mario Campanelli"
      ],
      "published": "2024-11-20T20:04:55Z",
      "categories": "",
      "summary": "Grading assessments is time-consuming and prone to human bias. Students may experience delays in receiving feedback that may not be tailored to their expectations or needs. Harnessing AI in education can be effective for grading undergraduate physics problems, enhancing the efficiency of undergraduate-level physics learning and teaching, and helping students understand concepts with the help of a constantly available tutor. This report devises a simple empirical procedure to investigate and quantify how well large language model (LLM) based AI chatbots can grade solutions to undergraduate phys...",
      "pdf_url": "https://arxiv.org/pdf/2411.13685v1.pdf",
      "relevance_score": 44,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2210.07332v2",
      "title": "Secure Multiparty Computation for Synthetic Data Generation from Distributed Data",
      "authors": [
        "Mayana Pereira",
        "Sikha Pentyala",
        "Anderson Nascimento",
        "Rafael T. de Sousa",
        "Martine De Cock"
      ],
      "published": "2022-10-13T20:09:17Z",
      "categories": "",
      "summary": "Legal and ethical restrictions on accessing relevant data inhibit data science research in critical domains such as health, finance, and education. Synthetic data generation algorithms with privacy guarantees are emerging as a paradigm to break this data logjam. Existing approaches, however, assume that the data holders supply their raw data to a trusted curator, who uses it as fuel for synthetic data generation. This severely limits the applicability, as much of the valuable data in the world is locked up in silos, controlled by entities who cannot show their data to each other or a central a...",
      "pdf_url": "https://arxiv.org/pdf/2210.07332v2.pdf",
      "relevance_score": 44,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.15769v1",
      "title": "Data-Chain Backdoor: Do You Trust Diffusion Models as Generative Data Supplier?",
      "authors": [
        "Junchi Lu",
        "Xinke Li",
        "Yuheng Liu",
        "Qi Alfred Chen"
      ],
      "published": "2025-12-12T18:53:38Z",
      "categories": "",
      "summary": "The increasing use of generative models such as diffusion models for synthetic data augmentation has greatly reduced the cost of data collection and labeling in downstream perception tasks. However, this new data source paradigm may introduce important security concerns. This work investigates backdoor propagation in such emerging generative data supply chains, namely Data-Chain Backdoor (DCB). Specifically, we find that open-source diffusion models can become hidden carriers of backdoors. Their strong distribution-fitting ability causes them to memorize and reproduce backdoor triggers during ...",
      "pdf_url": "https://arxiv.org/pdf/2512.15769v1.pdf",
      "relevance_score": 44,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.17506v1",
      "title": "Optimizing Resource Allocation for Multi-modal Semantic Communication in Mobile AIGC Networks: A Diffusion-based Game Approach",
      "authors": [
        "Jian Liu",
        "Ming Xiao",
        "Jinbo Wen",
        "Jiawen Kang",
        "Ruichen Zhang",
        "Tao Zhang",
        "Dusit Niyato",
        "Weiting Zhang",
        "Ying Liu"
      ],
      "published": "2024-09-26T03:25:31Z",
      "categories": "",
      "summary": "Mobile Artificial Intelligence-Generated Content (AIGC) networks enable massive users to obtain customized content generation services. However, users still need to download a large number of AIGC outputs from mobile AIGC service providers, which strains communication resources and increases the risk of transmission failures. Fortunately, Semantic Communication (SemCom) can improve transmission efficiency and reliability through semantic information processing. Moreover, recent advances in Generative Artificial Intelligence (GAI) further enhanced the effectiveness of SemCom through its powerfu...",
      "pdf_url": "https://arxiv.org/pdf/2409.17506v1.pdf",
      "relevance_score": 44,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.11808v1",
      "title": "Accelerating the Training and Improving the Reliability of Machine-Learned Interatomic Potentials for Strongly Anharmonic Materials through Active Learning",
      "authors": [
        "Kisung Kang",
        "Thomas A. R. Purcell",
        "Christian Carbogno",
        "Matthias Scheffler"
      ],
      "published": "2024-09-18T08:52:30Z",
      "categories": "",
      "summary": "Molecular dynamics (MD) employing machine-learned interatomic potentials (MLIPs) serve as an efficient, urgently needed complement to ab initio molecular dynamics (aiMD). By training these potentials on data generated from ab initio methods, their averaged predictions can exhibit comparable performance to ab initio methods at a fraction of the cost. However, insufficient training sets might lead to an improper description of the dynamics in strongly anharmonic materials, because critical effects might be overlooked in relevant cases, or only incorrectly captured, or hallucinated by the MLIP wh...",
      "pdf_url": "https://arxiv.org/pdf/2409.11808v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.23793v1",
      "title": "USB: A Comprehensive and Unified Safety Evaluation Benchmark for Multimodal Large Language Models",
      "authors": [
        "Baolin Zheng",
        "Guanlin Chen",
        "Hongqiong Zhong",
        "Qingyang Teng",
        "Yingshui Tan",
        "Zhendong Liu",
        "Weixun Wang",
        "Jiaheng Liu",
        "Jian Yang",
        "Huiyun Jing",
        "Jincheng Wei",
        "Wenbo Su",
        "Xiaoyong Zhu",
        "Bo Zheng",
        "Kaifu Zhang"
      ],
      "published": "2025-05-26T08:39:14Z",
      "categories": "",
      "summary": "Despite their remarkable achievements and widespread adoption, Multimodal Large Language Models (MLLMs) have revealed significant security vulnerabilities, highlighting the urgent need for robust safety evaluation benchmarks. Existing MLLM safety benchmarks, however, fall short in terms of data quality and coverge, and modal risk combinations, resulting in inflated and contradictory evaluation results, which hinders the discovery and governance of security concerns. Besides, we argue that vulnerabilities to harmful queries and oversensitivity to harmless ones should be considered simultaneousl...",
      "pdf_url": "https://arxiv.org/pdf/2505.23793v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.01603v3",
      "title": "Towards Generalizable AI-Generated Image Detection via Image-Adaptive Prompt Learning",
      "authors": [
        "Yiheng Li",
        "Zichang Tan",
        "Zhen Lei",
        "Xu Zhou",
        "Yang Yang"
      ],
      "published": "2025-08-03T05:41:24Z",
      "categories": "",
      "summary": "In AI-generated image detection, current cutting-edge methods typically adapt pre-trained foundation models through partial-parameter fine-tuning. However, these approaches often struggle to generalize to forgeries from unseen generators, as the fine-tuned models capture only limited patterns from training data and fail to reflect the evolving traits of new ones. To overcome this limitation, we propose Image-Adaptive Prompt Learning (IAPL), a novel paradigm that dynamically adjusts the prompts fed into the encoder according to each testing image, rather than fixing them after training. This de...",
      "pdf_url": "https://arxiv.org/pdf/2508.01603v3.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2303.13294v4",
      "title": "Considerations on the Evaluation of Biometric Quality Assessment Algorithms",
      "authors": [
        "Torsten Schlett",
        "Christian Rathgeb",
        "Juan Tapia",
        "Christoph Busch"
      ],
      "published": "2023-03-23T14:26:21Z",
      "categories": "",
      "summary": "Quality assessment algorithms can be used to estimate the utility of a biometric sample for the purpose of biometric recognition. \"Error versus Discard Characteristic\" (EDC) plots, and \"partial Area Under Curve\" (pAUC) values of curves therein, are generally used by researchers to evaluate the predictive performance of such quality assessment algorithms. An EDC curve depends on an error type such as the \"False Non Match Rate\" (FNMR), a quality assessment algorithm, a biometric recognition system, a set of comparisons each corresponding to a biometric sample pair, and a comparison score thresho...",
      "pdf_url": "https://arxiv.org/pdf/2303.13294v4.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.00023v1",
      "title": "A Novel Distance-Based Metric for Quality Assessment in Image Segmentation",
      "authors": [
        "Niklas Rottmayer",
        "Claudia Redenbach"
      ],
      "published": "2025-03-28T12:02:09Z",
      "categories": "",
      "summary": "The assessment of segmentation quality plays a fundamental role in the development, optimization, and comparison of segmentation methods which are used in a wide range of applications. With few exceptions, quality assessment is performed using traditional metrics, which are based on counting the number of erroneous pixels but do not capture the spatial distribution of errors. Established distance-based metrics such as the average Hausdorff distance are difficult to interpret and compare for different methods and datasets. In this paper, we introduce the Surface Consistency Coefficient (SCC), a...",
      "pdf_url": "https://arxiv.org/pdf/2504.00023v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.18577v1",
      "title": "Assessing Quality Metrics for Neural Reality Gap Input Mitigation in Autonomous Driving Testing",
      "authors": [
        "Stefano Carlo Lambertenghi",
        "Andrea Stocco"
      ],
      "published": "2024-04-29T10:37:38Z",
      "categories": "",
      "summary": "Simulation-based testing of automated driving systems (ADS) is the industry standard, being a controlled, safe, and cost-effective alternative to real-world testing. Despite these advantages, virtual simulations often fail to accurately replicate real-world conditions like image fidelity, texture representation, and environmental accuracy. This can lead to significant differences in ADS behavior between simulated and real-world domains, a phenomenon known as the sim2real gap. Researchers have used Image-to-Image (I2I) neural translation to mitigate the sim2real gap, enhancing the realism of si...",
      "pdf_url": "https://arxiv.org/pdf/2404.18577v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.15795v1",
      "title": "Lean-ing on Quality: How High-Quality Data Beats Diverse Multilingual Data in AutoFormalization",
      "authors": [
        "Willy Chan",
        "Michael Souliman",
        "Jakob Nordhagen",
        "Brando Miranda",
        "Elyas Obbad",
        "Kai Fronsdal Sanmi Koyejo"
      ],
      "published": "2025-02-18T19:16:54Z",
      "categories": "",
      "summary": "Autoformalization, the process of transforming informal mathematical language into formal specifications and proofs remains a difficult task for state-of-the-art (large) language models. Existing works point to competing explanations for the performance gap. To this end, we introduce a novel methodology that leverages back-translation with hand-curated prompts to enhance the mathematical capabilities of language models, particularly addressing the challenge posed by the scarcity of labeled data. Specifically, we evaluate three primary variations of this strategy: (1) on-the-fly (online) backtr...",
      "pdf_url": "https://arxiv.org/pdf/2502.15795v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1701.02797v2",
      "title": "Full-reference image quality assessment-based B-mode ultrasound image similarity measure",
      "authors": [
        "Kele Xu",
        "Xi Liu",
        "Hengxing Cai",
        "Zhifeng Gao"
      ],
      "published": "2017-01-10T21:54:02Z",
      "categories": "",
      "summary": "During the last decades, the number of new full-reference image quality assessment algorithms has been increasing drastically. Yet, despite of the remarkable progress that has been made, the medical ultrasound image similarity measurement remains largely unsolved due to a high level of speckle noise contamination. Potential applications of the ultrasound image similarity measurement seem evident in several aspects. To name a few, ultrasound imaging quality assessment, abnormal function region detection, etc. In this paper, a comparative study was made on full-reference image quality assessment...",
      "pdf_url": "https://arxiv.org/pdf/1701.02797v2.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.13004v1",
      "title": "Data Poisoning and Leakage Analysis in Federated Learning",
      "authors": [
        "Wenqi Wei",
        "Tiansheng Huang",
        "Zachary Yahn",
        "Anoop Singhal",
        "Margaret Loper",
        "Ling Liu"
      ],
      "published": "2024-09-19T16:50:29Z",
      "categories": "",
      "summary": "Data poisoning and leakage risks impede the massive deployment of federated learning in the real world. This chapter reveals the truths and pitfalls of understanding two dominating threats: {\\em training data privacy intrusion} and {\\em training data poisoning}. We first investigate training data privacy threat and present our observations on when and how training data may be leaked during the course of federated training. One promising defense strategy is to perturb the raw gradient update by adding some controlled randomized noise prior to sharing during each round of federated learning. We ...",
      "pdf_url": "https://arxiv.org/pdf/2409.13004v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.09647v1",
      "title": "Rounding-Guided Backdoor Injection in Deep Learning Model Quantization",
      "authors": [
        "Xiangxiang Chen",
        "Peixin Zhang",
        "Jun Sun",
        "Wenhai Wang",
        "Jingyi Wang"
      ],
      "published": "2025-10-05T15:45:49Z",
      "categories": "",
      "summary": "Model quantization is a popular technique for deploying deep learning models on resource-constrained environments. However, it may also introduce previously overlooked security risks. In this work, we present QuRA, a novel backdoor attack that exploits model quantization to embed malicious behaviors. Unlike conventional backdoor attacks relying on training data poisoning or model training manipulation, QuRA solely works using the quantization operations. In particular, QuRA first employs a novel weight selection strategy to identify critical weights that influence the backdoor target (with the...",
      "pdf_url": "https://arxiv.org/pdf/2510.09647v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.10804v1",
      "title": "Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment",
      "authors": [
        "Jinhao Jiang",
        "Junyi Li",
        "Wayne Xin Zhao",
        "Yang Song",
        "Tao Zhang",
        "Ji-Rong Wen"
      ],
      "published": "2024-07-15T15:20:13Z",
      "categories": "",
      "summary": "Adapting general large language models (LLMs) to specialized domains presents great challenges due to varied data distributions. This adaptation typically requires continual pre-training on massive domain-specific corpora to facilitate knowledge memorization, followed by training to apply this knowledge following human instructions and preferences. However, this method may result in inefficient knowledge memorization due to a lack of awareness of knowledge utilization and imposes substantial demands on LLMs to simultaneously learn knowledge utilization and format alignment with limited trainin...",
      "pdf_url": "https://arxiv.org/pdf/2407.10804v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.01019v3",
      "title": "Source-Aware Training Enables Knowledge Attribution in Language Models",
      "authors": [
        "Muhammad Khalifa",
        "David Wadden",
        "Emma Strubell",
        "Honglak Lee",
        "Lu Wang",
        "Iz Beltagy",
        "Hao Peng"
      ],
      "published": "2024-04-01T09:39:38Z",
      "categories": "",
      "summary": "Large language models (LLMs) learn a vast amount of knowledge during pretraining, but they are often oblivious to the source(s) of such knowledge. We investigate the problem of intrinsic source citation, where LLMs are required to cite the pretraining source supporting a generated response. Intrinsic source citation can enhance LLM transparency, interpretability, and verifiability. To give LLMs such ability, we explore source-aware training -- a recipe that involves (i) training the LLM to associate unique source document identifiers with the knowledge in each document, followed by (ii) an ins...",
      "pdf_url": "https://arxiv.org/pdf/2404.01019v3.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.13510v1",
      "title": "Prompt Sentiment: The Catalyst for LLM Change",
      "authors": [
        "Vishal Gandhi",
        "Sagar Gandhi"
      ],
      "published": "2025-03-14T06:25:21Z",
      "categories": "",
      "summary": "The rise of large language models (LLMs) has revolutionized natural language processing (NLP), yet the influence of prompt sentiment, a latent affective characteristic of input text, remains underexplored. This study systematically examines how sentiment variations in prompts affect LLM-generated outputs in terms of coherence, factuality, and bias. Leveraging both lexicon-based and transformer-based sentiment analysis methods, we categorize prompts and evaluate responses from five leading LLMs: Claude, DeepSeek, GPT-4, Gemini, and LLaMA. Our analysis spans six AI-driven applications, including...",
      "pdf_url": "https://arxiv.org/pdf/2503.13510v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.22047v1",
      "title": "Evaluating the Robustness of Large Language Model Safety Guardrails Against Adversarial Attacks",
      "authors": [
        "Richard J. Young"
      ],
      "published": "2025-11-27T03:01:09Z",
      "categories": "",
      "summary": "Large Language Model (LLM) safety guardrail models have emerged as a primary defense mechanism against harmful content generation, yet their robustness against sophisticated adversarial attacks remains poorly characterized. This study evaluated ten publicly available guardrail models from Meta, Google, IBM, NVIDIA, Alibaba, and Allen AI across 1,445 test prompts spanning 21 attack categories. While Qwen3Guard-8B achieved the highest overall accuracy (85.3%, 95% CI: 83.4-87.1%), a critical finding emerged when separating public benchmark prompts from novel attacks: all models showed substantial...",
      "pdf_url": "https://arxiv.org/pdf/2511.22047v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2007.06078v1",
      "title": "Fine-grained Language Identification with Multilingual CapsNet Model",
      "authors": [
        "Mudit Verma",
        "Arun Balaji Buduru"
      ],
      "published": "2020-07-12T20:01:22Z",
      "categories": "",
      "summary": "Due to a drastic improvement in the quality of internet services worldwide, there is an explosion of multilingual content generation and consumption. This is especially prevalent in countries with large multilingual audience, who are increasingly consuming media outside their linguistic familiarity/preference. Hence, there is an increasing need for real-time and fine-grained content analysis services, including language identification, content transcription, and analysis. Accurate and fine-grained spoken language detection is an essential first step for all the subsequent content analysis algo...",
      "pdf_url": "https://arxiv.org/pdf/2007.06078v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.10990v1",
      "title": "On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances",
      "authors": [
        "Roberto Vergallo",
        "Lu\u00eds Cruz",
        "Alessio Errico",
        "Luca Mainetti"
      ],
      "published": "2025-03-20T09:27:29Z",
      "categories": "",
      "summary": "'Follow-the-Sun' (FtS) is a theoretical computational model aimed at minimizing the carbon footprint of computer workloads. It involves dynamically moving workloads to regions with cleaner energy sources as demand increases and energy production relies more on fossil fuels. With the significant power consumption of Artificial Intelligence (AI) being a subject of extensive debate, FtS is proposed as a strategy to mitigate the carbon footprint of training AI models. However, the literature lacks scientific evidence on the advantages of FtS to mitigate the carbon footprint of AI workloads. In thi...",
      "pdf_url": "https://arxiv.org/pdf/2506.10990v1.pdf",
      "relevance_score": 43,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.21972v2",
      "title": "From Superficial Outputs to Superficial Learning: Risks of Large Language Models in Education",
      "authors": [
        "Iris Delikoura",
        "Yi. R Fung",
        "Pan Hui"
      ],
      "published": "2025-09-26T06:59:36Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) are transforming education by enabling personalization, feedback, and knowledge access, while also raising concerns about risks to students and learning systems. Yet empirical evidence on these risks remains fragmented. This paper presents a systematic review of 70 empirical studies across computer science, education, and psychology. Guided by four research questions, we examine: (i) which applications of LLMs in education have been most frequently explored; (ii) how researchers have measured their impact; (iii) which risks stem from such applications; and (iv) wha...",
      "pdf_url": "https://arxiv.org/pdf/2509.21972v2.pdf",
      "relevance_score": 42,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.07220v1",
      "title": "Handwritten Code Recognition for Pen-and-Paper CS Education",
      "authors": [
        "Md Sazzad Islam",
        "Moussa Koulako Bala Doumbouya",
        "Christopher D. Manning",
        "Chris Piech"
      ],
      "published": "2024-08-07T21:02:17Z",
      "categories": "",
      "summary": "Teaching Computer Science (CS) by having students write programs by hand on paper has key pedagogical advantages: It allows focused learning and requires careful thinking compared to the use of Integrated Development Environments (IDEs) with intelligent support tools or \"just trying things out\". The familiar environment of pens and paper also lessens the cognitive load of students with no prior experience with computers, for whom the mere basic usage of computers can be intimidating. Finally, this teaching approach opens learning opportunities to students with limited access to computers.   Ho...",
      "pdf_url": "https://arxiv.org/pdf/2408.07220v1.pdf",
      "relevance_score": 42,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.22886v1",
      "title": "Theory and Algorithms for Learning with Multi-Class Abstention and Multi-Expert Deferral",
      "authors": [
        "Anqi Mao"
      ],
      "published": "2025-12-28T11:33:39Z",
      "categories": "",
      "summary": "Large language models (LLMs) have achieved remarkable performance but face critical challenges: hallucinations and high inference costs. Leveraging multiple experts offers a solution: deferring uncertain inputs to more capable experts improves reliability, while routing simpler queries to smaller, distilled models enhances efficiency. This motivates the problem of learning with multiple-expert deferral. This thesis presents a comprehensive study of this problem and the related problem of learning with abstention, supported by strong consistency guarantees.   First, for learning with abstention...",
      "pdf_url": "https://arxiv.org/pdf/2512.22886v1.pdf",
      "relevance_score": 42,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.17975v1",
      "title": "Enabling PSO-Secure Synthetic Data Sharing Using Diversity-Aware Diffusion Models",
      "authors": [
        "Mischa Dombrowski",
        "Bernhard Kainz"
      ],
      "published": "2025-06-22T10:26:35Z",
      "categories": "",
      "summary": "Synthetic data has recently reached a level of visual fidelity that makes it nearly indistinguishable from real data, offering great promise for privacy-preserving data sharing in medical imaging. However, fully synthetic datasets still suffer from significant limitations: First and foremost, the legal aspect of sharing synthetic data is often neglected and data regulations, such as the GDPR, are largley ignored. Secondly, synthetic models fall short of matching the performance of real data, even for in-domain downstream applications. Recent methods for image generation have focused on maximis...",
      "pdf_url": "https://arxiv.org/pdf/2506.17975v1.pdf",
      "relevance_score": 42,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.00539v1",
      "title": "SAIDO: Generalizable Detection of AI-Generated Images via Scene-Aware and Importance-Guided Dynamic Optimization in Continual Learning",
      "authors": [
        "Yongkang Hu",
        "Yu Cheng",
        "Yushuo Zhang",
        "Yuan Xie",
        "Zhaoxia Yin"
      ],
      "published": "2025-11-29T16:13:50Z",
      "categories": "",
      "summary": "The widespread misuse of image generation technologies has raised security concerns, driving the development of AI-generated image detection methods. However, generalization has become a key challenge and open problem: existing approaches struggle to adapt to emerging generative methods and content types in real-world scenarios. To address this issue, we propose a Scene-Aware and Importance-Guided Dynamic Optimization detection framework with continual learning (SAIDO). Specifically, we design Scene-Awareness-Based Expert Module (SAEM) that dynamically identifies and incorporates new scenes us...",
      "pdf_url": "https://arxiv.org/pdf/2512.00539v1.pdf",
      "relevance_score": 42,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2402.04655v4",
      "title": "Open-Vocabulary Calibration for Fine-tuned CLIP",
      "authors": [
        "Shuoyuan Wang",
        "Jindong Wang",
        "Guoqing Wang",
        "Bob Zhang",
        "Kaiyang Zhou",
        "Hongxin Wei"
      ],
      "published": "2024-02-07T08:42:48Z",
      "categories": "",
      "summary": "Vision-language models (VLMs) have emerged as formidable tools, showing their strong capability in handling various open-vocabulary tasks in image recognition, text-driven visual content generation, and visual chatbots, to name a few. In recent years, considerable efforts and resources have been devoted to adaptation methods for improving downstream performance of VLMs, particularly on parameter-efficient fine-tuning methods like prompt learning. However, a crucial aspect that has been largely overlooked is the confidence calibration problem in fine-tuned VLMs, which could greatly reduce relia...",
      "pdf_url": "https://arxiv.org/pdf/2402.04655v4.pdf",
      "relevance_score": 42,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.05248v1",
      "title": "The Role and Applications of Airport Digital Twin in Cyberattack Protection during the Generative AI Era",
      "authors": [
        "Abraham Itzhak Weinberg"
      ],
      "published": "2024-08-08T14:35:39Z",
      "categories": "",
      "summary": "In recent years, the threat facing airports from growing and increasingly sophisticated cyberattacks has become evident. Airports are considered a strategic national asset, so protecting them from attacks, specifically cyberattacks, is a crucial mission. One way to increase airports' security is by using Digital Twins (DTs). This paper shows and demonstrates how DTs can enhance the security mission. The integration of DTs with Generative AI (GenAI) algorithms can lead to synergy and new frontiers in fighting cyberattacks. The paper exemplifies ways to model cyberattack scenarios using simulati...",
      "pdf_url": "https://arxiv.org/pdf/2408.05248v1.pdf",
      "relevance_score": 41,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2305.04923v2",
      "title": "Learning to Evaluate the Artness of AI-generated Images",
      "authors": [
        "Junyu Chen",
        "Jie An",
        "Hanjia Lyu",
        "Christopher Kanan",
        "Jiebo Luo"
      ],
      "published": "2023-05-08T17:58:27Z",
      "categories": "",
      "summary": "Assessing the artness of AI-generated images continues to be a challenge within the realm of image generation. Most existing metrics cannot be used to perform instance-level and reference-free artness evaluation. This paper presents ArtScore, a metric designed to evaluate the degree to which an image resembles authentic artworks by artists (or conversely photographs), thereby offering a novel approach to artness assessment. We first blend pre-trained models for photo and artwork generation, resulting in a series of mixed models. Subsequently, we utilize these mixed models to generate images ex...",
      "pdf_url": "https://arxiv.org/pdf/2305.04923v2.pdf",
      "relevance_score": 41,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.18988v1",
      "title": "AEDR: Training-Free AI-Generated Image Attribution via Autoencoder Double-Reconstruction",
      "authors": [
        "Chao Wang",
        "Kejiang Chen",
        "Zijin Yang",
        "Yaofei Wang",
        "Weiming Zhang"
      ],
      "published": "2025-07-25T06:34:58Z",
      "categories": "",
      "summary": "The rapid advancement of image-generation technologies has made it possible for anyone to create photorealistic images using generative models, raising significant security concerns. To mitigate malicious use, tracing the origin of such images is essential. Reconstruction-based attribution methods offer a promising solution, but they often suffer from reduced accuracy and high computational costs when applied to state-of-the-art (SOTA) models. To address these challenges, we propose AEDR (AutoEncoder Double-Reconstruction), a novel training-free attribution method designed for generative model...",
      "pdf_url": "https://arxiv.org/pdf/2507.18988v1.pdf",
      "relevance_score": 41,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.20988v2",
      "title": "Reviewing Clinical Knowledge in Medical Large Language Models: Training and Beyond",
      "authors": [
        "Qiyuan Li",
        "Haijiang Liu",
        "Caicai Guo",
        "Chao Gao",
        "Deyu Chen",
        "Meng Wang",
        "Feng Gao",
        "Frank van Harmelen",
        "Jinguang Gu"
      ],
      "published": "2025-02-28T12:00:51Z",
      "categories": "",
      "summary": "The large-scale development of large language models (LLMs) in medical contexts, such as diagnostic assistance and treatment recommendations, necessitates that these models possess accurate medical knowledge and deliver traceable decision-making processes. Clinical knowledge, encompassing the insights gained from research on the causes, prognosis, diagnosis, and treatment of diseases, has been extensively examined within real-world medical practices. Recently, there has been a notable increase in research efforts aimed at integrating this type of knowledge into LLMs, encompassing not only trad...",
      "pdf_url": "https://arxiv.org/pdf/2502.20988v2.pdf",
      "relevance_score": 41,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.04460v1",
      "title": "CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection",
      "authors": [
        "Yihan Chen",
        "Jiawei Chen",
        "Guozhao Mo",
        "Xuanang Chen",
        "Ben He",
        "Xianpei Han",
        "Le Sun"
      ],
      "published": "2025-08-28T06:03:11Z",
      "categories": "",
      "summary": "The growing integration of large language models (LLMs) into the peer review process presents potential risks to the fairness and reliability of scholarly evaluation. While LLMs offer valuable assistance for reviewers with language refinement, there is growing concern over their use to generate substantive review content. Existing general AI-generated text detectors are vulnerable to paraphrasing attacks and struggle to distinguish between surface language refinement and substantial content generation, suggesting that they primarily rely on stylistic cues. When applied to peer review, this lim...",
      "pdf_url": "https://arxiv.org/pdf/2509.04460v1.pdf",
      "relevance_score": 41,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.05424v2",
      "title": "Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients",
      "authors": [
        "Niklas Penzel",
        "Joachim Denzler"
      ],
      "published": "2025-03-07T13:50:37Z",
      "categories": "",
      "summary": "Deep learning models achieve high predictive performance but lack intrinsic interpretability, hindering our understanding of the learned prediction behavior. Existing local explainability methods focus on associations, neglecting the causal drivers of model predictions. Other approaches adopt a causal perspective but primarily provide global, model-level explanations. However, for specific inputs, it's unclear whether globally identified factors apply locally. To address this limitation, we introduce a novel framework for local interventional explanations by leveraging recent advances in image...",
      "pdf_url": "https://arxiv.org/pdf/2503.05424v2.pdf",
      "relevance_score": 41,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.01462v1",
      "title": "Faculty Perspectives on the Potential of RAG in Computer Science Higher Education",
      "authors": [
        "Sagnik Dakshit"
      ],
      "published": "2024-07-28T14:55:22Z",
      "categories": "",
      "summary": "The emergence of Large Language Models (LLMs) has significantly impacted the field of Natural Language Processing and has transformed conversational tasks across various domains because of their widespread integration in applications and public access. The discussion surrounding the application of LLMs in education has raised ethical concerns, particularly concerning plagiarism and policy compliance. Despite the prowess of LLMs in conversational tasks, the limitations of reliability and hallucinations exacerbate the need to guardrail conversations, motivating our investigation of RAG in comput...",
      "pdf_url": "https://arxiv.org/pdf/2408.01462v1.pdf",
      "relevance_score": 40,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.09296v2",
      "title": "Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT",
      "authors": [
        "Tuan Bui",
        "Oanh Tran",
        "Phuong Nguyen",
        "Bao Ho",
        "Long Nguyen",
        "Thang Bui",
        "Tho Quan"
      ],
      "published": "2024-04-14T16:34:31Z",
      "categories": "",
      "summary": "In today's rapidly evolving landscape of Artificial Intelligence, large language models (LLMs) have emerged as a vibrant research topic. LLMs find applications in various fields and contribute significantly. Despite their powerful language capabilities, similar to pre-trained language models (PLMs), LLMs still face challenges in remembering events, incorporating new information, and addressing domain-specific issues or hallucinations. To overcome these limitations, researchers have proposed Retrieval-Augmented Generation (RAG) techniques, some others have proposed the integration of LLMs with ...",
      "pdf_url": "https://arxiv.org/pdf/2404.09296v2.pdf",
      "relevance_score": 40,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2308.00479v1",
      "title": "Retrieval Augmented Generation and Representative Vector Summarization for large unstructured textual data in Medical Education",
      "authors": [
        "S. S. Manathunga",
        "Y. A. Illangasekara"
      ],
      "published": "2023-08-01T12:04:50Z",
      "categories": "",
      "summary": "Large Language Models are increasingly being used for various tasks including content generation and as chatbots. Despite their impressive performances in general tasks, LLMs need to be aligned when applying for domain specific tasks to mitigate the problems of hallucination and producing harmful answers. Retrieval Augmented Generation (RAG) allows to easily attach and manipulate a non-parametric knowledgebases to LLMs. Applications of RAG in the field of medical education are discussed in this paper. A combined extractive and abstractive summarization method for large unstructured textual dat...",
      "pdf_url": "https://arxiv.org/pdf/2308.00479v1.pdf",
      "relevance_score": 40,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.04831v2",
      "title": "Code Hallucination",
      "authors": [
        "Mirza Masfiqur Rahman",
        "Ashish Kundu"
      ],
      "published": "2024-07-05T19:37:37Z",
      "categories": "",
      "summary": "Generative models such as large language models are extensively used as code copilots and for whole program generation. However, the programs they generate often have questionable correctness, authenticity and reliability in terms of integration as they might not follow the user requirements, provide incorrect and/or nonsensical outputs, or even contain semantic/syntactic errors - overall known as LLM hallucination. In this work, we present several types of code hallucination. We have generated such hallucinated code manually using large language models. We also present a technique - HallTrigg...",
      "pdf_url": "https://arxiv.org/pdf/2407.04831v2.pdf",
      "relevance_score": 40,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2501.16497v1",
      "title": "Smoothed Embeddings for Robust Language Models",
      "authors": [
        "Ryo Hase",
        "Md Rafi Ur Rashid",
        "Ashley Lewis",
        "Jing Liu",
        "Toshiaki Koike-Akino",
        "Kieran Parsons",
        "Ye Wang"
      ],
      "published": "2025-01-27T20:57:26Z",
      "categories": "",
      "summary": "Improving the safety and reliability of large language models (LLMs) is a crucial aspect of realizing trustworthy AI systems. Although alignment methods aim to suppress harmful content generation, LLMs are often still vulnerable to jailbreaking attacks that employ adversarial inputs that subvert alignment and induce harmful outputs. We propose the Randomized Embedding Smoothing and Token Aggregation (RESTA) defense, which adds random noise to the embedding vectors and performs aggregation during the generation of each output token, with the aim of better preserving semantic information. Our ex...",
      "pdf_url": "https://arxiv.org/pdf/2501.16497v1.pdf",
      "relevance_score": 40,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.00934v1",
      "title": "InformGen: An AI Copilot for Accurate and Compliant Clinical Research Consent Document Generation",
      "authors": [
        "Zifeng Wang",
        "Junyi Gao",
        "Benjamin Danek",
        "Brandon Theodorou",
        "Ruba Shaik",
        "Shivashankar Thati",
        "Seunghyun Won",
        "Jimeng Sun"
      ],
      "published": "2025-04-01T16:14:48Z",
      "categories": "",
      "summary": "Leveraging large language models (LLMs) to generate high-stakes documents, such as informed consent forms (ICFs), remains a significant challenge due to the extreme need for regulatory compliance and factual accuracy. Here, we present InformGen, an LLM-driven copilot for accurate and compliant ICF drafting by optimized knowledge document parsing and content generation, with humans in the loop. We further construct a benchmark dataset comprising protocols and ICFs from 900 clinical trials. Experimental results demonstrate that InformGen achieves near 100% compliance with 18 core regulatory rule...",
      "pdf_url": "https://arxiv.org/pdf/2504.00934v1.pdf",
      "relevance_score": 40,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.14232v2",
      "title": "Assessing AI-Generated Questions' Alignment with Cognitive Frameworks in Educational Assessment",
      "authors": [
        "Antoun Yaacoub",
        "J\u00e9r\u00f4me Da-Rugna",
        "Zainab Assaghir"
      ],
      "published": "2025-04-19T09:03:39Z",
      "categories": "",
      "summary": "This study evaluates the integration of Bloom's Taxonomy into OneClickQuiz, an Artificial Intelligence (AI) driven plugin for automating Multiple-Choice Question (MCQ) generation in Moodle. Bloom's Taxonomy provides a structured framework for categorizing educational objectives into hierarchical cognitive levels. Our research investigates whether incorporating this taxonomy can improve the alignment of AI-generated questions with specific cognitive objectives. We developed a dataset of 3691 questions categorized according to Bloom's levels and employed various classification models-Multinomial...",
      "pdf_url": "https://arxiv.org/pdf/2504.14232v2.pdf",
      "relevance_score": 40,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.02863v1",
      "title": "Leveraging generative adversarial networks with spatially adaptive denormalization for multivariate stochastic seismic data inversion",
      "authors": [
        "Roberto Miele",
        "Leonardo Azevedo"
      ],
      "published": "2025-12-02T15:25:22Z",
      "categories": "",
      "summary": "Probabilistic seismic inverse modeling often requires the prediction of both spatially correlated geological heterogeneities (e.g., facies) and continuous parameters (e.g., rock and elastic properties). Generative adversarial networks (GANs) provide an efficient training-image-based simulation framework capable of reproducing complex geological models with high accuracy and comparably low generative cost. However, their application in stochastic geophysical inversion for multivariate property prediction is limited, as representing multiple coupled properties requires large and unstable network...",
      "pdf_url": "https://arxiv.org/pdf/2512.02863v1.pdf",
      "relevance_score": 40,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1912.11283v1",
      "title": "An Analisys of Application Logs with Splunk : developing an App for the synthetic analysis of data and security incidents",
      "authors": [
        "Roberto Bruzzese"
      ],
      "published": "2019-12-24T10:42:42Z",
      "categories": "",
      "summary": "The present work aims to enhance the application logs of an hypothetical infrastructure platform, and to build an App that displays the synthetic data about performance, anomalies and security incidents synthesized in the form of a Dashboard. The reference architecture, with multiple applications and multiple HW distribution, implementing a Service Oriented Architecture, is a real case of which the details have been abstracted because we want to extend the concept to all architectures with similar characteristics.",
      "pdf_url": "https://arxiv.org/pdf/1912.11283v1.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2212.08445v1",
      "title": "Conditional Generative Adversarial Network for keystroke presentation attack",
      "authors": [
        "Idoia Eizaguirre-Peral",
        "Lander Segurola-Gil",
        "Francesco Zola"
      ],
      "published": "2022-12-16T12:45:16Z",
      "categories": "",
      "summary": "Cybersecurity is a crucial step in data protection to ensure user security and personal data privacy. In this sense, many companies have started to control and restrict access to their data using authentication systems. However, these traditional authentication methods, are not enough for ensuring data protection, and for this reason, behavioral biometrics have gained importance. Despite their promising results and the wide range of applications, biometric systems have shown to be vulnerable to malicious attacks, such as Presentation Attacks. For this reason, in this work, we propose to study ...",
      "pdf_url": "https://arxiv.org/pdf/2212.08445v1.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1912.00314v2",
      "title": "ACE -- An Anomaly Contribution Explainer for Cyber-Security Applications",
      "authors": [
        "Xiao Zhang",
        "Manish Marwah",
        "I-ta Lee",
        "Martin Arlitt",
        "Dan Goldwasser"
      ],
      "published": "2019-12-01T04:16:12Z",
      "categories": "",
      "summary": "In this paper, we introduce Anomaly Contribution Explainer or ACE, a tool to explain security anomaly detection models in terms of the model features through a regression framework, and its variant, ACE-KL, which highlights the important anomaly contributors. ACE and ACE-KL provide insights in diagnosing which attributes significantly contribute to an anomaly by building a specialized linear model to locally approximate the anomaly score that a black-box model generates. We conducted experiments with these anomaly detection models to detect security anomalies on both synthetic data and real da...",
      "pdf_url": "https://arxiv.org/pdf/1912.00314v2.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2303.01230v3",
      "title": "Synthetic Data: Methods, Use Cases, and Risks",
      "authors": [
        "Emiliano De Cristofaro"
      ],
      "published": "2023-03-01T16:35:33Z",
      "categories": "",
      "summary": "Sharing data can often enable compelling applications and analytics. However, more often than not, valuable datasets contain information of a sensitive nature, and thus, sharing them can endanger the privacy of users and organizations. A possible alternative gaining momentum in both the research community and industry is to share synthetic data instead. The idea is to release artificially generated datasets that resemble the actual data -- more precisely, having similar statistical properties. In this article, we provide a gentle introduction to synthetic data and discuss its use cases, the pr...",
      "pdf_url": "https://arxiv.org/pdf/2303.01230v3.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.16638v1",
      "title": "AI-Generated Video Detection via Spatio-Temporal Anomaly Learning",
      "authors": [
        "Jianfa Bai",
        "Man Lin",
        "Gang Cao"
      ],
      "published": "2024-03-25T11:26:18Z",
      "categories": "",
      "summary": "The advancement of generation models has led to the emergence of highly realistic artificial intelligence (AI)-generated videos. Malicious users can easily create non-existent videos to spread false information. This letter proposes an effective AI-generated video detection (AIGVDet) scheme by capturing the forensic traces with a two-branch spatio-temporal convolutional neural network (CNN). Specifically, two ResNet sub-detectors are learned separately for identifying the anomalies in spatical and optical flow domains, respectively. Results of such sub-detectors are fused to further enhance th...",
      "pdf_url": "https://arxiv.org/pdf/2403.16638v1.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2405.07822v2",
      "title": "Synthetic Tabular Data Validation: A Divergence-Based Approach",
      "authors": [
        "Patricia A. Apell\u00e1niz",
        "Ana Jim\u00e9nez",
        "Borja Arroyo Galende",
        "Juan Parras",
        "Santiago Zazo"
      ],
      "published": "2024-05-13T15:07:52Z",
      "categories": "",
      "summary": "The ever-increasing use of generative models in various fields where tabular data is used highlights the need for robust and standardized validation metrics to assess the similarity between real and synthetic data. Current methods lack a unified framework and rely on diverse and often inconclusive statistical measures. Divergences, which quantify discrepancies between data distributions, offer a promising avenue for validation. However, traditional approaches calculate divergences independently for each feature due to the complexity of joint distribution modeling. This paper addresses this cha...",
      "pdf_url": "https://arxiv.org/pdf/2405.07822v2.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.12827v3",
      "title": "Practical Equivalence Testing and Its Application in Synthetic Pre-Crash Scenario Validation",
      "authors": [
        "Jian Wu",
        "Ulrich Sander",
        "Carol Flannagan",
        "Minxiang Zhao",
        "Jonas B\u00e4rgman"
      ],
      "published": "2025-05-19T08:12:35Z",
      "categories": "",
      "summary": "The use of representative pre-crash scenarios is critical for assessing the safety impact of driving automation systems through simulation. However, a gap remains in the robust evaluation of the similarity between synthetic and real-world pre-crash scenarios and their crash characteristics. Without proper validation, it cannot be ensured that the synthetic test scenarios adequately represent real-world driving behaviors and crash characteristics. One reason for this validation gap is the lack of focus on methods to confirm that the synthetic test scenarios are practically equivalent to real-wo...",
      "pdf_url": "https://arxiv.org/pdf/2505.12827v3.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2201.00672v1",
      "title": "Compression-Resistant Backdoor Attack against Deep Neural Networks",
      "authors": [
        "Mingfu Xue",
        "Xin Wang",
        "Shichang Sun",
        "Yushu Zhang",
        "Jian Wang",
        "Weiqiang Liu"
      ],
      "published": "2022-01-03T14:23:58Z",
      "categories": "",
      "summary": "In recent years, many backdoor attacks based on training data poisoning have been proposed. However, in practice, those backdoor attacks are vulnerable to image compressions. When backdoor instances are compressed, the feature of specific backdoor trigger will be destroyed, which could result in the backdoor attack performance deteriorating. In this paper, we propose a compression-resistant backdoor attack based on feature consistency training. To the best of our knowledge, this is the first backdoor attack that is robust to image compressions. First, both backdoor images and their compressed ...",
      "pdf_url": "https://arxiv.org/pdf/2201.00672v1.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2210.09539v1",
      "title": "Hierarchical Model-Based Imitation Learning for Planning in Autonomous Driving",
      "authors": [
        "Eli Bronstein",
        "Mark Palatucci",
        "Dominik Notz",
        "Brandyn White",
        "Alex Kuefler",
        "Yiren Lu",
        "Supratik Paul",
        "Payam Nikdel",
        "Paul Mougin",
        "Hongge Chen",
        "Justin Fu",
        "Austin Abrams",
        "Punit Shah",
        "Evan Racah",
        "Benjamin Frenkel",
        "Shimon Whiteson",
        "Dragomir Anguelov"
      ],
      "published": "2022-10-18T02:15:34Z",
      "categories": "",
      "summary": "We demonstrate the first large-scale application of model-based generative adversarial imitation learning (MGAIL) to the task of dense urban self-driving. We augment standard MGAIL using a hierarchical model to enable generalization to arbitrary goal routes, and measure performance using a closed-loop evaluation framework with simulated interactive agents. We train policies from expert trajectories collected from real vehicles driving over 100,000 miles in San Francisco, and demonstrate a steerable policy that can navigate robustly even in a zero-shot setting, generalizing to synthetic scenari...",
      "pdf_url": "https://arxiv.org/pdf/2210.09539v1.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2302.00531v2",
      "title": "Quantifying errors in 3D CME parameters derived from synthetic data using white-light reconstruction techniques",
      "authors": [
        "Christine Verbeke",
        "M. Leila Mays",
        "Christina Kay",
        "Pete Riley",
        "Erika Palmerio",
        "Mateja Dumbovi\u0107",
        "Marilena Mierla",
        "Camilla Scolini",
        "Manuela Temmer",
        "Evangelos Paouris",
        "Laura A. Balmaceda",
        "Hebe Cremades",
        "J\u00fcrgen Hinterreiter"
      ],
      "published": "2023-02-01T15:58:20Z",
      "categories": "",
      "summary": "(Shortened version) Current efforts in space weather forecasting of CMEs have been focused on predicting their arrival time and magnetic structure. To make predictions, methods have been developed to derive the true CME speed, size and position, among others. Difficulties in determining input parameters for CME forecasting arise from the lack of direct measurements of the coronal magnetic fields and uncertainties in estimating the CME 3D geometric and kinematic parameters. White-light coronagraph images are usually employed by a variety of CME reconstruction techniques. We explore how subjecti...",
      "pdf_url": "https://arxiv.org/pdf/2302.00531v2.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2006.04201v1",
      "title": "Learning Behaviors with Uncertain Human Feedback",
      "authors": [
        "Xu He",
        "Haipeng Chen",
        "Bo An"
      ],
      "published": "2020-06-07T16:51:48Z",
      "categories": "",
      "summary": "Human feedback is widely used to train agents in many domains. However, previous works rarely consider the uncertainty when humans provide feedback, especially in cases that the optimal actions are not obvious to the trainers. For example, the reward of a sub-optimal action can be stochastic and sometimes exceeds that of the optimal action, which is common in games or real-world. Trainers are likely to provide positive feedback to sub-optimal actions, negative feedback to the optimal actions and even do not provide feedback in some confusing situations. Existing works, which utilize the Expect...",
      "pdf_url": "https://arxiv.org/pdf/2006.04201v1.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.18863v2",
      "title": "PlanNetX: Learning an Efficient Neural Network Planner from MPC for Longitudinal Control",
      "authors": [
        "Jasper Hoffmann",
        "Diego Fernandez",
        "Julien Brosseit",
        "Julian Bernhard",
        "Klemens Esterle",
        "Moritz Werling",
        "Michael Karg",
        "Joschka Boedecker"
      ],
      "published": "2024-04-29T16:52:07Z",
      "categories": "",
      "summary": "Model predictive control (MPC) is a powerful, optimization-based approach for controlling dynamical systems. However, the computational complexity of online optimization can be problematic on embedded devices. Especially, when we need to guarantee fixed control frequencies. Thus, previous work proposed to reduce the computational burden using imitation learning (IL) approximating the MPC policy by a neural network. In this work, we instead learn the whole planned trajectory of the MPC. We introduce a combination of a novel neural network architecture PlanNetX and a simple loss function based o...",
      "pdf_url": "https://arxiv.org/pdf/2404.18863v2.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2312.14532v1",
      "title": "DuaLight: Enhancing Traffic Signal Control by Leveraging Scenario-Specific and Scenario-Shared Knowledge",
      "authors": [
        "Jiaming Lu",
        "Jingqing Ruan",
        "Haoyuan Jiang",
        "Ziyue Li",
        "Hangyu Mao",
        "Rui Zhao"
      ],
      "published": "2023-12-22T08:57:43Z",
      "categories": "",
      "summary": "Reinforcement learning has been revolutionizing the traditional traffic signal control task, showing promising power to relieve congestion and improve efficiency. However, the existing methods lack effective learning mechanisms capable of absorbing dynamic information inherent to a specific scenario and universally applicable dynamic information across various scenarios. Moreover, within each specific scenario, they fail to fully capture the essential empirical experiences about how to coordinate between neighboring and target intersections, leading to sub-optimal system-wide outcomes.   Viewi...",
      "pdf_url": "https://arxiv.org/pdf/2312.14532v1.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "cond-mat/9911421v2",
      "title": "Artifactual log-periodicity in finite size data: Relevance for earthquake aftershocks",
      "authors": [
        "Y. Huang",
        "A. Johansen",
        "M. W. Lee",
        "H. Saleur",
        "D. Sornette"
      ],
      "published": "1999-11-25T23:47:36Z",
      "categories": "",
      "summary": "The recently proposed discrete scale invariance and its associated log-periodicity are an elaboration of the concept of scale invariance in which the system is scale invariant only under powers of specific values of the magnification factor. We report on the discovery of a novel mechanism for such log-periodicity relying solely on the manipulation of data. This ``synthetic'' scenario for log-periodicity relies on two steps: (1) the fact that approximately logarithmic sampling in time corresponds to uniform sampling in the logarithm of time; and (2) a low-pass-filtering step, as occurs in const...",
      "pdf_url": "https://arxiv.org/pdf/cond-mat/9911421v2.pdf",
      "relevance_score": 39,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2310.19902v2",
      "title": "Herd: Using multiple, smaller LLMs to match the performances of proprietary, large LLMs via an intelligent composer",
      "authors": [
        "Surya Narayanan Hari",
        "Rex Liu",
        "Matt Thomson"
      ],
      "published": "2023-10-30T18:11:02Z",
      "categories": "",
      "summary": "Currently, over a thousand LLMs exist that are multi-purpose and are capable of performing real world tasks, including Q&A, text summarization, content generation, etc. However, accessibility, scale and reliability of free models prevents them from being widely deployed in everyday use cases. To address the first two issues of access and scale, organisations such as HuggingFace have created model repositories where users have uploaded model weights and quantized versions of models trained using different paradigms, as well as model cards describing their training process. While some models rep...",
      "pdf_url": "https://arxiv.org/pdf/2310.19902v2.pdf",
      "relevance_score": 38,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2309.06135v2",
      "title": "Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts",
      "authors": [
        "Zhi-Yi Chin",
        "Chieh-Ming Jiang",
        "Ching-Chun Huang",
        "Pin-Yu Chen",
        "Wei-Chen Chiu"
      ],
      "published": "2023-09-12T11:19:36Z",
      "categories": "",
      "summary": "Text-to-image diffusion models, e.g. Stable Diffusion (SD), lately have shown remarkable ability in high-quality content generation, and become one of the representatives for the recent wave of transformative AI. Nevertheless, such advance comes with an intensifying concern about the misuse of this generative technology, especially for producing copyrighted or NSFW (i.e. not safe for work) images. Although efforts have been made to filter inappropriate images/prompts or remove undesirable concepts/styles via model fine-tuning, the reliability of these safety mechanisms against diversified prob...",
      "pdf_url": "https://arxiv.org/pdf/2309.06135v2.pdf",
      "relevance_score": 38,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2310.06278v1",
      "title": "BC4LLM: Trusted Artificial Intelligence When Blockchain Meets Large Language Models",
      "authors": [
        "Haoxiang Luo",
        "Jian Luo",
        "Athanasios V. Vasilakos"
      ],
      "published": "2023-10-10T03:18:26Z",
      "categories": "",
      "summary": "In recent years, artificial intelligence (AI) and machine learning (ML) are reshaping society's production methods and productivity, and also changing the paradigm of scientific research. Among them, the AI language model represented by ChatGPT has made great progress. Such large language models (LLMs) serve people in the form of AI-generated content (AIGC) and are widely used in consulting, healthcare, and education. However, it is difficult to guarantee the authenticity and reliability of AIGC learning data. In addition, there are also hidden dangers of privacy disclosure in distributed AI t...",
      "pdf_url": "https://arxiv.org/pdf/2310.06278v1.pdf",
      "relevance_score": 38,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2304.05090v1",
      "title": "CrowdSim2: an Open Synthetic Benchmark for Object Detectors",
      "authors": [
        "Pawe\u0142 Foszner",
        "Agnieszka Szcz\u0119sna",
        "Luca Ciampi",
        "Nicola Messina",
        "Adam Cygan",
        "Bartosz Bizo\u0144",
        "Micha\u0142 Cogiel",
        "Dominik Golba",
        "El\u017cbieta Macioszek",
        "Micha\u0142 Staniszewski"
      ],
      "published": "2023-04-11T09:35:57Z",
      "categories": "",
      "summary": "Data scarcity has become one of the main obstacles to developing supervised models based on Artificial Intelligence in Computer Vision. Indeed, Deep Learning-based models systematically struggle when applied in new scenarios never seen during training and may not be adequately tested in non-ordinary yet crucial real-world situations. This paper presents and publicly releases CrowdSim2, a new synthetic collection of images suitable for people and vehicle detection gathered from a simulator based on the Unity graphical engine. It consists of thousands of images gathered from various synthetic sc...",
      "pdf_url": "https://arxiv.org/pdf/2304.05090v1.pdf",
      "relevance_score": 38,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.07456v1",
      "title": "ExpertAgent: Enhancing Personalized Education through Dynamic Planning and Retrieval-Augmented Long-Chain Reasoning",
      "authors": [
        "Binrong Zhu",
        "Guiran Liu",
        "Nina Jiang"
      ],
      "published": "2025-10-08T19:03:34Z",
      "categories": "",
      "summary": "The application of advanced generative artificial intelligence in education is often constrained by the lack of real-time adaptability, personalization, and reliability of the content. To address these challenges, we propose ExpertAgent - an intelligent agent framework designed for personalized education that provides reliable knowledge and enables highly adaptive learning experiences. Therefore, we developed ExpertAgent, an innovative learning agent that provides users with a proactive and personalized learning experience. ExpertAgent dynamic planning of the learning content and strategy base...",
      "pdf_url": "https://arxiv.org/pdf/2510.07456v1.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.13124v2",
      "title": "Learning to Generate Answers with Citations via Factual Consistency Models",
      "authors": [
        "Rami Aly",
        "Zhiqiang Tang",
        "Samson Tan",
        "George Karypis"
      ],
      "published": "2024-06-19T00:40:19Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) frequently hallucinate, impeding their reliability in mission-critical situations. One approach to address this issue is to provide citations to relevant sources alongside generated content, enhancing the verifiability of generations. However, citing passages accurately in answers remains a substantial challenge. This paper proposes a weakly-supervised fine-tuning method leveraging factual consistency models (FCMs). Our approach alternates between generating texts with citations and supervised fine-tuning with FCM-filtered citation data. Focused learning is integra...",
      "pdf_url": "https://arxiv.org/pdf/2406.13124v2.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.16584v1",
      "title": "Case Study: Fine-tuning Small Language Models for Accurate and Private CWE Detection in Python Code",
      "authors": [
        "Md. Azizul Hakim Bappy",
        "Hossen A Mustafa",
        "Prottoy Saha",
        "Rajinus Salehat"
      ],
      "published": "2025-04-23T10:05:27Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) have demonstrated significant capabilities in understanding and analyzing code for security vulnerabilities, such as Common Weakness Enumerations (CWEs). However, their reliance on cloud infrastructure and substantial computational requirements pose challenges for analyzing sensitive or proprietary codebases due to privacy concerns and inference costs. This work explores the potential of Small Language Models (SLMs) as a viable alternative for accurate, on-premise vulnerability detection. We investigated whether a 350-million parameter pre-trained code model (codeg...",
      "pdf_url": "https://arxiv.org/pdf/2504.16584v1.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.09635v1",
      "title": "A Method for Quantifying Human Risk and a Blueprint for LLM Integration",
      "authors": [
        "Giuseppe Canale"
      ],
      "published": "2025-09-29T20:31:27Z",
      "categories": "",
      "summary": "This paper presents the Cybersecurity Psychology Framework (CPF), a novel methodology for quantifying human-centric vulnerabilities in security operations through systematic integration of established psychological constructs with operational security telemetry. While individual human factors-alert fatigue, compliance fatigue, cognitive overload, and risk perception biases-have been extensively studied in isolation, no framework provides end-to-end operationalization across the full spectrum of psychological vulnerabilities. We address this gap by: (1) defining specific, measurable algorithms ...",
      "pdf_url": "https://arxiv.org/pdf/2510.09635v1.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.11423v2",
      "title": "Generated Data with Fake Privacy: Hidden Dangers of Fine-tuning Large Language Models on Generated Data",
      "authors": [
        "Atilla Akkus",
        "Masoud Poorghaffar Aghdam",
        "Mingjie Li",
        "Junjie Chu",
        "Michael Backes",
        "Yang Zhang",
        "Sinem Sav"
      ],
      "published": "2024-09-12T10:14:12Z",
      "categories": "",
      "summary": "Large language models (LLMs) have demonstrated significant success in various domain-specific tasks, with their performance often improving substantially after fine-tuning. However, fine-tuning with real-world data introduces privacy risks. To mitigate these risks, developers increasingly rely on synthetic data generation as an alternative to using real data, as data generated by traditional models is believed to be different from real-world data. However, with the advanced capabilities of LLMs, the distinction between real data and data generated by these models has become nearly indistinguis...",
      "pdf_url": "https://arxiv.org/pdf/2409.11423v2.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.19864v1",
      "title": "MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support",
      "authors": [
        "Valerie Lockhart",
        "Dan McCreary",
        "Troy A. Peterson"
      ],
      "published": "2025-11-25T03:14:39Z",
      "categories": "",
      "summary": "Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enabl...",
      "pdf_url": "https://arxiv.org/pdf/2511.19864v1.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.09364v2",
      "title": "Is Contrasting All You Need? Contrastive Learning for the Detection and Attribution of AI-generated Text",
      "authors": [
        "Lucio La Cava",
        "Davide Costa",
        "Andrea Tagarelli"
      ],
      "published": "2024-07-12T15:44:56Z",
      "categories": "",
      "summary": "The significant progress in the development of Large Language Models has contributed to blurring the distinction between human and AI-generated text. The increasing pervasiveness of AI-generated text and the difficulty in detecting it poses new challenges for our society. In this paper, we tackle the problem of detecting and attributing AI-generated text by proposing WhosAI, a triplet-network contrastive learning framework designed to predict whether a given input text has been generated by humans or AI and to unveil the authorship of the text. Unlike most existing approaches, our proposed fra...",
      "pdf_url": "https://arxiv.org/pdf/2407.09364v2.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1605.02797v3",
      "title": "The BSM-AI project: SUSY-AI - Generalizing LHC limits on Supersymmetry with Machine Learning",
      "authors": [
        "Sascha Caron",
        "Jong Soo Kim",
        "Krzysztof Rolbiecki",
        "Roberto Ruiz de Austri",
        "Bob Stienen"
      ],
      "published": "2016-05-09T22:11:47Z",
      "categories": "",
      "summary": "A key research question at the Large Hadron Collider (LHC) is the test of models of new physics. Testing if a particular parameter set of such a model is excluded by LHC data is a challenge: It requires the time consuming generation of scattering events, the simulation of the detector response, the event reconstruction, cross section calculations and analysis code to test against several hundred signal regions defined by the ATLAS and CMS experiment. In the BSM-AI project we attack this challenge with a new approach. Machine learning tools are thought to predict within a fraction of a millisec...",
      "pdf_url": "https://arxiv.org/pdf/1605.02797v3.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.04645v2",
      "title": "PAIGE: Examining Learning Outcomes and Experiences with Personalized AI-Generated Educational Podcasts",
      "authors": [
        "Tiffany D. Do",
        "Usama Bin Shafqat",
        "Elsie Ling",
        "Nikhil Sarda"
      ],
      "published": "2024-09-06T22:31:15Z",
      "categories": "",
      "summary": "Generative AI is revolutionizing content creation and has the potential to enable real-time, personalized educational experiences. We investigated the effectiveness of converting textbook chapters into AI-generated podcasts and explored the impact of personalizing these podcasts for individual learner profiles. We conducted a 3x3 user study with 180 college students in the United States, comparing traditional textbook reading with both generalized and personalized AI-generated podcasts across three textbook subjects. The personalized podcasts were tailored to students' majors, interests, and l...",
      "pdf_url": "https://arxiv.org/pdf/2409.04645v2.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.15690v1",
      "title": "EAGLE: A Domain Generalization Framework for AI-generated Text Detection",
      "authors": [
        "Amrita Bhattacharjee",
        "Raha Moraffah",
        "Joshua Garland",
        "Huan Liu"
      ],
      "published": "2024-03-23T02:44:20Z",
      "categories": "",
      "summary": "With the advancement in capabilities of Large Language Models (LLMs), one major step in the responsible and safe use of such LLMs is to be able to detect text generated by these models. While supervised AI-generated text detectors perform well on text generated by older LLMs, with the frequent release of new LLMs, building supervised detectors for identifying text from such new models would require new labeled training data, which is infeasible in practice. In this work, we tackle this problem and propose a domain generalization framework for the detection of AI-generated text from unseen targ...",
      "pdf_url": "https://arxiv.org/pdf/2403.15690v1.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1809.02383v2",
      "title": "Group-based Learning of Disentangled Representations with Generalizability for Novel Contents",
      "authors": [
        "Haruo Hosoya"
      ],
      "published": "2018-09-07T10:00:54Z",
      "categories": "",
      "summary": "Sensory data are often comprised of independent content and transformation factors. For example, face images may have shapes as content and poses as transformation. To infer separately these factors from given data, various ``disentangling'' models have been proposed. However, many of these are supervised or semi-supervised, either requiring attribute labels that are often unavailable or disallowing for generalization over new contents. In this study, we introduce a novel deep generative model, called group-based variational autoencoders. In this, we assume no explicit labels, but a weaker for...",
      "pdf_url": "https://arxiv.org/pdf/1809.02383v2.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.11522v2",
      "title": "FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks",
      "authors": [
        "Tobias Lorenz",
        "Marta Kwiatkowska",
        "Mario Fritz"
      ],
      "published": "2024-06-17T13:23:52Z",
      "categories": "",
      "summary": "Modern machine learning models are sensitive to the manipulation of both the training data (poisoning attacks) and inference data (adversarial examples). Recognizing this issue, the community has developed many empirical defenses against both attacks and, more recently, certification methods with provable guarantees against inference-time attacks. However, such guarantees are still largely lacking for training-time attacks. In this work, we present FullCert, the first end-to-end certifier with sound, deterministic bounds, which proves robustness against both training-time and inference-time at...",
      "pdf_url": "https://arxiv.org/pdf/2406.11522v2.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2101.11073v1",
      "title": "Property Inference From Poisoning",
      "authors": [
        "Melissa Chase",
        "Esha Ghosh",
        "Saeed Mahloujifar"
      ],
      "published": "2021-01-26T20:35:28Z",
      "categories": "",
      "summary": "Property inference attacks consider an adversary who has access to the trained model and tries to extract some global statistics of the training data. In this work, we study property inference in scenarios where the adversary can maliciously control part of the training data (poisoning data) with the goal of increasing the leakage.   Previous work on poisoning attacks focused on trying to decrease the accuracy of models either on the whole population or on specific sub-populations or instances. Here, for the first time, we study poisoning attacks where the goal of the adversary is to increase ...",
      "pdf_url": "https://arxiv.org/pdf/2101.11073v1.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.15549v3",
      "title": "Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs",
      "authors": [
        "Abhay Sheshadri",
        "Aidan Ewart",
        "Phillip Guo",
        "Aengus Lynch",
        "Cindy Wu",
        "Vivek Hebbar",
        "Henry Sleight",
        "Asa Cooper Stickland",
        "Ethan Perez",
        "Dylan Hadfield-Menell",
        "Stephen Casper"
      ],
      "published": "2024-07-22T11:19:14Z",
      "categories": "",
      "summary": "Large language models (LLMs) can often be made to behave in undesirable ways that they are explicitly fine-tuned not to. For example, the LLM red-teaming literature has produced a wide variety of 'jailbreaking' techniques to elicit harmful text from models that were fine-tuned to be harmless. Recent work on red-teaming, model editing, and interpretability suggests that this challenge stems from how (adversarial) fine-tuning largely serves to suppress rather than remove undesirable capabilities from LLMs. Prior work has introduced latent adversarial training (LAT) as a way to improve robustness...",
      "pdf_url": "https://arxiv.org/pdf/2407.15549v3.pdf",
      "relevance_score": 37,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.14654v1",
      "title": "ChatGPT in Veterinary Medicine: A Practical Guidance of Generative Artificial Intelligence in Clinics, Education, and Research",
      "authors": [
        "Candice P. Chu"
      ],
      "published": "2024-02-26T02:59:07Z",
      "categories": "",
      "summary": "ChatGPT, the most accessible generative artificial intelligence (AI) tool, offers considerable potential for veterinary medicine, yet a dedicated review of its specific applications is lacking. This review concisely synthesizes the latest research and practical applications of ChatGPT within the clinical, educational, and research domains of veterinary medicine. It intends to provide specific guidance and actionable examples of how generative AI can be directly utilized by veterinary professionals without a programming background. For practitioners, ChatGPT can extract patient data, generate p...",
      "pdf_url": "https://arxiv.org/pdf/2403.14654v1.pdf",
      "relevance_score": 36,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.12391v1",
      "title": "On the Content Bias in Fr\u00e9chet Video Distance",
      "authors": [
        "Songwei Ge",
        "Aniruddha Mahapatra",
        "Gaurav Parmar",
        "Jun-Yan Zhu",
        "Jia-Bin Huang"
      ],
      "published": "2024-04-18T17:59:58Z",
      "categories": "",
      "summary": "Fr\u00e9chet Video Distance (FVD), a prominent metric for evaluating video generation models, is known to conflict with human perception occasionally. In this paper, we aim to explore the extent of FVD's bias toward per-frame quality over temporal realism and identify its sources. We first quantify the FVD's sensitivity to the temporal axis by decoupling the frame and motion quality and find that the FVD increases only slightly with large temporal corruption. We then analyze the generated videos and show that via careful sampling from a large set of generated videos that do not contain motions, one...",
      "pdf_url": "https://arxiv.org/pdf/2404.12391v1.pdf",
      "relevance_score": 36,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.11543v1",
      "title": "A Review of Generative AI in Computer Science Education: Challenges and Opportunities in Accuracy, Authenticity, and Assessment",
      "authors": [
        "Iman Reihanian",
        "Yunfei Hou",
        "Yu Chen",
        "Yifei Zheng"
      ],
      "published": "2025-06-17T19:20:58Z",
      "categories": "",
      "summary": "This paper surveys the use of Generative AI tools, such as ChatGPT and Claude, in computer science education, focusing on key aspects of accuracy, authenticity, and assessment. Through a literature review, we highlight both the challenges and opportunities these AI tools present. While Generative AI improves efficiency and supports creative student work, it raises concerns such as AI hallucinations, error propagation, bias, and blurred lines between AI-assisted and student-authored content. Human oversight is crucial for addressing these concerns. Existing literature recommends adopting hybrid...",
      "pdf_url": "https://arxiv.org/pdf/2507.11543v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2103.10369v1",
      "title": "Combining Pessimism with Optimism for Robust and Efficient Model-Based Deep Reinforcement Learning",
      "authors": [
        "Sebastian Curi",
        "Ilija Bogunovic",
        "Andreas Krause"
      ],
      "published": "2021-03-18T16:50:17Z",
      "categories": "",
      "summary": "In real-world tasks, reinforcement learning (RL) agents frequently encounter situations that are not present during training time. To ensure reliable performance, the RL agents need to exhibit robustness against worst-case situations. The robust RL framework addresses this challenge via a worst-case optimization between an agent and an adversary. Previous robust RL algorithms are either sample inefficient, lack robustness guarantees, or do not scale to large problems. We propose the Robust Hallucinated Upper-Confidence RL (RH-UCRL) algorithm to provably solve this problem while attaining near-...",
      "pdf_url": "https://arxiv.org/pdf/2103.10369v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.06686v1",
      "title": "Atlas-X Equity Financing: Unlocking New Methods to Securely Obfuscate Axe Inventory Data Based on Differential Privacy",
      "authors": [
        "Antigoni Polychroniadou",
        "Gabriele Cipriani",
        "Richard Hua",
        "Tucker Balch"
      ],
      "published": "2024-04-10T02:19:37Z",
      "categories": "",
      "summary": "Banks publish daily a list of available securities/assets (axe list) to selected clients to help them effectively locate Long (buy) or Short (sell) trades at reduced financing rates. This reduces costs for the bank, as the list aggregates the bank's internal firm inventory per asset for all clients of long as well as short trades. However, this is somewhat problematic: (1) the bank's inventory is revealed; (2) trades of clients who contribute to the aggregated list, particularly those deemed large, are revealed to other clients. Clients conducting sizable trades with the bank and possessing a ...",
      "pdf_url": "https://arxiv.org/pdf/2404.06686v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.20964v1",
      "title": "DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning",
      "authors": [
        "Xun Guo",
        "Shan Zhang",
        "Yongxin He",
        "Ting Zhang",
        "Wanquan Feng",
        "Haibin Huang",
        "Chongyang Ma"
      ],
      "published": "2024-10-28T12:34:49Z",
      "categories": "",
      "summary": "Current techniques for detecting AI-generated text are largely confined to manual feature crafting and supervised binary classification paradigms. These methodologies typically lead to performance bottlenecks and unsatisfactory generalizability. Consequently, these methods are often inapplicable for out-of-distribution (OOD) data and newly emerged large language models (LLMs). In this paper, we revisit the task of AI-generated text detection. We argue that the key to accomplishing this task lies in distinguishing writing styles of different authors, rather than simply classifying the text into...",
      "pdf_url": "https://arxiv.org/pdf/2410.20964v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.21693v1",
      "title": "MultiAIGCD: A Comprehensive dataset for AI Generated Code Detection Covering Multiple Languages, Models,Prompts, and Scenarios",
      "authors": [
        "Basak Demirok",
        "Mucahid Kutlu",
        "Selin Mergen"
      ],
      "published": "2025-07-29T11:16:55Z",
      "categories": "",
      "summary": "As large language models (LLMs) rapidly advance, their role in code generation has expanded significantly. While this offers streamlined development, it also creates concerns in areas like education and job interviews. Consequently, developing robust systems to detect AI-generated code is imperative to maintain academic integrity and ensure fairness in hiring processes. In this study, we introduce MultiAIGCD, a dataset for AI-generated code detection for Python, Java, and Go. From the CodeNet dataset's problem definitions and human-authored codes, we generate several code samples in Java, Pyth...",
      "pdf_url": "https://arxiv.org/pdf/2507.21693v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.14271v2",
      "title": "FAID: Fine-Grained AI-Generated Text Detection Using Multi-Task Auxiliary and Multi-Level Contrastive Learning",
      "authors": [
        "Minh Ngoc Ta",
        "Dong Cao Van",
        "Duc-Anh Hoang",
        "Minh Le-Anh",
        "Truong Nguyen",
        "My Anh Tran Nguyen",
        "Yuxia Wang",
        "Preslav Nakov",
        "Sang Dinh"
      ],
      "published": "2025-05-20T12:23:31Z",
      "categories": "",
      "summary": "The growing collaboration between humans and AI models in generative tasks has introduced new challenges in distinguishing between human-written, LLM-generated, and human--LLM collaborative texts. In this work, we collect a multilingual, multi-domain, multi-generator dataset FAIDSet. We further introduce a fine-grained detection framework FAID to classify text into these three categories, and also to identify the underlying LLM family of the generator. Unlike existing binary classifiers, FAID is built to capture both authorship and model-specific characteristics. Our method combines multi-leve...",
      "pdf_url": "https://arxiv.org/pdf/2505.14271v2.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1708.00541v1",
      "title": "Application of Time Transfer Functions to Gaia's global astrometry - Validation on DPAC simulated Gaia-like observations",
      "authors": [
        "Stefano Bertone",
        "Alberto Vecchiato",
        "Beatrice Bucciarelli",
        "Mariateresa Crosta",
        "Mario G. Lattanzi",
        "Luca Bianchi",
        "Marie-Christine Angonin",
        "Christophe Le Poncin-Lafitte"
      ],
      "published": "2017-08-01T22:43:05Z",
      "categories": "",
      "summary": "A key objective of the ESA Gaia satellite is the realization of a quasi-inertial reference frame at visual wavelengths by means of global astrometric techniques. This requires an accurate mathematical and numerical modeling of relativistic light propagation, as well as double-blind-like procedures for the internal validation of the results, before they are released to the scientific community at large. Aim of this work is to specialize the Time Transfer Functions (TTF) formalism to the case of the Gaia observer and prove its applicability to the task of Global Sphere Reconstruction (GSR), in a...",
      "pdf_url": "https://arxiv.org/pdf/1708.00541v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.20621v1",
      "title": "Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning",
      "authors": [
        "Shijie Liu",
        "Andrew C. Cullen",
        "Paul Montague",
        "Sarah Erfani",
        "Benjamin I. P. Rubinstein"
      ],
      "published": "2025-05-27T01:59:25Z",
      "categories": "",
      "summary": "Similar to other machine learning frameworks, Offline Reinforcement Learning (RL) is shown to be vulnerable to poisoning attacks, due to its reliance on externally sourced datasets, a vulnerability that is exacerbated by its sequential nature. To mitigate the risks posed by RL poisoning, we extend certified defenses to provide larger guarantees against adversarial manipulation, ensuring robustness for both per-state actions, and the overall expected cumulative reward. Our approach leverages properties of Differential Privacy, in a manner that allows this work to span both continuous and discre...",
      "pdf_url": "https://arxiv.org/pdf/2505.20621v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.05200v4",
      "title": "KIF: Knowledge Identification and Fusion for Language Model Continual Learning",
      "authors": [
        "Yujie Feng",
        "Xu Chu",
        "Yongxin Xu",
        "Zexin Lu",
        "Bo Liu",
        "Philip S. Yu",
        "Xiao-Ming Wu"
      ],
      "published": "2024-08-09T17:44:45Z",
      "categories": "",
      "summary": "Language model continual learning (CL) has recently attracted significant interest for its ability to adapt large language models (LLMs) to dynamic real-world scenarios without retraining. A major challenge in this domain is catastrophic forgetting, where models lose previously acquired knowledge upon learning new tasks. Existing approaches commonly utilize multiple parameter-efficient fine-tuning (PEFT) blocks to acquire task-specific knowledge, yet these methods are inefficient and fail to leverage potential knowledge transfer across tasks. In this paper, we introduce a novel CL framework fo...",
      "pdf_url": "https://arxiv.org/pdf/2408.05200v4.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.14215v2",
      "title": "Information Retrieval Induced Safety Degradation in AI Agents",
      "authors": [
        "Cheng Yu",
        "Benedikt Stroebl",
        "Diyi Yang",
        "Orestis Papakyriakopoulos"
      ],
      "published": "2025-05-20T11:21:40Z",
      "categories": "",
      "summary": "Despite the growing integration of retrieval-enabled AI agents into society, their safety and ethical behavior remain inadequately understood. In particular, the integration of LLMs and AI agents with external information sources and real-world environments raises critical questions about how they engage with and are influenced by these external data sources and interactive contexts. This study investigates how expanding retrieval access -- from no external sources to Wikipedia-based retrieval and open web search -- affects model reliability, bias propagation, and harmful content generation. T...",
      "pdf_url": "https://arxiv.org/pdf/2505.14215v2.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.09694v1",
      "title": "Kelp: A Streaming Safeguard for Large Models via Latent Dynamics-Guided Risk Detection",
      "authors": [
        "Xiaodan Li",
        "Mengjie Wu",
        "Yao Zhu",
        "Yunna Lv",
        "YueFeng Chen",
        "Cen Chen",
        "Jianmei Guo",
        "Hui Xue"
      ],
      "published": "2025-10-09T14:42:50Z",
      "categories": "",
      "summary": "Large models (LMs) are powerful content generators, yet their open-ended nature can also introduce potential risks, such as generating harmful or biased content. Existing guardrails mostly perform post-hoc detection that may expose unsafe content before it is caught, and the latency constraints further push them toward lightweight models, limiting detection accuracy. In this work, we propose Kelp, a novel plug-in framework that enables streaming risk detection within the LM generation pipeline. Kelp leverages intermediate LM hidden states through a Streaming Latent Dynamics Head (SLD), which m...",
      "pdf_url": "https://arxiv.org/pdf/2510.09694v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.03728v1",
      "title": "Evaluating Durability: Benchmark Insights into Multimodal Watermarking",
      "authors": [
        "Jielin Qiu",
        "William Han",
        "Xuandong Zhao",
        "Shangbang Long",
        "Christos Faloutsos",
        "Lei Li"
      ],
      "published": "2024-06-06T03:57:08Z",
      "categories": "",
      "summary": "With the development of large models, watermarks are increasingly employed to assert copyright, verify authenticity, or monitor content distribution. As applications become more multimodal, the utility of watermarking techniques becomes even more critical. The effectiveness and reliability of these watermarks largely depend on their robustness to various disturbances. However, the robustness of these watermarks in real-world scenarios, particularly under perturbations and corruption, is not well understood. To highlight the significance of robustness in watermarking techniques, our study evalu...",
      "pdf_url": "https://arxiv.org/pdf/2406.03728v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.13101v1",
      "title": "Who Wrote This? Identifying Machine vs Human-Generated Text in Hausa",
      "authors": [
        "Babangida Sani",
        "Aakansha Soy",
        "Sukairaj Hafiz Imam",
        "Ahmad Mustapha",
        "Lukman Jibril Aliyu",
        "Idris Abdulmumin",
        "Ibrahim Said Ahmad",
        "Shamsuddeen Hassan Muhammad"
      ],
      "published": "2025-03-17T12:13:37Z",
      "categories": "",
      "summary": "The advancement of large language models (LLMs) has allowed them to be proficient in various tasks, including content generation. However, their unregulated usage can lead to malicious activities such as plagiarism and generating and spreading fake news, especially for low-resource languages. Most existing machine-generated text detectors are trained on high-resource languages like English, French, etc. In this study, we developed the first large-scale detector that can distinguish between human- and machine-generated content in Hausa. We scrapped seven Hausa-language media outlets for the hum...",
      "pdf_url": "https://arxiv.org/pdf/2503.13101v1.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.24085v2",
      "title": "PEARL: Peer-Enhanced Adaptive Radio via On-Device LLM",
      "authors": [
        "Ju-Hyung Lee",
        "Yanqing Lu",
        "Klaus Doppler"
      ],
      "published": "2025-09-28T21:43:17Z",
      "categories": "",
      "summary": "We present PEARL (Peer-Enhanced Adaptive Radio via On-Device LLM), a framework for cooperative cross-layer optimization in device-to-device (D2D) communication. Building on our previous work on single-device on-device LLMs, PEARL extends the paradigm by leveraging both publisher and subscriber states to guide Wi-Fi Aware (WA) parameter selection. A context-aware reward, which normalizes latency by application tolerances and modulates energy by device battery states, provides richer supervision for KL-based finetuning. We study two lightweight variants: PEARL (Head + Low-Rank Adaptation (LoRA))...",
      "pdf_url": "https://arxiv.org/pdf/2509.24085v2.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.06380v2",
      "title": "Protecting Bystander Privacy via Selective Hearing in Audio LLMs",
      "authors": [
        "Xiao Zhan",
        "Guangzhi Sun",
        "Jose Such",
        "Phil Woodland"
      ],
      "published": "2025-12-06T10:24:04Z",
      "categories": "",
      "summary": "Audio Large language models (LLMs) are increasingly deployed in the real world, where they inevitably capture speech from unintended nearby bystanders, raising privacy risks that existing benchmarks and defences did not consider. We introduce SH-Bench, the first benchmark designed to evaluate selective hearing: a model's ability to attend to an intended main speaker while refusing to process or reveal information about incidental bystander speech. SH-Bench contains 3,968 multi-speaker audio mixtures, including both real-world and synthetic scenarios, paired with 77k multiple-choice questions t...",
      "pdf_url": "https://arxiv.org/pdf/2512.06380v2.pdf",
      "relevance_score": 35,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.09172v1",
      "title": "Bridging the Gap Between Ideal and Real-world Evaluation: Benchmarking AI-Generated Image Detection in Challenging Scenarios",
      "authors": [
        "Chunxiao Li",
        "Xiaoxiao Wang",
        "Meiling Li",
        "Boming Miao",
        "Peng Sun",
        "Yunjian Zhang",
        "Xiangyang Ji",
        "Yao Zhu"
      ],
      "published": "2025-09-11T06:15:52Z",
      "categories": "",
      "summary": "With the rapid advancement of generative models, highly realistic image synthesis has posed new challenges to digital security and media credibility. Although AI-generated image detection methods have partially addressed these concerns, a substantial research gap remains in evaluating their performance under complex real-world conditions. This paper introduces the Real-World Robustness Dataset (RRDataset) for comprehensive evaluation of detection models across three dimensions: 1) Scenario Generalization: RRDataset encompasses high-quality images from seven major scenarios (War and Conflict, D...",
      "pdf_url": "https://arxiv.org/pdf/2509.09172v1.pdf",
      "relevance_score": 34,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2104.13437v1",
      "title": "Incident Detection on Junctions Using Image Processing",
      "authors": [
        "Murat Tulga\u00e7",
        "Enes Y\u00fcnc\u00fc",
        " Mohamad-Alhaddad",
        "Ceylan Yozgatl\u0131gil"
      ],
      "published": "2021-04-27T19:18:05Z",
      "categories": "",
      "summary": "In traffic management, it is a very important issue to shorten the response time by detecting the incidents (accident, vehicle breakdown, an object falling on the road, etc.) and informing the corresponding personnel. In this study, an anomaly detection framework for road junctions is proposed. The final judgment is based on the trajectories followed by the vehicles. Trajectory information is provided by vehicle detection and tracking algorithms on visual data streamed from a fisheye camera. Deep learning algorithms are used for vehicle detection, and Kalman Filter is used for tracking. To obs...",
      "pdf_url": "https://arxiv.org/pdf/2104.13437v1.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2310.07726v4",
      "title": "Warfare:Breaking the Watermark Protection of AI-Generated Content",
      "authors": [
        "Guanlin Li",
        "Yifei Chen",
        "Jie Zhang",
        "Shangwei Guo",
        "Han Qiu",
        "Guoyin Wang",
        "Jiwei Li",
        "Tianwei Zhang"
      ],
      "published": "2023-09-27T06:32:00Z",
      "categories": "",
      "summary": "AI-Generated Content (AIGC) is rapidly expanding, with services using advanced generative models to create realistic images and fluent text. Regulating such content is crucial to prevent policy violations, such as unauthorized commercialization or unsafe content distribution. Watermarking is a promising solution for content attribution and verification, but we demonstrate its vulnerability to two key attacks: (1) Watermark removal, where adversaries erase embedded marks to evade regulation, and (2) Watermark forging, where they generate illicit content with forged watermarks, leading to misatt...",
      "pdf_url": "https://arxiv.org/pdf/2310.07726v4.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2306.06135v1",
      "title": "Safety and Fairness for Content Moderation in Generative Models",
      "authors": [
        "Susan Hao",
        "Piyush Kumar",
        "Sarah Laszlo",
        "Shivani Poddar",
        "Bhaktipriya Radharapu",
        "Renee Shelby"
      ],
      "published": "2023-06-09T01:37:32Z",
      "categories": "",
      "summary": "With significant advances in generative AI, new technologies are rapidly being deployed with generative components. Generative models are typically trained on large datasets, resulting in model behaviors that can mimic the worst of the content in the training data. Responsible deployment of generative technologies requires content moderation strategies, such as safety input and output filters. Here, we provide a theoretical framework for conceptualizing responsible content moderation of text-to-image generative technologies, including a demonstration of how to empirically measure the construct...",
      "pdf_url": "https://arxiv.org/pdf/2306.06135v1.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.06763v3",
      "title": "Cross Validation in Stochastic Analytic Continuation",
      "authors": [
        "Gabe Schumm",
        "Sibin Yang",
        "Anders W. Sandvik"
      ],
      "published": "2024-06-10T19:48:22Z",
      "categories": "",
      "summary": "Stochastic Analytic Continuation (SAC) of Quantum Monte Carlo (QMC) imaginary-time correlation function data is a valuable tool in connecting many-body models to experimentally measurable dynamic response functions. Recent developments of the SAC method have allowed for spectral functions with sharp features, e.g. narrow peaks and divergent edges, to be resolved with unprecedented fidelity. Often times, it is not known what exact sharp features, if any, are present \\textit{a priori}, and, due to the ill-posed nature of the analytic continuation problem, multiple spectral representations may be...",
      "pdf_url": "https://arxiv.org/pdf/2406.06763v3.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.15443v1",
      "title": "SKETCH: Structured Knowledge Enhanced Text Comprehension for Holistic Retrieval",
      "authors": [
        "Aakash Mahalingam",
        "Vinesh Kumar Gande",
        "Aman Chadha",
        "Vinija Jain",
        "Divya Chaudhary"
      ],
      "published": "2024-12-19T22:51:56Z",
      "categories": "",
      "summary": "Retrieval-Augmented Generation (RAG) systems have become pivotal in leveraging vast corpora to generate informed and contextually relevant responses, notably reducing hallucinations in Large Language Models. Despite significant advancements, these systems struggle to efficiently process and retrieve information from large datasets while maintaining a comprehensive understanding of the context. This paper introduces SKETCH, a novel methodology that enhances the RAG retrieval process by integrating semantic text retrieval with knowledge graphs, thereby merging structured and unstructured data fo...",
      "pdf_url": "https://arxiv.org/pdf/2412.15443v1.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2301.04408v1",
      "title": "GPT as Knowledge Worker: A Zero-Shot Evaluation of (AI)CPA Capabilities",
      "authors": [
        "Jillian Bommarito",
        "Michael Bommarito",
        "Daniel Martin Katz",
        "Jessica Katz"
      ],
      "published": "2023-01-11T11:30:42Z",
      "categories": "",
      "summary": "The global economy is increasingly dependent on knowledge workers to meet the needs of public and private organizations. While there is no single definition of knowledge work, organizations and industry groups still attempt to measure individuals' capability to engage in it. The most comprehensive assessment of capability readiness for professional knowledge workers is the Uniform CPA Examination developed by the American Institute of Certified Public Accountants (AICPA). In this paper, we experimentally evaluate OpenAI's `text-davinci-003` and prior versions of GPT on both a sample Regulation...",
      "pdf_url": "https://arxiv.org/pdf/2301.04408v1.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2302.00179v1",
      "title": "Stable Attribute Group Editing for Reliable Few-shot Image Generation",
      "authors": [
        "Guanqi Ding",
        "Xinzhe Han",
        "Shuhui Wang",
        "Xin Jin",
        "Dandan Tu",
        "Qingming Huang"
      ],
      "published": "2023-02-01T01:51:47Z",
      "categories": "",
      "summary": "Few-shot image generation aims to generate data of an unseen category based on only a few samples. Apart from basic content generation, a bunch of downstream applications hopefully benefit from this task, such as low-data detection and few-shot classification. To achieve this goal, the generated images should guarantee category retention for classification beyond the visual quality and diversity. In our preliminary work, we present an ``editing-based'' framework Attribute Group Editing (AGE) for reliable few-shot image generation, which largely improves the generation performance. Nevertheless...",
      "pdf_url": "https://arxiv.org/pdf/2302.00179v1.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.13982v2",
      "title": "Safety Without Semantic Disruptions: Editing-free Safe Image Generation via Context-preserving Dual Latent Reconstruction",
      "authors": [
        "Jordan Vice",
        "Naveed Akhtar",
        "Mubarak Shah",
        "Richard Hartley",
        "Ajmal Mian"
      ],
      "published": "2024-11-21T09:47:13Z",
      "categories": "",
      "summary": "Training multimodal generative models on large, uncurated datasets can result in users being exposed to harmful, unsafe and controversial or culturally-inappropriate outputs. While model editing has been proposed to remove or filter undesirable concepts in embedding and latent spaces, it can inadvertently damage learned manifolds, distorting concepts in close semantic proximity. We identify limitations in current model editing techniques, showing that even benign, proximal concepts may become misaligned. To address the need for safe content generation, we leverage safe embeddings and a modifie...",
      "pdf_url": "https://arxiv.org/pdf/2411.13982v2.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.07377v2",
      "title": "COLoRIS: Localization-agnostic Smart Surfaces Enabling Opportunistic ISAC in 6G Networks",
      "authors": [
        "Guillermo Encinas-Lago",
        "Francesco Devoti",
        "Marco Rossanese",
        "Vincenzo Sciancalepore",
        "Marco Di Renzo",
        "Xavier Costa-P\u00e9rez"
      ],
      "published": "2024-06-11T15:45:00Z",
      "categories": "",
      "summary": "The integration of Smart Surfaces in 6G communication networks, also dubbed as Reconfigurable Intelligent Surfaces (RISs), is a promising paradigm change gaining significant attention given its disruptive features. RISs are a key enabler in the realm of 6G Integrated Sensing and Communication (ISAC) systems where novel services can be offered together with the future mobile networks communication capabilities. This paper addresses the critical challenge of precisely localizing users within a communication network by leveraging the controlled-reflective properties of RIS elements without relyin...",
      "pdf_url": "https://arxiv.org/pdf/2406.07377v2.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1902.10953v1",
      "title": "Extended Gaze Following: Detecting Objects in Videos Beyond the Camera Field of View",
      "authors": [
        "Benoit Mass\u00e9",
        "St\u00e9phane Lathuili\u00e8re",
        "Pablo Mesejo",
        "Radu Horaud"
      ],
      "published": "2019-02-28T08:59:59Z",
      "categories": "",
      "summary": "In this paper we address the problems of detecting objects of interest in a video and of estimating their locations, solely from the gaze directions of people present in the video. Objects can be indistinctly located inside or outside the camera field of view. We refer to this problem as extended gaze following. The contributions of the paper are the followings. First, we propose a novel spatial representation of the gaze directions adopting a top-view perspective. Second, we develop several convolutional encoder/decoder networks to predict object locations and compare them with heuristics and...",
      "pdf_url": "https://arxiv.org/pdf/1902.10953v1.pdf",
      "relevance_score": 33,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.16036v1",
      "title": "Topic Discovery and Classification for Responsible Generative AI Adaptation in Higher Education",
      "authors": [
        "Diane Myung-kyung Woodbridge",
        "Allyson Seba",
        "Freddie Seba",
        "Aydin Schwartz"
      ],
      "published": "2025-12-17T23:39:19Z",
      "categories": "",
      "summary": "As generative artificial intelligence (GenAI) becomes increasingly capable of delivering personalized learning experiences and real-time feedback, a growing number of students are incorporating these tools into their academic workflows. They use GenAI to clarify concepts, solve complex problems, and, in some cases, complete assignments by copying and pasting model-generated contents. While GenAI has the potential to enhance learning experience, it also raises concerns around misinformation, hallucinated outputs, and its potential to undermine critical thinking and problem-solving skills. In re...",
      "pdf_url": "https://arxiv.org/pdf/2512.16036v1.pdf",
      "relevance_score": 32,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2311.15565v3",
      "title": "Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing AI-Generated Text",
      "authors": [
        "Abiodun Finbarrs Oketunji"
      ],
      "published": "2023-11-27T06:26:53Z",
      "categories": "",
      "summary": "My research investigates the use of cutting-edge hybrid deep learning models to accurately differentiate between AI-generated text and human writing. I applied a robust methodology, utilising a carefully selected dataset comprising AI and human texts from various sources, each tagged with instructions. Advanced natural language processing techniques facilitated the analysis of textual features. Combining sophisticated neural networks, the custom model enabled it to detect nuanced differences between AI and human content.",
      "pdf_url": "https://arxiv.org/pdf/2311.15565v3.pdf",
      "relevance_score": 32,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2402.03339v1",
      "title": "Interplay of Semantic Communication and Knowledge Learning",
      "authors": [
        "Fei Ni",
        "Bingyan Wang",
        "Rongpeng Li",
        "Zhifeng Zhao",
        "Honggang Zhang"
      ],
      "published": "2024-01-18T06:11:06Z",
      "categories": "",
      "summary": "In the swiftly advancing realm of communication technologies, Semantic Communication (SemCom), which emphasizes knowledge understanding and processing, has emerged as a hot topic. By integrating artificial intelligence technologies, SemCom facilitates a profound understanding, analysis and transmission of communication content. In this chapter, we clarify the means of knowledge learning in SemCom with a particular focus on the utilization of Knowledge Graphs (KGs). Specifically, we first review existing efforts that combine SemCom with knowledge learning. Subsequently, we introduce a KG-enhanc...",
      "pdf_url": "https://arxiv.org/pdf/2402.03339v1.pdf",
      "relevance_score": 32,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.17196v1",
      "title": "Detecting LLM-Generated Short Answers and Effects on Learner Performance",
      "authors": [
        "Shambhavi Bhushan",
        "Danielle R Thomas",
        "Conrad Borchers",
        "Isha Raghuvanshi",
        "Ralph Abboud",
        "Erin Gatz",
        "Shivang Gupta",
        "Kenneth Koedinger"
      ],
      "published": "2025-06-20T17:47:36Z",
      "categories": "",
      "summary": "The increasing availability of large language models (LLMs) has raised concerns about their potential misuse in online learning. While tools for detecting LLM-generated text exist and are widely used by researchers and educators, their reliability varies. Few studies have compared the accuracy of detection methods, defined criteria to identify content generated by LLM, or evaluated the effect on learner performance from LLM misuse within learning. In this study, we define LLM-generated text within open responses as those produced by any LLM without paraphrasing or refinement, as evaluated by h...",
      "pdf_url": "https://arxiv.org/pdf/2506.17196v1.pdf",
      "relevance_score": 32,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.18218v1",
      "title": "Learning to Drive via Asymmetric Self-Play",
      "authors": [
        "Chris Zhang",
        "Sourav Biswas",
        "Kelvin Wong",
        "Kion Fallah",
        "Lunjun Zhang",
        "Dian Chen",
        "Sergio Casas",
        "Raquel Urtasun"
      ],
      "published": "2024-09-26T18:55:38Z",
      "categories": "",
      "summary": "Large-scale data is crucial for learning realistic and capable driving policies. However, it can be impractical to rely on scaling datasets with real data alone. The majority of driving data is uninteresting, and deliberately collecting new long-tail scenarios is expensive and unsafe. We propose asymmetric self-play to scale beyond real data with additional challenging, solvable, and realistic synthetic scenarios. Our approach pairs a teacher that learns to generate scenarios it can solve but the student cannot, with a student that learns to solve them. When applied to traffic simulation, we l...",
      "pdf_url": "https://arxiv.org/pdf/2409.18218v1.pdf",
      "relevance_score": 32,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.24108v1",
      "title": "ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring",
      "authors": [
        "Zhenxin Li",
        "Wenhao Yao",
        "Zi Wang",
        "Xinglong Sun",
        "Jingde Chen",
        "Nadine Chang",
        "Maying Shen",
        "Jingyu Song",
        "Zuxuan Wu",
        "Shiyi Lan",
        "Jose M. Alvarez"
      ],
      "published": "2025-10-28T06:26:36Z",
      "categories": "",
      "summary": "End-to-end autonomous driving maps raw sensor inputs directly into ego-vehicle trajectories to avoid cascading errors from perception modules and to leverage rich semantic cues. Existing frameworks largely rely on Imitation Learning (IL), which can be limited by sub-optimal expert demonstrations and covariate shift during deployment. On the other hand, Reinforcement Learning (RL) has recently shown potential in scaling up with simulations, but is typically confined to low-dimensional symbolic inputs (e.g. 3D objects and maps), falling short of full end-to-end learning from raw sensor data. We ...",
      "pdf_url": "https://arxiv.org/pdf/2510.24108v1.pdf",
      "relevance_score": 32,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.14030v1",
      "title": "Training-free Detection of AI-generated images via Cropping Robustness",
      "authors": [
        "Sungik Choi",
        "Hankook Lee",
        "Moontae Lee"
      ],
      "published": "2025-11-18T01:21:47Z",
      "categories": "",
      "summary": "AI-generated image detection has become crucial with the rapid advancement of vision-generative models. Instead of training detectors tailored to specific datasets, we study a training-free approach leveraging self-supervised models without requiring prior data knowledge. These models, pre-trained with augmentations like RandomResizedCrop, learn to produce consistent representations across varying resolutions. Motivated by this, we propose WaRPAD, a training-free AI-generated image detection algorithm based on self-supervised models. Since neighborhood pixel differences in images are highly se...",
      "pdf_url": "https://arxiv.org/pdf/2511.14030v1.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.15422v1",
      "title": "Can AI Generate more Comprehensive Test Scenarios? Review on Automated Driving Systems Test Scenario Generation Methods",
      "authors": [
        "Ji Zhou",
        "Yongqi Zhao",
        "Yixian Hu",
        "Hexuan Li",
        "Zhengguo Gu",
        "Nan Xu",
        "Arno Eichberger"
      ],
      "published": "2025-12-17T13:14:15Z",
      "categories": "",
      "summary": "Ensuring the safety and reliability of Automated Driving Systems (ADS) remains a critical challenge, as traditional verification methods such as large-scale on-road testing are prohibitively costly and time-consuming.To address this,scenario-based testing has emerged as a scalable and efficient alternative,yet existing surveys provide only partial coverage of recent methodological and technological advances.This review systematically analyzes 31 primary studies,and 10 surveys identified through a comprehensive search spanning 2015~2025;however,the in-depth methodological synthesis and comparat...",
      "pdf_url": "https://arxiv.org/pdf/2512.15422v1.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.19117v1",
      "title": "Understanding and Improving Training-Free AI-Generated Image Detections with Vision Foundation Models",
      "authors": [
        "Chung-Ting Tsai",
        "Ching-Yun Ko",
        "I-Hsin Chung",
        "Yu-Chiang Frank Wang",
        "Pin-Yu Chen"
      ],
      "published": "2024-11-28T13:04:45Z",
      "categories": "",
      "summary": "The rapid advancement of generative models has introduced serious risks, including deepfake techniques for facial synthesis and editing. Traditional approaches rely on training classifiers and enhancing generalizability through various feature extraction techniques. Meanwhile, training-free detection methods address issues like limited data and overfitting by directly leveraging statistical properties from vision foundation models to distinguish between real and fake images. The current leading training-free approach, RIGID, utilizes DINOv2 sensitivity to perturbations in image space for detec...",
      "pdf_url": "https://arxiv.org/pdf/2411.19117v1.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.10250v1",
      "title": "GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection",
      "authors": [
        "Haozhen Yan",
        "Yan Hong",
        "Suning Lang",
        "Jiahui Zhan",
        "Yikun Ji",
        "Yujie Gao",
        "Jun Lan",
        "Huijia Zhu",
        "Weiqiang Wang",
        "Jianfu Zhang"
      ],
      "published": "2025-09-12T13:46:54Z",
      "categories": "",
      "summary": "With generative models becoming increasingly sophisticated and diverse, detecting AI-generated images has become increasingly challenging. While existing AI-genereted Image detectors achieve promising performance on in-distribution generated images, their generalization to unseen generative models remains limited. This limitation is largely attributed to their reliance on generation-specific artifacts, such as stylistic priors and compression patterns. To address these limitations, we propose GAMMA, a novel training framework designed to reduce domain bias and enhance semantic alignment. GAMMA...",
      "pdf_url": "https://arxiv.org/pdf/2509.10250v1.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.06928v1",
      "title": "How Important are Videos for Training Video LLMs?",
      "authors": [
        "George Lydakis",
        "Alexander Hermans",
        "Ali Athar",
        "Daan de Geus",
        "Bastian Leibe"
      ],
      "published": "2025-06-07T21:32:19Z",
      "categories": "",
      "summary": "Research into Video Large Language Models (LLMs) has progressed rapidly, with numerous models and benchmarks emerging in just a few years. Typically, these models are initialized with a pretrained text-only LLM and finetuned on both image- and video-caption datasets. In this paper, we present findings indicating that Video LLMs are more capable of temporal reasoning after image-only training than one would assume, and that improvements from video-specific training are surprisingly small. Specifically, we show that image-trained versions of two LLMs trained with the recent LongVU algorithm perf...",
      "pdf_url": "https://arxiv.org/pdf/2506.06928v1.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.02370v2",
      "title": "How Training Data Shapes the Use of Parametric and In-Context Knowledge in Language Models",
      "authors": [
        "Minsung Kim",
        "Dong-Kyum Kim",
        "Jea Kwon",
        "Nakyeong Yang",
        "Kyomin Jung",
        "Meeyoung Cha"
      ],
      "published": "2025-09-29T06:18:18Z",
      "categories": "",
      "summary": "Large language models leverage not only parametric knowledge acquired during training but also in-context knowledge provided at inference time, despite the absence of explicit training objectives for using both sources. Prior work has further shown that when these knowledge sources conflict, models resolve the tension based on their internal confidence, preferring parametric knowledge for high-confidence facts while deferring to contextual information for less familiar ones. However, the training conditions that give rise to such knowledge utilization behaviors remain unclear. To address this ...",
      "pdf_url": "https://arxiv.org/pdf/2510.02370v2.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.14302v1",
      "title": "Scaling Law for Quantization-Aware Training",
      "authors": [
        "Mengzhao Chen",
        "Chaoyi Zhang",
        "Jing Liu",
        "Yutao Zeng",
        "Zeyue Xue",
        "Zhiheng Liu",
        "Yunshui Li",
        "Jin Ma",
        "Jie Huang",
        "Xun Zhou",
        "Ping Luo"
      ],
      "published": "2025-05-20T12:54:43Z",
      "categories": "",
      "summary": "Large language models (LLMs) demand substantial computational and memory resources, creating deployment challenges. Quantization-aware training (QAT) addresses these challenges by reducing model precision while maintaining performance. However, the scaling behavior of QAT, especially at 4-bit precision (W4A4), is not well understood. Existing QAT scaling laws often ignore key factors such as the number of training tokens and quantization granularity, which limits their applicability. This paper proposes a unified scaling law for QAT that models quantization error as a function of model size, t...",
      "pdf_url": "https://arxiv.org/pdf/2505.14302v1.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2512.21799v2",
      "title": "KG20C & KG20C-QA: Scholarly Knowledge Graph Benchmarks for Link Prediction and Question Answering",
      "authors": [
        "Hung-Nghiep Tran",
        "Atsuhiro Takasu"
      ],
      "published": "2025-12-25T22:29:54Z",
      "categories": "",
      "summary": "In this paper, we present KG20C and KG20C-QA, two curated datasets for advancing question answering (QA) research on scholarly data. KG20C is a high-quality scholarly knowledge graph constructed from the Microsoft Academic Graph through targeted selection of venues, quality-based filtering, and schema definition. Although KG20C has been available online in non-peer-reviewed sources such as GitHub repository, this paper provides the first formal, peer-reviewed description of the dataset, including clear documentation of its construction and specifications. KG20C-QA is built upon KG20C to suppor...",
      "pdf_url": "https://arxiv.org/pdf/2512.21799v2.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2312.03360v2",
      "title": "Teaching Specific Scientific Knowledge into Large Language Models through Additional Training",
      "authors": [
        "Kan Hatakeyama-Sato",
        "Yasuhiko Igarashi",
        "Shun Katakami",
        "Yuta Nabae",
        "Teruaki Hayakawa"
      ],
      "published": "2023-12-06T08:55:55Z",
      "categories": "",
      "summary": "Through additional training, we explore embedding specialized scientific knowledge into the Llama 2 Large Language Model (LLM). Key findings reveal that effective knowledge integration requires reading texts from multiple perspectives, especially in instructional formats. We utilize text augmentation to tackle the scarcity of specialized texts, including style conversions and translations. Hyperparameter optimization proves crucial, with different size models (7b, 13b, and 70b) reasonably undergoing additional training. Validating our methods, we construct a dataset of 65,000 scientific papers...",
      "pdf_url": "https://arxiv.org/pdf/2312.03360v2.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.04108v2",
      "title": "Large language models as oracles for instantiating ontologies with domain-specific knowledge",
      "authors": [
        "Giovanni Ciatto",
        "Andrea Agiollo",
        "Matteo Magnini",
        "Andrea Omicini"
      ],
      "published": "2024-04-05T14:04:07Z",
      "categories": "",
      "summary": "Background. Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer. Objective. To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on la...",
      "pdf_url": "https://arxiv.org/pdf/2404.04108v2.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.11196v2",
      "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training",
      "authors": [
        "Yixin Ou",
        "Yunzhi Yao",
        "Ningyu Zhang",
        "Hui Jin",
        "Jiacheng Sun",
        "Shumin Deng",
        "Zhenguo Li",
        "Huajun Chen"
      ],
      "published": "2025-02-16T16:55:43Z",
      "categories": "",
      "summary": "Despite exceptional capabilities in knowledge-intensive tasks, Large Language Models (LLMs) face a critical gap in understanding how they internalize new knowledge, particularly how to structurally embed acquired knowledge in their neural computations. We address this issue through the lens of knowledge circuit evolution, identifying computational subgraphs that facilitate knowledge storage and processing. Our systematic analysis of circuit evolution throughout continual pre-training reveals several key findings: (1) the acquisition of new knowledge is influenced by its relevance to pre-existi...",
      "pdf_url": "https://arxiv.org/pdf/2502.11196v2.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.02209v1",
      "title": "Balancing Information Accuracy and Response Timeliness in Networked LLMs",
      "authors": [
        "Yigit Turkmen",
        "Baturalp Buyukates",
        "Melih Bastopcu"
      ],
      "published": "2025-08-04T09:00:01Z",
      "categories": "",
      "summary": "Recent advancements in Large Language Models (LLMs) have transformed many fields including scientific discovery, content generation, biomedical text mining, and educational technology. However, the substantial requirements for training data, computational resources, and energy consumption pose significant challenges for their practical deployment. A promising alternative is to leverage smaller, specialized language models and aggregate their outputs to improve overall response quality. In this work, we investigate a networked LLM system composed of multiple users, a central task processor, and...",
      "pdf_url": "https://arxiv.org/pdf/2508.02209v1.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.20265v1",
      "title": "A Blockchain-Based Quality Control Model for Online Collaboration Systems",
      "authors": [
        "Sadegh Sohani",
        "Maliheh Shahryari",
        "Salar Ghazi",
        "Mohammad Allahbakhsh",
        "Haleh Amintoosi",
        "Boualem Benatallah"
      ],
      "published": "2025-07-27T13:23:00Z",
      "categories": "",
      "summary": "Collaborative content generation (CCG) enables collective creation of artifacts like scientific articles. Quality is a paramount concern in CCG, and a multitude of methods have been proposed to evaluate the quality of artifacts. Nevertheless, the majority of these methods are reliant on centralized architectures, which present challenges pertaining to security, privacy, and availability. Blockchain technology proffers a potential resolution to these challenges, by furnishing a decentralized and immutable ledger of quality scores. In this manuscript, we introduce a blockchain-based quality cont...",
      "pdf_url": "https://arxiv.org/pdf/2507.20265v1.pdf",
      "relevance_score": 31,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2401.12453v1",
      "title": "\"The teachers are confused as well\": A Multiple-Stakeholder Ethics Discussion on Large Language Models in Computing Education",
      "authors": [
        "Kyrie Zhixuan Zhou",
        "Zachary Kilhoffer",
        "Madelyn Rose Sanfilippo",
        "Ted Underwood",
        "Ece Gumusel",
        "Mengyi Wei",
        "Abhinav Choudhry",
        "Jinjun Xiong"
      ],
      "published": "2024-01-23T02:43:00Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) are advancing quickly and impacting people's lives for better or worse. In higher education, concerns have emerged such as students' misuse of LLMs and degraded education outcomes. To unpack the ethical concerns of LLMs for higher education, we conducted a case study consisting of stakeholder interviews (n=20) in higher education computer science. We found that students use several distinct mental models to interact with LLMs - LLMs serve as a tool for (a) writing, (b) coding, and (c) information retrieval, which differ somewhat in ethical considerations. Students ...",
      "pdf_url": "https://arxiv.org/pdf/2401.12453v1.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.03487v1",
      "title": "Artificial Intelligence and Legal Analysis: Implications for Legal Education and the Profession",
      "authors": [
        "Lee Peoples"
      ],
      "published": "2025-02-04T19:50:48Z",
      "categories": "",
      "summary": "This article reports the results of a study examining the ability of legal and non-legal Large Language Models to perform legal analysis using the Issue-Rule-Application-Conclusion framework. LLMs were tested on legal reasoning tasks involving rule analysis and analogical reasoning. The results show that LLMs can conduct basic IRAC analysis, but are limited by brief responses lacking detail, an inability to commit to answers, false confidence, and hallucinations. The study compares legal and nonlegal LLMs, identifies shortcomings, and explores traits that may hinder their ability to think like...",
      "pdf_url": "https://arxiv.org/pdf/2502.03487v1.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2507.19183v1",
      "title": "Agentic AI and Hallucinations",
      "authors": [
        "Engin Iyidogan",
        "Ali I. Ozkes"
      ],
      "published": "2025-07-25T11:45:21Z",
      "categories": "",
      "summary": "We model a competitive market where AI agents buy answers from upstream generative models and resell them to users who differ in how much they value accuracy and in how much they fear hallucinations. Agents can privately exert effort for costly verification to lower hallucination risks. Since interactions halt in the event of a hallucination, the threat of losing future rents disciplines effort. A unique reputational equilibrium exists under nontrivial discounting. The equilibrium effort, and thus the price, increases with the share of users who have high accuracy concerns, implying that hallu...",
      "pdf_url": "https://arxiv.org/pdf/2507.19183v1.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2402.14683v2",
      "title": "Visual Hallucinations of Multi-modal Large Language Models",
      "authors": [
        "Wen Huang",
        "Hongbin Liu",
        "Minxin Guo",
        "Neil Zhenqiang Gong"
      ],
      "published": "2024-02-22T16:40:33Z",
      "categories": "",
      "summary": "Visual hallucination (VH) means that a multi-modal LLM (MLLM) imagines incorrect details about an image in visual question answering. Existing studies find VH instances only in existing image datasets, which results in biased understanding of MLLMs' performance under VH due to limited diversity of such VH instances. In this work, we propose a tool called VHTest to generate a diverse set of VH instances. Specifically, VHTest finds some initial VH instances in existing image datasets (e.g., COCO), generates a text description for each VH mode, and uses a text-to-image generative model (e.g., DAL...",
      "pdf_url": "https://arxiv.org/pdf/2402.14683v2.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2306.13272v1",
      "title": "Spotting Hallucinations in Inverse Problems with Data-Driven Priors",
      "authors": [
        "Matt L. Sampson",
        "Peter Melchior"
      ],
      "published": "2023-06-23T02:55:24Z",
      "categories": "",
      "summary": "Hallucinations are an inescapable consequence of solving inverse problems with deep neural networks. The expressiveness of recent generative models is the reason why they can yield results far superior to conventional regularizers; it can also lead to realistic-looking but incorrect features, potentially undermining the trust in important aspects of the reconstruction. We present a practical and computationally efficient method to determine, which regions in the solutions of inverse problems with data-driven priors are prone to hallucinations. By computing the diagonal elements of the Fisher i...",
      "pdf_url": "https://arxiv.org/pdf/2306.13272v1.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.04330v1",
      "title": "Temporal Interest-Driven Multimodal Personalized Content Generation",
      "authors": [
        "Tian Miao"
      ],
      "published": "2025-09-04T15:49:26Z",
      "categories": "",
      "summary": "With the dynamic evolution of user interests and the increasing multimodal demands in internet applications, personalized content generation strategies based on static interest preferences struggle to meet practical application requirements. The proposed TIMGen (Temporal Interest-driven Multimodal Generation) model addresses this challenge by modeling the long-term temporal evolution of users' interests and capturing dynamic interest representations with strong temporal dependencies. This model also supports the fusion of multimodal features, such as text, images, video, and audio, and deliver...",
      "pdf_url": "https://arxiv.org/pdf/2509.04330v1.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.01837v1",
      "title": "Enabling Explainable Recommendation in E-commerce with LLM-powered Product Knowledge Graph",
      "authors": [
        "Menghan Wang",
        "Yuchen Guo",
        "Duanfeng Zhang",
        "Jianian Jin",
        "Minnie Li",
        "Dan Schonfeld",
        "Shawn Zhou"
      ],
      "published": "2024-11-17T10:57:31Z",
      "categories": "",
      "summary": "How to leverage large language model's superior capability in e-commerce recommendation has been a hot topic. In this paper, we propose LLM-PKG, an efficient approach that distills the knowledge of LLMs into product knowledge graph (PKG) and then applies PKG to provide explainable recommendations. Specifically, we first build PKG by feeding curated prompts to LLM, and then map LLM response to real enterprise products. To mitigate the risks associated with LLM hallucination, we employ rigorous evaluation and pruning methods to ensure the reliability and availability of the KG. Through an A/B te...",
      "pdf_url": "https://arxiv.org/pdf/2412.01837v1.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.23667v1",
      "title": "Context-Independent OCR with Multimodal LLMs: Effects of Image Resolution and Visual Complexity",
      "authors": [
        "Kotaro Inoue"
      ],
      "published": "2025-03-31T02:09:19Z",
      "categories": "",
      "summary": "Due to their high versatility in tasks such as image captioning, document analysis, and automated content generation, multimodal Large Language Models (LLMs) have attracted significant attention across various industrial fields. In particular, they have been shown to surpass specialized models in Optical Character Recognition (OCR). Nevertheless, their performance under different image conditions remains insufficiently investigated, and individual character recognition is not guaranteed due to their reliance on contextual cues. In this work, we examine a context-independent OCR task using sing...",
      "pdf_url": "https://arxiv.org/pdf/2503.23667v1.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2308.13768v1",
      "title": "Adversarial Fine-Tuning of Language Models: An Iterative Optimisation Approach for the Generation and Detection of Problematic Content",
      "authors": [
        "Charles O'Neill",
        "Jack Miller",
        "Ioana Ciuca",
        "Yuan-Sen Ting",
        "Thang Bui"
      ],
      "published": "2023-08-26T05:20:58Z",
      "categories": "",
      "summary": "In this paper, we tackle the emerging challenge of unintended harmful content generation in Large Language Models (LLMs) with a novel dual-stage optimisation technique using adversarial fine-tuning. Our two-pronged approach employs an adversarial model, fine-tuned to generate potentially harmful prompts, and a judge model, iteratively optimised to discern these prompts. In this adversarial cycle, the two models seek to outperform each other in the prompting phase, generating a dataset of rich examples which are then used for fine-tuning. This iterative application of prompting and fine-tuning ...",
      "pdf_url": "https://arxiv.org/pdf/2308.13768v1.pdf",
      "relevance_score": 30,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.04852v1",
      "title": "Improving AI-generated music with user-guided training",
      "authors": [
        "Vishwa Mohan Singh",
        "Sai Anirudh Aryasomayajula",
        "Ahan Chatterjee",
        "Beste Aydemir",
        "Rifat Mehreen Amin"
      ],
      "published": "2025-06-05T10:22:54Z",
      "categories": "",
      "summary": "AI music generation has advanced rapidly, with models like diffusion and autoregressive algorithms enabling high-fidelity outputs. These tools can alter styles, mix instruments, or isolate them. Since sound can be visualized as spectrograms, image-generation algorithms can be applied to generate novel music. However, these algorithms are typically trained on fixed datasets, which makes it challenging for them to interpret and respond to user input accurately. This is especially problematic because music is highly subjective and requires a level of personalization that image generation does not...",
      "pdf_url": "https://arxiv.org/pdf/2506.04852v1.pdf",
      "relevance_score": 28,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1503.03355v1",
      "title": "Automatic Unsupervised Tensor Mining with Quality Assessment",
      "authors": [
        "Evangelos E. Papalexakis"
      ],
      "published": "2015-03-11T14:34:46Z",
      "categories": "",
      "summary": "A popular tool for unsupervised modelling and mining multi-aspect data is tensor decomposition. In an exploratory setting, where and no labels or ground truth are available how can we automatically decide how many components to extract? How can we assess the quality of our results, so that a domain expert can factor this quality measure in the interpretation of our results? In this paper, we introduce AutoTen, a novel automatic unsupervised tensor mining algorithm with minimal user intervention, which leverages and improves upon heuristics that assess the result quality. We extensively evaluat...",
      "pdf_url": "https://arxiv.org/pdf/1503.03355v1.pdf",
      "relevance_score": 28,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1911.03432v6",
      "title": "Penalty Method for Inversion-Free Deep Bilevel Optimization",
      "authors": [
        "Akshay Mehra",
        "Jihun Hamm"
      ],
      "published": "2019-11-08T18:33:29Z",
      "categories": "",
      "summary": "Solving a bilevel optimization problem is at the core of several machine learning problems such as hyperparameter tuning, data denoising, meta- and few-shot learning, and training-data poisoning. Different from simultaneous or multi-objective optimization, the steepest descent direction for minimizing the upper-level cost in a bilevel problem requires the inverse of the Hessian of the lower-level cost. In this work, we propose a novel algorithm for solving bilevel optimization problems based on the classical penalty function approach. Our method avoids computing the Hessian inverse and can han...",
      "pdf_url": "https://arxiv.org/pdf/1911.03432v6.pdf",
      "relevance_score": 28,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.23706v1",
      "title": "Distributed Federated Learning for Vehicular Network Security: Anomaly Detection Benefits and Multi-Domain Attack Threats",
      "authors": [
        "Utku Demir",
        "Yalin E. Sagduyu",
        "Tugba Erpek",
        "Hossein Jafari",
        "Sastry Kompella",
        "Mengran Xue"
      ],
      "published": "2025-05-29T17:41:02Z",
      "categories": "",
      "summary": "In connected and autonomous vehicles, machine learning for safety message classification has become critical for detecting malicious or anomalous behavior. However, conventional approaches that rely on centralized data collection or purely local training face limitations due to the large scale, high mobility, and heterogeneous data distributions inherent in inter-vehicle networks. To overcome these challenges, this paper explores Distributed Federated Learning (DFL), whereby vehicles collaboratively train deep learning models by exchanging model updates among one-hop neighbors and propagating ...",
      "pdf_url": "https://arxiv.org/pdf/2505.23706v1.pdf",
      "relevance_score": 28,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.00412v4",
      "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation",
      "authors": [
        "Bohan Lyu",
        "Yadi Cao",
        "Duncan Watson-Parris",
        "Leon Bergen",
        "Taylor Berg-Kirkpatrick",
        "Rose Yu"
      ],
      "published": "2024-11-01T07:18:31Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) demonstrate promising capabilities in solving scientific problems but often suffer from the issue of hallucination. While integrating LLMs with tools can mitigate this issue, models fine-tuned on tool usage become overreliant on them and incur unnecessary costs. Inspired by how human experts assess problem complexity before selecting solutions, we propose a novel two-component fine-tuning method, Adapting While Learning (AWL). In the first component, World Knowledge Learning (WKL), LLMs internalize scientific knowledge by learning from tool-generated solutions. In ...",
      "pdf_url": "https://arxiv.org/pdf/2411.00412v4.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.00386v1",
      "title": "What comes after transformers? -- A selective survey connecting ideas in deep learning",
      "authors": [
        "Johannes Schneider"
      ],
      "published": "2024-08-01T08:50:25Z",
      "categories": "",
      "summary": "Transformers have become the de-facto standard model in artificial intelligence since 2017 despite numerous shortcomings ranging from energy inefficiency to hallucinations. Research has made a lot of progress in improving elements of transformers, and, more generally, deep learning manifesting in many proposals for architectures, layers, optimization objectives, and optimization techniques. For researchers it is difficult to keep track of such developments on a broader level. We provide a comprehensive overview of the many important, recent works in these areas to those who already have a basi...",
      "pdf_url": "https://arxiv.org/pdf/2408.00386v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2006.08684v3",
      "title": "Efficient Model-Based Reinforcement Learning through Optimistic Policy Search and Planning",
      "authors": [
        "Sebastian Curi",
        "Felix Berkenkamp",
        "Andreas Krause"
      ],
      "published": "2020-06-15T18:37:38Z",
      "categories": "",
      "summary": "Model-based reinforcement learning algorithms with probabilistic dynamical models are amongst the most data-efficient learning methods. This is often attributed to their ability to distinguish between epistemic and aleatoric uncertainty. However, while most algorithms distinguish these two uncertainties for learning the model, they ignore it when optimizing the policy, which leads to greedy and insufficient exploration. At the same time, there are no practical solvers for optimistic exploration algorithms. In this paper, we propose a practical optimistic exploration algorithm (H-UCRL). H-UCRL ...",
      "pdf_url": "https://arxiv.org/pdf/2006.08684v3.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2111.06387v1",
      "title": "Learning Signal-Agnostic Manifolds of Neural Fields",
      "authors": [
        "Yilun Du",
        "Katherine M. Collins",
        "Joshua B. Tenenbaum",
        "Vincent Sitzmann"
      ],
      "published": "2021-11-11T18:57:40Z",
      "categories": "",
      "summary": "Deep neural networks have been used widely to learn the latent structure of datasets, across modalities such as images, shapes, and audio signals. However, existing models are generally modality-dependent, requiring custom architectures and objectives to process different classes of signals. We leverage neural fields to capture the underlying structure in image, shape, audio and cross-modal audiovisual domains in a modality-independent manner. We cast our task as one of learning a manifold, where we aim to infer a low-dimensional, locally linear subspace in which our data resides. By enforcing...",
      "pdf_url": "https://arxiv.org/pdf/2111.06387v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.19485v1",
      "title": "Identifying and Addressing User-level Security Concerns in Smart Homes Using \"Smaller\" LLMs",
      "authors": [
        "Hafijul Hoque Chowdhury",
        "Riad Ahmed Anonto",
        "Sourov Jajodia",
        "Suryadipta Majumdar",
        "Md. Shohrab Hossain"
      ],
      "published": "2025-09-23T18:47:59Z",
      "categories": "",
      "summary": "With the rapid growth of smart home IoT devices, users are increasingly exposed to various security risks, as evident from recent studies. While seeking answers to know more on those security concerns, users are mostly left with their own discretion while going through various sources, such as online blogs and technical manuals, which may render higher complexity to regular users trying to extract the necessary information. This requirement does not go along with the common mindsets of smart home users and hence threatens the security of smart homes furthermore. In this paper, we aim to identi...",
      "pdf_url": "https://arxiv.org/pdf/2509.19485v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.02413v2",
      "title": "A TEE-based Approach for Security and Privacy in Decision Support",
      "authors": [
        "Edoardo Marangone",
        "Eugenio Nerio Nemmi",
        "Daniele Friolo",
        "Giuseppe Ateniese",
        "Ingo Weber",
        "Claudio Di Ciccio"
      ],
      "published": "2025-09-02T15:20:45Z",
      "categories": "",
      "summary": "Decision Support Systems are increasingly adopted to automate decision-making processes across industries, organizations and governments. However, decision support requires maintaining data privacy, integrity, and availability while ensuring customization, security, and verifiability of the decision process. Existing solutions fail to guarantee those properties altogether. Most commercial tools cater for data integrity and process customization but are centralized. This centralization potentially compromises data privacy and availability, as well as process security and verifiability. To overc...",
      "pdf_url": "https://arxiv.org/pdf/2509.02413v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1905.11701v1",
      "title": "Putting Together the Pieces: A Concept for Holistic Industrial Intrusion Detection",
      "authors": [
        "Simon D. Duque Ant\u00f3n",
        "Hans Dieter Schotten"
      ],
      "published": "2019-05-28T09:30:35Z",
      "categories": "",
      "summary": "Besides the advantages derived from the ever present communication properties, it increases the attack surface of a network as well. As industrial protocols and systems were not designed with security in mind, spectacular attacks on industrial systems occurred over the last years. Most industrial communication protocols do not provide means to ensure authentication or encryption. This means attackers with access to a network can read and write information. Originally not meant to be connected to public networks, the use cases of Industry 4.0 require interconnectivity, often through insecure pu...",
      "pdf_url": "https://arxiv.org/pdf/1905.11701v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2506.08740v2",
      "title": "Urban Incident Prediction with Graph Neural Networks: Integrating Government Ratings and Crowdsourced Reports",
      "authors": [
        "Sidhika Balachandar",
        "Shuvom Sadhuka",
        "Bonnie Berger",
        "Emma Pierson",
        "Nikhil Garg"
      ],
      "published": "2025-06-10T12:37:17Z",
      "categories": "",
      "summary": "Graph neural networks (GNNs) are widely used in urban spatiotemporal forecasting, such as predicting infrastructure problems. In this setting, government officials wish to know in which neighborhoods incidents like potholes or rodent issues occur. The true state of incidents (e.g., street conditions) for each neighborhood is observed via government inspection ratings. However, these ratings are only conducted for a sparse set of neighborhoods and incident types. We also observe the state of incidents via crowdsourced reports, which are more densely observed but may be biased due to heterogeneo...",
      "pdf_url": "https://arxiv.org/pdf/2506.08740v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.26150v1",
      "title": "Bubble, Bubble, AI's Rumble: Why Global Financial Regulatory Incident Reporting is Our Shield Against Systemic Stumbles",
      "authors": [
        "Anchal Gupta",
        "Gleb Pappyshev",
        "James T Kwok"
      ],
      "published": "2025-09-30T12:01:25Z",
      "categories": "",
      "summary": "\"Double, double toil and trouble; Fire burn and cauldron bubble.\" As Shakespeare's witches foretold chaos through cryptic prophecies, modern capital markets grapple with systemic risks concealed by opaque AI systems. According to IMF, the August 5, 2024, plunge in Japanese and U.S. equities can be linked to algorithmic trading yet ab-sent from existing AI incidents database exemplifies this transparency crisis. Current AI incident databases, reliant on crowdsourcing or news scraping, systematically over-look capital market anomalies, particularly in algorithmic and high-frequency trading. We a...",
      "pdf_url": "https://arxiv.org/pdf/2509.26150v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2303.15371v2",
      "title": "Accelerating Bayesian inference for stochastic epidemic models using incidence data",
      "authors": [
        "Andrew Golightly",
        "Laura E. Wadkin",
        "Sam A. Whitaker",
        "Andrew W. Baggaley",
        "Nick G. Parker",
        "Theodore Kypraios"
      ],
      "published": "2023-03-27T16:43:24Z",
      "categories": "",
      "summary": "We consider the case of performing Bayesian inference for stochastic epidemic compartment models, using incomplete time course data consisting of incidence counts that are either the number of new infections or removals in time intervals of fixed length. We eschew the most natural Markov jump process representation for reasons of computational efficiency, and focus on a stochastic differential equation representation. This is further approximated to give a tractable Gaussian process, that is, the linear noise approximation (LNA). Unless the observation model linking the LNA to data is both lin...",
      "pdf_url": "https://arxiv.org/pdf/2303.15371v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2111.05108v1",
      "title": "\"How Does It Detect A Malicious App?\" Explaining the Predictions of AI-based Android Malware Detector",
      "authors": [
        "Zhi Lu",
        "Vrizlynn L. L. Thing"
      ],
      "published": "2021-11-06T11:25:24Z",
      "categories": "",
      "summary": "AI methods have been proven to yield impressive performance on Android malware detection. However, most AI-based methods make predictions of suspicious samples in a black-box manner without transparency on models' inference. The expectation on models' explainability and transparency by cyber security and AI practitioners to assure the trustworthiness increases. In this article, we present a novel model-agnostic explanation method for AI models applied for Android malware detection. Our proposed method identifies and quantifies the data features relevance to the predictions by two steps: i) dat...",
      "pdf_url": "https://arxiv.org/pdf/2111.05108v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1903.07047v1",
      "title": "General techniques for approximate incidences and their application to the camera posing problem",
      "authors": [
        "Dror Aiger",
        "Haim Kaplan",
        "Efi Kokiopoulou",
        "Micha Sharir",
        "Bernhard Zeisl"
      ],
      "published": "2019-03-17T09:44:23Z",
      "categories": "",
      "summary": "We consider the classical camera pose estimation problem that arises in many computer vision applications, in which we are given n 2D-3D correspondences between points in the scene and points in the camera image (some of which are incorrect associations), and where we aim to determine the camera pose (the position and orientation of the camera in the scene) from this data. We demonstrate that this posing problem can be reduced to the problem of computing \u03b5-approximate incidences between two-dimensional surfaces (derived from the input correspondences) and points (on a grid) in a four-dimension...",
      "pdf_url": "https://arxiv.org/pdf/1903.07047v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1409.8035v2",
      "title": "Detecting Behavioral and Structural Anomalies in MediaCloud Applications",
      "authors": [
        "Guido Schwenk",
        "Sebastian Bach"
      ],
      "published": "2014-09-29T09:16:00Z",
      "categories": "",
      "summary": "In the past years technological advances such as the increasing bandwidth in network infrastructures and new software developments such as message and agent-based systems gave rise to the field of cloud technologies, which have evolved from abstract concepts to concrete solutions, ranging from flexible, platform-independent systems to highly specialized software solutions. In this paper we introduce and evaluate two anomaly detection methods to achieve a higher level of security in a specific cloud solution for interactive media, the Media Cloud from Alcatel-Lucent. The Media Cloud focuses on ...",
      "pdf_url": "https://arxiv.org/pdf/1409.8035v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.08122v2",
      "title": "PP-GWAS: Privacy Preserving Multi-Site Genome-wide Association Studies",
      "authors": [
        "Arjhun Swaminathan",
        "Anika Hannemann",
        "Ali Burak \u00dcnal",
        "Nico Pfeifer",
        "Mete Akg\u00fcn"
      ],
      "published": "2024-10-10T17:07:57Z",
      "categories": "",
      "summary": "Genome-wide association studies are pivotal in understanding the genetic underpinnings of complex traits and diseases. Collaborative, multi-site GWAS aim to enhance statistical power but face obstacles due to the sensitive nature of genomic data sharing. Current state-of-the-art methods provide a privacy-focused approach utilizing computationally expensive methods such as Secure Multi-Party Computation and Homomorphic Encryption. In this context, we present a novel algorithm PP-GWAS designed to improve upon existing standards in terms of computational efficiency and scalability without sacrifi...",
      "pdf_url": "https://arxiv.org/pdf/2410.08122v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1810.07260v1",
      "title": "Statistical Estimation of Malware Detection Metrics in the Absence of Ground Truth",
      "authors": [
        "Pang Du",
        "Zheyuan Sun",
        "Huashan Chen",
        "Jin-Hee Cho",
        "Shouhuai Xu"
      ],
      "published": "2018-09-24T02:40:31Z",
      "categories": "",
      "summary": "The accurate measurement of security metrics is a critical research problem because an improper or inaccurate measurement process can ruin the usefulness of the metrics, no matter how well they are defined. This is a highly challenging problem particularly when the ground truth is unknown or noisy. In contrast to the well perceived importance of defining security metrics, the measurement of security metrics has been little understood in the literature. In this paper, we measure five malware detection metrics in the {\\em absence} of ground truth, which is a realistic setting that imposes many t...",
      "pdf_url": "https://arxiv.org/pdf/1810.07260v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.10032v1",
      "title": "Detecting AI Generated Text Based on NLP and Machine Learning Approaches",
      "authors": [
        "Nuzhat Prova"
      ],
      "published": "2024-04-15T16:37:44Z",
      "categories": "",
      "summary": "Recent advances in natural language processing (NLP) may enable artificial intelligence (AI) models to generate writing that is identical to human written form in the future. This might have profound ethical, legal, and social repercussions. This study aims to address this problem by offering an accurate AI detector model that can differentiate between electronically produced text and human-written text. Our approach includes machine learning methods such as XGB Classifier, SVM, BERT architecture deep learning models. Furthermore, our results show that the BERT performs better than previous mo...",
      "pdf_url": "https://arxiv.org/pdf/2404.10032v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2501.02207v1",
      "title": "Self-Supervised Learning for Detecting AI-Generated Faces as Anomalies",
      "authors": [
        "Mian Zou",
        "Baosheng Yu",
        "Yibing Zhan",
        "Kede Ma"
      ],
      "published": "2025-01-04T06:23:24Z",
      "categories": "",
      "summary": "The detection of AI-generated faces is commonly approached as a binary classification task. Nevertheless, the resulting detectors frequently struggle to adapt to novel AI face generators, which evolve rapidly. In this paper, we describe an anomaly detection method for AI-generated faces by leveraging self-supervised learning of camera-intrinsic and face-specific features purely from photographic face images. The success of our method lies in designing a pretext task that trains a feature extractor to rank four ordinal exchangeable image file format (EXIF) tags and classify artificially manipul...",
      "pdf_url": "https://arxiv.org/pdf/2501.02207v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2303.13869v2",
      "title": "AI-Generated Network Design: A Diffusion Model-based Learning Approach",
      "authors": [
        "Yudong Huang",
        "Minrui Xu",
        "Xinyuan Zhang",
        "Dusit Niyato",
        "Zehui Xiong",
        "Shuo Wang",
        "Tao Huang"
      ],
      "published": "2023-03-24T09:20:28Z",
      "categories": "",
      "summary": "The future networks pose intense demands for intelligent and customized designs to cope with the surging network scale, dynamically time-varying environments, diverse user requirements, and complicated manual configuration. However, traditional rule-based solutions heavily rely on human efforts and expertise, while data-driven intelligent algorithms still lack interpretability and generalization. In this paper, we propose the AIGN (AI-Generated Network), a novel intention-driven paradigm for network design, which allows operators to quickly generate a variety of customized network solutions an...",
      "pdf_url": "https://arxiv.org/pdf/2303.13869v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.17477v1",
      "title": "LingoQ: Bridging the Gap between ESL Learning and Work through AI-Generated Work-Related Quizzes",
      "authors": [
        "Yeonsun Yang",
        "Sang Won Lee",
        "Jean Y. Song",
        "Sangdoo Yun",
        "Young-Ho Kim"
      ],
      "published": "2025-09-22T08:12:10Z",
      "categories": "",
      "summary": "Non-native English speakers performing English-related tasks at work struggle to sustain ESL learning, despite their motivation. Often, study materials are disconnected from their work context. Although workers rely on LLM assistants to address their immediate needs, these interactions may not directly contribute to their English skills. We present LingoQ, an AI-mediated system that allows workers to practice English using quizzes generated from their LLM queries during work. LingoQ leverages these queries using AI to generate personalized quizzes that workers can review and practice on their ...",
      "pdf_url": "https://arxiv.org/pdf/2509.17477v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.01525v1",
      "title": "MiraGe: Multimodal Discriminative Representation Learning for Generalizable AI-Generated Image Detection",
      "authors": [
        "Kuo Shi",
        "Jie Lu",
        "Shanshan Ye",
        "Guangquan Zhang",
        "Zhen Fang"
      ],
      "published": "2025-08-03T00:19:18Z",
      "categories": "",
      "summary": "Recent advances in generative models have highlighted the need for robust detectors capable of distinguishing real images from AI-generated images. While existing methods perform well on known generators, their performance often declines when tested with newly emerging or unseen generative models due to overlapping feature embeddings that hinder accurate cross-generator classification. In this paper, we propose Multimodal Discriminative Representation Learning for Generalizable AI-generated Image Detection (MiraGe), a method designed to learn generator-invariant features. Motivated by theoreti...",
      "pdf_url": "https://arxiv.org/pdf/2508.01525v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.04787v1",
      "title": "Evaluating the Impact of LLM-guided Reflection on Learning Outcomes with Interactive AI-Generated Educational Podcasts",
      "authors": [
        "Vishnu Menon",
        "Andy Cherney",
        "Elizabeth B. Cloude",
        "Li Zhang",
        "Tiffany D. Do"
      ],
      "published": "2025-08-06T18:03:42Z",
      "categories": "",
      "summary": "This study examined whether embedding LLM-guided reflection prompts in an interactive AI-generated podcast improved learning and user experience compared to a version without prompts. Thirty-six undergraduates participated, and while learning outcomes were similar across conditions, reflection prompts reduced perceived attractiveness, highlighting a call for more research on reflective interactivity design.",
      "pdf_url": "https://arxiv.org/pdf/2508.04787v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.08922v1",
      "title": "Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning",
      "authors": [
        "Majeed Kazemitabaar",
        "Oliver Huang",
        "Sangho Suh",
        "Austin Z. Henley",
        "Tovi Grossman"
      ],
      "published": "2024-10-11T15:49:42Z",
      "categories": "",
      "summary": "Novice programmers are increasingly relying on Large Language Models (LLMs) to generate code for learning programming concepts. However, this interaction can lead to superficial engagement, giving learners an illusion of learning and hindering skill development. To address this issue, we conducted a systematic design exploration to develop seven cognitive engagement techniques aimed at promoting deeper engagement with AI-generated code. In this paper, we describe our design process, the initial seven techniques and results from a between-subjects study (N=82). We then iteratively refined the t...",
      "pdf_url": "https://arxiv.org/pdf/2410.08922v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2302.06949v1",
      "title": "Camera Calibration without Camera Access -- A Robust Validation Technique for Extended PnP Methods",
      "authors": [
        "Emil Brissman",
        "Per-Erik Forss\u00e9n",
        "Johan Edstedt"
      ],
      "published": "2023-02-14T10:09:34Z",
      "categories": "",
      "summary": "A challenge in image based metrology and forensics is intrinsic camera calibration when the used camera is unavailable. The unavailability raises two questions. The first question is how to find the projection model that describes the camera, and the second is to detect incorrect models. In this work, we use off-the-shelf extended PnP-methods to find the model from 2D-3D correspondences, and propose a method for model validation. The most common strategy for evaluating a projection model is comparing different models' residual variances - however, this naive strategy cannot distinguish whether...",
      "pdf_url": "https://arxiv.org/pdf/2302.06949v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.01391v2",
      "title": "Knowledge Graph in Astronomical Research with Large Language Models: Quantifying Driving Forces in Interdisciplinary Scientific Discovery",
      "authors": [
        "Zechang Sun",
        "Yuan-Sen Ting",
        "Yaobo Liang",
        "Nan Duan",
        "Song Huang",
        "Zheng Cai"
      ],
      "published": "2024-06-03T14:55:57Z",
      "categories": "",
      "summary": "Identifying and predicting the factors that contribute to the success of interdisciplinary research is crucial for advancing scientific discovery. However, there is a lack of methods to quantify the integration of new ideas and technological advancements in astronomical research and how these new technologies drive further scientific breakthroughs. Large language models, with their ability to extract key concepts from vast literature beyond keyword searches, provide a new tool to quantify such processes. In this study, we extracted concepts in astronomical research from 297,807 publications be...",
      "pdf_url": "https://arxiv.org/pdf/2406.01391v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.18137v1",
      "title": "Simulating Dynamic Cloud Marketspaces: Modeling Spot Instance Behavior and Scheduling with CloudSim Plus",
      "authors": [
        "Christoph Goldgruber",
        "Benedikt Pittl",
        "Erich Schikuta"
      ],
      "published": "2025-11-22T17:48:52Z",
      "categories": "",
      "summary": "The increasing reliance on dynamic pricing models, such as spot instances, in public cloud environments presents new challenges for workload scheduling and reliability. While these models offer cost advantages, they introduce volatility and uncertainty that are not fully addressed by current allocation algorithms or simulation tools. This work contributes to the modeling and evaluation of such environments by extending the CloudSim Plus simulation framework to support realistic spot instance lifecycle management, including interruption, termination, hibernation, and reallocation. The enhanced ...",
      "pdf_url": "https://arxiv.org/pdf/2511.18137v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.04642v1",
      "title": "RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case",
      "authors": [
        "Baihui Xiao",
        "Chengjian Feng",
        "Zhijian Huang",
        "Feng yan",
        "Yujie Zhong",
        "Lin Ma"
      ],
      "published": "2025-08-06T17:07:25Z",
      "categories": "",
      "summary": "Collecting real-world data for rare high-risk scenarios, long-tailed driving events, and complex interactions remains challenging, leading to poor performance of existing autonomous driving systems in these critical situations. In this paper, we propose RoboTron-Sim that improves real-world driving in critical situations by utilizing simulated hard cases. First, we develop a simulated dataset called Hard-case Augmented Synthetic Scenarios (HASS), which covers 13 high-risk edge-case categories, as well as balanced environmental conditions such as day/night and sunny/rainy. Second, we introduce ...",
      "pdf_url": "https://arxiv.org/pdf/2508.04642v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.21802v1",
      "title": "An Adaptive Real-Time Forecasting Framework for Cryogenic Fluid Management in Space Systems",
      "authors": [
        "Qiyun Cheng",
        "Huihua Yang",
        "Wei Ji"
      ],
      "published": "2025-08-29T17:31:14Z",
      "categories": "",
      "summary": "Accurate real-time forecasting of cryogenic tank behavior is essential for the safe and efficient operation of propulsion and storage systems in future deep-space missions. While cryogenic fluid management (CFM) systems increasingly require autonomous capabilities, conventional simulation methods remain hindered by high computational cost, model imperfections, and sensitivity to unanticipated boundary condition changes. To address these limitations, this study proposes an Adaptive Real-Time Forecasting Framework for Cryogenic Propellant Management in Space Systems, featuring a lightweight, non...",
      "pdf_url": "https://arxiv.org/pdf/2508.21802v1.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2111.15318v2",
      "title": "DiffSDFSim: Differentiable Rigid-Body Dynamics With Implicit Shapes",
      "authors": [
        "Michael Strecke",
        "Joerg Stueckler"
      ],
      "published": "2021-11-30T11:56:24Z",
      "categories": "",
      "summary": "Differentiable physics is a powerful tool in computer vision and robotics for scene understanding and reasoning about interactions. Existing approaches have frequently been limited to objects with simple shape or shapes that are known in advance. In this paper, we propose a novel approach to differentiable physics with frictional contacts which represents object shapes implicitly using signed distance fields (SDFs). Our simulation supports contact point calculation even when the involved shapes are nonconvex. Moreover, we propose ways for differentiating the dynamics for the object shape to fa...",
      "pdf_url": "https://arxiv.org/pdf/2111.15318v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.08700v2",
      "title": "Progressive Pruning: Analyzing the Impact of Intersection Attacks",
      "authors": [
        "Christoph D\u00f6pmann",
        "Maximilian Weisenseel",
        "Florian Tschorsch"
      ],
      "published": "2024-10-11T10:40:51Z",
      "categories": "",
      "summary": "Stream-based communication dominates today's Internet, posing unique challenges for anonymous communication networks (ACNs). Traditionally designed for independent messages, ACNs struggle to account for the inherent vulnerabilities of streams, such as susceptibility to intersection attacks. In this work, we address this gap and introduce progressive pruning, a novel methodology for quantifying the susceptibility to intersection attacks. Progressive pruning quantifies and monitors anonymity sets over time, providing an assessment of an adversary's success in correlating senders and receivers. W...",
      "pdf_url": "https://arxiv.org/pdf/2410.08700v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2111.13456v2",
      "title": "A posteriori error estimation and adaptivity for multiple-network poroelasticity",
      "authors": [
        "Emilie Eliseussen",
        "Marie E. Rognes",
        "Travis B. Thompson"
      ],
      "published": "2021-11-26T12:16:17Z",
      "categories": "",
      "summary": "The multiple-network poroelasticity (MPET) equations describe deformation and pressures in an elastic medium permeated by interacting fluid networks. In this paper, we (i) place these equations in the theoretical context of coupled elliptic-parabolic problems, (ii) use this context to derive residual-based a posteriori error estimates and indicators for fully discrete MPET solutions and (iii) evaluate the performance of these error estimators in adaptive algorithms for a set of test cases: ranging from synthetic scenarios to physiologically realistic simulations of brain mechanics.",
      "pdf_url": "https://arxiv.org/pdf/2111.13456v2.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2305.16772v4",
      "title": "Real-Time Scheduling for 802.1Qbv Time-Sensitive Networking (TSN): A Systematic Review and Experimental Study",
      "authors": [
        "Chuanyu Xue",
        "Tianyu Zhang",
        "Yuanbin Zhou",
        "Mark Nixon",
        "Andrew Loveless",
        "Song Han"
      ],
      "published": "2023-05-26T09:33:18Z",
      "categories": "",
      "summary": "Time-Sensitive Networking (TSN) has been recognized as one of the key enabling technologies for Industry 4.0 and has been deployed in many mission- and safety-critical applications e.g., automotive and aerospace systems. Given the stringent real-time requirements of these applications, the Time-Aware Shaper (TAS) draws special attention among TSN's many traffic shapers due to its ability to achieve deterministic timing guarantees. Many scheduling methods for TAS shapers have been recently developed that claim to improve system schedulability. However, these scheduling methods have yet to be th...",
      "pdf_url": "https://arxiv.org/pdf/2305.16772v4.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1105.5004v6",
      "title": "Bayesian Decision-theoretic Methods for Parameter Ensembles with Application to Epidemiology",
      "authors": [
        "Cedric E. Ginestet"
      ],
      "published": "2011-05-25T12:37:41Z",
      "categories": "",
      "summary": "Parameter ensembles or sets of random effects constitute one of the cornerstones of modern statistical practice. This is especially the case in Bayesian hierarchical models, where several decision theoretic frameworks can be deployed. The estimation of these parameter ensembles may substantially vary depending on which inferential goals are prioritised by the modeller. Since one may wish to satisfy a range of desiderata, it is therefore of interest to investigate whether some sets of point estimates can simultaneously meet several inferential objectives. In this thesis, we will be especially c...",
      "pdf_url": "https://arxiv.org/pdf/1105.5004v6.pdf",
      "relevance_score": 27,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2311.02956v1",
      "title": "In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models",
      "authors": [
        "Yunlong Chen",
        "Yaming Zhang",
        "Jianfei Yu",
        "Li Yang",
        "Rui Xia"
      ],
      "published": "2023-11-06T08:52:11Z",
      "categories": "",
      "summary": "Knowledge Base Question Answering (KBQA) aims to answer factoid questions based on knowledge bases. However, generating the most appropriate knowledge base query code based on Natural Language Questions (NLQ) poses a significant challenge in KBQA. In this work, we focus on the CCKS2023 Competition of Question Answering with Knowledge Graph Inference for Unmanned Systems. Inspired by the recent success of large language models (LLMs) like ChatGPT and GPT-3 in many QA tasks, we propose a ChatGPT-based Cypher Query Language (CQL) generation framework to generate the most appropriate CQL based on ...",
      "pdf_url": "https://arxiv.org/pdf/2311.02956v1.pdf",
      "relevance_score": 26,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.17402v2",
      "title": "CDDIP: Constrained Diffusion-Driven Deep Image Prior for Seismic Image Reconstruction",
      "authors": [
        "Paul Goyes-Pe\u00f1afiel",
        "Ulugbek Kamilov",
        "Henry Arguello"
      ],
      "published": "2024-07-24T16:26:23Z",
      "categories": "",
      "summary": "Seismic data frequently exhibits missing traces, substantially affecting subsequent seismic processing and interpretation. Deep learning-based approaches have demonstrated significant advancements in reconstructing irregularly missing seismic data through supervised and unsupervised methods. Nonetheless, substantial challenges remain, such as generalization capacity and computation time cost during the inference. Our work introduces a reconstruction method that uses a pre-trained generative diffusion model for image synthesis and incorporates Deep Image Prior to enforce data consistency when r...",
      "pdf_url": "https://arxiv.org/pdf/2407.17402v2.pdf",
      "relevance_score": 26,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1205.2603v1",
      "title": "A Bayesian Framework for Community Detection Integrating Content and Link",
      "authors": [
        "Tianbao Yang",
        "Rong Jin",
        "Yun Chi",
        "Shenghuo Zhu"
      ],
      "published": "2012-05-09T18:45:08Z",
      "categories": "",
      "summary": "This paper addresses the problem of community detection in networked data that combines link and content analysis. Most existing work combines link and content information by a generative model. There are two major shortcomings with the existing approaches. First, they assume that the probability of creating a link between two nodes is determined only by the community memberships of the nodes; however other factors (e.g. popularity) could also affect the link pattern. Second, they use generative models to model the content of individual nodes, whereas these generative models are vulnerable to ...",
      "pdf_url": "https://arxiv.org/pdf/1205.2603v1.pdf",
      "relevance_score": 25,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.20950v1",
      "title": "DEMENTIA-PLAN: An Agent-Based Framework for Multi-Knowledge Graph Retrieval-Augmented Generation in Dementia Care",
      "authors": [
        "Yutong Song",
        "Chenhan Lyu",
        "Pengfei Zhang",
        "Sabine Brunswicker",
        "Nikil Dutt",
        "Amir Rahmani"
      ],
      "published": "2025-03-26T19:34:04Z",
      "categories": "",
      "summary": "Mild-stage dementia patients primarily experience two critical symptoms: severe memory loss and emotional instability. To address these challenges, we propose DEMENTIA-PLAN, an innovative retrieval-augmented generation framework that leverages large language models to enhance conversational support. Our model employs a multiple knowledge graph architecture, integrating various dimensional knowledge representations including daily routine graphs and life memory graphs. Through this multi-graph architecture, DEMENTIA-PLAN comprehensively addresses both immediate care needs and facilitates deeper...",
      "pdf_url": "https://arxiv.org/pdf/2503.20950v1.pdf",
      "relevance_score": 25,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.16910v1",
      "title": "Unbiased Reasoning for Knowledge-Intensive Tasks in Large Language Models via Conditional Front-Door Adjustment",
      "authors": [
        "Bo Zhao",
        "Yinghao Zhang",
        "Ziqi Xu",
        "Yongli Ren",
        "Xiuzhen Zhang",
        "Renqiang Luo",
        "Zaiwen Feng",
        "Feng Xia"
      ],
      "published": "2025-08-23T05:52:39Z",
      "categories": "",
      "summary": "Large Language Models (LLMs) have shown impressive capabilities in natural language processing but still struggle to perform well on knowledge-intensive tasks that require deep reasoning and the integration of external knowledge. Although methods such as Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT) have been proposed to enhance LLMs with external knowledge, they still suffer from internal bias in LLMs, which often leads to incorrect answers. In this paper, we propose a novel causal prompting framework, Conditional Front-Door Prompting (CFD-Prompting), which enables the unbia...",
      "pdf_url": "https://arxiv.org/pdf/2508.16910v1.pdf",
      "relevance_score": 25,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.15256v1",
      "title": "Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search",
      "authors": [
        "Edward Kim",
        "Manil Shrestha",
        "Richard Foty",
        "Tom DeLay",
        "Vicki Seyfert-Margolis"
      ],
      "published": "2024-12-16T02:57:00Z",
      "categories": "",
      "summary": "Creation and curation of knowledge graphs can accelerate disease discovery and analysis in real-world data. While disease ontologies aid in biological data annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture patient condition nuances or rare diseases. Multiple disease definitions across data sources complicate ontology mapping and disease clustering. We propose creating patient knowledge graphs using large language model extraction techniques, allowing data extraction via natural language rather than rigid ontological hierarchies. Our method maps to existing ontologies (MeS...",
      "pdf_url": "https://arxiv.org/pdf/2412.15256v1.pdf",
      "relevance_score": 25,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.23783v1",
      "title": "Falcon: A Cross-Modal Evaluation Dataset for Comprehensive Safety Perception",
      "authors": [
        "Qi Xue",
        "Minrui Jiang",
        "Runjia Zhang",
        "Xiurui Xie",
        "Pei Ke",
        "Guisong Liu"
      ],
      "published": "2025-09-28T10:00:37Z",
      "categories": "",
      "summary": "Existing methods for evaluating the harmfulness of content generated by large language models (LLMs) have been well studied. However, approaches tailored to multimodal large language models (MLLMs) remain underdeveloped and lack depth. This work highlights the crucial role of visual information in moderating content in visual question answering (VQA), a dimension often overlooked in current research. To bridge this gap, we introduce Falcon, a large-scale vision-language safety dataset containing 57,515 VQA pairs across 13 harm categories. The dataset provides explicit annotations for harmful a...",
      "pdf_url": "https://arxiv.org/pdf/2509.23783v1.pdf",
      "relevance_score": 25,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2201.07378v1",
      "title": "Tracking Where Events Take Place: Reverse Spatial Term Queries on Streaming Data",
      "authors": [
        "Sara Farazi",
        "Davood Rafiei"
      ],
      "published": "2022-01-19T01:47:20Z",
      "categories": "",
      "summary": "A large volume of content generated by online users is geo-tagged and this provides a rich source for querying in various location-based services. An important class of queries within such services involves the association between content and locations. In this paper, we study two types of queries on streaming geo-tagged data: 1) \"Top-k reverse frequent spatial queries\", where given a term, the goal is to find top K locations where the term is frequent, and 2) \"Term frequency spatial queries\", which is finding the expected frequency of a term in a given location. To efficiently support these q...",
      "pdf_url": "https://arxiv.org/pdf/2201.07378v1.pdf",
      "relevance_score": 25,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.07366v1",
      "title": "Differentially Private GANs for Generating Synthetic Indoor Location Data",
      "authors": [
        "Vahideh Moghtadaiee",
        "Mina Alishahi",
        "Milad Rabiei"
      ],
      "published": "2024-04-10T21:43:27Z",
      "categories": "",
      "summary": "The advent of location-based services has led to the widespread adoption of indoor localization systems, which enable location tracking of individuals within enclosed spaces such as buildings. While these systems provide numerous benefits such as improved security and personalized services, they also raise concerns regarding privacy violations. As such, there is a growing need for privacy-preserving solutions that can protect users' sensitive location information while still enabling the functionality of indoor localization systems. In recent years, Differentially Private Generative Adversaria...",
      "pdf_url": "https://arxiv.org/pdf/2404.07366v1.pdf",
      "relevance_score": 24,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2212.01629v1",
      "title": "Generating Synthetic Data in a Secure Federated General Adversarial Networks for a Consortium of Health Registries",
      "authors": [
        "Narasimha Raghavan Veeraragavan",
        "Jan Franz Nyg\u00e5rd"
      ],
      "published": "2022-12-03T15:01:38Z",
      "categories": "",
      "summary": "In this work, we review the architecture design of existing federated General Adversarial Networks (GAN) solutions and highlight the security and trust-related weaknesses in the existing designs. We then describe how these weaknesses make existing designs unsuitable for the requirements needed for a consortium of health registries working towards generating synthetic datasets for research purposes. Moreover, we propose how these weaknesses can be addressed with our novel architecture solution. Our novel architecture solution combines several building blocks to generate synthetic data in a dece...",
      "pdf_url": "https://arxiv.org/pdf/2212.01629v1.pdf",
      "relevance_score": 24,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1804.00785v1",
      "title": "Learning-Based Task Offloading for Vehicular Cloud Computing Systems",
      "authors": [
        "Yuxuan Sun",
        "Xueying Guo",
        "Sheng Zhou",
        "Zhiyuan Jiang",
        "Xin Liu",
        "Zhisheng Niu"
      ],
      "published": "2018-04-03T02:05:41Z",
      "categories": "",
      "summary": "Vehicular cloud computing (VCC) is proposed to effectively utilize and share the computing and storage resources on vehicles. However, due to the mobility of vehicles, the network topology, the wireless channel states and the available computing resources vary rapidly and are difficult to predict. In this work, we develop a learning-based task offloading framework using the multi-armed bandit (MAB) theory, which enables vehicles to learn the potential task offloading performance of its neighboring vehicles with excessive computing resources, namely service vehicles (SeVs), and minimizes the av...",
      "pdf_url": "https://arxiv.org/pdf/1804.00785v1.pdf",
      "relevance_score": 24,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1901.05205v1",
      "title": "Adaptive Learning-Based Task Offloading for Vehicular Edge Computing Systems",
      "authors": [
        "Yuxuan Sun",
        "Xueying Guo",
        "Jinhui Song",
        "Sheng Zhou",
        "Zhiyuan Jiang",
        "Xin Liu",
        "Zhisheng Niu"
      ],
      "published": "2019-01-16T10:15:02Z",
      "categories": "",
      "summary": "The vehicular edge computing (VEC) system integrates the computing resources of vehicles, and provides computing services for other vehicles and pedestrians with task offloading. However, the vehicular task offloading environment is dynamic and uncertain, with fast varying network topologies, wireless channel states and computing workloads. These uncertainties bring extra challenges to task offloading. In this work, we consider the task offloading among vehicles, and propose a solution that enables vehicles to learn the offloading delay performance of their neighboring vehicles while offloadin...",
      "pdf_url": "https://arxiv.org/pdf/1901.05205v1.pdf",
      "relevance_score": 24,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2505.01877v3",
      "title": "Humans can learn to detect AI-generated texts, or at least learn when they can't",
      "authors": [
        "Ji\u0159\u00ed Mili\u010dka",
        "Anna Marklov\u00e1",
        "Ond\u0159ej Drobil",
        "Eva Posp\u00ed\u0161ilov\u00e1"
      ],
      "published": "2025-05-03T17:42:49Z",
      "categories": "",
      "summary": "This study investigates whether individuals can learn to accurately discriminate between human-written and AI-produced texts when provided with immediate feedback, and if they can use this feedback to recalibrate their self-perceived competence. We also explore the specific criteria individuals rely upon when making these decisions, focusing on textual style and perceived readability.   We used GPT-4o to generate several hundred texts across various genres and text types comparable to Koditex, a multi-register corpus of human-written texts. We then presented randomized text pairs to 254 Czech ...",
      "pdf_url": "https://arxiv.org/pdf/2505.01877v3.pdf",
      "relevance_score": 23,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2008.09279v1",
      "title": "Defending Regression Learners Against Poisoning Attacks",
      "authors": [
        "Sandamal Weerasinghe",
        "Sarah M. Erfani",
        "Tansu Alpcan",
        "Christopher Leckie",
        "Justin Kopacz"
      ],
      "published": "2020-08-21T03:02:58Z",
      "categories": "",
      "summary": "Regression models, which are widely used from engineering applications to financial forecasting, are vulnerable to targeted malicious attacks such as training data poisoning, through which adversaries can manipulate their predictions. Previous works that attempt to address this problem rely on assumptions about the nature of the attack/attacker or overestimate the knowledge of the learner, making them impractical. We introduce a novel Local Intrinsic Dimensionality (LID) based measure called N-LID that measures the local deviation of a given data point's LID with respect to its neighbors. We t...",
      "pdf_url": "https://arxiv.org/pdf/2008.09279v1.pdf",
      "relevance_score": 23,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2309.14770v3",
      "title": "KERMIT: Knowledge Graph Completion of Enhanced Relation Modeling with Inverse Transformation",
      "authors": [
        "Haotian Li",
        "Bin Yu",
        "Yuliang Wei",
        "Kai Wang",
        "Richard Yi Da Xu",
        "Bailing Wang"
      ],
      "published": "2023-09-26T09:03:25Z",
      "categories": "",
      "summary": "Knowledge graph completion (KGC) revolves around populating missing triples in a knowledge graph using available information. Text-based methods, which depend on textual descriptions of triples, often encounter difficulties when these descriptions lack sufficient information for accurate prediction-an issue inherent to the datasets and not easily resolved through modeling alone. To address this and ensure data consistency, we first use large language models (LLMs) to generate coherent descriptions, bridging the semantic gap between queries and answers. Secondly, we utilize inverse relations to...",
      "pdf_url": "https://arxiv.org/pdf/2309.14770v3.pdf",
      "relevance_score": 23,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.17253v3",
      "title": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?",
      "authors": [
        "Huaizhi Ge",
        "Frank Rudzicz",
        "Zining Zhu"
      ],
      "published": "2024-06-25T03:41:02Z",
      "categories": "",
      "summary": "Large language models (LLMs) have demonstrated remarkable capabilities, but updating their knowledge post-training remains a critical challenge. While recent model editing techniques like Rank-One Model Editing (ROME) show promise, their effectiveness may vary based on the nature of the knowledge being edited. We introduce the concept of ``perplexingness'': the degree to which new knowledge conflicts with an LLM's learned conceptual hierarchies and categorical relationships. For instance, editing ``British Shorthair is a kind of cat'' to ``British Shorthair is a kind of dog'' represents a low-...",
      "pdf_url": "https://arxiv.org/pdf/2406.17253v3.pdf",
      "relevance_score": 23,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2406.19502v2",
      "title": "Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization",
      "authors": [
        "Miyoung Ko",
        "Sue Hyun Park",
        "Joonsuk Park",
        "Minjoon Seo"
      ],
      "published": "2024-06-27T19:29:36Z",
      "categories": "",
      "summary": "Despite the advances in large language models (LLMs), how they use their knowledge for reasoning is not yet well understood. In this study, we propose a method that deconstructs complex real-world questions into a graph, representing each question as a node with predecessors of background knowledge needed to solve the question. We develop the DepthQA dataset, deconstructing questions into three depths: (i) recalling conceptual knowledge, (ii) applying procedural knowledge, and (iii) analyzing strategic knowledge. Based on a hierarchical graph, we quantify forward discrepancy, a discrepancy in ...",
      "pdf_url": "https://arxiv.org/pdf/2406.19502v2.pdf",
      "relevance_score": 23,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.15714v1",
      "title": "TrustDataFilter:Leveraging Trusted Knowledge Base Data for More Effective Filtering of Unknown Information",
      "authors": [
        "Jinghong Zhang",
        "Yidong Cui",
        "Weiling Wang",
        "Xianyou Cheng"
      ],
      "published": "2025-01-25T04:18:35Z",
      "categories": "",
      "summary": "With the advancement of technology and changes in the market, the demand for the construction of domain-specific knowledge bases has been increasing, either to improve model performance or to promote enterprise innovation and competitiveness. The construction of domain-specific knowledge bases typically relies on web crawlers or existing industry databases, leading to problems with accuracy and consistency of the data. To address these challenges, we considered the characteristics of domain data, where internal knowledge is interconnected, and proposed the Self-Natural Language Inference Data ...",
      "pdf_url": "https://arxiv.org/pdf/2502.15714v1.pdf",
      "relevance_score": 23,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.16490v2",
      "title": "Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs",
      "authors": [
        "Alexander Scarlatos",
        "Ryan S. Baker",
        "Andrew Lan"
      ],
      "published": "2024-09-24T22:31:39Z",
      "categories": "",
      "summary": "Recent advances in large language models (LLMs) have led to the development of artificial intelligence (AI)-powered tutoring chatbots, showing promise in providing broad access to high-quality personalized education. Existing works have studied how to make LLMs follow tutoring principles, but have not studied broader uses of LLMs for supporting tutoring. Up until now, tracing student knowledge and analyzing misconceptions has been difficult and time-consuming to implement for open-ended dialogue tutoring. In this work, we investigate whether LLMs can be supportive of this task: we first use LL...",
      "pdf_url": "https://arxiv.org/pdf/2409.16490v2.pdf",
      "relevance_score": 23,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2408.01310v3",
      "title": "PsybORG+: Modeling and Simulation for Detecting Cognitive Biases in Advanced Persistent Threats",
      "authors": [
        "Shuo Huang",
        "Fred Jones",
        "Nikolos Gurney",
        "David Pynadath",
        "Kunal Srivastava",
        "Stoney Trent",
        "Peggy Wu",
        "Quanyan Zhu"
      ],
      "published": "2024-08-02T15:00:58Z",
      "categories": "",
      "summary": "Advanced Persistent Threats (APTs) bring significant challenges to cybersecurity due to their sophisticated and stealthy nature. Traditional cybersecurity measures fail to defend against APTs. Cognitive vulnerabilities can significantly influence attackers' decision-making processes, which presents an opportunity for defenders to exploit. This work introduces PsybORG$^+$, a multi-agent cybersecurity simulation environment designed to model APT behaviors influenced by cognitive vulnerabilities. A classification model is built for cognitive vulnerability inference and a simulator is designed for...",
      "pdf_url": "https://arxiv.org/pdf/2408.01310v3.pdf",
      "relevance_score": 22,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2508.03284v1",
      "title": "ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools",
      "authors": [
        "Shaofeng Yin",
        "Ting Lei",
        "Yang Liu"
      ],
      "published": "2025-08-05T10:06:16Z",
      "categories": "",
      "summary": "Integrating external tools into Large Foundation Models (LFMs) has emerged as a promising approach to enhance their problem-solving capabilities. While existing studies have demonstrated strong performance in tool-augmented Visual Question Answering (VQA), recent benchmarks reveal significant gaps in real-world tool-use proficiency, particularly in functionally diverse multimodal settings requiring multi-step reasoning. In this work, we introduce ToolVQA, a large-scale multimodal dataset comprising 23K instances, designed to bridge this gap. Unlike previous datasets that rely on synthetic scen...",
      "pdf_url": "https://arxiv.org/pdf/2508.03284v1.pdf",
      "relevance_score": 22,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.11733v1",
      "title": "LLM Agents for Education: Advances and Applications",
      "authors": [
        "Zhendong Chu",
        "Shen Wang",
        "Jian Xie",
        "Tinghui Zhu",
        "Yibo Yan",
        "Jinheng Ye",
        "Aoxiao Zhong",
        "Xuming Hu",
        "Jing Liang",
        "Philip S. Yu",
        "Qingsong Wen"
      ],
      "published": "2025-03-14T11:53:44Z",
      "categories": "",
      "summary": "Large Language Model (LLM) agents have demonstrated remarkable capabilities in automating tasks and driving innovation across diverse educational applications. In this survey, we provide a systematic review of state-of-the-art research on LLM agents in education, categorizing them into two broad classes: (1) \\emph{Pedagogical Agents}, which focus on automating complex pedagogical tasks to support both teachers and students; and (2) \\emph{Domain-Specific Educational Agents}, which are tailored for specialized fields such as science education, language learning, and professional development. We ...",
      "pdf_url": "https://arxiv.org/pdf/2503.11733v1.pdf",
      "relevance_score": 21,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.18708v1",
      "title": "Embracing AI in Education: Understanding the Surge in Large Language Model Use by Secondary Students",
      "authors": [
        "Tiffany Zhu",
        "Kexun Zhang",
        "William Yang Wang"
      ],
      "published": "2024-11-27T19:19:34Z",
      "categories": "",
      "summary": "The impressive essay writing and problem-solving capabilities of large language models (LLMs) like OpenAI's ChatGPT have opened up new avenues in education. Our goal is to gain insights into the widespread use of LLMs among secondary students to inform their future development. Despite school restrictions, our survey of over 300 middle and high school students revealed that a remarkable 70% of students have utilized LLMs, higher than the usage percentage among young adults, and this percentage remains consistent across 7th to 12th grade. Students also reported using LLMs for multiple subjects,...",
      "pdf_url": "https://arxiv.org/pdf/2411.18708v1.pdf",
      "relevance_score": 21,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.10855v4",
      "title": "Core Knowledge Deficits in Multi-Modal Language Models",
      "authors": [
        "Yijiang Li",
        "Qingying Gao",
        "Tianwei Zhao",
        "Bingyang Wang",
        "Haoran Sun",
        "Haiyun Lyu",
        "Robert D. Hawkins",
        "Nuno Vasconcelos",
        "Tal Golan",
        "Dezhi Luo",
        "Hokin Deng"
      ],
      "published": "2024-10-06T20:13:11Z",
      "categories": "",
      "summary": "While Multi-modal Large Language Models (MLLMs) demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasks that are intuitive and effortless for humans. We examine the hypothesis that these deficiencies stem from the absence of core knowledge--rudimentary cognitive abilities innate to humans from early childhood. To explore the core knowledge representation in MLLMs, we introduce CoreCognition, a large-scale benchmark encompassing 12 core knowledge concepts grounded in developmental cognitive science. We...",
      "pdf_url": "https://arxiv.org/pdf/2410.10855v4.pdf",
      "relevance_score": 21,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2410.10829v3",
      "title": "Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks",
      "authors": [
        "Zhangqi Duan",
        "Nigel Fernandez",
        "Alexander Hicks",
        "Andrew Lan"
      ],
      "published": "2024-09-28T03:13:40Z",
      "categories": "",
      "summary": "Open-ended coding tasks, which ask students to construct programs according to certain specifications, are common in computer science education. Student modeling can be challenging since their open-ended nature means that student code can be diverse. Traditional knowledge tracing (KT) models that only analyze response correctness may not fully capture nuances in student knowledge from student code. In this paper, we introduce Test case-Informed Knowledge Tracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze and predict both open-ended student code and whether the code p...",
      "pdf_url": "https://arxiv.org/pdf/2410.10829v3.pdf",
      "relevance_score": 21,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2307.11772v3",
      "title": "AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment enabled by Large Language Models",
      "authors": [
        "Rui Zhang",
        "Yixin Su",
        "Bayu Distiawan Trisedya",
        "Xiaoyan Zhao",
        "Min Yang",
        "Hong Cheng",
        "Jianzhong Qi"
      ],
      "published": "2023-07-18T04:43:24Z",
      "categories": "",
      "summary": "The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require manually crafted seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help...",
      "pdf_url": "https://arxiv.org/pdf/2307.11772v3.pdf",
      "relevance_score": 21,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.03034v1",
      "title": "Knowledge Distillation from Large Language Models for Household Energy Modeling",
      "authors": [
        "Mohannad Takrouri",
        "Nicol\u00e1s M. Cuadrado",
        "Martin Tak\u00e1\u010d"
      ],
      "published": "2025-02-05T09:43:14Z",
      "categories": "",
      "summary": "Machine learning (ML) is increasingly vital for smart-grid research, yet restricted access to realistic, diverse data - often due to privacy concerns - slows progress and fuels doubts within the energy sector about adopting ML-based strategies. We propose integrating Large Language Models (LLMs) in energy modeling to generate realistic, culturally sensitive, and behavior-specific data for household energy usage across diverse geographies. In this study, we employ and compare five different LLMs to systematically produce family structures, weather patterns, and daily consumption profiles for ho...",
      "pdf_url": "https://arxiv.org/pdf/2502.03034v1.pdf",
      "relevance_score": 21,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2411.19417v2",
      "title": "Any-Resolution AI-Generated Image Detection by Spectral Learning",
      "authors": [
        "Dimitrios Karageorgiou",
        "Symeon Papadopoulos",
        "Ioannis Kompatsiaris",
        "Efstratios Gavves"
      ],
      "published": "2024-11-28T23:55:19Z",
      "categories": "",
      "summary": "Recent works have established that AI models introduce spectral artifacts into generated images and propose approaches for learning to capture them using labeled data. However, the significant differences in such artifacts among different generative models hinder these approaches from generalizing to generators not seen during training. In this work, we build upon the key idea that the spectral distribution of real images constitutes both an invariant and highly discriminative pattern for AI-generated image detection. To model this under a self-supervised setup, we employ masked spectral learn...",
      "pdf_url": "https://arxiv.org/pdf/2411.19417v2.pdf",
      "relevance_score": 20,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1811.04422v1",
      "title": "An Optimal Control View of Adversarial Machine Learning",
      "authors": [
        "Xiaojin Zhu"
      ],
      "published": "2018-11-11T14:28:34Z",
      "categories": "",
      "summary": "I describe an optimal control view of adversarial machine learning, where the dynamical system is the machine learner, the input are adversarial actions, and the control costs are defined by the adversary's goals to do harm and be hard to detect. This view encompasses many types of adversarial machine learning, including test-item attacks, training-data poisoning, and adversarial reward shaping. The view encourages adversarial machine learning researcher to utilize advances in control theory and reinforcement learning.",
      "pdf_url": "https://arxiv.org/pdf/1811.04422v1.pdf",
      "relevance_score": 20,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.15109v1",
      "title": "Targeted Attacks and Defenses for Distributed Federated Learning in Vehicular Networks",
      "authors": [
        "Utku Demir",
        "Tugba Erpek",
        "Yalin E. Sagduyu",
        "Sastry Kompella",
        "Mengran Xue"
      ],
      "published": "2025-10-16T20:05:13Z",
      "categories": "",
      "summary": "In emerging networked systems, mobile edge devices such as ground vehicles and unmanned aerial system (UAS) swarms collectively aggregate vast amounts of data to make machine learning decisions such as threat detection in remote, dynamic, and infrastructure-constrained environments where power and bandwidth are scarce. Federated learning (FL) addresses these constraints and privacy concerns by enabling nodes to share local model weights for deep neural networks instead of raw data, facilitating more reliable decision-making than individual learning. However, conventional FL relies on a central...",
      "pdf_url": "https://arxiv.org/pdf/2510.15109v1.pdf",
      "relevance_score": 20,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2412.07493v3",
      "title": "LLM-guided Task and Motion Planning using Knowledge-based Reasoning",
      "authors": [
        "Muhayy Ud Din",
        "Jan Rosell",
        "Waseem Akram",
        "Isiah Zaplana",
        "Maximo A Roa",
        "Irfan Hussain"
      ],
      "published": "2024-12-10T13:18:45Z",
      "categories": "",
      "summary": "Performing complex manipulation tasks in dynamic environments requires efficient Task and Motion Planning (TAMP) approaches that combine high-level symbolic plans with low-level motion control. Advances in Large Language Models (LLMs), such as GPT-4, are transforming task planning by offering natural language as an intuitive and flexible way to describe tasks, generate symbolic plans, and reason. However, the effectiveness of LLM-based TAMP approaches is limited due to static and template-based prompting, which limits adaptability to dynamic environments and complex task contexts. To address t...",
      "pdf_url": "https://arxiv.org/pdf/2412.07493v3.pdf",
      "relevance_score": 20,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2307.06985v10",
      "title": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "authors": [
        "L. Siddharth",
        "Jianxi Luo"
      ],
      "published": "2023-07-13T17:25:28Z",
      "categories": "",
      "summary": "Aiming to support Retrieval Augmented Generation (RAG) in the design process, we present a method to identify explicit, engineering design facts - {head entity :: relationship :: tail entity} from patented artefact descriptions. Given a sentence with a pair of entities (based on noun phrases) marked in a unique manner, our method extracts the relationship that is explicitly communicated in the sentence. For this task, we create a dataset of 375,084 examples and fine-tune language models for relation identification (token classification) and elicitation (sequence-to-sequence). The token classif...",
      "pdf_url": "https://arxiv.org/pdf/2307.06985v10.pdf",
      "relevance_score": 20,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.15401v3",
      "title": "Large Language Model for Mental Health: A Systematic Review",
      "authors": [
        "Zhijun Guo",
        "Alvina Lai",
        "Johan Hilge Thygesen",
        "Joseph Farrington",
        "Thomas Keen",
        "Kezhi Li"
      ],
      "published": "2024-02-19T17:58:41Z",
      "categories": "",
      "summary": "Large language models (LLMs) have attracted significant attention for potential applications in digital health, while their application in mental health is subject to ongoing debate. This systematic review aims to evaluate the usage of LLMs in mental health, focusing on their strengths and limitations in early screening, digital interventions, and clinical applications. Adhering to PRISMA guidelines, we searched PubMed, IEEE Xplore, Scopus, JMIR, and ACM using keywords: 'mental health OR mental illness OR mental disorder OR psychiatry' AND 'large language models'. We included articles publishe...",
      "pdf_url": "https://arxiv.org/pdf/2403.15401v3.pdf",
      "relevance_score": 20,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2207.13500v1",
      "title": "Modelling Social Context for Fake News Detection: A Graph Neural Network Based Approach",
      "authors": [
        "Pallabi Saikia",
        "Kshitij Gundale",
        "Ankit Jain",
        "Dev Jadeja",
        "Harvi Patel",
        "Mohendra Roy"
      ],
      "published": "2022-07-27T12:58:33Z",
      "categories": "",
      "summary": "Detection of fake news is crucial to ensure the authenticity of information and maintain the news ecosystems reliability. Recently, there has been an increase in fake news content due to the recent proliferation of social media and fake content generation techniques such as Deep Fake. The majority of the existing modalities of fake news detection focus on content based approaches. However, most of these techniques fail to deal with ultra realistic synthesized media produced by generative models. Our recent studies find that the propagation characteristics of authentic and fake news are disting...",
      "pdf_url": "https://arxiv.org/pdf/2207.13500v1.pdf",
      "relevance_score": 20,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2309.08075v1",
      "title": "Social media polarization reflects shifting political alliances in Pakistan",
      "authors": [
        "Anees Baqir",
        "Alessandro Galeazzi",
        "Andrea Drocco",
        "Fabiana Zollo"
      ],
      "published": "2023-09-15T00:07:48Z",
      "categories": "",
      "summary": "The rise of ideological divides in public discourse has received considerable attention in recent years. However, much of this research has been concentrated on Western democratic nations, leaving other regions largely unexplored. Here, we delve into the political landscape of Pakistan, a nation marked by intricate political dynamics and persistent turbulence. Spanning from 2018 to 2022, our analysis of Twitter data allows us to capture pivotal shifts and developments in Pakistan's political arena. By examining interactions and content generated by politicians affiliated with major political p...",
      "pdf_url": "https://arxiv.org/pdf/2309.08075v1.pdf",
      "relevance_score": 20,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2502.05215v1",
      "title": "Watermarking across Modalities for Content Tracing and Generative AI",
      "authors": [
        "Pierre Fernandez"
      ],
      "published": "2025-02-04T18:49:50Z",
      "categories": "",
      "summary": "Watermarking embeds information into digital content like images, audio, or text, imperceptible to humans but robustly detectable by specific algorithms. This technology has important applications in many challenges of the industry such as content moderation, tracing AI-generated content, and monitoring the usage of AI models. The contributions of this thesis include the development of new watermarking techniques for images, audio, and text. We first introduce methods for active moderation of images on social platforms. We then develop specific techniques for AI-generated content. We specifica...",
      "pdf_url": "https://arxiv.org/pdf/2502.05215v1.pdf",
      "relevance_score": 18,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2306.08302v3",
      "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
      "authors": [
        "Shirui Pan",
        "Linhao Luo",
        "Yufei Wang",
        "Chen Chen",
        "Jiapu Wang",
        "Xindong Wu"
      ],
      "published": "2023-06-14T07:15:26Z",
      "categories": "",
      "summary": "Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolving b...",
      "pdf_url": "https://arxiv.org/pdf/2306.08302v3.pdf",
      "relevance_score": 18,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.11017v1",
      "title": "AI Agent-Driven Framework for Automated Product Knowledge Graph Construction in E-Commerce",
      "authors": [
        "Dimitar Peshevski",
        "Riste Stojanov",
        "Dimitar Trajanov"
      ],
      "published": "2025-11-14T07:09:13Z",
      "categories": "",
      "summary": "The rapid expansion of e-commerce platforms generates vast amounts of unstructured product data, creating significant challenges for information retrieval, recommendation systems, and data analytics. Knowledge Graphs (KGs) offer a structured, interpretable format to organize such data, yet constructing product-specific KGs remains a complex and manual process. This paper introduces a fully automated, AI agent-driven framework for constructing product knowledge graphs directly from unstructured product descriptions. Leveraging Large Language Models (LLMs), our method operates in three stages us...",
      "pdf_url": "https://arxiv.org/pdf/2511.11017v1.pdf",
      "relevance_score": 18,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2503.22736v1",
      "title": "Cyborg Data: Merging Human with AI Generated Training Data",
      "authors": [
        "Kai North",
        "Christopher Ormerod"
      ],
      "published": "2025-03-26T16:38:20Z",
      "categories": "",
      "summary": "Automated scoring (AS) systems used in large-scale assessment have traditionally used small statistical models that require a large quantity of hand-scored data to make accurate predictions, which can be time-consuming and costly. Generative Large Language Models are trained on many tasks and have shown impressive abilities to generalize to new tasks with little to no data. While these models require substantially more computational power to make predictions, they still require some fine-tuning to meet operational standards. Evidence suggests that these models can exceed human-human levels of ...",
      "pdf_url": "https://arxiv.org/pdf/2503.22736v1.pdf",
      "relevance_score": 16,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2504.00310v1",
      "title": "Detecting and Mitigating Bias in LLMs through Knowledge Graph-Augmented Training",
      "authors": [
        "Rajeev Kumar",
        "Harishankar Kumar",
        "Kumari Shalini"
      ],
      "published": "2025-04-01T00:27:50Z",
      "categories": "",
      "summary": "Large language models have revolutionized natural language processing with their surprising capability to understand and generate human-like text. However, many of these models inherit and further amplify the biases present in their training data, raising ethical and fairness concerns. The detection and mitigation of such biases are vital to ensuring that LLMs act responsibly and equitably across diverse domains. This work investigates Knowledge Graph-Augmented Training (KGAT) as a novel method to mitigate bias in LLM. Using structured domain-specific knowledge from real-world knowledge graphs...",
      "pdf_url": "https://arxiv.org/pdf/2504.00310v1.pdf",
      "relevance_score": 16,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.09744v1",
      "title": "Evaluating the Application of Large Language Models to Generate Feedback in Programming Education",
      "authors": [
        "Sven Jacobs",
        "Steffen Jaschke"
      ],
      "published": "2024-03-13T23:14:35Z",
      "categories": "",
      "summary": "This study investigates the application of large language models, specifically GPT-4, to enhance programming education. The research outlines the design of a web application that uses GPT-4 to provide feedback on programming tasks, without giving away the solution. A web application for working on programming tasks was developed for the study and evaluated with 51 students over the course of one semester. The results show that most of the feedback generated by GPT-4 effectively addressed code errors. However, challenges with incorrect suggestions and hallucinated issues indicate the need for f...",
      "pdf_url": "https://arxiv.org/pdf/2403.09744v1.pdf",
      "relevance_score": 15,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2403.08319v2",
      "title": "Knowledge Conflicts for LLMs: A Survey",
      "authors": [
        "Rongwu Xu",
        "Zehan Qi",
        "Zhijiang Guo",
        "Cunxiang Wang",
        "Hongru Wang",
        "Yue Zhang",
        "Wei Xu"
      ],
      "published": "2024-03-13T08:02:23Z",
      "categories": "",
      "summary": "This survey provides an in-depth analysis of knowledge conflicts for large language models (LLMs), highlighting the complex challenges they encounter when blending contextual and parametric knowledge. Our focus is on three categories of knowledge conflicts: context-memory, inter-context, and intra-memory conflict. These conflicts can significantly impact the trustworthiness and performance of LLMs, especially in real-world applications where noise and misinformation are common. By categorizing these conflicts, exploring the causes, examining the behaviors of LLMs under such conflicts, and revi...",
      "pdf_url": "https://arxiv.org/pdf/2403.08319v2.pdf",
      "relevance_score": 15,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2309.08491v1",
      "title": "Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata",
      "authors": [
        "Bohui Zhang",
        "Ioannis Reklos",
        "Nitisha Jain",
        "Albert Mero\u00f1o Pe\u00f1uela",
        "Elena Simperl"
      ],
      "published": "2023-09-15T15:51:14Z",
      "categories": "",
      "summary": "In this work, we explore the use of Large Language Models (LLMs) for knowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge. For this task, given subject and relation pairs sourced from Wikidata, we utilize pre-trained LLMs to produce the relevant objects in string format and link them to their respective Wikidata QIDs. We developed a pipeline using LLMs for Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata entity mapping. The method achieved a macro-averaged F1-score of 0.701 across the properties, with the scores varying from 1.00 to 0.328. These r...",
      "pdf_url": "https://arxiv.org/pdf/2309.08491v1.pdf",
      "relevance_score": 15,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2407.16073v1",
      "title": "KaPQA: Knowledge-Augmented Product Question-Answering",
      "authors": [
        "Swetha Eppalapally",
        "Daksh Dangi",
        "Chaithra Bhat",
        "Ankita Gupta",
        "Ruiyi Zhang",
        "Shubham Agarwal",
        "Karishma Bagga",
        "Seunghyun Yoon",
        "Nedim Lipka",
        "Ryan A. Rossi",
        "Franck Dernoncourt"
      ],
      "published": "2024-07-22T22:14:56Z",
      "categories": "",
      "summary": "Question-answering for domain-specific applications has recently attracted much interest due to the latest advancements in large language models (LLMs). However, accurately assessing the performance of these applications remains a challenge, mainly due to the lack of suitable benchmarks that effectively simulate real-world scenarios. To address this challenge, we introduce two product question-answering (QA) datasets focused on Adobe Acrobat and Photoshop products to help evaluate the performance of existing models on domain-specific product QA tasks. Additionally, we propose a novel knowledge...",
      "pdf_url": "https://arxiv.org/pdf/2407.16073v1.pdf",
      "relevance_score": 15,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2405.17249v2",
      "title": "Assessing LLMs Suitability for Knowledge Graph Completion",
      "authors": [
        "Vasile Ionut Remus Iga",
        "Gheorghe Cosmin Silaghi"
      ],
      "published": "2024-05-27T15:04:50Z",
      "categories": "",
      "summary": "Recent work has shown the capability of Large Language Models (LLMs) to solve tasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in Zero- or Few-Shot paradigms. However, they are known to hallucinate answers, or output results in a non-deterministic manner, thus leading to wrongly reasoned responses, even if they satisfy the user's demands. To highlight opportunities and challenges in knowledge graphs-related tasks, we experiment with three distinguished LLMs, namely Mixtral-8x7b-Instruct-v0.1, GPT-3.5-Turbo-0125 and GPT-4o, on Knowledge Graph Completion for static kno...",
      "pdf_url": "https://arxiv.org/pdf/2405.17249v2.pdf",
      "relevance_score": 15,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "1906.03671v2",
      "title": "Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds",
      "authors": [
        "Jordan T. Ash",
        "Chicheng Zhang",
        "Akshay Krishnamurthy",
        "John Langford",
        "Alekh Agarwal"
      ],
      "published": "2019-06-09T16:52:09Z",
      "categories": "",
      "summary": "We design a new algorithm for batch active learning with deep neural network models. Our algorithm, Batch Active learning by Diverse Gradient Embeddings (BADGE), samples groups of points that are disparate and high-magnitude when represented in a hallucinated gradient space, a strategy designed to incorporate both predictive uncertainty and sample diversity into every selected batch. Crucially, BADGE trades off between diversity and uncertainty without requiring any hand-tuned hyperparameters. We show that while other approaches sometimes succeed for particular batch sizes or architectures, BA...",
      "pdf_url": "https://arxiv.org/pdf/1906.03671v2.pdf",
      "relevance_score": 12,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2510.12172v2",
      "title": "Leaking Queries On Secure Stream Processing Systems",
      "authors": [
        "Hung Pham",
        "Viet Vo",
        "Tien Tuan Anh Dinh",
        "Duc Tran",
        "Shuhao Zhang"
      ],
      "published": "2025-10-14T06:01:14Z",
      "categories": "",
      "summary": "Stream processing systems are important in modern applications in which data arrive continuously and need to be processed in real time. Because of their resource and scalability requirements, many of these systems run on the cloud, which is considered untrusted. Existing works on securing databases on the cloud focus on protecting the data, and most systems leverage trusted hardware for high performance. However, in stream processing systems, queries are as sensitive as the data because they contain the application logics.   We demonstrate that it is practical to extract the queries from strea...",
      "pdf_url": "https://arxiv.org/pdf/2510.12172v2.pdf",
      "relevance_score": 12,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2409.19090v1",
      "title": "Calibrating microscopic traffic models with macroscopic data",
      "authors": [
        "Yanbing Wang",
        "Felipe de Souza",
        "Dominik Karbowski"
      ],
      "published": "2024-09-27T18:41:26Z",
      "categories": "",
      "summary": "Traffic microsimulation is a crucial tool that uses microscopic traffic models, such as car-following and lane-change models, to simulate the trajectories of individual agents. This digital platform allows for the assessment of the impact of emerging technologies on transportation system performance. While these microscopic models are based on mathematical structures, their parameters must be fitted to real-world data through a process called model calibration. Despite extensive studies on calibration, the focus has predominantly been on fitting microscopic data, such as trajectories, rather t...",
      "pdf_url": "https://arxiv.org/pdf/2409.19090v1.pdf",
      "relevance_score": 12,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2509.08950v1",
      "title": "Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities",
      "authors": [
        "Jarvis Haupt",
        "Qin Lu",
        "Yanning Shen",
        "Jia Chen",
        "Yue Dong",
        "Dan McCreary",
        "Mehmet Ak\u00e7akaya",
        "Georgios B. Giannakis"
      ],
      "published": "2025-09-10T19:19:26Z",
      "categories": "",
      "summary": "Powerful artificial intelligence (AI) tools that have emerged in recent years -- including large language models, automated coding assistants, and advanced image and speech generation technologies -- are the result of monumental human achievements. These breakthroughs reflect mastery across multiple technical disciplines and the resolution of significant technological challenges. However, some of the most profound challenges may still lie ahead. These challenges are not purely technical but pertain to the fair and responsible use of AI in ways that genuinely improve the global human condition....",
      "pdf_url": "https://arxiv.org/pdf/2509.08950v1.pdf",
      "relevance_score": 10,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2511.06455v1",
      "title": "A Multi-Agent System for Semantic Mapping of Relational Data to Knowledge Graphs",
      "authors": [
        "Milena Trajanoska",
        "Riste Stojanov",
        "Dimitar Trajanov"
      ],
      "published": "2025-11-09T16:41:46Z",
      "categories": "",
      "summary": "Enterprises often maintain multiple databases for storing critical business data in siloed systems, resulting in inefficiencies and challenges with data interoperability. A key to overcoming these challenges lies in integrating disparate data sources, enabling businesses to unlock the full potential of their data. Our work presents a novel approach for integrating multiple databases using knowledge graphs, focusing on the application of large language models as semantic agents for mapping and connecting structured data across systems by leveraging existing vocabularies. The proposed methodolog...",
      "pdf_url": "https://arxiv.org/pdf/2511.06455v1.pdf",
      "relevance_score": 0,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2310.00637v1",
      "title": "Knowledge Engineering using Large Language Models",
      "authors": [
        "Bradley P. Allen",
        "Lise Stork",
        "Paul Groth"
      ],
      "published": "2023-10-01T10:26:25Z",
      "categories": "",
      "summary": "Knowledge engineering is a discipline that focuses on the creation and maintenance of processes that generate and apply knowledge. Traditionally, knowledge engineering approaches have focused on knowledge expressed in formal languages. The emergence of large language models and their capabilities to effectively work with natural language, in its broadest sense, raises questions about the foundations and practice of knowledge engineering. Here, we outline the potential role of LLMs in knowledge engineering, identifying two central directions: 1) creating hybrid neuro-symbolic knowledge systems;...",
      "pdf_url": "https://arxiv.org/pdf/2310.00637v1.pdf",
      "relevance_score": 0,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2309.12731v1",
      "title": "Defeasible Reasoning with Knowledge Graphs",
      "authors": [
        "Dave Raggett"
      ],
      "published": "2023-09-22T09:27:26Z",
      "categories": "",
      "summary": "Human knowledge is subject to uncertainties, imprecision, incompleteness and inconsistencies. Moreover, the meaning of many everyday terms is dependent on the context. That poses a huge challenge for the Semantic Web. This paper introduces work on an intuitive notation and model for defeasible reasoning with imperfect knowledge, and relates it to previous work on argumentation theory. PKN is to N3 as defeasible reasoning is to deductive logic. Further work is needed on an intuitive syntax for describing reasoning strategies and tactics in declarative terms, drawing upon the AIF ontology for in...",
      "pdf_url": "https://arxiv.org/pdf/2309.12731v1.pdf",
      "relevance_score": 0,
      "dimension": "cluster_f_training"
    },
    {
      "arxiv_id": "2404.06833v3",
      "title": "Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural Knowledge",
      "authors": [
        "Li Zhou",
        "Taelin Karidi",
        "Wanlong Liu",
        "Nicolas Garneau",
        "Yong Cao",
        "Wenyu Chen",
        "Haizhou Li",
        "Daniel Hershcovich"
      ],
      "published": "2024-04-10T08:49:27Z",
      "categories": "",
      "summary": "Recent studies have highlighted the presence of cultural biases in Large Language Models (LLMs), yet often lack a robust methodology to dissect these phenomena comprehensively. Our work aims to bridge this gap by delving into the Food domain, a universally relevant yet culturally diverse aspect of human life. We introduce FmLAMA, a multilingual dataset centered on food-related cultural facts and variations in food practices. We analyze LLMs across various architectures and configurations, evaluating their performance in both monolingual and multilingual settings. By leveraging templates in six...",
      "pdf_url": "https://arxiv.org/pdf/2404.06833v3.pdf",
      "relevance_score": 0,
      "dimension": "cluster_f_training"
    }
  ],
  "green_papers": [
    {
      "arxiv_id": "2501.08292v1",
      "title": "HALoGEN: Fantastic LLM Hallucinations and Where to Find Them",
      "authors": [
        "Abhilasha Ravichander",
        "Shrusti Ghela",
        "David Wadden",
        "Yejin Choi"
      ],
      "published": "2025-01-14T18:13:08Z",
      "categories": "",
      "summary": "Despite their impressive ability to generate high-quality and fluent text, generative large language models (LLMs) also produce hallucinations: statements that are misaligned with established world knowledge or provided input context. However, measuring hallucination can be challenging, as having humans verify model generations on-the-fly is both expensive and time-consuming. In this work, we release HALoGEN, a comprehensive hallucination benchmark consisting of: (1) 10,923 prompts for generative models spanning nine domains including programming, scientific attribution, and summarization, and...",
      "pdf_url": "https://arxiv.org/pdf/2501.08292v1.pdf",
      "relevance_score": 97,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2501.08292v1_paper.pdf"
    },
    {
      "arxiv_id": "2412.02980v2",
      "title": "Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models",
      "authors": [
        "Alex Havrilla",
        "Andrew Dai",
        "Laura O'Mahony",
        "Koen Oostermeijer",
        "Vera Zisler",
        "Alon Albalak",
        "Fabrizio Milo",
        "Sharath Chandra Raparthy",
        "Kanishk Gandhi",
        "Baber Abbasi",
        "Duy Phung",
        "Maia Iyer",
        "Dakota Mahan",
        "Chase Blagden",
        "Srishti Gureja",
        "Mohammed Hamdy",
        "Wen-Ding Li",
        "Giovanni Paolini",
        "Pawan Sasanka Ammanamanchi",
        "Elliot Meyerson"
      ],
      "published": "2024-12-04T02:47:45Z",
      "categories": "",
      "summary": "Synthetic data generation with Large Language Models is a promising paradigm for augmenting natural data over a nearly infinite range of tasks. Given this variety, direct comparisons among synthetic data generation algorithms are scarce, making it difficult to understand where improvement comes from and what bottlenecks exist. We propose to evaluate algorithms via the makeup of synthetic data generated by each algorithm in terms of data quality, diversity, and complexity. We choose these three characteristics for their significance in open-ended processes and the impact each has on the capabil...",
      "pdf_url": "https://arxiv.org/pdf/2412.02980v2.pdf",
      "relevance_score": 97,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2412.02980v2_paper.pdf"
    },
    {
      "arxiv_id": "2406.09358v2",
      "title": "Understanding Hallucinations in Diffusion Models through Mode Interpolation",
      "authors": [
        "Sumukh K Aithal",
        "Pratyush Maini",
        "Zachary C. Lipton",
        "J. Zico Kolter"
      ],
      "published": "2024-06-13T17:43:41Z",
      "categories": "",
      "summary": "Colloquially speaking, image generation models based upon diffusion processes are frequently said to exhibit \"hallucinations,\" samples that could never occur in the training data. But where do such hallucinations come from? In this paper, we study a particular failure mode in diffusion models, which we term mode interpolation. Specifically, we find that diffusion models smoothly \"interpolate\" between nearby data modes in the training set, to generate samples that are completely outside the support of the original training distribution; this phenomenon leads diffusion models to generate artifac...",
      "pdf_url": "https://arxiv.org/pdf/2406.09358v2.pdf",
      "relevance_score": 93,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2406.09358v2_paper.pdf"
    },
    {
      "arxiv_id": "2509.11273v1",
      "title": "Synthetic Dataset Evaluation Based on Generalized Cross Validation",
      "authors": [
        "Zhihang Song",
        "Dingyi Yao",
        "Ruibo Ming",
        "Lihui Peng",
        "Danya Yao",
        "Yi Zhang"
      ],
      "published": "2025-09-14T13:57:33Z",
      "categories": "",
      "summary": "With the rapid advancement of synthetic dataset generation techniques, evaluating the quality of synthetic data has become a critical research focus. Robust evaluation not only drives innovations in data generation methods but also guides researchers in optimizing the utilization of these synthetic resources. However, current evaluation studies for synthetic datasets remain limited, lacking a universally accepted standard framework. To address this, this paper proposes a novel evaluation framework integrating generalized cross-validation experiments and domain transfer learning principles, ena...",
      "pdf_url": "https://arxiv.org/pdf/2509.11273v1.pdf",
      "relevance_score": 89,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2509.11273v1_paper.pdf"
    },
    {
      "arxiv_id": "2510.24052v1",
      "title": "SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration",
      "authors": [
        "Jongsuk Kim",
        "Jaeyoung Lee",
        "Gyojin Han",
        "Dongjae Lee",
        "Minki Jeong",
        "Junmo Kim"
      ],
      "published": "2025-10-28T04:22:02Z",
      "categories": "",
      "summary": "Recent advancements in deep learning and the availability of high-quality real-world driving datasets have propelled end-to-end autonomous driving. Despite this progress, relying solely on real-world data limits the variety of driving scenarios for training. Synthetic scenario generation has emerged as a promising solution to enrich the diversity of training data; however, its application within E2E AD models remains largely unexplored. This is primarily due to the absence of a designated ego vehicle and the associated sensor inputs, such as camera or LiDAR, typically provided in real-world sc...",
      "pdf_url": "https://arxiv.org/pdf/2510.24052v1.pdf",
      "relevance_score": 89,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2510.24052v1_paper.pdf"
    },
    {
      "arxiv_id": "2211.09878v2",
      "title": "Reducing Hallucinations in Neural Machine Translation with Feature Attribution",
      "authors": [
        "Jo\u00ebl Tang",
        "Marina Fomicheva",
        "Lucia Specia"
      ],
      "published": "2022-11-17T20:33:56Z",
      "categories": "",
      "summary": "Neural conditional language generation models achieve the state-of-the-art in Neural Machine Translation (NMT) but are highly dependent on the quality of parallel training dataset. When trained on low-quality datasets, these models are prone to various error types, including hallucinations, i.e. outputs that are fluent, but unrelated to the source sentences. These errors are particularly dangerous, because on the surface the translation can be perceived as a correct output, especially if the reader does not understand the source language. We present a case study focusing on model understanding...",
      "pdf_url": "https://arxiv.org/pdf/2211.09878v2.pdf",
      "relevance_score": 87,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2211.09878v2_paper.pdf"
    },
    {
      "arxiv_id": "2510.06596v1",
      "title": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation",
      "authors": [
        "Ayush Zenith",
        "Arnold Zumbrun",
        "Neel Raut",
        "Jing Lin"
      ],
      "published": "2025-10-08T03:01:26Z",
      "categories": "",
      "summary": "The performance of machine learning models depends heavily on training data. The scarcity of large-scale, well-annotated datasets poses significant challenges in creating robust models. To address this, synthetic data generated through simulations and generative models has emerged as a promising solution, enhancing dataset diversity and improving the performance, reliability, and resilience of models. However, evaluating the quality of this generated data requires an effective metric. This paper introduces the Synthetic Dataset Quality Metric (SDQM) to assess data quality for object detection ...",
      "pdf_url": "https://arxiv.org/pdf/2510.06596v1.pdf",
      "relevance_score": 87,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2510.06596v1_paper.pdf"
    },
    {
      "arxiv_id": "2403.03307v1",
      "title": "Book2Dial: Generating Teacher-Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots",
      "authors": [
        "Junling Wang",
        "Jakub Macina",
        "Nico Daheim",
        "Sankalan Pal Chowdhury",
        "Mrinmaya Sachan"
      ],
      "published": "2024-03-05T20:12:05Z",
      "categories": "",
      "summary": "Educational chatbots are a promising tool for assisting student learning. However, the development of effective chatbots in education has been challenging, as high-quality data is seldom available in this domain. In this paper, we propose a framework for generating synthetic teacher-student interactions grounded in a set of textbooks. Our approaches capture one aspect of learning interactions where curious students with partial knowledge interactively ask a teacher questions about the material in the textbook. We highlight various quality criteria that such dialogues should fulfill and compare...",
      "pdf_url": "https://arxiv.org/pdf/2403.03307v1.pdf",
      "relevance_score": 82,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2403.03307v1_paper.pdf"
    },
    {
      "arxiv_id": "2410.19217v1",
      "title": "No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models",
      "authors": [
        "Changlong Wu",
        "Ananth Grama",
        "Wojciech Szpankowski"
      ],
      "published": "2024-10-24T23:57:11Z",
      "categories": "",
      "summary": "Generative models have shown impressive capabilities in synthesizing high-quality outputs across various domains. However, a persistent challenge is the occurrence of \"hallucinations\", where the model produces outputs that are plausible but invalid. While empirical strategies have been explored to mitigate this issue, a rigorous theoretical understanding remains elusive. In this paper, we develop a theoretical framework to analyze the learnability of non-hallucinating generative models from a learning-theoretic perspective. Our results reveal that non-hallucinating learning is statistically im...",
      "pdf_url": "https://arxiv.org/pdf/2410.19217v1.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2410.19217v1_paper.pdf"
    },
    {
      "arxiv_id": "2410.16326v2",
      "title": "Synthetic Network Traffic Data Generation: A Comparative Study",
      "authors": [
        "Dure Adan Ammara",
        "Jianguo Ding",
        "Kurt Tutschku"
      ],
      "published": "2024-10-18T14:19:25Z",
      "categories": "",
      "summary": "The generation of synthetic network traffic data is essential for network security testing, machine learning model training, and performance analysis. However, existing methods for synthetic data generation differ significantly in their ability to maintain statistical fidelity, utility for classification tasks, and class balance. This study presents a comparative analysis of twelve synthetic network traffic data generation methods, encompassing non-AI (statistical), classical AI, and generative AI techniques. Using NSL-KDD and CIC-IDS2017 datasets, we evaluate the fidelity, utility, class bala...",
      "pdf_url": "https://arxiv.org/pdf/2410.16326v2.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2410.16326v2_paper.pdf"
    },
    {
      "arxiv_id": "2510.13080v2",
      "title": "Counting Hallucinations in Diffusion Models",
      "authors": [
        "Shuai Fu",
        "Jian Zhou",
        "Qi Chen",
        "Huang Jing",
        "Huy Anh Nguyen",
        "Xiaohan Liu",
        "Zhixiong Zeng",
        "Lin Ma",
        "Quanshi Zhang",
        "Qi Wu"
      ],
      "published": "2025-10-15T01:48:04Z",
      "categories": "",
      "summary": "Diffusion probabilistic models (DPMs) have demonstrated remarkable progress in generative tasks, such as image and video synthesis. However, they still often produce hallucinated samples (hallucinations) that conflict with real-world knowledge, such as generating an implausible duplicate cup floating beside another cup. Despite their prevalence, the lack of feasible methodologies for systematically quantifying such hallucinations hinders progress in addressing this challenge and obscures potential pathways for designing next-generation generative models under factual constraints. In this work,...",
      "pdf_url": "https://arxiv.org/pdf/2510.13080v2.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2510.13080v2_paper.pdf"
    },
    {
      "arxiv_id": "2203.03429v1",
      "title": "Synthetic Defect Generation for Display Front-of-Screen Quality Inspection: A Survey",
      "authors": [
        "Shancong Mou",
        "Meng Cao",
        "Zhendong Hong",
        "Ping Huang",
        "Jiulong Shan",
        "Jianjun Shi"
      ],
      "published": "2022-03-03T20:56:28Z",
      "categories": "",
      "summary": "Display front-of-screen (FOS) quality inspection is essential for the mass production of displays in the manufacturing process. However, the severe imbalanced data, especially the limited number of defect samples, has been a long-standing problem that hinders the successful application of deep learning algorithms. Synthetic defect data generation can help address this issue. This paper reviews the state-of-the-art synthetic data generation methods and the evaluation metrics that can potentially be applied to display FOS quality inspection tasks.",
      "pdf_url": "https://arxiv.org/pdf/2203.03429v1.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2203.03429v1_paper.pdf"
    },
    {
      "arxiv_id": "2507.11687v2",
      "title": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization",
      "authors": [
        "Atharva Naik",
        "Lawanya Baghel",
        "Dhakshin Govindarajan",
        "Darsh Agrawal",
        "Daniel Fried",
        "Carolyn Rose"
      ],
      "published": "2025-07-15T19:44:20Z",
      "categories": "",
      "summary": "Large Language Models, though successful in code generation, struggle with code quality analysis because they are limited by static training data and can't easily adapt to evolving best practices. We introduce MetaLint, an instruction-following framework that formulates code quality analysis as the task of detecting and fixing problematic semantic code fragments or code idioms based on high-level specifications. Unlike conventional approaches that train models on static code quality conventions, MetaLint employs instruction tuning on synthetic linter-generated data with dynamic conventions to ...",
      "pdf_url": "https://arxiv.org/pdf/2507.11687v2.pdf",
      "relevance_score": 81,
      "dimension": "f_training_hallucinations",
      "pdf_downloaded": true,
      "pdf_local_path": "cluster_f_training/pdfs/2507.11687v2_paper.pdf"
    }
  ],
  "dimension": "f_training_hallucinations",
  "downloaded_papers": 13
}