rank,arxiv_id,title,first_author,all_authors,published_date,pages,relevance_score,pdf_filename,main_topic,attack_type,key_findings
1,2512.10998v1,SCOUT: A Defense Against Data Poisoning Attacks in Fine-Tuned Language Models,Mohamed Afane,"Mohamed Afane, Abhishek Satyam, Ke Chen, Tao Li, Junaid Farooq, Juntao Chen",2025-12-10,unknown,58,2512.10998v1.pdf,Backdoor Attacks,Data Poisoning,"Backdoor attacks create significant security threats to language models by embedding hidden triggers that manipulate model behavior during inference, ..."
2,2511.06212v1,RAG-targeted Adversarial Attack on LLM-based Threat Detection and Mitigation Framework,Seif Ikbarieh,"Seif Ikbarieh, Kshitiz Aryal, Maanak Gupta",2025-11-09,unknown,56,2511.06212v1.pdf,RAG Security,Adversarial Attack,"The rapid expansion of the Internet of Things (IoT) is reshaping communication and operational practices across industries, but it also broadens the a..."
3,2512.13207v2,Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting,Karina Chichifoi,"Karina Chichifoi, Fabio Merizzi, Michele Colajanni",2025-12-15,unknown,46,2512.13207v2.pdf,Federated Learning,Adversarial Attack,Deep learning and federated learning (FL) are becoming powerful partners for next-generation weather forecasting. Deep learning enables high-resolutio...
4,2510.10008v1,RIPRAG: Hack a Black-box Retrieval-Augmented Generation Question-Answering System with Reinforcement Learning,Meng Xi,"Meng Xi, Sihan Lv, Yechen Jin, Guanjie Cheng, Naibo Wang, Ying Li, Jianwei Yin",2025-10-11,unknown,45,2510.10008v1.pdf,RAG Security,Security Analysis,Retrieval-Augmented Generation (RAG) systems based on Large Language Models (LLMs) have become a core technology for tasks such as question-answering ...
5,2512.21681v1,Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation,Tian Li,"Tian Li, Bo Lin, Shangwen Wang, Yusong Tan",2025-12-25,unknown,45,2512.21681v1.pdf,Backdoor Attacks,Security Analysis,"Retrieval-Augmented Code Generation (RACG) is increasingly adopted to enhance Large Language Models for software development, yet its security implica..."
6,2511.01268v1,Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems,Minseok Kim,"Minseok Kim, Hankook Lee, Hyungjoon Koo",2025-11-03,unknown,40,2511.01268v1.pdf,RAG Security,Data Poisoning,"Large language models (LLMs) are reshaping numerous facets of our daily lives, leading widespread adoption as web-based services. Despite their versat..."
7,2511.11240v1,HealSplit: Towards Self-Healing through Adversarial Distillation in Split Federated Learning,Yuhan Xie,"Yuhan Xie, Chen Lyu",2025-11-14,unknown,38,2511.11240v1.pdf,Data Poisoning,Security Analysis,"Split Federated Learning (SFL) is an emerging paradigm for privacy-preserving distributed learning. However, it remains vulnerable to sophisticated da..."
8,2511.09105v1,Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment,Shigeki Kusaka,"Shigeki Kusaka, Keita Saito, Mikoto Kudo, Takumi Tanabe, Akifumi Wachi, Youhei Akimoto",2025-11-12,unknown,38,2511.09105v1.pdf,Data Poisoning,Data Poisoning,"Large language models (LLMs) are increasingly deployed in real-world systems, making it critical to understand their vulnerabilities. While data poiso..."
9,2512.19286v2,GShield: Mitigating Poisoning Attacks in Federated Learning,Sameera K. M.,"Sameera K. M., Serena Nicolazzo, Antonino Nocera, Vinod P., Rafidha Rehiman K. A",2025-12-22,unknown,38,2512.19286v2.pdf,Data Poisoning,Data Poisoning,"Federated Learning (FL) has recently emerged as a revolutionary approach to collaborative training Machine Learning models. In particular, it enables ..."
10,2511.15435v1,HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation,Linyin Luo,"Linyin Luo, Yujuan Ding, Yunshan Ma, Wenqi Fan, Hanjiang Lai",2025-11-19,unknown,35,2511.15435v1.pdf,RAG Security,Direct Attack,Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (...
11,2512.16962v1,MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval,Saksham Sahai Srivastava,"Saksham Sahai Srivastava, Haoyu He",2025-12-18,unknown,35,2512.16962v1.pdf,RAG Security,Security Analysis,Large Language Model (LLM) agents increasingly rely on long-term memory and Retrieval-Augmented Generation (RAG) to persist experiences and refine fut...
12,2512.23132v1,Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems,Armstrong Foundjem,"Armstrong Foundjem, Lionel Nganyewou Tidjon, Leuson Da Silva, Foutse Khomh",2025-12-29,unknown,28,2512.23132v1.pdf,Data Poisoning,Defense/Detection Mechanism,"Machine learning (ML) underpins foundation models in finance, healthcare, and critical infrastructure, making them targets for data poisoning, model e..."
13,2512.22860v1,"Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks",Soham Padia,"Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar",2025-12-28,unknown,28,2512.22860v1.pdf,General Adversarial Attacks,Direct Attack,Securing blockchain-enabled IoT networks against sophisticated adversarial attacks remains a critical challenge. This paper presents a trust-based del...
14,2511.09392v4,Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm,Jiajie Su,"Jiajie Su, Zihan Nan, Yunshan Ma, Xiaobo Xia, Xiaohua Feng, Weiming Liu, Xiang Chen, Xiaolin Zheng, Chaochao Chen",2025-11-12,unknown,26,2511.09392v4.pdf,Data Poisoning,Security Analysis,"Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attack..."
15,2512.23809v1,Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems,Samaresh Kumar Singh,"Samaresh Kumar Singh, Joyjit Roy, Martin So",2025-12-29,unknown,20,2512.23809v1.pdf,Federated Learning,Defense/Detection Mechanism,"Recent attacks on critical infrastructure, including the 2021 Oldsmar water treatment breach and 2023 Danish energy sector compromises, highlight urge..."
