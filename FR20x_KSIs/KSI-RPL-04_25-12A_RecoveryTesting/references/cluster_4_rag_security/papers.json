[
  {
    "arxiv_id": "2512.10998v1",
    "title": "SCOUT: A Defense Against Data Poisoning Attacks in Fine-Tuned Language Models",
    "authors": "Mohamed Afane, Abhishek Satyam, Ke Chen, Tao Li, Junaid Farooq, Juntao Chen",
    "first_author": "Mohamed Afane",
    "published_date": "2025-12-10",
    "pages": "unknown",
    "relevance_score": 58,
    "pdf_filename": "2512.10998v1.pdf",
    "summary": "Backdoor attacks create significant security threats to language models by embedding hidden triggers that manipulate model behavior during inference, presenting critical risks for AI systems deployed "
  },
  {
    "arxiv_id": "2511.06212v1",
    "title": "RAG-targeted Adversarial Attack on LLM-based Threat Detection and Mitigation Framework",
    "authors": "Seif Ikbarieh, Kshitiz Aryal, Maanak Gupta",
    "first_author": "Seif Ikbarieh",
    "published_date": "2025-11-09",
    "pages": "unknown",
    "relevance_score": 56,
    "pdf_filename": "2511.06212v1.pdf",
    "summary": "The rapid expansion of the Internet of Things (IoT) is reshaping communication and operational practices across industries, but it also broadens the attack surface and increases susceptibility to secu"
  },
  {
    "arxiv_id": "2512.13207v2",
    "title": "Evaluating Adversarial Attacks on Federated Learning for Temperature Forecasting",
    "authors": "Karina Chichifoi, Fabio Merizzi, Michele Colajanni",
    "first_author": "Karina Chichifoi",
    "published_date": "2025-12-15",
    "pages": "unknown",
    "relevance_score": 46,
    "pdf_filename": "2512.13207v2.pdf",
    "summary": "Deep learning and federated learning (FL) are becoming powerful partners for next-generation weather forecasting. Deep learning enables high-resolution spatiotemporal forecasts that can surpass tradit"
  },
  {
    "arxiv_id": "2510.10008v1",
    "title": "RIPRAG: Hack a Black-box Retrieval-Augmented Generation Question-Answering System with Reinforcement Learning",
    "authors": "Meng Xi, Sihan Lv, Yechen Jin, Guanjie Cheng, Naibo Wang, Ying Li, Jianwei Yin",
    "first_author": "Meng Xi",
    "published_date": "2025-10-11",
    "pages": "unknown",
    "relevance_score": 45,
    "pdf_filename": "2510.10008v1.pdf",
    "summary": "Retrieval-Augmented Generation (RAG) systems based on Large Language Models (LLMs) have become a core technology for tasks such as question-answering (QA) and content generation. However, by injecting"
  },
  {
    "arxiv_id": "2512.21681v1",
    "title": "Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation",
    "authors": "Tian Li, Bo Lin, Shangwen Wang, Yusong Tan",
    "first_author": "Tian Li",
    "published_date": "2025-12-25",
    "pages": "unknown",
    "relevance_score": 45,
    "pdf_filename": "2512.21681v1.pdf",
    "summary": "Retrieval-Augmented Code Generation (RACG) is increasingly adopted to enhance Large Language Models for software development, yet its security implications remain dangerously underexplored. This paper"
  },
  {
    "arxiv_id": "2511.01268v1",
    "title": "Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems",
    "authors": "Minseok Kim, Hankook Lee, Hyungjoon Koo",
    "first_author": "Minseok Kim",
    "published_date": "2025-11-03",
    "pages": "unknown",
    "relevance_score": 40,
    "pdf_filename": "2511.01268v1.pdf",
    "summary": "Large language models (LLMs) are reshaping numerous facets of our daily lives, leading widespread adoption as web-based services. Despite their versatility, LLMs face notable challenges, such as gener"
  },
  {
    "arxiv_id": "2511.11240v1",
    "title": "HealSplit: Towards Self-Healing through Adversarial Distillation in Split Federated Learning",
    "authors": "Yuhan Xie, Chen Lyu",
    "first_author": "Yuhan Xie",
    "published_date": "2025-11-14",
    "pages": "unknown",
    "relevance_score": 38,
    "pdf_filename": "2511.11240v1.pdf",
    "summary": "Split Federated Learning (SFL) is an emerging paradigm for privacy-preserving distributed learning. However, it remains vulnerable to sophisticated data poisoning attacks targeting local features, lab"
  },
  {
    "arxiv_id": "2511.09105v1",
    "title": "Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment",
    "authors": "Shigeki Kusaka, Keita Saito, Mikoto Kudo, Takumi Tanabe, Akifumi Wachi, Youhei Akimoto",
    "first_author": "Shigeki Kusaka",
    "published_date": "2025-11-12",
    "pages": "unknown",
    "relevance_score": 38,
    "pdf_filename": "2511.09105v1.pdf",
    "summary": "Large language models (LLMs) are increasingly deployed in real-world systems, making it critical to understand their vulnerabilities. While data poisoning attacks during RLHF/DPO alignment have been s"
  },
  {
    "arxiv_id": "2512.19286v2",
    "title": "GShield: Mitigating Poisoning Attacks in Federated Learning",
    "authors": "Sameera K. M., Serena Nicolazzo, Antonino Nocera, Vinod P., Rafidha Rehiman K. A",
    "first_author": "Sameera K. M.",
    "published_date": "2025-12-22",
    "pages": "unknown",
    "relevance_score": 38,
    "pdf_filename": "2512.19286v2.pdf",
    "summary": "Federated Learning (FL) has recently emerged as a revolutionary approach to collaborative training Machine Learning models. In particular, it enables decentralized model training while preserving data"
  },
  {
    "arxiv_id": "2511.15435v1",
    "title": "HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation",
    "authors": "Linyin Luo, Yujuan Ding, Yunshan Ma, Wenqi Fan, Hanjiang Lai",
    "first_author": "Linyin Luo",
    "published_date": "2025-11-19",
    "pages": "unknown",
    "relevance_score": 35,
    "pdf_filename": "2511.15435v1.pdf",
    "summary": "Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issu"
  },
  {
    "arxiv_id": "2512.16962v1",
    "title": "MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval",
    "authors": "Saksham Sahai Srivastava, Haoyu He",
    "first_author": "Saksham Sahai Srivastava",
    "published_date": "2025-12-18",
    "pages": "unknown",
    "relevance_score": 35,
    "pdf_filename": "2512.16962v1.pdf",
    "summary": "Large Language Model (LLM) agents increasingly rely on long-term memory and Retrieval-Augmented Generation (RAG) to persist experiences and refine future performance. While this experience learning ca"
  },
  {
    "arxiv_id": "2512.23132v1",
    "title": "Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems",
    "authors": "Armstrong Foundjem, Lionel Nganyewou Tidjon, Leuson Da Silva, Foutse Khomh",
    "first_author": "Armstrong Foundjem",
    "published_date": "2025-12-29",
    "pages": "unknown",
    "relevance_score": 28,
    "pdf_filename": "2512.23132v1.pdf",
    "summary": "Machine learning (ML) underpins foundation models in finance, healthcare, and critical infrastructure, making them targets for data poisoning, model extraction, prompt injection, automated jailbreakin"
  },
  {
    "arxiv_id": "2512.22860v1",
    "title": "Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks",
    "authors": "Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar",
    "first_author": "Soham Padia",
    "published_date": "2025-12-28",
    "pages": "unknown",
    "relevance_score": 28,
    "pdf_filename": "2512.22860v1.pdf",
    "summary": "Securing blockchain-enabled IoT networks against sophisticated adversarial attacks remains a critical challenge. This paper presents a trust-based delegated consensus framework integrating Fully Homom"
  },
  {
    "arxiv_id": "2511.09392v4",
    "title": "Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm",
    "authors": "Jiajie Su, Zihan Nan, Yunshan Ma, Xiaobo Xia, Xiaohua Feng, Weiming Liu, Xiang Chen, Xiaolin Zheng, Chaochao Chen",
    "first_author": "Jiajie Su",
    "published_date": "2025-11-12",
    "pages": "unknown",
    "relevance_score": 26,
    "pdf_filename": "2511.09392v4.pdf",
    "summary": "Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require l"
  },
  {
    "arxiv_id": "2512.23809v1",
    "title": "Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems",
    "authors": "Samaresh Kumar Singh, Joyjit Roy, Martin So",
    "first_author": "Samaresh Kumar Singh",
    "published_date": "2025-12-29",
    "pages": "unknown",
    "relevance_score": 20,
    "pdf_filename": "2512.23809v1.pdf",
    "summary": "Recent attacks on critical infrastructure, including the 2021 Oldsmar water treatment breach and 2023 Danish energy sector compromises, highlight urgent security gaps in Industrial IoT (IIoT) deployme"
  }
]