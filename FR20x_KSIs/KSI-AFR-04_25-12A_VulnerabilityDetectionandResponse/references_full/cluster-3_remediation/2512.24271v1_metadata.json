{
  "arxiv_id": "2512.24271v1",
  "title": "Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation",
  "authors": [
    "Zhe Huang",
    "Hao Wen",
    "Aiming Hao",
    "Bingze Song",
    "Meiqi Wu",
    "Jiahong Wu",
    "Xiangxiang Chu",
    "Sheng Lu",
    "Haoqian Wang"
  ],
  "published": "2025-12-30",
  "summary": "Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy common sense. This limitation, stemming from the intrinsic data imbalance between text and video, is challenging to address due to the substantial cost of collecting and annotating counterfactual data. To ...",
  "categories": "cs.CV",
  "relevance_score": 83,
  "color": "GREEN",
  "download_date": "2026-01-10T19:01:36.754146",
  "pdf_url": "https://arxiv.org/pdf/2512.24271v1.pdf",
  "abs_url": "https://arxiv.org/abs/2512.24271v1"
}