<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .paper-title { font-size: 18px; font-weight: bold; margin-bottom: 10px; }
        .paper-meta { color: #666; margin-bottom: 15px; }
        .paper-link { margin: 10px 0; }
        a { color: #0066cc; text-decoration: none; }
        a:hover { text-decoration: underline; }
        .summary { margin-top: 15px; padding: 10px; background: #f5f5f5; }
    </style>
</head>
<body>
    <div class="paper-title">Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements</div>
    <div class="paper-meta">
        <p><strong>ArXiv ID:</strong> 2512.24867v2</p>
        <p><strong>Published:</strong> 2025-12-31</p>
        <p><strong>Relevance Score:</strong> 74/100</p>
        <p><strong>Authors:</strong> Yiming Liang, Yizhi Li, Yantao Du, Ge Zhang, Jiayi Zhou, Yuchen Wu, Yinzhu Piao, Denghui Cao, Tong Sun, Ziniu Li, Li Du, Bo Lei, Jiaheng Liu, Chenghua Lin, Zhaoxiang Zhang, Wenhao Huang, Jiajun Zhang</p>
    </div>
    <div class="paper-link">
        <a href="https://arxiv.org/abs/2512.24867v2" target="_blank">View on ArXiv (Abstract)</a><br>
        <a href="https://arxiv.org/pdf/2512.24867v2.pdf" target="_blank">Download PDF</a>
    </div>
    <div class="summary">
        <strong>Summary:</strong><br>
        Benchmarks play a crucial role in tracking the rapid advancement of large language models (LLMs) and identifying their capability boundaries. However, existing benchmarks predominantly curate questions at the question level, suffering from three fundamental limitations: vulnerability to data contami...
    </div>
</body>
</html>
