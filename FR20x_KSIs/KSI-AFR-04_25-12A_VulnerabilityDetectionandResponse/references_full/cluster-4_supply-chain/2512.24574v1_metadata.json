{
  "arxiv_id": "2512.24574v1",
  "title": "Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time",
  "authors": [
    "Zhenyu Zhang",
    "Xiaoxia Wu",
    "Zhongzhu Zhou",
    "Qingyang Wu",
    "Yineng Zhang",
    "Pragaash Ponnusamy",
    "Harikaran Subbaraj",
    "Jue Wang",
    "Shuaiwen Leon Song",
    "Ben Athiwaratkun"
  ],
  "published": "2025-12-31",
  "summary": "Large Language Models (LLMs) often rely on long chain-of-thought (CoT) reasoning to solve complex tasks. While effective, these trajectories are frequently inefficient, leading to high latency from excessive token generation, or unstable reasoning that alternates between underthinking (shallow, inconsistent steps) and overthinking (repetitive, verbose reasoning). In this work, we study the structure of reasoning trajectories and uncover specialized attention heads that correlate with distinct co...",
  "categories": "cs.CL",
  "relevance_score": 70,
  "color": "GREEN",
  "download_date": "2026-01-10T19:02:18.873280",
  "pdf_url": "https://arxiv.org/pdf/2512.24574v1.pdf",
  "abs_url": "https://arxiv.org/abs/2512.24574v1"
}