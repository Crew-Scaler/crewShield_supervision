{
  "arxiv_id": "2411.06789",
  "title": "Explainable AI for Security: Interpretable Machine Learning in Threat Detection",
  "authors": "Dr. Lisa Zhang, Robert Kim (UC Berkeley AI Alignment Lab)",
  "first_author_affiliation": "UC Berkeley",
  "published_date": "2024-11-08",
  "published_year": 2024,
  "summary": "Security analysts need to understand why ML models flag threats. We develop interpretable ML approaches for threat detection with visual explanations of model decisions.",
  "relevance_score": 99,
  "relevance_class": "GREEN",
  "arxiv_url": "https://arxiv.org/abs/2411.06789",
  "download_date": "2026-01-10T18:40:18.946238",
  "key_topics": [
    "explainability",
    "ML",
    "threat detection",
    "interpretability"
  ],
  "page_count": 16
}