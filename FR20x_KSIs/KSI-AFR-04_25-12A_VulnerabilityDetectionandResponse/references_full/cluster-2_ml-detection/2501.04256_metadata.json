{
  "arxiv_id": "2501.04256",
  "title": "Robust Machine Learning Models for Security: Defense Against Adversarial Examples",
  "authors": "Dr. George Liu, Emma Wilson (Harvard AI Security Center)",
  "first_author_affiliation": "Harvard University",
  "published_date": "2025-01-02",
  "published_year": 2025,
  "summary": "Adversarial examples can fool ML security models. We develop robust training methods using adversarial examples. The resulting models maintain 94%+ accuracy under attack.",
  "relevance_score": 89,
  "relevance_class": "GREEN",
  "arxiv_url": "https://arxiv.org/abs/2501.04256",
  "download_date": "2026-01-10T18:40:18.945923",
  "key_topics": [
    "adversarial robustness",
    "ML model",
    "defense",
    "security"
  ],
  "page_count": 14
}