{
  "arxiv_id": "2410.18934",
  "title": "Adversarial Robustness in ML-Based Security Systems: Defense Against Evasion Attacks",
  "authors": "Dr. Yuki Matsuda, Sarah Johnson (Stanford AI Security Lab)",
  "first_author_affiliation": "Stanford University",
  "published_date": "2024-10-20",
  "published_year": 2024,
  "summary": "Machine learning models powering security systems are vulnerable to adversarial attacks. We present novel defense mechanisms against evasion attacks targeting vulnerability detection systems. Our approach reduces attack success rate from 45% to 8%.",
  "relevance_score": 85,
  "relevance_class": "GREEN",
  "arxiv_url": "https://arxiv.org/abs/2410.18934",
  "download_date": "2026-01-10T18:40:18.945267",
  "key_topics": [
    "adversarial robustness",
    "evasion",
    "defense",
    "ML",
    "security"
  ],
  "page_count": 14
}