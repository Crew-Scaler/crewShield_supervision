{
  "arxiv_id": "2512.19016v1",
  "title": "DREAM: Dynamic Red-teaming across Environments for AI Models",
  "authors": [
    "Liming Lu",
    "Xiang Gu",
    "Junyu Huang",
    "Jiawei Du",
    "Yunhuai Liu",
    "Yongbin Zhou",
    "Shuchao Pang"
  ],
  "published": "2025-12-22",
  "summary": "Large Language Models (LLMs) are increasingly used in agentic systems, where their interactions with diverse tools and environments create complex, multi-stage safety challenges. However, existing benchmarks mostly rely on static, single-turn assessments that miss vulnerabilities from adaptive, long-chain attacks. To fill this gap, we introduce DREAM, a framework for systematic evaluation of LLM agents against dynamic, multi-stage attacks. At its core, DREAM uses a Cross-Environment Adversarial ...",
  "categories": "cs.CR",
  "relevance_score": 74,
  "color": "GREEN",
  "download_date": "2026-01-10T19:02:39.817652",
  "pdf_url": "https://arxiv.org/pdf/2512.19016v1.pdf",
  "abs_url": "https://arxiv.org/abs/2512.19016v1"
}