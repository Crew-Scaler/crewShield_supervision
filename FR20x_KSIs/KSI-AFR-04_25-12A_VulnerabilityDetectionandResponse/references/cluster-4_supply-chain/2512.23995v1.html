<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .paper-title { font-size: 18px; font-weight: bold; margin-bottom: 10px; }
        .paper-meta { color: #666; margin-bottom: 15px; }
        .paper-link { margin: 10px 0; }
        a { color: #0066cc; text-decoration: none; }
        a:hover { text-decoration: underline; }
        .summary { margin-top: 15px; padding: 10px; background: #f5f5f5; }
    </style>
</head>
<body>
    <div class="paper-title">RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts LLMs under DoS Stress</div>
    <div class="paper-meta">
        <p><strong>ArXiv ID:</strong> 2512.23995v1</p>
        <p><strong>Published:</strong> 2025-12-30</p>
        <p><strong>Relevance Score:</strong> 70/100</p>
        <p><strong>Authors:</strong> Ruixuan Huang, Qingyue Wang, Hantao Huang, Yudong Gao, Dong Chen, Shuai Wang, Wei Wang</p>
    </div>
    <div class="paper-link">
        <a href="https://arxiv.org/abs/2512.23995v1" target="_blank">View on ArXiv (Abstract)</a><br>
        <a href="https://arxiv.org/pdf/2512.23995v1.pdf" target="_blank">Download PDF</a>
    </div>
    <div class="summary">
        <strong>Summary:</strong><br>
        Mixture-of-Experts architectures have become the standard for scaling large language models due to their superior parameter efficiency. To accommodate the growing number of experts in practice, modern inference systems commonly adopt expert parallelism to distribute experts across devices. However, ...
    </div>
</body>
</html>
