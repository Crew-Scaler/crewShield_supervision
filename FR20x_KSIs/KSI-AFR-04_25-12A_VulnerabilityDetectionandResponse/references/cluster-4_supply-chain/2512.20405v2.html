<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .paper-title { font-size: 18px; font-weight: bold; margin-bottom: 10px; }
        .paper-meta { color: #666; margin-bottom: 15px; }
        .paper-link { margin: 10px 0; }
        a { color: #0066cc; text-decoration: none; }
        a:hover { text-decoration: underline; }
        .summary { margin-top: 15px; padding: 10px; background: #f5f5f5; }
    </style>
</head>
<body>
    <div class="paper-title">ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected</div>
    <div class="paper-meta">
        <p><strong>ArXiv ID:</strong> 2512.20405v2</p>
        <p><strong>Published:</strong> 2025-12-23</p>
        <p><strong>Relevance Score:</strong> 74/100</p>
        <p><strong>Authors:</strong> Kanchon Gharami, Sanjiv Kumar Sarkar, Yongxin Liu, Shafika Showkat Moni</p>
    </div>
    <div class="paper-link">
        <a href="https://arxiv.org/abs/2512.20405v2" target="_blank">View on ArXiv (Abstract)</a><br>
        <a href="https://arxiv.org/pdf/2512.20405v2.pdf" target="_blank">Download PDF</a>
    </div>
    <div class="summary">
        <strong>Summary:</strong><br>
        Large Language Models (LLMs) like ChatGPT are now widely used in writing and reviewing scientific papers. While this trend accelerates publication growth and reduces human workload, it also introduces serious risks. Papers written or reviewed by LLMs may lack real novelty, contain fabricated or bias...
    </div>
</body>
</html>
