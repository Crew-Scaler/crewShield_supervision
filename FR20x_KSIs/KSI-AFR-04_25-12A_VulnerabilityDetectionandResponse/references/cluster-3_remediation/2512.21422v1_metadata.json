{
  "arxiv_id": "2512.21422v1",
  "title": "Teaching People LLM's Errors and Getting it Right",
  "authors": [
    "Nathan Stringham",
    "Fateme Hashemi Chaleshtori",
    "Xinyuan Yan",
    "Zhichao Xu",
    "Bei Wang",
    "Ana Marasovi\u0107"
  ],
  "published": "2025-12-24",
  "summary": "People use large language models (LLMs) when they should not. This is partly because they see LLMs compose poems and answer intricate questions, so they understandably, but incorrectly, assume LLMs won't stumble on basic tasks like simple arithmetic. Prior work has tried to address this by clustering instance embeddings into regions where an LLM is likely to fail and automatically describing patterns in these regions. The found failure patterns are taught to users to mitigate their overreliance....",
  "categories": "cs.CL",
  "relevance_score": 74,
  "color": "GREEN",
  "download_date": "2026-01-10T19:01:50.773062",
  "pdf_url": "https://arxiv.org/pdf/2512.21422v1.pdf",
  "abs_url": "https://arxiv.org/abs/2512.21422v1"
}