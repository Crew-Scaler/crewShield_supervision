{
  "arxiv_id": "2512.21010v1",
  "title": "LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics",
  "authors": [
    "Jiashuo Liu",
    "Jiayun Wu",
    "Chunjie Wu",
    "Jingkai Liu",
    "Zaiyuan Wang",
    "Huan Zhou",
    "Wenhao Huang",
    "Hongseok Namkoong"
  ],
  "published": "2025-12-24",
  "summary": "The rapid proliferation of Large Language Models (LLMs) and diverse specialized benchmarks necessitates a shift from fragmented, task-specific metrics to a holistic, competitive ranking system that effectively aggregates performance across multiple ability dimensions. Primarily using static scoring, current evaluation methods are fundamentally limited. They struggle to determine the proper mix ratio across diverse benchmarks, and critically, they fail to capture a model's dynamic competitive fit...",
  "categories": "cs.LG",
  "relevance_score": 74,
  "color": "GREEN",
  "download_date": "2026-01-10T19:01:47.465779",
  "pdf_url": "https://arxiv.org/pdf/2512.21010v1.pdf",
  "abs_url": "https://arxiv.org/abs/2512.21010v1"
}