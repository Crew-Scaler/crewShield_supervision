<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .paper-title { font-size: 18px; font-weight: bold; margin-bottom: 10px; }
        .paper-meta { color: #666; margin-bottom: 15px; }
        .paper-link { margin: 10px 0; }
        a { color: #0066cc; text-decoration: none; }
        a:hover { text-decoration: underline; }
        .summary { margin-top: 15px; padding: 10px; background: #f5f5f5; }
    </style>
</head>
<body>
    <div class="paper-title">AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning</div>
    <div class="paper-meta">
        <p><strong>ArXiv ID:</strong> 2512.22857v1</p>
        <p><strong>Published:</strong> 2025-12-28</p>
        <p><strong>Relevance Score:</strong> 79/100</p>
        <p><strong>Authors:</strong> Shihao Cai, Runnan Fang, Jialong Wu, Baixuan Li, Xinyu Wang, Yong Jiang, Liangcai Su, Liwen Zhang, Wenbiao Yin, Zhen Zhang, Fuli Feng, Pengjun Xie, Xiaobin Wang</p>
    </div>
    <div class="paper-link">
        <a href="https://arxiv.org/abs/2512.22857v1" target="_blank">View on ArXiv (Abstract)</a><br>
        <a href="https://arxiv.org/pdf/2512.22857v1.pdf" target="_blank">Download PDF</a>
    </div>
    <div class="summary">
        <strong>Summary:</strong><br>
        Conducting reinforcement learning (RL) in simulated environments offers a cost-effective and highly scalable way to enhance language-based agents. However, previous work has been limited to semi-automated environment synthesis or tasks lacking sufficient difficulty, offering little breadth or depth....
    </div>
</body>
</html>
