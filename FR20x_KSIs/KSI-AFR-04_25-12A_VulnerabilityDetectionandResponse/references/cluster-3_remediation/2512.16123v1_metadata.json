{
  "arxiv_id": "2512.16123v1",
  "title": "Autoencoder-based Denoising Defense against Adversarial Attacks on Object Detection",
  "authors": [
    "Min Geun Song",
    "Gang Min Kim",
    "Woonmin Kim",
    "Yongsik Kim",
    "Jeonghyun Sim",
    "Sangbeom Park",
    "Huy Kang Kim"
  ],
  "published": "2025-12-18",
  "summary": "Deep learning-based object detection models play a critical role in real-world applications such as autonomous driving and security surveillance systems, yet they remain vulnerable to adversarial examples. In this work, we propose an autoencoder-based denoising defense to recover object detection performance degraded by adversarial perturbations. We conduct adversarial attacks using Perlin noise on vehicle-related images from the COCO dataset, apply a single-layer convolutional autoencoder to re...",
  "categories": "cs.CR",
  "relevance_score": 78,
  "color": "GREEN",
  "download_date": "2026-01-10T19:01:54.271100",
  "pdf_url": "https://arxiv.org/pdf/2512.16123v1.pdf",
  "abs_url": "https://arxiv.org/abs/2512.16123v1"
}