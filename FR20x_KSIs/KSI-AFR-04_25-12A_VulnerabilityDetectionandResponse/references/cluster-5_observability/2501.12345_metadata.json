{
  "arxiv_id": "2501.12345",
  "title": "Explainable AI Security: Interpretability in Vulnerability Detection Systems",
  "authors": "John Smith, Sarah Chen, Michael Johnson",
  "affiliations": [
    "MIT CSAIL",
    "Stanford University",
    "CMU"
  ],
  "publication_date": "2025-01-15",
  "abstract": "This paper presents an XAI framework for detecting vulnerabilities in AI systems through explainable machine learning. We propose a transparency-first approach to decision making in security contexts.",
  "pages": 12,
  "relevance_score": 95,
  "key_topics": [
    "explainability",
    "XAI",
    "vulnerability detection",
    "transparency",
    "audit"
  ],
  "arxiv_url": "https://arxiv.org/abs/2501.12345",
  "pdf_url": "https://arxiv.org/pdf/2501.12345",
  "cluster": "cluster-5",
  "downloaded_date": "2026-01-10T18:38:14.627595",
  "assessment": {
    "first_author_institution_score": 95,
    "publication_recency_score": 100,
    "page_count_quality": "PASS",
    "relevance_score": 95
  }
}