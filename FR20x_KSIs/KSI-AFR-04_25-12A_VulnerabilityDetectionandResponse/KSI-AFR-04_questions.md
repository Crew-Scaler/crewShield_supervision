# KSI-AFR-04 Discovery Questions: Vulnerability Detection and Response

**Version:** 2.0.0
**Date:** January 13, 2026
**KSI:** AFR-04 - Vulnerability Detection and Response (AI-Enhanced)
**Focus:** AI and Agentic AI in Federal Cloud Security

---

## Summary Statistics

- **Original question count:** 67
- **Pre-refinement count:** 62
- **Post-guidance refinement:** 56
- **Questions moved to other KSIs:** 11
  - Q001, Q051 → KSI-IAM (agent identity/credentials)
  - Q003 → KSI Supply Chain (AI-BOM/model integrity)
  - Q039 → KSI SVC-01 (continuous improvement)
  - Q045-Q047 → KSI SDLC (code security/dependencies)
  - Q059 → KSI Meta-Governance (control mapping)
  - Q062 → KSI-AFR-01 (authorization documentation)
- **Questions consolidated:** 3 (Q043+Q054, Q044+Q048 merged for clarity)
- **Final VDR-focused question count:** 56

### Key Refinements Applied

Per GitHub issue #51 guidance:
- Removed questions focused on generic IAM (delegated to specialized KSIs)
- Removed questions about code security scanning (better suited for SDLC KSIs)
- Kept AI-BOM questions only where they inform VDR detection system integrity
- Consolidated overlapping governance and explainability questions
- Removed benchmarking question (low-value for VDR compliance)
- Tightened focus to VDR-specific rather than cross-framework mapping
- Softened numeric claims in detection questions to avoid implied performance requirements

---

## Section 1: Strategic and Governance Questions (8 questions)

### KSI-AFR-04-Q1
How much automation are you willing to delegate to AI agents for vulnerability remediation without human approval? Given that 46% of vulnerabilities can be auto-remediated without human intervention but 45% of AI-generated code contains OWASP Top 10 security vulnerabilities, are you implementing fully autonomous remediation with post-action monitoring, validation-gated autonomy (another AI validates before deployment), human approval loops for remediation above specific risk thresholds, or capability-limited automation?

### KSI-AFR-04-Q2
How will you address FedRAMP's explainability requirements while maintaining AI detection performance? For your vulnerability detection and response decisions, can you explain why specific vulnerabilities were scored as N1-N5 impact, justify remediation recommendations to federal auditors, and provide risk scores with human-interpretable reasoning traces?

### KSI-AFR-04-Q3
What is your organization's risk tolerance for adversarial attacks against vulnerability detection models? Given that adversarial attacks reduce ML-based security model accuracy by up to 47% under white-box scenarios and model drift degrades accuracy over time, does your strategy address adversarial robustness testing before model deployment, model drift monitoring and retraining frequency, ensemble methods combining multiple detection approaches, and independent validation of model accuracy?

### KSI-AFR-04-Q4
How will your organization demonstrate continuous VDR effectiveness to FedRAMP assessors? Does your organization currently have real-time observability dashboards for federal assessors, automated metric calculation enabling FedRAMP 20x marketplace scoring, API-based access to historical and current vulnerability data, and immutable audit trails for all security decisions?

### KSI-AFR-04-Q5
What governance mechanisms will you implement to prevent rogue AI agent scenarios? Given autonomous decision-making risks including prompt injection manipulation, goal manipulation through memory poisoning, decision opacity, and recursive AI-to-AI remediation without human oversight, does your governance framework include approval gates for autonomous remediation, prompt injection detection mechanisms, agent behavior monitoring, explicit audit trails, and rate limiting?

### KSI-AFR-04-Q6
How does your organization balance the speed benefits of autonomous AI remediation (potential near-zero MTTR for critical vulnerabilities) against the quality risks (45% of AI-generated code contains security vulnerabilities)? What validation frameworks, approval gates, and monitoring mechanisms ensure safe autonomous operations?

### KSI-AFR-04-Q7
What is your organization's strategy for maintaining authorization validity through continuous monitoring rather than periodic assessment cycles? How do you provide real-time evidence of VDR effectiveness to support persistent validation and assessment requirements?

### KSI-AFR-04-Q8
How does your organization address the "governance and explainability gaps" where black-box AI vulnerability assessments cannot provide justifications needed for agency confidence and FedRAMP audit compliance?

---

## Section 2: AI-Enhanced Detection Mechanisms (8 questions)

### KSI-AFR-04-Q9
Has your organization transitioned from scheduled vulnerability scanning (e.g., 24-hour cycles) to continuous, real-time AI-powered detection? Do your detection systems provide faster threat response times and more rapid cyberattack detection compared to traditional signature-based tools?

### KSI-AFR-04-Q10
Do your vulnerability detection systems employ machine learning models that process code repositories, container images, and infrastructure-as-code to identify zero-day vulnerabilities through pattern recognition of code anomalies missed by signature-based approaches?

### KSI-AFR-04-Q11
How do your AI-powered detection systems synthesize threat intelligence from multiple sources (CVE databases, exploit databases, dark web monitoring, bug bounty platforms) simultaneously? Do you use natural language processing to analyze security advisories and vulnerability disclosures at scale?

### KSI-AFR-04-Q12
Do your detection systems monitor AI-specific supply chain vulnerabilities including AI model dependencies, LLM APIs, ML framework ecosystems, third-party model versions, and unauthorized model deployments within your cloud infrastructure?

### KSI-AFR-04-Q13
Do your AI-powered detection systems achieve measurable reduction in false positive alerts through AI correlation, enabling security teams to focus investigation resources on genuine threats rather than alert fatigue?

### KSI-AFR-04-Q14
Do your detection systems employ behavioral anomaly detection through context-aware analysis, identifying vulnerable configurations through drift detection between deployed and baseline states? Do they detect unusual API call patterns indicating exploitation attempts including lateral movement and privilege escalation activities?

### KSI-AFR-04-Q15
Do your detection systems perform real-time correlation of network traffic anomalies with known vulnerability signatures to enable detection of active exploitation attempts in heterogeneous cloud environments?

### KSI-AFR-04-Q16
How do you address detection system limitations including model drift risk (degrading accuracy as data distributions change), adversarial vulnerability (ML models vulnerable to adversarial training attacks), and hallucination concerns (AI systems generating false vulnerability reports)?

---

## Section 3: AI-Driven Risk Evaluation and Prioritization (7 questions)

### KSI-AFR-04-Q17
Do your AI agents autonomously map attack paths from internet-facing resources to internal vulnerable components, identifying unexpected exposure routes in complex multi-cloud architectures? Do they identify exposed AI service endpoints (LLM APIs, model inference endpoints) that create unique attack surface?

### KSI-AFR-04-Q18
Do your risk evaluation systems integrate Exploit Prediction Scoring System (EPSS) machine learning models to predict exploitation likelihood based on threat landscape data and historical exploit availability? Do they analyze code context to determine actual exploitability beyond CVSS scores?

### KSI-AFR-04-Q19
Do your systems perform automated correlation of vulnerability characteristics with active threat campaigns to enable detection of targeted exploitation attempts against specific vulnerability classes?

### KSI-AFR-04-Q20
Do your AI-powered risk scoring systems incorporate asset criticality, data sensitivity, and business impact through machine learning models trained on historical breach data? Do they dynamically adjust risk scores based on real-time threat intelligence and environmental context?

### KSI-AFR-04-Q21
Do your systems perform automated business impact analysis considering cascading failures across AI system dependencies, identifying "toxic combinations" where multiple low-severity vulnerabilities create critical attack paths?

### KSI-AFR-04-Q22
Do your systems employ graph-based vulnerability interaction analysis across multi-cloud environments to identify privilege escalation chains through AI agent tool integrations and cross-service dependencies?

### KSI-AFR-04-Q23
How do your risk evaluation systems distinguish between internet-reachable vulnerabilities and internal-only flaws, treating accessible N4/N5 vulnerabilities as potential security incidents per FedRAMP requirements?

---

## Section 4: AI-Accelerated Response and Remediation (7 questions)

### KSI-AFR-04-Q24
Do your AI agents generate code fixes for identified vulnerabilities with automated validation loops, creating patches at machine speed? Given that research indicates 45% of AI-generated code contains OWASP Top 10 vulnerabilities, what robust validation mechanisms do you employ?

### KSI-AFR-04-Q25
Do your systems perform automated patch orchestration across containerized AI workloads and serverless functions enabling rapid deployment at scale? Do you have self-healing infrastructure that autonomously deploys compensating controls?

### KSI-AFR-04-Q26
Do your AI systems recommend remediation approaches based on deployment environment (public cloud, private cloud, hybrid), risk tolerance, and business continuity requirements? Do they automatically generate IaC templates, CLI commands, and configuration changes?

### KSI-AFR-04-Q27
Do your systems perform intelligent scheduling of remediation activities to minimize service disruption through analysis of business calendars, traffic patterns, and dependency relationships?

### KSI-AFR-04-Q28
Do you employ multi-agent validation frameworks where one agent generates fixes and another independently validates to prevent introduction of new vulnerabilities? Do you perform automated regression testing of remediated code through CI/CD pipelines?

### KSI-AFR-04-Q29
Do you have continuous monitoring post-remediation to detect effectiveness and potential side effects, validating that fixes achieve intended security outcomes? Do you have monitoring mechanisms to prevent recursive AI-to-AI remediation without human oversight?

### KSI-AFR-04-Q30
Does your autonomous remediation achieve rapid mean-time-to-remediate (MTTR) for critical vulnerabilities? What percentage of high-risk violations can be auto-remediated without human intervention?

---

## Section 5: Machine-Readable Reporting and Continuous Monitoring (6 questions)

### KSI-AFR-04-Q31
Do your AI systems automatically generate structured vulnerability data in machine-readable formats (CVRF, OpenVEX, similar standards) enabling machine-to-machine integration? Do they provide continuous telemetry streaming for vulnerability status, remediation progress, and risk metrics?

### KSI-AFR-04-Q32
Do you provide API-based access to historical and current vulnerability data to support FedRAMP compliance through machine-readable authorization data sharing with agencies?

### KSI-AFR-04-Q33
Do you maintain comprehensive logging of AI agent actions during detection, evaluation, and remediation enabling incident reconstruction and compliance verification?

### KSI-AFR-04-Q34
Do you employ explainable AI techniques to provide reasoning for risk scores and remediation recommendations, addressing FedRAMP requirement that CSPs demonstrate presumption of adequacy?

### KSI-AFR-04-Q35
Do you maintain immutable audit trails using cryptographic hashing to prevent tampering with security logs, ensuring integrity for compliance audits?

### KSI-AFR-04-Q36
Do you perform automated calculation of time-to-detect (TTD), time-to-evaluate (TTE), and time-to-remediate (MTTR) metrics to enable FedRAMP marketplace scoring based on VDR effectiveness?

---

## Section 6: AI Supply Chain and Model Vulnerability Management (3 questions)

### KSI-AFR-04-Q37
Do you maintain comprehensive inventory of AI models, training datasets, dependencies, and APIs (AI-BOM) integrated into your vulnerability detection systems, enabling tracking of all external components that could impact VDR integrity?

### KSI-AFR-04-Q38
Do you track third-party model provenance and detect unauthorized model versions to prevent deployment of trojanized or poisoned models used in VDR? Do you document AI framework versions, libraries, and plugin ecosystems?

### KSI-AFR-04-Q39
Do you detect adversarial vulnerabilities including data poisoning, model theft, and backdoor triggers in your VDR AI models to enable identification of compromised detection systems before operational deployment?

---

## Section 7: AI-Introduced Vulnerabilities and Risk Mitigation (8 questions)

### KSI-AFR-04-Q40
How do you protect your AI-driven detection systems against prompt injection attacks that manipulate AI agents into unauthorized actions? What mechanisms detect and prevent agents from following embedded malicious instructions in vulnerability data, threat intelligence feeds, or code repositories?

### KSI-AFR-04-Q41
How do you protect your AI-driven detection systems against data poisoning attacks that introduce persistent backdoors and hallucination risks, potentially creating intentional blindspots for specific vulnerability classes or generating false vulnerability reports that compromise reporting integrity?

### KSI-AFR-04-Q42
How do you defend against adversarial attacks that can reduce ML-based security model accuracy in white-box scenarios where attackers have model access, potentially degrading VDR effectiveness?

### KSI-AFR-04-Q43
How do you protect against LLM hijacking attacks that exploit compromised cloud credentials to abuse AI infrastructure for cryptomining or unauthorized access, threatening VDR system availability?

### KSI-AFR-04-Q44
How do you protect against cross-protocol authentication vulnerabilities in agent-to-agent communication that enable attackers to transition between authentication mechanisms and compromise VDR agent interactions?

### KSI-AFR-04-Q45
How do you prevent privilege escalation through AI agent tool chaining across multiple systems that enables attackers to achieve unauthorized objectives through orchestrated agent actions?

### KSI-AFR-04-Q46
How do you prevent goal manipulation through memory poisoning and context tampering that causes VDR agents to deviate from intended security objectives?

### KSI-AFR-04-Q47
How does your organization address residual decision opacity in AI systems that creates compliance and accountability challenges, ensuring VDR decisions can be explained to federal agencies even with advanced AI techniques?

---

## Section 8: VDR for Disaster Recovery Scenarios (5 questions)

### KSI-AFR-04-Q48
What defenses prevent prompt injection attacks specifically against LLM-based recovery agents orchestrating disaster recovery procedures, and how are malicious instructions injected into recovery documentation detected before agents execute unauthorized actions during recovery scenarios? [Addressed for KSI-AFR-04 per issue #42 cross-KSI review]

### KSI-AFR-04-Q49
Has the organization assessed risks of RAG backdoor attacks where recovery documentation or procedures are poisoned with malicious instructions that recovery agents follow during automated disaster recovery execution? [Addressed for KSI-AFR-04 per issue #42 cross-KSI review]

### KSI-AFR-04-Q50
For recovery systems using AI-powered anomaly detection to validate procedures and detect drift, what protections prevent attackers from poisoning these detection systems to hide recovery failures or cause false recovery alerts that could compromise disaster recovery effectiveness? [Addressed for KSI-AFR-04 per issue #42 cross-KSI review]

### KSI-AFR-04-Q51
Have recovery orchestration agents been tested for adversarial robustness specific to disaster recovery scenarios, ensuring they refuse malicious instructions and only execute legitimate recovery procedures aligned with documented RTO/RPO objectives? [Addressed for KSI-AFR-04 per issue #42 cross-KSI review]

### KSI-AFR-04-Q52
Does the organization conduct red team testing specifically targeting recovery agents and procedures, simulating attacker attempts to manipulate recovery through prompt injection, RAG backdoors, poisoned test data, or supply chain compromise of recovery orchestration software? [Addressed for KSI-AFR-04 per issue #42 cross-KSI review]

---

## Section 9: Compliance and Regulatory Alignment (4 questions)

### KSI-AFR-04-Q53
How do your AI systems generate structured vulnerability data meeting FedRAMP 20x marketplace scoring requirements, enabling comparative assessment of CSP vulnerability management effectiveness across the FedRAMP inventory?

### KSI-AFR-04-Q54
How does your KSI-AFR-04 implementation integrate with KSI-AFR-09 (Persistent Validation and Assessment), providing continuous validation evidence beyond periodic assessments?

### KSI-AFR-04-Q55
How do you maintain radical transparency through comprehensive audit trails and explainability enabling agency confidence in AI-driven VDR decisions?

### KSI-AFR-04-Q56
How do you implement discovery mechanisms to prevent shadow AI deployments that operate outside monitoring frameworks and create visibility gaps preventing VDR audit compliance?

---

## Questions Moved to Other KSIs

### Moved to KSI-IAM (Agent Identity & Credentials Management)
- **Original Q001, Q051**: Long-lived credentials, short-lived tokens, and workload identity for AI agents
  - *Rationale:* Primary focus is identity & access management (AC-2/IA-2), which is better handled by a dedicated IAM KSI
  - *VDR Reference:* VDR agents should use short-lived, scoped identities; details delegated to IAM KSI

### Moved to KSI Supply Chain (AI-BOM & Model Integrity)
- **Original Q003**: AI-BOM generation, model integrity verification, vendor assessment
  - *Rationale:* Supply chain governance is a dedicated KSI responsibility; VDR consumes this as input
  - *VDR Reference:* VDR systems depend on trustworthy AI components; supply chain KSI owns verification

### Moved to KSI SDLC (Secure Code Development & Dependencies)
- **Original Q045, Q046, Q047**: AI-generated code scanning, insecure coding patterns, dependency confusion
  - *Rationale:* Code security is an SDLC responsibility; while VDR can generate code, validation belongs with SDLC
  - *VDR Reference:* VDR agents may generate patches; security validation is owned by SDLC KSI

### Moved to KSI SVC-01 (Continuous Improvement)
- **Original Q039**: Benchmarking against peer CSPs and industry standards
  - *Rationale:* Useful for organizational maturity but not mandated by VDR standard or FedRAMP 20x
  - *VDR Reference:* VDR focuses on capability demonstration, not competitive comparison

### Moved to KSI Meta-Governance (Control Mapping & Documentation)
- **Original Q059**: Broad mapping to NIST SP 800-53 controls (RA, SI, AC, AU, IR)
  - *Rationale:* Cross-framework control mapping is documentation; VDR owns specific control implementations
  - *VDR Reference:* VDR implements controls; control mapping is meta-governance documentation

### Moved to KSI-AFR-01 (Minimum Assessment Scope & Authorization Documentation)
- **Original Q062**: Authorization documentation currency and AI capability evolution tracking
  - *Rationale:* Authorization documentation is AFR-01's responsibility; VDR documents capabilities, AFR-01 maintains authorization
  - *VDR Reference:* VDR contributes capability evidence; AFR-01 maintains authorization documentation

---

## Questions Consolidated for Clarity

### Consolidated: Prompt Injection Against VDR Systems
- **Original Q043 & Q054** → **KSI-AFR-04-Q40**
  - Q043: Monitor prompt injection attacks and jailbreak attempts
  - Q054: Protect against prompt injection that manipulates agents into unauthorized actions
  - *Consolidation:* Single comprehensive question addressing prompt injection threats to VDR agents

### Consolidated: Hallucination and Data Poisoning Against VDR Systems
- **Original Q044 & Q048** → **KSI-AFR-04-Q41**
  - Q044: Identify hallucination risks to prevent false vulnerability reports
  - Q048: Protect against data poisoning attacks creating intentional blindspots
  - *Consolidation:* Single comprehensive question addressing both poisoning and hallucination threats to VDR integrity

---
