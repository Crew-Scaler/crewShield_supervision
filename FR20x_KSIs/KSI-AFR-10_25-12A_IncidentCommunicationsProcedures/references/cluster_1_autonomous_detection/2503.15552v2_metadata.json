{
  "arxiv_id": "2503.15552v2",
  "title": "Personalized Attacks of Social Engineering in Multi-turn Conversations: LLM Agents for Simulation and Detection",
  "authors": [
    "Tharindu Kumarage",
    "Cameron Johnson",
    "Jadie Adams",
    "Lin Ai",
    "Matthias Kirchner",
    "Anthony Hoogs",
    "Joshua Garland",
    "Julia Hirschberg",
    "Arslan Basharat",
    "Huan Liu"
  ],
  "published": "2025-03-18T19:14:44Z",
  "url": "http://arxiv.org/abs/2503.15552v2",
  "pdf_url": "http://arxiv.org/pdf/2503.15552v2.pdf",
  "relevance_score": 100,
  "summary": "The rapid advancement of conversational agents, particularly chatbots powered by Large Language Models (LLMs), poses a significant risk of social engineering (SE) attacks on social media platforms. SE detection in multi-turn, chat-based interactions is considerably more complex than single-instance detection due to the dynamic nature of these conversations. A critical factor in mitigating this threat is understanding the SE attack mechanisms through which SE attacks operate, specifically how attackers exploit vulnerabilities and how victims' personality traits contribute to their susceptibility. In this work, we propose an LLM-agentic framework, SE-VSim, to simulate SE attack mechanisms by generating multi-turn conversations. We model victim agents with varying personality traits to assess how psychological profiles influence susceptibility to manipulation. Using a dataset of over 1000 simulated conversations, we examine attack scenarios in which adversaries, posing as recruiters, funding agencies, and journalists, attempt to extract sensitive information. Based on this analysis, we present a proof of concept, SE-OmniGuard, to offer personalized protection to users by leveraging prior knowledge of the victims personality, evaluating attack strategies, and monitoring information exchanges in conversations to identify potential SE attempts."
}