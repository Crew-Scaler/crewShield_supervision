{
  "arxiv_id": "2511.12668",
  "title": "AI Bill of Materials and Beyond: Systematizing Security Assurance through the AI Risk Scanning (AIRS) Framework",
  "authors": [
    "Samuel Nathanson",
    "Alexander Lee",
    "Catherine Chen Kieffer",
    "Jared Junkin",
    "Jessica Ye",
    "Amir Saeed",
    "Melanie Lockhart",
    "Russ Fink",
    "Elisha Peterson",
    "Lanier Watkins"
  ],
  "published": "2025-11-16T16:10:38Z",
  "url": "http://arxiv.org/abs/2511.12668",
  "pdf_url": "http://arxiv.org/pdf/2511.12668.pdf",
  "relevance_score": 90,
  "summary": "Assurance for artificial intelligence (AI) systems remains fragmented across software supply-chain security, adversarial machine learning, and governance documentation. Existing transparency mechanisms - including Model Cards, Datasheets, and Software Bills of Materials (SBOMs) - advance provenance reporting but rarely provide verifiable, machine-readable evidence of model security. This paper introduces the AI Risk Scanning (AIRS) Framework, a threat-model-based, evidence-generating framework d"
}