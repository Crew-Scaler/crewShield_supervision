{
  "arxiv_id": "2510.25863v2",
  "title": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI",
  "authors": [
    "Ken Huang",
    "Kyriakos Rock Lambros",
    "Jerry Huang",
    "Yasir Mehmood",
    "Hammad Atta",
    "Joshua Beck",
    "Vineeth Sai Narajala",
    "Muhammad Zeeshan Baig",
    "Muhammad Aziz Ul Haq",
    "Nadeem Shahzad",
    "Bhavya Gupta"
  ],
  "published": "2025-10-29T18:06:28Z",
  "url": "http://arxiv.org/abs/2510.25863v2",
  "pdf_url": "http://arxiv.org/pdf/2510.25863v2.pdf",
  "relevance_score": 95,
  "summary": "This paper introduces the Agentic AI Governance Assurance & Trust Engine (AAGATE), a Kubernetes-native control plane designed to address the unique security and governance challenges posed by autonomous, language-model-driven agents in production. Recognizing the limitations of traditional Application Security (AppSec) tooling for improvisational, machine-speed systems, AAGATE operationalizes the NIST AI Risk Management Framework (AI RMF). It integrates specialized security frameworks for each RMF function: the Agentic AI Threat Modeling MAESTRO framework for Map, a hybrid of OWASP's AIVSS and SEI's SSVC for Measure, and the Cloud Security Alliance's Agentic AI Red Teaming Guide for Manage. By incorporating a zero-trust service mesh, an explainable policy engine, behavioral analytics, and decentralized accountability hooks, AAGATE provides a continuous, verifiable governance solution for agentic AI, enabling safe, accountable, and scalable deployment. The framework is further extended with DIRF for digital identity rights, LPCI defenses for logic-layer injection, and QSAF monitors for cognitive degradation, ensuring governance spans systemic, adversarial, and ethical risks."
}