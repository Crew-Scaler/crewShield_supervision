{
  "arxiv_id": "2504.21034v2",
  "title": "SAGA: A Security Architecture for Governing AI Agentic Systems",
  "authors": [
    "Georgios Syros",
    "Anshuman Suri",
    "Jacob Ginesin",
    "Cristina Nita-Rotaru",
    "Alina Oprea"
  ],
  "published": "2025-04-27T23:10:00Z",
  "url": "http://arxiv.org/abs/2504.21034v2",
  "pdf_url": "http://arxiv.org/pdf/2504.21034v2.pdf",
  "relevance_score": 100,
  "summary": "Large Language Model (LLM)-based agents increasingly interact, collaborate, and delegate tasks to one another autonomously with minimal human interaction. Industry guidelines for agentic system governance emphasize the need for users to maintain comprehensive control over their agents, mitigating potential damage from malicious agents. Several proposed agentic system designs address agent identity, authorization, and delegation, but remain purely theoretical, without concrete implementation and evaluation. Most importantly, they do not provide user-controlled agent management.   To address this gap, we propose SAGA, a scalable Security Architecture for Governing Agentic systems, that offers user oversight over their agents' lifecycle. In our design, users register their agents with a central entity, the Provider, that maintains agent contact information, user-defined access control policies, and helps agents enforce these policies on inter-agent communication. We introduce a cryptographic mechanism for deriving access control tokens, that offers fine-grained control over an agent's interaction with other agents, providing formal security guarantees. We evaluate SAGA on several agentic tasks, using agents in different geolocations, and multiple on-device and cloud LLMs, demonstrating minimal performance overhead with no impact on underlying task utility in a wide range of conditions. Our architecture enables secure and trustworthy deployment of autonomous agents, accelerating the responsible adoption of this technology in sensitive environments."
}