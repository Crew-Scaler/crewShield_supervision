arxiv_id,title,authors,publish_date,page_count,first_author_affiliation,relevance_score,abstract_summary
2510.04073,Moral Anchor System: A Predictive Framework for AI Value Alignment and Drift Prevention,Santhosh Kumar Ravindran,2025-10-05,11,Unknown,9,"Bayesian framework for detecting and mitigating value drift in AI agents through LSTM networks and governance mechanisms, targeting response times under 20ms"
2511.07585,LLM Output Drift: Cross-Provider Validation & Mitigation for Financial Workflows,"Raffi Khatchadourian, Rolando Franco",2025-11-10,11,Unknown,8,Analyzes LLM output nondeterminism across providers with validation and mitigation strategies for critical financial workflows
2507.11546,AI Governance InternationaL Evaluation Index (AGILE Index) 2025,"Yi Zeng, Enmeng Lu, Xiaoyang Guo, Cunqing Huangfu, et al.",2025-07-10,81,Unknown,9,"Comprehensive global AI governance framework evaluating 40 countries across 4 pillars, 17 dimensions, and 43 indicators for AI regulatory advancement"
2511.13432,The Last Vote: A Multi-Stakeholder Framework for Language Model Governance,"Subramanyam Sahoo, Aditi Chhawacharia",2025-11-17,26,Unknown,8,Multi-stakeholder governance framework for LLMs addressing deployment accountability and distributed decision-making
2509.11332,"A five-layer framework for AI governance: integrating regulation, standards, and certification","Avinash Agarwal, Manisha J. Nene",2025-09-14,17,Unknown,8,"Five-layer governance framework spanning regulatory mandates, standards, assessment methodologies, and certification for AI systems"
2409.13864,Persistent Backdoor Attacks in Continual Learning,"Zhen Guo, Abhinav Kumar, Reza Tourani",2024-09-20,19,Unknown,8,Two persistent backdoor attack methods in continual learning: Blind Task Backdoor and Latent Task Backdoor with minimal adversarial influence
2502.11687,ReVeil: Unconstrained Concealed Backdoor Attack on Deep Neural Networks using Machine Unlearning,"Manaar Alam, Hithem Lamri, Michail Maniatakos",2025-02-17,9,Unknown,8,"Concealed backdoor attacks evading detection via machine unlearning, restoring high attack success rates post-deployment"
2502.05224,"A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations","Yihe Zhou, Tao Ni, Wei-Bin Lee, Qingchuan Zhao",2025-02-06,12,Unknown,9,"Comprehensive survey of backdoor attack vectors in LLMs including triggered responses, trojan weights, and defense mechanisms"
2502.02649,Fully Autonomous AI Agents Should Not be Developed,"Margaret Mitchell, Avijit Ghosh, Alexandra Sasha Luccioni, Giada Pistilli",2025-02-04,8,Hugging Face / AI Now Institute,9,"Policy analysis arguing that risks to people increase with system autonomy, requiring human oversight and intervention mechanisms"
2508.11824,Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering,"Satyam Kumar Navneet, Joydeep Chandra",2025-08-15,12,Unknown,8,Analysis of autonomous system failure modes in AI-driven code generation with mitigation strategies for software engineering
2503.04739,"Responsible Artificial Intelligence Systems: A Roadmap to Society's Trust through Trustworthy AI, Auditability, Accountability, and Governance","Andrés Herrera-Poyatos, Javier Del Ser, Marcos López de Prado, et al.",2025-02-04,22,Unknown,9,"Holistic framework for responsible AI spanning regulatory context, trustworthy technology, auditability, and governance"
2509.03286,Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making,"Prachi Bagave, Marcus Westberg, Marijn Janssen, Aaron Yi Ding",2025-09-03,10,Unknown,7,Joint accountability framework for healthcare AI addressing multi-stakeholder responsibility in automated decision making
2504.18236,Two Means to an End Goal: Connecting Explainability and Contestability in the Regulation of Public Sector AI,"Timothée Schmude, Mireia Yurrita, Kars Alfrink, et al.",2025-04-25,19,Unknown,8,Analysis of explainability and contestability as complementary governance mechanisms for trustworthy public sector AI
2408.02946,Scaling Trends for Data Poisoning in LLMs,"Dillon Bowen, Brendan Murphy, Will Cai, David Khachaturov, Adam Gleave, Kellin Pelrine",2024-08-06,15,Unknown,9,"Demonstrates larger LLMs are more susceptible to data poisoning, with 24 frontier models (1.5-72B params) across threat scenarios"
2509.08713,"The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems","Ziming Luo, Atoosa Kasirzadeh, Nihar B. Shah",2025-09-10,12,Carnegie Mellon University,8,"Identifies four failure modes in AI scientist systems: inappropriate benchmark selection, data leakage, metric misuse, and selection bias"
2503.22759,Data Poisoning in Deep Learning: A Survey,"Pinlong Zhao, Weiyao Zhu, Pengfei Jiao, Di Gao, Ou Wu",2025-03-27,18,Unknown,9,"Comprehensive survey of data poisoning in deep learning and LLMs with attack vectors, defenses, and evaluation methods"
2510.07192,Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples,"Alexandra Souly, Javier Rando, Ed Chapman, et al.",2025-10-08,13,University of Oxford,9,"Research showing ~250 poisoned documents effectively compromise LLMs regardless of dataset size, with novel defense analysis"
2505.15175,A Linear Approach to Data Poisoning,"Donald Flynn, Diego Granziol",2025-05-21,9,University of Bath,7,Linear algebraic approach to understanding and analyzing data poisoning attacks with theoretical analysis
2410.15042,Adversarial Training: A Survey,"Mengnan Zhao, Lihe Zhang, Jingwen Ye, Huchuan Lu, Baocai Yin, Xinchao Wang",2024-10-19,16,Unknown,7,Comprehensive survey of adversarial training as min-max optimization for robust model training
2508.03970,"Data and AI governance: Promoting equity, ethics, and fairness in large language models","Alok Abhishek, Lisa Erickson, Tushar Bandopadhyay",2025-08-05,11,Unknown,8,"Governance framework for data lifecycle management in AI systems emphasizing equity, ethics, and fairness"
2503.05773,"Between Innovation and Oversight: A Cross-Regional Study of AI Risk Management Frameworks in the EU, U.S., UK, and China",Amir Al-Maamari,2025-02-25,15,Unknown,8,Cross-regional analysis of AI risk management frameworks comparing regulatory approaches across major jurisdictions
2511.05535,Future of AI Models: A Computational perspective on Model collapse,"Trivikram Satharasi, S Sitharama Iyengar, et al.",2025-10-29,11,University of Florida,8,Analysis of model collapse from synthetic data training with semantic similarity tracking in Wikipedia corpus (2013-2025)
2411.15616,A Scalable Approach to Covariate and Concept Drift Management via Adaptive Data Segmentation,"Vennela Yarabolu, Govind Waghmare, Sonia Gupta, Siddhartha Asthana",2024-11-23,10,Unknown,8,Scalable algorithm for managing data and concept drift in continuous ML systems via adaptive segmentation
2410.13995,Adversarial Inception Backdoor Attacks against Reinforcement Learning,Unknown,2024-10-18,13,Unknown,8,Novel backdoor attacks on deep RL agents via adversarial training data poisoning with trigger manipulation
