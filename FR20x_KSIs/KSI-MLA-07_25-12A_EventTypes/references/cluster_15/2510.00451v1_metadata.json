{
  "arxiv_id": "2510.00451v1",
  "title": "A Call to Action for a Secure-by-Design Generative AI Paradigm",
  "published": "2025-10-01T03:05:07Z",
  "summary": "Large language models have gained widespread prominence, yet their vulnerability to prompt injection and other adversarial attacks remains a critical concern. This paper argues for a security-by-design AI paradigm that proactively mitigates LLM vulnerabilities while enhancing performance. To achieve this, we introduce PromptShield, an ontology-driven framework that ensures deterministic and secure prompt interactions. It standardizes user inputs through semantic validation, eliminating ambiguity",
  "category": "cs.CR",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2510.00451v1",
  "cluster": 15,
  "issue": 172,
  "downloaded_at": "2026-01-11T10:27:41.326566"
}