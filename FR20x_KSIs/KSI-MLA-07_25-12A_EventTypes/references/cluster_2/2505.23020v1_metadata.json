{
  "arxiv_id": "2505.23020v1",
  "title": "AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models",
  "published": "2025-05-29T03:02:18Z",
  "summary": "The acquisition of agentic capabilities has transformed LLMs from \"knowledge providers\" to \"action executors\", a trend that while expanding LLMs' capability boundaries, significantly increases their susceptibility to malicious use. Previous work has shown that current LLM-based agents execute numerous malicious tasks even without being attacked, indicating a deficiency in agentic use safety alignment during the post-training phase. To address this gap, we propose AgentAlign, a novel framework th",
  "category": "cs.CR",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2505.23020v1",
  "cluster": 2,
  "issue": 172,
  "downloaded_at": "2026-01-11T10:27:41.292215"
}