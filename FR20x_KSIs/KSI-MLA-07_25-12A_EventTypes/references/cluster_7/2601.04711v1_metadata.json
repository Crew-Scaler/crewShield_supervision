{
  "arxiv_id": "2601.04711v1",
  "title": "DSC2025 -- ViHallu Challenge: Detecting Hallucination in Vietnamese LLMs",
  "published": "2026-01-08T08:27:47Z",
  "summary": "The reliability of large language models (LLMs) in production environments remains significantly constrained by their propensity to generate hallucinations -- fluent, plausible-sounding outputs that contradict or fabricate information. While hallucination detection has recently emerged as a priority in English-centric benchmarks, low-to-medium resource languages such as Vietnamese remain inadequately covered by standardized evaluation frameworks. This paper introduces the DSC2025 ViHallu Challen",
  "category": "cs.CL",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2601.04711v1",
  "cluster": 7,
  "issue": 172,
  "downloaded_at": "2026-01-11T10:27:41.318175"
}