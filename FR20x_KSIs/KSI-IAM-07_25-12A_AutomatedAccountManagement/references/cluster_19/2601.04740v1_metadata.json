{
  "arxiv_id": "2601.04740v1",
  "title": "RiskAtlas: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation",
  "published": "2026-01-08T09:05:28Z",
  "summary": "Large language models (LLMs) are increasingly applied in specialized domains such as finance and healthcare, where they introduce unique safety risks. Domain-specific datasets of harmful prompts remain scarce and still largely rely on manual construction; public datasets mainly focus on explicit harmful prompts, which modern LLM defenses can often detect and refuse. In contrast, implicit harmful prompts-expressed through indirect domain knowledge-are harder to detect and better reflect real-worl",
  "category": "cs.CL",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2601.04740v1",
  "cluster": 19,
  "issue": 171,
  "downloaded_at": "2026-01-11T10:27:49.561627"
}