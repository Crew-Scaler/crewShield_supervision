{
  "arxiv_id": "2601.00270v1",
  "title": "Rectifying Adversarial Examples Using Their Vulnerabilities",
  "published": "2026-01-01T09:22:11Z",
  "summary": "Deep neural network-based classifiers are prone to errors when processing adversarial examples (AEs). AEs are minimally perturbed input data undetectable to humans posing significant risks to security-dependent applications. Hence, extensive research has been undertaken to develop defense mechanisms that mitigate their threats. Most existing methods primarily focus on discriminating AEs based on the input sample features, emphasizing AE detection without addressing the correct sample categorizat",
  "category": "cs.CR",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2601.00270v1",
  "cluster": 10,
  "issue": 171,
  "downloaded_at": "2026-01-11T10:27:49.548291"
}