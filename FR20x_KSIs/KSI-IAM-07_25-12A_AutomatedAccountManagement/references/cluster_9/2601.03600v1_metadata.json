{
  "arxiv_id": "2601.03600v1",
  "title": "ALERT: Zero-shot LLM Jailbreak Detection via Internal Discrepancy Amplification",
  "published": "2026-01-07T05:30:53Z",
  "summary": "Despite rich safety alignment strategies, large language models (LLMs) remain highly susceptible to jailbreak attacks, which compromise safety guardrails and pose serious security risks. Existing detection methods mainly detect jailbreak status relying on jailbreak templates present in the training data. However, few studies address the more realistic and challenging zero-shot jailbreak detection setting, where no jailbreak templates are available during training. This setting better reflects re",
  "category": "cs.LG",
  "relevance": 85,
  "url": "https://arxiv.org/abs/2601.03600v1",
  "cluster": 9,
  "issue": 171,
  "downloaded_at": "2026-01-11T10:27:49.546043"
}