{
  "arxiv_id": "2512.24766",
  "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
  "authors": [
    "Karthik Dharmarajan",
    "Wenlong Huang",
    "Jiajun Wu",
    "Li Fei-Fei",
    "Ruohan Zhang"
  ],
  "published": "2025-12-31T10:25:24Z",
  "url": "http://arxiv.org/abs/2512.24766v1",
  "pdf_url": "https://arxiv.org/pdf/2512.24766v1",
  "relevance_score": 75,
  "dimension": "Knowledge Retention and Continuous Learning",
  "cluster": "E",
  "summary": "Generative video modeling has emerged as a compelling tool to zero-shot reason about plausible physical interactions for open-world manipulation. Yet, it remains a challenge to translate such human-led motions into the low-level actions demanded by robotic systems. We observe that given an initial i"
}