{
  "arxiv_id": "2512.24574",
  "title": "Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time",
  "authors": [
    "Zhenyu Zhang",
    "Xiaoxia Wu",
    "Zhongzhu Zhou",
    "Qingyang Wu",
    "Yineng Zhang",
    "Pragaash Ponnusamy",
    "Harikaran Subbaraj",
    "Jue Wang",
    "Shuaiwen Leon Song",
    "Ben Athiwaratkun"
  ],
  "published": "2025-12-31T02:46:04Z",
  "url": "http://arxiv.org/abs/2512.24574v1",
  "pdf_url": "https://arxiv.org/pdf/2512.24574v1",
  "relevance_score": 90,
  "dimension": "Knowledge Retention and Continuous Learning",
  "cluster": "E",
  "summary": "Large Language Models (LLMs) often rely on long chain-of-thought (CoT) reasoning to solve complex tasks. While effective, these trajectories are frequently inefficient, leading to high latency from excessive token generation, or unstable reasoning that alternates between underthinking (shallow, inco"
}