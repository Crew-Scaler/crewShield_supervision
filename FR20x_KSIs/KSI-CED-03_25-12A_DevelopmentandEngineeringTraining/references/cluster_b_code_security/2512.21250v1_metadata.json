{
  "arxiv_id": "2512.21250v1",
  "title": "CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents",
  "authors": [
    "Haoyang Li",
    "Mingjin Li",
    "Jinxin Zuo",
    "Siqi Li",
    "Xiao Li",
    "Hao Wu",
    "Yueming Lu",
    "Xiaochuan He"
  ],
  "published": "2025-12-24T15:55:42Z",
  "url": "http://arxiv.org/abs/2512.21250v1",
  "pdf_url": "http://arxiv.org/pdf/2512.21250v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "LLM-based code agents(e.g., ChatGPT Codex) are increasingly deployed as detector for code review and security auditing tasks. Although CoT-enhanced LLM vulnerability detectors are believed to provide improved robustness against obfuscated malicious code, we find that their reasoning chains and semantic abstraction processes exhibit exploitable systematic weaknesses.This allows attackers to covertly embed malicious logic, bypass code review, and propagate backdoored components throughout real-wor"
}