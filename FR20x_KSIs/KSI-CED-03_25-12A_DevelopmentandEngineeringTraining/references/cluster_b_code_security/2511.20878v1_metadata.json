{
  "arxiv_id": "2511.20878v1",
  "title": "Supporting Students in Navigating LLM-Generated Insecure Code",
  "authors": [
    "Jaehwan Park",
    "Kyungchan Lim",
    "Seonhye Park",
    "Doowon Kim"
  ],
  "published": "2025-11-25T21:49:36Z",
  "url": "http://arxiv.org/abs/2511.20878v1",
  "pdf_url": "http://arxiv.org/pdf/2511.20878v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "The advent of Artificial Intelligence (AI), particularly large language models (LLMs), has revolutionized software development by enabling developers to specify tasks in natural language and receive corresponding code, boosting productivity. However, this shift also introduces security risks, as LLMs may generate insecure code that can be exploited by adversaries. Current educational approaches emphasize efficiency while overlooking these risks, leaving students underprepared to identify and mit"
}