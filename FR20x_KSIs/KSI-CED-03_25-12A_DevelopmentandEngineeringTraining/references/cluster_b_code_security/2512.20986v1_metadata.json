{
  "arxiv_id": "2512.20986v1",
  "title": "AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs",
  "authors": [
    "Yihan Wang",
    "Huanqi Yang",
    "Shantanu Pal",
    "Weitao Xu"
  ],
  "published": "2025-12-24T06:29:24Z",
  "url": "http://arxiv.org/abs/2512.20986v1",
  "pdf_url": "http://arxiv.org/pdf/2512.20986v1.pdf",
  "relevance_score": 81,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "The integration of Large Language Models (LLMs) into wearable sensing is creating a new class of mobile applications capable of nuanced human activity understanding. However, the reliability of these systems is critically undermined by their vulnerability to prompt injection attacks, where attackers deliberately input deceptive instructions into LLMs. Traditional defenses, based on static filters and rigid rules, are insufficient to address the semantic complexity of these new attacks. We argue "
}