{
  "arxiv_id": "2512.03720v1",
  "title": "Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs",
  "authors": [
    "Tengyun Ma",
    "Jiaqi Yao",
    "Daojing He",
    "Shihao Peng",
    "Yu Li",
    "Shaohui Liu",
    "Zhuotao Tian"
  ],
  "published": "2025-12-03T12:10:21Z",
  "url": "http://arxiv.org/abs/2512.03720v1",
  "pdf_url": "http://arxiv.org/pdf/2512.03720v1.pdf",
  "relevance_score": 73,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Co"
}