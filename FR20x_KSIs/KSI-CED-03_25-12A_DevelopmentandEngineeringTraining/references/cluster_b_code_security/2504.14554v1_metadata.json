{
  "arxiv_id": "2504.14554v1",
  "title": "REDEditing: Relationship-Driven Precise Backdoor Poisoning on Text-to-Image Diffusion Models",
  "authors": [
    "Chongye Guo",
    "Jinhu Fu",
    "Junfeng Fang",
    "Kun Wang",
    "Guorui Feng"
  ],
  "published": "2025-04-20T09:54:59Z",
  "url": "http://arxiv.org/abs/2504.14554v1",
  "pdf_url": "http://arxiv.org/pdf/2504.14554v1.pdf",
  "relevance_score": 70,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "The rapid advancement of generative AI highlights the importance of text-to-image (T2I) security, particularly with the threat of backdoor poisoning. Timely disclosure and mitigation of security vulnerabilities in T2I models are crucial for ensuring the safe deployment of generative models. We explore a novel training-free backdoor poisoning paradigm through model editing, which is recently employed for knowledge updating in large language models. Nevertheless, we reveal the potential security r"
}