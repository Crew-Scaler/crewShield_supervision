{
  "arxiv_id": "2512.20823v1",
  "title": "NotSoTiny: A Large, Living Benchmark for RTL Code Generation",
  "authors": [
    "Razine Moundir Ghorab",
    "Emanuele Parisi",
    "Cristian Gutierrez",
    "Miquel Alberti-Binimelis",
    "Miquel Moreto",
    "Dario Garcia-Gasulla",
    "Gokcen Kestor"
  ],
  "published": "2025-12-23T22:53:47Z",
  "url": "http://arxiv.org/abs/2512.20823v1",
  "pdf_url": "http://arxiv.org/pdf/2512.20823v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "LLMs have shown early promise in generating RTL code, yet evaluating their capabilities in realistic setups remains a challenge. So far, RTL benchmarks have been limited in scale, skewed toward trivial designs, offering minimal verification rigor, and remaining vulnerable to data contamination. To overcome these limitations and to push the field forward, this paper introduces NotSoTiny, a benchmark that assesses LLM on the generation of structurally rich and context-aware RTL. Built from hundred"
}