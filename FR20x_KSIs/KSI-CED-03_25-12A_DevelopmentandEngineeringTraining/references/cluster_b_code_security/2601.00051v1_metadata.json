{
  "arxiv_id": "2601.00051v1",
  "title": "TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model",
  "authors": [
    "Yabo Chen",
    "Yuanzhi Liang",
    "Jiepeng Wang",
    "Tingxi Chen",
    "Junfei Cheng",
    "Zixiao Gu",
    "Yuyang Huang",
    "Zicheng Jiang",
    "Wei Li",
    "Tian Li",
    "Weichen Li",
    "Zuoxin Li",
    "Guangce Liu",
    "Jialun Liu",
    "Junqi Liu",
    "Haoyuan Wang",
    "Qizhen Weng",
    "Xuan'er Wu",
    "Xunzhi Xiang",
    "Xiaoyan Yang",
    "Xin Zhang",
    "Shiwen Zhang",
    "Junyu Zhou",
    "Chengcheng Zhou",
    "Haibin Huang",
    "Chi Zhang",
    "Xuelong Li"
  ],
  "published": "2025-12-31T18:31:46Z",
  "url": "http://arxiv.org/abs/2601.00051v1",
  "pdf_url": "http://arxiv.org/pdf/2601.00051v1.pdf",
  "relevance_score": 85,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framew"
}