{
  "arxiv_id": "2601.00086v2",
  "title": "RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning",
  "authors": [
    "Xiang Gao",
    "Yuguang Yao",
    "Qi Zhang",
    "Kaiwen Dong",
    "Avinash Baidya",
    "Ruocheng Guo",
    "Hilaf Hasson",
    "Kamalika Das"
  ],
  "published": "2025-12-31T19:40:10Z",
  "url": "http://arxiv.org/abs/2601.00086v2",
  "pdf_url": "http://arxiv.org/pdf/2601.00086v2.pdf",
  "relevance_score": 71,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rule"
}