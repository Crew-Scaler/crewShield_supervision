{
  "arxiv_id": "2510.24677v1",
  "title": "Dissecting Role Cognition in Medical LLMs via Neuronal Ablation",
  "authors": [
    "Xun Liang",
    "Huayi Lai",
    "Hanyu Wang",
    "Wentao Zhang",
    "Linfeng Zhang",
    "Yanfang Chen",
    "Feiyu Xiong",
    "Zhiyu Li"
  ],
  "published": "2025-10-28T17:40:53Z",
  "url": "http://arxiv.org/abs/2510.24677v1",
  "pdf_url": "http://arxiv.org/pdf/2510.24677v1.pdf",
  "relevance_score": 73,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large language models (LLMs) have gained significant traction in medical decision support systems, particularly in the\n  context of medical question answering and role-playing simulations. A common practice, Prompt-Based Role Playing (PBRP),\n  instructs models to adopt different clinical roles (e.g., medical students, residents, attending physicians) to simulate varied\n  professional behaviors. However, the impact of such role prompts on model reasoning capabilities remains unclear. This\n  study"
}