{
  "arxiv_id": "2601.00100v1",
  "title": "Learning Speech Representations with Variational Predictive Coding",
  "authors": [
    "Sung-Lin Yeh",
    "Peter Bell",
    "Hao Tang"
  ],
  "published": "2025-12-31T20:10:29Z",
  "url": "http://arxiv.org/abs/2601.00100v1",
  "pdf_url": "http://arxiv.org/pdf/2601.00100v1.pdf",
  "relevance_score": 63,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Despite being the best known objective for learning speech representations, the HuBERT objective has not been further developed and improved. We argue that it is the lack of an underlying principle that stalls the development, and, in this paper, we show that predictive coding under a variational view is the principle behind the HuBERT objective. Due to its generality, our formulation provides opportunities to improve parameterization and optimization, and we show two simple modifications that b"
}