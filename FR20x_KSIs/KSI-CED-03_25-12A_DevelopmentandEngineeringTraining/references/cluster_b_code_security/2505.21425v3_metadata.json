{
  "arxiv_id": "2505.21425v3",
  "title": "GUARD:Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural Code Generation",
  "authors": [
    "Naizhu Jin",
    "Zhong Li",
    "Tian Zhang",
    "Qingkai Zeng"
  ],
  "published": "2025-05-27T16:55:46Z",
  "url": "http://arxiv.org/abs/2505.21425v3",
  "pdf_url": "http://arxiv.org/pdf/2505.21425v3.pdf",
  "relevance_score": 95,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "With the widespread application of large language models in code generation, recent studies demonstrate that employing additional Chain-of-Thought generation models can significantly enhance code generation performance by providing explicit reasoning steps. However, as external components, CoT models are particularly vulnerable to backdoor attacks, which existing defense mechanisms often fail to detect effectively. To address this challenge, we propose GUARD, a novel dual-agent defense framework"
}