{
  "arxiv_id": "2512.24440v1",
  "title": "Towards mechanistic understanding in a data-driven weather model: internal activations reveal interpretable physical features",
  "authors": [
    "Theodore MacMillan",
    "Nicholas T. Ouellette"
  ],
  "published": "2025-12-30T19:50:30Z",
  "url": "http://arxiv.org/abs/2512.24440v1",
  "pdf_url": "http://arxiv.org/pdf/2512.24440v1.pdf",
  "relevance_score": 59,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large data-driven physics models like DeepMind's weather model GraphCast have empirically succeeded in parameterizing time operators for complex dynamical systems with an accuracy reaching or in some cases exceeding that of traditional physics-based solvers. Unfortunately, how these data-driven models perform computations is largely unknown and whether their internal representations are interpretable or physically consistent is an open question. Here, we adapt tools from interpretability researc"
}