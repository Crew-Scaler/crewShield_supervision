{
  "arxiv_id": "2505.11586v1",
  "title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks",
  "authors": [
    "Rui Zhang",
    "Yun Shen",
    "Hongwei Li",
    "Wenbo Jiang",
    "Hanxiao Chen",
    "Yuan Zhang",
    "Guowen Xu",
    "Yang Zhang"
  ],
  "published": "2025-05-16T17:59:53Z",
  "url": "http://arxiv.org/abs/2505.11586v1",
  "pdf_url": "http://arxiv.org/pdf/2505.11586v1.pdf",
  "relevance_score": 62,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Recent research highlights concerns about the trustworthiness of third-party Pre-Trained Language Models (PTLMs) due to potential backdoor attacks. These backdoored PTLMs, however, are effective only for specific pre-defined downstream tasks. In reality, these PTLMs can be adapted to many other unrelated downstream tasks. Such adaptation may lead to unforeseen consequences in downstream model outputs, consequently raising user suspicion and compromising attack stealthiness. We refer to this phen"
}