{
  "arxiv_id": "2510.22170v1",
  "title": "Measure what Matters: Psychometric Evaluation of AI with Situational Judgment Tests",
  "authors": [
    "Alexandra Yost",
    "Shreyans Jain",
    "Shivam Raval",
    "Grant Corser",
    "Allen Roush",
    "Nina Xu",
    "Jacqueline Hammack",
    "Ravid Shwartz-Ziv",
    "Amirali Abdullah"
  ],
  "published": "2025-10-25T05:45:10Z",
  "url": "http://arxiv.org/abs/2510.22170v1",
  "pdf_url": "http://arxiv.org/pdf/2510.22170v1.pdf",
  "relevance_score": 62,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "AI psychometrics evaluates AI systems in roles that traditionally require emotional judgment and ethical consideration. Prior work often reuses human trait inventories (Big Five, \\hexaco) or ad hoc personas, limiting behavioral realism and domain relevance. We propose a framework that (1) uses situational judgment tests (SJTs) from realistic scenarios to probe domain-specific competencies; (2) integrates industrial-organizational and personality psychology to design sophisticated personas which "
}