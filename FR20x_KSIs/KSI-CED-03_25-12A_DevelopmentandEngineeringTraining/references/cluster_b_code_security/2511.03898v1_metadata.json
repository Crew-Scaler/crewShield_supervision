{
  "arxiv_id": "2511.03898v1",
  "title": "Secure Code Generation at Scale with Reflexion",
  "authors": [
    "Arup Datta",
    "Ahmed Aljohani",
    "Hyunsook Do"
  ],
  "published": "2025-11-05T22:46:24Z",
  "url": "http://arxiv.org/abs/2511.03898v1",
  "pdf_url": "http://arxiv.org/pdf/2511.03898v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large language models (LLMs) are now widely used to draft and refactor code, but code that works is not necessarily secure. We evaluate secure code generation using the Instruct Prime, which eliminated compliance-required prompts and cue contamination, and evaluate five instruction-tuned code LLMs using a zero-shot baseline and a three-round reflexion prompting approach. Security is measured using the Insecure Code Detector (ICD), and results are reported by measuring Repair, Regression, and Net"
}