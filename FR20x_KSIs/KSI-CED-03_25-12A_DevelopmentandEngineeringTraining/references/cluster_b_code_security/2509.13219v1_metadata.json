{
  "arxiv_id": "2509.13219v1",
  "title": "On the Out-of-Distribution Backdoor Attack for Federated Learning",
  "authors": [
    "Jiahao Xu",
    "Zikai Zhang",
    "Rui Hu"
  ],
  "published": "2025-09-16T16:23:39Z",
  "url": "http://arxiv.org/abs/2509.13219v1",
  "pdf_url": "http://arxiv.org/pdf/2509.13219v1.pdf",
  "relevance_score": 62,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Traditional backdoor attacks in federated learning (FL) operate within constrained attack scenarios, as they depend on visible triggers and require physical modifications to the target object, which limits their practicality. To address this limitation, we introduce a novel backdoor attack prototype for FL called the out-of-distribution (OOD) backdoor attack ($\\mathtt{OBA}$), which uses OOD data as both poisoned samples and triggers simultaneously. Our approach significantly broadens the scope o"
}