{
  "arxiv_id": "2510.03442v1",
  "title": "The Argument is the Explanation: Structured Argumentation for Trust in Agents",
  "authors": [
    "Ege Cakar",
    "Per Ola Kristensson"
  ],
  "published": "2025-10-03T19:04:15Z",
  "url": "http://arxiv.org/abs/2510.03442v1",
  "pdf_url": "http://arxiv.org/pdf/2510.03442v1.pdf",
  "relevance_score": 72,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Humans are black boxes -- we cannot observe their neural processes, yet society functions by evaluating verifiable arguments. AI explainability should follow this principle: stakeholders need verifiable reasoning chains, not mechanistic transparency. We propose using structured argumentation to provide a level of explanation and verification neither interpretability nor LLM-generated explanation is able to offer. Our pipeline achieves state-of-the-art 94.44 macro F1 on the AAEC published train/t"
}