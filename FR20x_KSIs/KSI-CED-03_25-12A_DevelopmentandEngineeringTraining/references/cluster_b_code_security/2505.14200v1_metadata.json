{
  "arxiv_id": "2505.14200v1",
  "title": "Capturing the Effects of Quantization on Trojans in Code LLMs",
  "authors": [
    "Aftab Hussain",
    "Sadegh AlMahdi Kazemi Zarkouei",
    "Md Rafiqul Islam Rabin",
    "Mohammad Amin Alipour",
    "Sen Lin",
    "Bowen Xu"
  ],
  "published": "2025-05-20T11:01:14Z",
  "url": "http://arxiv.org/abs/2505.14200v1",
  "pdf_url": "http://arxiv.org/pdf/2505.14200v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large language models of code exhibit high capability in performing diverse software engineering tasks, such as code translation, defect detection, text-to-code generation, and code summarization. While their ability to enhance developer productivity has spurred widespread use, these models have also seen substantial growth in size, often reaching billions of parameters. This scale demands efficient memory resource usage, prompting practitioners to use optimization techniques such as model quant"
}