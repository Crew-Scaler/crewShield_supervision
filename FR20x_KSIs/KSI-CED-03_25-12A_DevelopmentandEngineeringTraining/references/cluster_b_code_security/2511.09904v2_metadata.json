{
  "arxiv_id": "2511.09904v2",
  "title": "CTRL-ALT-DECEIT: Sabotage Evaluations for Automated AI R&amp;D",
  "authors": [
    "Francis Rhys Ward",
    "Teun van der Weij",
    "Hanna G\u00e1bor",
    "Sam Martin",
    "Raja Mehta Moreno",
    "Harel Lidar",
    "Louis Makower",
    "Thomas Jodrell",
    "Lauren Robson"
  ],
  "published": "2025-11-13T03:02:36Z",
  "url": "http://arxiv.org/abs/2511.09904v2",
  "pdf_url": "http://arxiv.org/pdf/2511.09904v2.pdf",
  "relevance_score": 69,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "AI systems are increasingly able to autonomously conduct realistic software engineering tasks, and may soon be deployed to automate machine learning (ML) R&amp;D itself. Frontier AI systems may be deployed in safety-critical settings, including to help ensure the safety of future systems. Unfortunately, frontier and future systems may not be sufficiently trustworthy, and there is evidence that these systems may even be misaligned with their developers or users. Therefore, we investigate the capa"
}