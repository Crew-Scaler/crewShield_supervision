{
  "arxiv_id": "2504.07717v3",
  "title": "PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization",
  "authors": [
    "Yang Jiao",
    "Xiaodong Wang",
    "Kai Yang"
  ],
  "published": "2025-04-10T13:09:50Z",
  "url": "http://arxiv.org/abs/2504.07717v3",
  "pdf_url": "http://arxiv.org/pdf/2504.07717v3.pdf",
  "relevance_score": 97,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LL"
}