{
  "arxiv_id": "2511.07099v1",
  "title": "E2E-VGuard: Adversarial Prevention for Production LLM-based End-To-End Speech Synthesis",
  "authors": [
    "Zhisheng Zhang",
    "Derui Wang",
    "Yifan Mi",
    "Zhiyong Wu",
    "Jie Gao",
    "Yuxin Cao",
    "Kai Ye",
    "Minhui Xue",
    "Jie Hao"
  ],
  "published": "2025-11-10T13:38:53Z",
  "url": "http://arxiv.org/abs/2511.07099v1",
  "pdf_url": "http://arxiv.org/pdf/2511.07099v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Recent advancements in speech synthesis technology have enriched our daily lives, with high-quality and human-like audio widely adopted across real-world applications. However, malicious exploitation like voice-cloning fraud poses severe security risks. Existing defense techniques struggle to address the production large language model (LLM)-based speech synthesis. While previous studies have considered the protection for fine-tuning synthesizers, they assume manually annotated transcripts. Give"
}