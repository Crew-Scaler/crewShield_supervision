{
  "arxiv_id": "2511.22119v1",
  "title": "PROMPTMINER: Black-Box Prompt Stealing against Text-to-Image Generative Models via Reinforcement Learning and Fuzz Optimization",
  "authors": [
    "Mingzhe Li",
    "Renhao Zhang",
    "Zhiyang Wen",
    "Siqi Pan",
    "Bruno Castro da Silva",
    "Juan Zhai",
    "Shiqing Ma"
  ],
  "published": "2025-11-27T05:22:10Z",
  "url": "http://arxiv.org/abs/2511.22119v1",
  "pdf_url": "http://arxiv.org/pdf/2511.22119v1.pdf",
  "relevance_score": 72,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Text-to-image (T2I) generative models such as Stable Diffusion and FLUX can synthesize realistic, high-quality images directly from textual prompts. The resulting image quality depends critically on well-crafted prompts that specify both subjects and stylistic modifiers, which have become valuable digital assets. However, the rising value and ubiquity of high-quality prompts expose them to security and intellectual-property risks. One key threat is the prompt stealing attack, i.e., the task of r"
}