{
  "arxiv_id": "2601.00092v1",
  "title": "Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark",
  "authors": [
    "Pan Wang",
    "Yang Liu",
    "Guile Wu",
    "Eduardo R. Corral-Soto",
    "Chengjie Huang",
    "Binbin Xu",
    "Dongfeng Bai",
    "Xu Yan",
    "Yuan Ren",
    "Xingxin Chen",
    "Yizhe Wu",
    "Tao Huang",
    "Wenjun Wan",
    "Xin Wu",
    "Pei Zhou",
    "Xuyang Dai",
    "Kangbo Lv",
    "Hongbo Zhang",
    "Yosef Fried",
    "Aixue Ye",
    "Bailan Feng",
    "Zhenyu Chen",
    "Zhen Li",
    "Yingcong Chen",
    "Yiyi Liao",
    "Bingbing Liu"
  ],
  "published": "2025-12-31T19:56:51Z",
  "url": "http://arxiv.org/abs/2601.00092v1",
  "pdf_url": "http://arxiv.org/pdf/2601.00092v1.pdf",
  "relevance_score": 66,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spat"
}