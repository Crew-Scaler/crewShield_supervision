{
  "arxiv_id": "2511.23408v1",
  "title": "Evaluating LLMs for One-Shot Patching of Real and Artificial Vulnerabilities",
  "authors": [
    "Aayush Garg",
    "Zanis Ali Khan",
    "Renzo Degiovanni",
    "Qiang Tang"
  ],
  "published": "2025-11-28T18:03:47Z",
  "url": "http://arxiv.org/abs/2511.23408v1",
  "pdf_url": "http://arxiv.org/pdf/2511.23408v1.pdf",
  "relevance_score": 97,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Automated vulnerability patching is crucial for software security, and recent advancements in Large Language Models (LLMs) present promising capabilities for automating this task. However, existing research has primarily assessed LLMs using publicly disclosed vulnerabilities, leaving their effectiveness on related artificial vulnerabilities largely unexplored. In this study, we empirically evaluate the patching effectiveness and complementarity of several prominent LLMs, such as OpenAI's GPT var"
}