{
  "arxiv_id": "2511.20104v1",
  "title": "The Devil in the Details: Emergent Misalignment, Format and Coherence in Open-Weights LLMs",
  "authors": [
    "Craig Dickson"
  ],
  "published": "2025-11-25T09:25:33Z",
  "url": "http://arxiv.org/abs/2511.20104v1",
  "pdf_url": "http://arxiv.org/pdf/2511.20104v1.pdf",
  "relevance_score": 83,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Prior work has shown that fine-tuning models on a narrow domain with misaligned data can lead to broad misalignment - a phenomenon termed \"emergent misalignment\" (Betley et al. 2025). While all tested models were susceptible to emergent misalignment, some models showed more resistance than others. Specifically the Qwen-2.5 family proved to be relatively resistant, while GPT-4o exhibited the strongest misalignment. In this paper we evaluate if current-generation open-weights models exhibit simila"
}