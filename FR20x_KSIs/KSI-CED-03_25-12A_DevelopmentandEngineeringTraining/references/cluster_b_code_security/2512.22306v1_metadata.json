{
  "arxiv_id": "2512.22306v1",
  "title": "Beyond Single Bugs: Benchmarking Large Language Models for Multi-Vulnerability Detection",
  "authors": [
    "Chinmay Pushkar",
    "Sanchit Kabra",
    "Dhruv Kumar",
    "Jagat Sesh Challa"
  ],
  "published": "2025-12-26T05:43:35Z",
  "url": "http://arxiv.org/abs/2512.22306v1",
  "pdf_url": "http://arxiv.org/pdf/2512.22306v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large Language Models (LLMs) have demonstrated significant potential in automated software security, particularly in vulnerability detection. However, existing benchmarks primarily focus on isolated, single-vulnerability samples or function-level classification, failing to reflect the complexity of real-world software where multiple interacting vulnerabilities often coexist within large files. Recent studies indicate that LLMs suffer from \"count bias\" and \"selection bias\" in multi-label tasks, y"
}