{
  "arxiv_id": "2512.25008v2",
  "title": "FoundationSLAM: Unleashing the Power of Depth Foundation Models for End-to-End Dense Visual SLAM",
  "authors": [
    "Yuchen Wu",
    "Jiahe Li",
    "Fabio Tosi",
    "Matteo Poggi",
    "Jin Zheng",
    "Xiao Bai"
  ],
  "published": "2025-12-31T17:57:45Z",
  "url": "http://arxiv.org/abs/2512.25008v2",
  "pdf_url": "http://arxiv.org/pdf/2512.25008v2.pdf",
  "relevance_score": 61,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "We present FoundationSLAM, a learning-based monocular dense SLAM system that addresses the absence of geometric consistency in previous flow-based approaches for accurate and robust tracking and mapping. Our core idea is to bridge flow estimation with geometric reasoning by leveraging the guidance from foundation depth models. To this end, we first develop a Hybrid Flow Network that produces geometry-aware correspondences, enabling consistent depth and pose inference across diverse keyframes. To"
}