{
  "arxiv_id": "2512.00343v1",
  "title": "Assimilation Matters: Model-level Backdoor Detection in Vision-Language Pretrained Models",
  "authors": [
    "Zhongqi Wang",
    "Jie Zhang",
    "Shiguang Shan",
    "Xilin Chen"
  ],
  "published": "2025-11-29T06:20:00Z",
  "url": "http://arxiv.org/abs/2512.00343v1",
  "pdf_url": "http://arxiv.org/pdf/2512.00343v1.pdf",
  "relevance_score": 62,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Vision-language pretrained models (VLPs) such as CLIP have achieved remarkable success, but are also highly vulnerable to backdoor attacks. Given a model fine-tuned by an untrusted third party, determining whether the model has been injected with a backdoor is a critical and challenging problem. Existing detection methods usually rely on prior knowledge of training dataset, backdoor triggers and targets, or downstream classifiers, which may be impractical for real-world applications. To address "
}