{
  "arxiv_id": "2512.24100v1",
  "title": "Think Before You Move: Latent Motion Reasoning for Text-to-Motion Generation",
  "authors": [
    "Yijie Qian",
    "Juncheng Wang",
    "Yuxiang Feng",
    "Chao Xu",
    "Wang Lu",
    "Yang Liu",
    "Baigui Sun",
    "Yiqiang Chen",
    "Yong Liu",
    "Shujun Wang"
  ],
  "published": "2025-12-30T09:17:44Z",
  "url": "http://arxiv.org/abs/2512.24100v1",
  "pdf_url": "http://arxiv.org/pdf/2512.24100v1.pdf",
  "relevance_score": 70,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Current state-of-the-art paradigms predominantly treat Text-to-Motion (T2M) generation as a direct translation problem, mapping symbolic language directly to continuous poses. While effective for simple actions, this System 1 approach faces a fundamental theoretical bottleneck we identify as the Semantic-Kinematic Impedance Mismatch: the inherent difficulty of grounding semantically dense, discrete linguistic intent into kinematically dense, high-frequency motion data in a single shot. In this p"
}