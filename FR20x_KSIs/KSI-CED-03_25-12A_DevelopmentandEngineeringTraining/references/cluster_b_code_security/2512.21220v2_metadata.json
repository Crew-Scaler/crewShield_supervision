{
  "arxiv_id": "2512.21220v2",
  "title": "RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic",
  "authors": [
    "Le Wang",
    "Zonghao Ying",
    "Xiao Yang",
    "Quanchen Zou",
    "Zhenfei Yin",
    "Tianlin Li",
    "Jian Yang",
    "Yaodong Yang",
    "Aishan Liu",
    "Xianglong Liu"
  ],
  "published": "2025-12-24T15:01:26Z",
  "url": "http://arxiv.org/abs/2512.21220v2",
  "pdf_url": "http://arxiv.org/pdf/2512.21220v2.pdf",
  "relevance_score": 58,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Embodied agents powered by vision-language models (VLMs) are increasingly capable of executing complex real-world tasks, yet they remain vulnerable to hazardous instructions that may trigger unsafe behaviors. Runtime safety guardrails, which intercept hazardous actions during task execution, offer a promising solution due to their flexibility. However, existing defenses often rely on static rule filters or prompt-level control, which struggle to address implicit risks arising in dynamic, tempora"
}