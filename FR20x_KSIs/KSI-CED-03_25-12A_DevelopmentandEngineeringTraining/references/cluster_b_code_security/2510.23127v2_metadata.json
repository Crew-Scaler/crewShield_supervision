{
  "arxiv_id": "2510.23127v2",
  "title": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs",
  "authors": [
    "Kai Zhuang",
    "Jiawei Zhang",
    "Yumou Liu",
    "Hanqun Cao",
    "Chunbin Gu",
    "Mengdi Liu",
    "Zhangyang Gao",
    "Zitong Jerry Wang",
    "Xuanhe Zhou",
    "Pheng-Ann Heng",
    "Lijun Wu",
    "Conghui He",
    "Cheng Tan"
  ],
  "published": "2025-10-27T09:03:21Z",
  "url": "http://arxiv.org/abs/2510.23127v2",
  "pdf_url": "http://arxiv.org/pdf/2510.23127v2.pdf",
  "relevance_score": 70,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Scientific Large Language Models (Sci-LLMs) have emerged as a promising frontier for accelerating biological discovery. However, these models face a fundamental challenge when processing raw biomolecular sequences: the tokenization dilemma. Whether treating sequences as a specialized language, risking the loss of functional motif information, or as a separate modality, introducing formidable alignment challenges, current strategies fundamentally limit their reasoning capacity. We challenge this "
}