{
  "arxiv_id": "2511.20613v1",
  "title": "Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning",
  "authors": [
    "Panayiotis Danassis",
    "Naman Goel"
  ],
  "published": "2025-11-25T18:40:22Z",
  "url": "http://arxiv.org/abs/2511.20613v1",
  "pdf_url": "http://arxiv.org/pdf/2511.20613v1.pdf",
  "relevance_score": 95,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "The rapid proliferation of Large Language Models (LLMs) has revolutionized AI-assisted code generation. This rapid development of LLMs has outpaced our ability to properly benchmark them. Prevailing benchmarks emphasize unit-test pass rates and syntactic correctness. Such metrics understate the difficulty of many real-world problems that require planning, optimization, and strategic interaction. We introduce a multi-agent reasoning-driven benchmark based on a real-world logistics optimization pr"
}