{
  "arxiv_id": "2512.23557v1",
  "title": "Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks",
  "authors": [
    "Toqeer Ali Syed",
    "Mishal Ateeq Almutairi",
    "Mahmoud Abdel Moaty"
  ],
  "published": "2025-12-29T15:54:33Z",
  "url": "http://arxiv.org/abs/2512.23557v1",
  "pdf_url": "http://arxiv.org/pdf/2512.23557v1.pdf",
  "relevance_score": 71,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Powerful autonomous systems, which reason, plan, and converse using and between numerous tools and agents, are made possible by Large Language Models (LLMs), Vision-Language Models (VLMs), and new agentic AI systems, like LangChain and GraphChain. Nevertheless, this agentic environment increases the probability of the occurrence of multimodal prompt injection (PI) attacks, in which concealed or malicious instructions carried in text, pictures, metadata, or agent-to-agent messages may spread thro"
}