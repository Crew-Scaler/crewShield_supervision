{
  "arxiv_id": "2512.10485v1",
  "title": "From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection",
  "authors": [
    "Chaomeng Lu",
    "Bert Lagaisse"
  ],
  "published": "2025-12-11T10:04:54Z",
  "url": "http://arxiv.org/abs/2512.10485v1",
  "pdf_url": "http://arxiv.org/pdf/2512.10485v1.pdf",
  "relevance_score": 93,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Vulnerability detection methods based on deep learning (DL) have shown strong performance on benchmark datasets, yet their real-world effectiveness remains underexplored. Recent work suggests that both graph neural network (GNN)-based and transformer-based models, including large language models (LLMs), yield promising results when evaluated on curated benchmark datasets. These datasets are typically characterized by consistent data distributions and heuristic or partially noisy labels. In this "
}