{
  "arxiv_id": "2512.04259v1",
  "title": "WildCode: An Empirical Analysis of Code Generated by ChatGPT",
  "authors": [
    "Kobra Khanmohammadi",
    "Pooria Roy",
    "Raphael Khoury",
    "Abdelwahab Hamou-Lhadj",
    "Wilfried Patrick Konan"
  ],
  "published": "2025-12-03T20:54:24Z",
  "url": "http://arxiv.org/abs/2512.04259v1",
  "pdf_url": "http://arxiv.org/pdf/2512.04259v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "LLM models are increasingly used to generate code, but the quality and security of this code are often uncertain. Several recent studies have raised alarm bells, indicating that such AI-generated code may be particularly vulnerable to cyberattacks. However, most of these studies rely on code that is generated specifically for the study, which raises questions about the realism of such experiments. In this study, we perform a large-scale empirical analysis of real-life code generated by ChatGPT. "
}