{
  "arxiv_id": "2512.11433v1",
  "title": "Back to the Baseline: Examining Baseline Effects on Explainability Metrics",
  "authors": [
    "Agustin Martin Picard",
    "Thibaut Boissin",
    "Varshini Subhash",
    "R\u00e9mi Cad\u00e8ne",
    "Thomas Fel"
  ],
  "published": "2025-12-12T10:13:44Z",
  "url": "http://arxiv.org/abs/2512.11433v1",
  "pdf_url": "http://arxiv.org/pdf/2512.11433v1.pdf",
  "relevance_score": 62,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over"
}