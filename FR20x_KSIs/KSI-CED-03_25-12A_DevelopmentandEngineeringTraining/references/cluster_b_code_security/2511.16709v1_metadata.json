{
  "arxiv_id": "2511.16709v1",
  "title": "AutoBackdoor: Automating Backdoor Attacks via LLM Agents",
  "authors": [
    "Yige Li",
    "Zhe Li",
    "Wei Zhao",
    "Nay Myat Min",
    "Hanxun Huang",
    "Xingjun Ma",
    "Jun Sun"
  ],
  "published": "2025-11-20T03:58:54Z",
  "url": "http://arxiv.org/abs/2511.16709v1",
  "pdf_url": "http://arxiv.org/pdf/2511.16709v1.pdf",
  "relevance_score": 75,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Backdoor attacks pose a serious threat to the secure deployment of large language models (LLMs), enabling adversaries to implant hidden behaviors triggered by specific inputs. However, existing methods often rely on manually crafted triggers and static data pipelines, which are rigid, labor-intensive, and inadequate for systematically evaluating modern defense robustness. As AI agents become increasingly capable, there is a growing need for more rigorous, diverse, and scalable \\textit{red-teamin"
}