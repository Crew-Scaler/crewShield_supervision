{
  "arxiv_id": "2504.20518v3",
  "title": "Dynamic Attention Analysis for Backdoor Detection in Text-to-Image Diffusion Models",
  "authors": [
    "Zhongqi Wang",
    "Jie Zhang",
    "Shiguang Shan",
    "Xilin Chen"
  ],
  "published": "2025-04-29T07:59:35Z",
  "url": "http://arxiv.org/abs/2504.20518v3",
  "pdf_url": "http://arxiv.org/pdf/2504.20518v3.pdf",
  "relevance_score": 65,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Recent studies have revealed that text-to-image diffusion models are vulnerable to backdoor attacks, where attackers implant stealthy textual triggers to manipulate model outputs. Previous backdoor detection methods primarily focus on the static features of backdoor samples. However, a vital property of diffusion models is their inherent dynamism. This study introduces a novel backdoor detection perspective named Dynamic Attention Analysis (DAA), showing that these dynamic characteristics serve "
}