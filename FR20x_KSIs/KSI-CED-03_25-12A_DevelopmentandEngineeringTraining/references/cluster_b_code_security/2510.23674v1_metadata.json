{
  "arxiv_id": "2510.23674v1",
  "title": "RefleXGen:The unexamined code is not worth using",
  "authors": [
    "Bin Wang",
    "Hui Li",
    "AoFan Liu",
    "BoTao Yang",
    "Ao Yang",
    "YiLu Zhong",
    "Weixiang Huang",
    "Yanping Zhang",
    "Runhuai Huang",
    "Weimin Zeng"
  ],
  "published": "2025-10-27T05:28:32Z",
  "url": "http://arxiv.org/abs/2510.23674v1",
  "pdf_url": "http://arxiv.org/pdf/2510.23674v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Security in code generation remains a pivotal challenge when applying large language models (LLMs). This paper introduces RefleXGen, an innovative method that significantly enhances code security by integrating Retrieval-Augmented Generation (RAG) techniques with guided self-reflection mechanisms inherent in LLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing specialized secure code datasets - processes that can be resource-intensive - RefleXGen iteratively optimizes "
}