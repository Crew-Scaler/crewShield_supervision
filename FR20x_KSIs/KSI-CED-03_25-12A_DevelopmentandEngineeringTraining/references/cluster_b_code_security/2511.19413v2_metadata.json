{
  "arxiv_id": "2511.19413v2",
  "title": "UniGame: Turning a Unified Multimodal Model Into Its Own Adversary",
  "authors": [
    "Zhaolong Su",
    "Wang Lu",
    "Hao Chen",
    "Sharon Li",
    "Jindong Wang"
  ],
  "published": "2025-11-24T18:50:01Z",
  "url": "http://arxiv.org/abs/2511.19413v2",
  "pdf_url": "http://arxiv.org/pdf/2511.19413v2.pdf",
  "relevance_score": 79,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame,"
}