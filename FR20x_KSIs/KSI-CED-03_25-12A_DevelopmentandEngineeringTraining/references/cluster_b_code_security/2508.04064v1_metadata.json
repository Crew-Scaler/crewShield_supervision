{
  "arxiv_id": "2508.04064v1",
  "title": "FLAT: Latent-Driven Arbitrary-Target Backdoor Attacks in Federated Learning",
  "authors": [
    "Tuan Nguyen",
    "Khoa D Doan",
    "Kok-Seng Wong"
  ],
  "published": "2025-08-06T03:54:29Z",
  "url": "http://arxiv.org/abs/2508.04064v1",
  "pdf_url": "http://arxiv.org/pdf/2508.04064v1.pdf",
  "relevance_score": 69,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Federated learning (FL) is vulnerable to backdoor attacks, yet most existing methods are limited by fixed-pattern or single-target triggers, making them inflexible and easier to detect. We propose FLAT (FL Arbitrary-Target Attack), a novel backdoor attack that leverages a latent-driven conditional autoencoder to generate diverse, target-specific triggers as needed. By introducing a latent code, FLAT enables the creation of visually adaptive and highly variable triggers, allowing attackers to sel"
}