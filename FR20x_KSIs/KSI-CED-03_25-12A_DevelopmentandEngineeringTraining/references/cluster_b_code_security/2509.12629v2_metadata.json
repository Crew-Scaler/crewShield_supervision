{
  "arxiv_id": "2509.12629v2",
  "title": "Ensembling Large Language Models for Code Vulnerability Detection: An Empirical Evaluation",
  "authors": [
    "Zhihong Sun",
    "Jia Li",
    "Yao Wan",
    "Chuanyi Li",
    "Hongyu Zhang",
    "Zhi jin",
    "Ge Li",
    "Hong Liu",
    "Chen Lyu",
    "Songlin Hu"
  ],
  "published": "2025-09-16T03:48:22Z",
  "url": "http://arxiv.org/abs/2509.12629v2",
  "pdf_url": "http://arxiv.org/pdf/2509.12629v2.pdf",
  "relevance_score": 85,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Code vulnerability detection is crucial for ensuring the security and reliability of modern software systems. Recently, Large Language Models (LLMs) have shown promising capabilities in this domain. However, notable discrepancies in detection results often arise when analyzing identical code segment"
}