{
  "arxiv_id": "2511.18966v1",
  "title": "LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by Large Language Models",
  "authors": [
    "Muhammad Usman Shahid",
    "Chuadhry Mujeeb Ahmed",
    "Rajiv Ranjan"
  ],
  "published": "2025-11-24T10:31:53Z",
  "url": "http://arxiv.org/abs/2511.18966v1",
  "pdf_url": "http://arxiv.org/pdf/2511.18966v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "The security of code generated by large language models (LLMs) is a significant concern, as studies indicate that such code often contains vulnerabilities and lacks essential defensive programming constructs. This work focuses on examining and evaluating the security of LLM-generated code, particularly in the context of C/C++. We categorized known vulnerabilities using the Common Weakness Enumeration (CWE) and, to study their criticality, mapped them to CVEs. We used ten different LLMs for code "
}