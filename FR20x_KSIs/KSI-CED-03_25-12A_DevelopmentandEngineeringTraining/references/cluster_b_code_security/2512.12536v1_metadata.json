{
  "arxiv_id": "2512.12536v1",
  "title": "Diverse LLMs vs. Vulnerabilities: Who Detects and Fixes Them Better?",
  "authors": [
    "Arastoo Zibaeirad",
    "Marco Vieira"
  ],
  "published": "2025-12-14T03:47:39Z",
  "url": "http://arxiv.org/abs/2512.12536v1",
  "pdf_url": "http://arxiv.org/pdf/2512.12536v1.pdf",
  "relevance_score": 97,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Large Language Models (LLMs) are increasingly being studied for Software Vulnerability Detection (SVD) and Repair (SVR). Individual LLMs have demonstrated code understanding abilities, but they frequently struggle when identifying complex vulnerabilities and generating fixes.\n  This study presents DVDR-LLM, an ensemble framework that combines outputs from diverse LLMs to determine whether aggregating multiple models reduces error rates. Our evaluation reveals that DVDR-LLM achieves 10-12% higher"
}