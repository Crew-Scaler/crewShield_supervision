{
  "arxiv_id": "2510.26025v2",
  "title": "Exploring Human-AI Conceptual Alignment through the Prism of Chess",
  "authors": [
    "Semyon Lomasov",
    "Judah Goldfeder",
    "Mehmet Hamza Erol",
    "Matthew So",
    "Yao Yan",
    "Addison Howard",
    "Nathan Kutz",
    "Ravid Shwartz Ziv"
  ],
  "published": "2025-10-29T23:40:40Z",
  "url": "http://arxiv.org/abs/2510.26025v2",
  "pdf_url": "http://arxiv.org/pdf/2510.26025v2.pdf",
  "relevance_score": 72,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Do AI systems truly understand human concepts or merely mimic surface patterns? We investigate this through chess, where human creativity meets precise strategic concepts. Analyzing a 270M-parameter transformer that achieves grandmaster-level play, we uncover a striking paradox: while early layers encode human concepts like center control and knight outposts with up to 85\\% accuracy, deeper layers, despite driving superior performance, drift toward alien representations, dropping to 50-65\\% accu"
}