{
  "arxiv_id": "2510.08602v1",
  "title": "Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection",
  "authors": [
    "Cong Zeng",
    "Shengkun Tang",
    "Yuanzhou Chen",
    "Zhiqiang Shen",
    "Wenchao Yu",
    "Xujiang Zhao",
    "Haifeng Chen",
    "Wei Cheng",
    "Zhiqiang Xu"
  ],
  "published": "2025-10-07T08:14:45Z",
  "url": "http://arxiv.org/abs/2510.08602v1",
  "pdf_url": "http://arxiv.org/pdf/2510.08602v1.pdf",
  "relevance_score": 73,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "The rapid advancement of large language models (LLMs) such as ChatGPT, DeepSeek, and Claude has significantly increased the presence of AI-generated text in digital communication. This trend has heightened the need for reliable detection methods to distinguish between human-authored and machine-generated content. Existing approaches both zero-shot methods and supervised classifiers largely conceptualize this task as a binary classification problem, often leading to poor generalization across dom"
}