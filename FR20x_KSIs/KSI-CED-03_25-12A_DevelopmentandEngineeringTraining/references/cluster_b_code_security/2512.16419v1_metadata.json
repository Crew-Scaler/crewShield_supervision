{
  "arxiv_id": "2512.16419v1",
  "title": "Large Language Models as a (Bad) Security Norm in the Context of Regulation and Compliance",
  "authors": [
    "Kaspar Rosager Ludvigsen"
  ],
  "published": "2025-12-18T11:14:21Z",
  "url": "http://arxiv.org/abs/2512.16419v1",
  "pdf_url": "http://arxiv.org/pdf/2512.16419v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "The use of Large Language Models (LLM) by providers of cybersecurity and digital infrastructures of all kinds is an ongoing development. It is suggested and on an experimental basis used to write the code for the systems, and potentially fed with sensitive data or what would otherwise be considered trade secrets. Outside of these obvious points, this paper asks how AI can negatively affect cybersecurity and law when used for the design and deployment of security infrastructure by its developers."
}