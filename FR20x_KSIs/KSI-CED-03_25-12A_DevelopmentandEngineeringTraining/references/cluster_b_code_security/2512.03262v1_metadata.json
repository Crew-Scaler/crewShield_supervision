{
  "arxiv_id": "2512.03262v1",
  "title": "Is Vibe Coding Safe? Benchmarking Vulnerability of Agent-Generated Code in Real-World Tasks",
  "authors": [
    "Songwen Zhao",
    "Danqing Wang",
    "Kexun Zhang",
    "Jiaxuan Luo",
    "Zhuo Li",
    "Lei Li"
  ],
  "published": "2025-12-02T22:11:56Z",
  "url": "http://arxiv.org/abs/2512.03262v1",
  "pdf_url": "http://arxiv.org/pdf/2512.03262v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Code Generation Security",
  "cluster": "B",
  "summary": "Vibe coding is a new programming paradigm in which human engineers instruct large language model (LLM) agents to complete complex coding tasks with little supervision. Although it is increasingly adopted, are vibe coding outputs really safe to deploy in production? To answer this question, we propose SU S VI B E S, a benchmark consisting of 200 feature-request software engineering tasks from real-world open-source projects, which, when given to human programmers, led to vulnerable implementation"
}