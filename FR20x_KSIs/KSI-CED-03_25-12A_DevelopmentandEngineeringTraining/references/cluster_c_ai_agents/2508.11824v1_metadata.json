{
  "arxiv_id": "2508.11824v1",
  "title": "Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering",
  "authors": [
    "Satyam Kumar Navneet",
    "Joydeep Chandra"
  ],
  "published": "2025-08-15T22:13:54Z",
  "url": "http://arxiv.org/abs/2508.11824v1",
  "pdf_url": "http://arxiv.org/pdf/2508.11824v1.pdf",
  "relevance_score": 87,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "The integration of Large Language Models (LLMs) into software engineering has revolutionized code generation, enabling unprecedented productivity through promptware and autonomous AI agents. However, this transformation introduces significant risks, including insecure code generation, hallucinated outputs, irreversible actions, and a lack of transparency and accountability. Incidents like the Replit database deletion underscore the urgent need for robust safety and governance mechanisms. This pa"
}