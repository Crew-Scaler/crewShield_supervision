{
  "arxiv_id": "2405.02769v1",
  "title": "Linear Convergence of Independent Natural Policy Gradient in Games with Entropy Regularization",
  "authors": [
    "Youbang Sun",
    "Tao Liu",
    "P. R. Kumar",
    "Shahin Shahrampour"
  ],
  "published": "2024-05-04T22:48:53Z",
  "url": "http://arxiv.org/abs/2405.02769v1",
  "pdf_url": "http://arxiv.org/pdf/2405.02769v1.pdf",
  "relevance_score": 77,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "This work focuses on the entropy-regularized independent natural policy gradient (NPG) algorithm in multi-agent reinforcement learning. In this work, agents are assumed to have access to an oracle with exact policy evaluation and seek to maximize their respective independent rewards. Each individual's reward is assumed to depend on the actions of all the agents in the multi-agent system, leading to a game between agents. We assume all agents make decisions under a policy with bounded rationality"
}