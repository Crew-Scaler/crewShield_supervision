{
  "arxiv_id": "2510.27623v1",
  "title": "Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning",
  "authors": [
    "Qiusi Zhan",
    "Hyeonjeong Ha",
    "Rui Yang",
    "Sirui Xu",
    "Hanyang Chen",
    "Liang-Yan Gui",
    "Yu-Xiong Wang",
    "Huan Zhang",
    "Heng Ji",
    "Daniel Kang"
  ],
  "published": "2025-10-31T16:50:49Z",
  "url": "http://arxiv.org/abs/2510.27623v1",
  "pdf_url": "http://arxiv.org/pdf/2510.27623v1.pdf",
  "relevance_score": 87,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Multimodal large language models (MLLMs) have advanced embodied agents by enabling direct perception, reasoning, and planning task-oriented actions from visual inputs. However, such vision driven embodied agents open a new attack surface: visual backdoor attacks, where the agent behaves normally until a visual trigger appears in the scene, then persistently executes an attacker-specified multi-step policy. We introduce BEAT, the first framework to inject such visual backdoors into MLLM-based emb"
}