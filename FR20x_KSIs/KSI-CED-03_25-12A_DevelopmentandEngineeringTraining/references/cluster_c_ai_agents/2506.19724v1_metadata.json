{
  "arxiv_id": "2506.19724v1",
  "title": "From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking",
  "authors": [
    "Gyeongwon James Kim",
    "Alex Wilf",
    "Louis-Philippe Morency",
    "Daniel Fried"
  ],
  "published": "2025-06-24T15:39:20Z",
  "url": "http://arxiv.org/abs/2506.19724v1",
  "pdf_url": "http://arxiv.org/pdf/2506.19724v1.pdf",
  "relevance_score": 91,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Recent progress in autonomous code generation has fueled excitement around AI agents capable of accelerating scientific discovery by running experiments. However, there is currently no benchmark that evaluates whether such agents can implement scientific ideas when given varied amounts of code as a starting point, interpolating between reproduction (running code) and from-scratch replication (fully re-implementing and running code). We introduce AutoExperiment, a benchmark that evaluates AI agen"
}