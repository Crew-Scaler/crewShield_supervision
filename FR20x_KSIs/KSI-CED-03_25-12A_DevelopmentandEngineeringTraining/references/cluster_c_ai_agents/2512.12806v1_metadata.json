{
  "arxiv_id": "2512.12806v1",
  "title": "Fault-Tolerant Sandboxing for AI Coding Agents: A Transactional Approach to Safe Autonomous Execution",
  "authors": [
    "Boyang Yan"
  ],
  "published": "2025-12-14T19:03:59Z",
  "url": "http://arxiv.org/abs/2512.12806v1",
  "pdf_url": "http://arxiv.org/pdf/2512.12806v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "The transition of Large Language Models (LLMs) from passive code generators to autonomous agents introduces significant safety risks, specifically regarding destructive commands and inconsistent system states. Existing commercial solutions often prioritize interactive user safety, enforcing authentication barriers that break the headless loops required for true autonomy. This paper presents a Fault-Tolerant Sandboxing framework designed to mitigate these risks through a policy-based interception"
}