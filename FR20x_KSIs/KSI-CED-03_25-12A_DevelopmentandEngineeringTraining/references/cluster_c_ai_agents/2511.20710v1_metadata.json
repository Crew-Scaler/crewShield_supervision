{
  "arxiv_id": "2511.20710v1",
  "title": "Are Neuro-Inspired Multi-Modal Vision-Language Models Resilient to Membership Inference Privacy Leakage?",
  "authors": [
    "David Amebley",
    "Sayanton Dibbo"
  ],
  "published": "2025-11-24T22:32:03Z",
  "url": "http://arxiv.org/abs/2511.20710v1",
  "pdf_url": "http://arxiv.org/pdf/2511.20710v1.pdf",
  "relevance_score": 75,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "In the age of agentic AI, the growing deployment of multi-modal models (MMs) has introduced new attack vectors that can leak sensitive training data in MMs, causing privacy leakage. This paper investigates a black-box privacy attack, i.e., membership inference attack (MIA) on multi-modal vision-language models (VLMs). State-of-the-art research analyzes privacy attacks primarily to unimodal AI-ML systems, while recent studies indicate MMs can also be vulnerable to privacy attacks. While researche"
}