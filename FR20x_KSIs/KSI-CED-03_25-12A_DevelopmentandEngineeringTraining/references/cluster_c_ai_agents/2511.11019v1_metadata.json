{
  "arxiv_id": "2511.11019v1",
  "title": "PATCHEVAL: A New Benchmark for Evaluating LLMs on Patching Real-World Vulnerabilities",
  "authors": [
    "Zichao Wei",
    "Jun Zeng",
    "Ming Wen",
    "Zeliang Yu",
    "Kai Cheng",
    "Yiding Zhu",
    "Jingyi Guo",
    "Shiqi Zhou",
    "Le Yin",
    "Xiaodong Su",
    "Zhechao Ma"
  ],
  "published": "2025-11-14T07:14:32Z",
  "url": "http://arxiv.org/abs/2511.11019v1",
  "pdf_url": "http://arxiv.org/pdf/2511.11019v1.pdf",
  "relevance_score": 63,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Software vulnerabilities are increasing at an alarming rate. However, manual patching is both time-consuming and resource-intensive, while existing automated vulnerability repair (AVR) techniques remain limited in effectiveness. Recent advances in large language models (LLMs) have opened a new paradigm for AVR, demonstrating remarkable progress. To examine the capability of LLMs in AVR, several vulnerability benchmarks have been proposed recently. However, they still suffer from key limitations "
}