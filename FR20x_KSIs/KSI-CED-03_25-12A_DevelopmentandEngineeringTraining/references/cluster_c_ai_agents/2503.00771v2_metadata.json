{
  "arxiv_id": "2503.00771v2",
  "title": "Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity",
  "authors": [
    "Yupu Hao",
    "Pengfei Cao",
    "Zhuoran Jin",
    "Huanxuan Liao",
    "Yubo Chen",
    "Kang Liu",
    "Jun Zhao"
  ],
  "published": "2025-03-02T07:36:22Z",
  "url": "http://arxiv.org/abs/2503.00771v2",
  "pdf_url": "http://arxiv.org/pdf/2503.00771v2.pdf",
  "relevance_score": 62,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Personalized tool utilization is essential for aligning large language models (LLMs) with user preference in interaction scenarios with various tools. However, most of the current benchmarks primarily focus on either personalization of text generation or direct tool-utilizing, without considering both. In this work, we introduce a novel benchmark ETAPP for evaluating personalized tool invocation, establishing a sandbox environment, and a comprehensive dataset of 800 testing cases covering divers"
}