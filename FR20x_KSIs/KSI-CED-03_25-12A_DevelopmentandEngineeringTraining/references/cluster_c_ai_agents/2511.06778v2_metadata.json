{
  "arxiv_id": "2511.06778v2",
  "title": "SAFENLIDB: A Privacy-Preserving Safety Alignment Framework for LLM-based Natural Language Database Interfaces",
  "authors": [
    "Ruiheng Liu",
    "XiaoBing Chen",
    "Jinyu Zhang",
    "Qiongwen Zhang",
    "Yu Zhang",
    "Bailong Yang"
  ],
  "published": "2025-11-10T07:05:59Z",
  "url": "http://arxiv.org/abs/2511.06778v2",
  "pdf_url": "http://arxiv.org/pdf/2511.06778v2.pdf",
  "relevance_score": 98,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "The rapid advancement of Large Language Models (LLMs) has driven significant progress in Natural Language Interface to Database (NLIDB). However, the widespread adoption of LLMs has raised critical privacy and security concerns. During interactions, LLMs may unintentionally expose confidential database contents or be manipulated by attackers to exfiltrate data through seemingly benign queries. While current efforts typically rely on rule-based heuristics or LLM agents to mitigate this leakage ri"
}