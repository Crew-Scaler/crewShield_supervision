{
  "arxiv_id": "2512.19537v1",
  "title": "Event Extraction in Large Language Model",
  "authors": [
    "Bobo Li",
    "Xudong Han",
    "Jiang Liu",
    "Yuzhe Ding",
    "Liqiang Jing",
    "Zhaoqi Zhang",
    "Jinheng Li",
    "Xinya Du",
    "Fei Li",
    "Meishan Zhang",
    "Min Zhang",
    "Aixin Sun",
    "Philip S. Yu",
    "Hao Fei"
  ],
  "published": "2025-12-22T16:22:14Z",
  "url": "http://arxiv.org/abs/2512.19537v1",
  "pdf_url": "http://arxiv.org/pdf/2512.19537v1.pdf",
  "relevance_score": 63,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large language models (LLMs) and multimodal LLMs are changing event extraction (EE): prompting and generation can often produce structured outputs in zero shot or few shot settings. Yet LLM based pipelines face deployment gaps, including hallucinations under weak constraints, fragile temporal and causal linking over long contexts and across documents, and limited long horizon knowledge management within a bounded context window. We argue that EE should be viewed as a system component that provid"
}