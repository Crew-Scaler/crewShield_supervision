{
  "arxiv_id": "2512.21919v1",
  "title": "SWE-RM: Execution-free Feedback For Software Engineering Agents",
  "authors": [
    "KaShun Shum",
    "Binyuan Hui",
    "Jiawei Chen",
    "Lei Zhang",
    "X. W.",
    "Jiaxi Yang",
    "Yuzhen Huang",
    "Junyang Lin",
    "Junxian He"
  ],
  "published": "2025-12-26T08:26:18Z",
  "url": "http://arxiv.org/abs/2512.21919v1",
  "pdf_url": "http://arxiv.org/pdf/2512.21919v1.pdf",
  "relevance_score": 80,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Execution-based feedback like unit testing is widely used in the development of coding agents through test-time scaling (TTS) and reinforcement learning (RL). This paradigm requires scalable and reliable collection of unit test cases to provide accurate feedback, and the resulting feedback is often sparse and cannot effectively distinguish between trajectories that are both successful or both unsuccessful. In contrast, execution-free feedback from reward models can provide more fine-grained sign"
}