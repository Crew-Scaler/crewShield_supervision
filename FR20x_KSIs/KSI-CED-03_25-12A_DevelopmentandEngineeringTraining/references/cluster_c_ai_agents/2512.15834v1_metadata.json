{
  "arxiv_id": "2512.15834v1",
  "title": "Optimizing Agentic Language Model Inference via Speculative Tool Calls",
  "authors": [
    "Daniel Nichols",
    "Prajwal Singhania",
    "Charles Jekel",
    "Abhinav Bhatele",
    "Harshitha Menon"
  ],
  "published": "2025-12-17T18:22:44Z",
  "url": "http://arxiv.org/abs/2512.15834v1",
  "pdf_url": "http://arxiv.org/pdf/2512.15834v1.pdf",
  "relevance_score": 85,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Language models (LMs) are becoming increasingly dependent on external tools. LM-based agentic frameworks frequently interact with their environment via such tools to search files, run code, call APIs, etc. Further, modern reasoning-based LMs use tools such as web search and Python code execution to enhance their reasoning capabilities. While tools greatly improve the capabilities of LMs, they also introduce performance bottlenecks during the inference process. In this paper, we introduce novel s"
}