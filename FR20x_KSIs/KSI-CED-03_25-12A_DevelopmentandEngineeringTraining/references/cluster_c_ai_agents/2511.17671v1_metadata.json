{
  "arxiv_id": "2511.17671v1",
  "title": "MURMUR: Using cross-user chatter to break collaborative language agents in groups",
  "authors": [
    "Atharv Singh Patlan",
    "Peiyao Sheng",
    "S. Ashwin Hebbar",
    "Prateek Mittal",
    "Pramod Viswanath"
  ],
  "published": "2025-11-21T04:56:37Z",
  "url": "http://arxiv.org/abs/2511.17671v1",
  "pdf_url": "http://arxiv.org/pdf/2511.17671v1.pdf",
  "relevance_score": 89,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Language agents are rapidly expanding from single-user assistants to multi-user collaborators in shared workspaces and groups. However, today's language models lack a mechanism for isolating user interactions and concurrent tasks, creating a new attack vector inherent to this new setting: cross-user poisoning (CUP). In a CUP attack, an adversary injects ordinary-looking messages that poison the persistent, shared state, which later triggers the agent to execute unintended, attacker-specified act"
}