{
  "arxiv_id": "2511.09586v3",
  "title": "Environment Scaling for Interactive Agentic Experience Collection: A Survey",
  "authors": [
    "Yuchen Huang",
    "Sijia Li",
    "Minghao Liu",
    "Wei Liu",
    "Shijue Huang",
    "Zhiyuan Fan",
    "Hou Pong Chan",
    "Yi R. Fung"
  ],
  "published": "2025-11-12T12:56:25Z",
  "url": "http://arxiv.org/abs/2511.09586v3",
  "pdf_url": "http://arxiv.org/pdf/2511.09586v3.pdf",
  "relevance_score": 98,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "LLM-based agents can autonomously accomplish complex tasks across various domains. However, to further cultivate capabilities such as adaptive behavior and long-term decision-making, training on static datasets built from human-level knowledge is insufficient. These datasets are costly to construct and lack both dynamism and realism. A growing consensus is that agents should instead interact directly with environments and learn from experience through reinforcement learning. We formalize this it"
}