{
  "arxiv_id": "2512.23738v1",
  "title": "Enforcing Temporal Constraints for LLM Agents",
  "authors": [
    "Adharsh Kamath",
    "Sishen Zhang",
    "Calvin Xu",
    "Shubham Ugare",
    "Gagandeep Singh",
    "Sasa Misailovic"
  ],
  "published": "2025-12-25T06:12:13Z",
  "url": "http://arxiv.org/abs/2512.23738v1",
  "pdf_url": "http://arxiv.org/pdf/2512.23738v1.pdf",
  "relevance_score": 85,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "LLM-based agents are deployed in safety-critical applications, yet current guardrail systems fail to prevent violations of temporal safety policies, requirements that govern the ordering and sequencing of agent actions. For instance, agents may access sensitive data before authenticating users or process refunds to unauthorized payment methods, violations that require reasoning about sequences of action rather than an individual action. Existing guardrails rely on imprecise natural language inst"
}