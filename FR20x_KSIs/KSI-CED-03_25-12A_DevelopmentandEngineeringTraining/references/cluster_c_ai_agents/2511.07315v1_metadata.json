{
  "arxiv_id": "2511.07315v1",
  "title": "JPRO: Automated Multimodal Jailbreaking via Multi-Agent Collaboration Framework",
  "authors": [
    "Yuxuan Zhou",
    "Yang Bai",
    "Kuofeng Gao",
    "Tao Dai",
    "Shu-Tao Xia"
  ],
  "published": "2025-11-10T17:16:46Z",
  "url": "http://arxiv.org/abs/2511.07315v1",
  "pdf_url": "http://arxiv.org/pdf/2511.07315v1.pdf",
  "relevance_score": 86,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "The widespread application of large VLMs makes ensuring their secure deployment critical. While recent studies have demonstrated jailbreak attacks on VLMs, existing approaches are limited: they require either white-box access, restricting practicality, or rely on manually crafted patterns, leading to poor sample diversity and scalability. To address these gaps, we propose JPRO, a novel multi-agent collaborative framework designed for automated VLM jailbreaking. It effectively overcomes the short"
}