{
  "arxiv_id": "2512.18733v1",
  "title": "Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection",
  "authors": [
    "Junjun Pan",
    "Yixin Liu",
    "Rui Miao",
    "Kaize Ding",
    "Yu Zheng",
    "Quoc Viet Hung Nguyen",
    "Alan Wee-Chung Liew",
    "Shirui Pan"
  ],
  "published": "2025-12-21T13:46:36Z",
  "url": "http://arxiv.org/abs/2512.18733v1",
  "pdf_url": "http://arxiv.org/pdf/2512.18733v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large language model (LLM)-based multi-agent systems (MAS) have shown strong capabilities in solving complex tasks. As MAS become increasingly autonomous in various safety-critical tasks, detecting malicious agents has become a critical security concern. Although existing graph anomaly detection (GAD)-based defenses can identify anomalous agents, they mainly rely on coarse sentence-level information and overlook fine-grained lexical cues, leading to suboptimal performance. Moreover, the lack of "
}