{
  "arxiv_id": "2511.16278v1",
  "title": "\"To Survive, I Must Defect\": Jailbreaking LLMs via the Game-Theory Scenarios",
  "authors": [
    "Zhen Sun",
    "Zongmin Zhang",
    "Deqi Liang",
    "Han Sun",
    "Yule Liu",
    "Yun Shen",
    "Xiangshan Gao",
    "Yilong Yang",
    "Shuai Liu",
    "Yutao Yue",
    "Xinlei He"
  ],
  "published": "2025-11-20T11:56:00Z",
  "url": "http://arxiv.org/abs/2511.16278v1",
  "pdf_url": "http://arxiv.org/pdf/2511.16278v1.pdf",
  "relevance_score": 69,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "As LLMs become more common, non-expert users can pose risks, prompting extensive research into jailbreak attacks. However, most existing black-box jailbreak attacks rely on hand-crafted heuristics or narrow search spaces, which limit scalability. Compared with prior attacks, we propose Game-Theory Attack (GTA), an scalable black-box jailbreak framework. Concretely, we formalize the attacker's interaction against safety-aligned LLMs as a finite-horizon, early-stoppable sequential stochastic game,"
}