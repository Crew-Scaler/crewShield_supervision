{
  "arxiv_id": "2511.20639v2",
  "title": "Latent Collaboration in Multi-Agent Systems",
  "authors": [
    "Jiaru Zou",
    "Xiyuan Yang",
    "Ruizhong Qiu",
    "Gaotang Li",
    "Katherine Tieu",
    "Pan Lu",
    "Ke Shen",
    "Hanghang Tong",
    "Yejin Choi",
    "Jingrui He",
    "James Zou",
    "Mengdi Wang",
    "Ling Yang"
  ],
  "published": "2025-11-25T18:56:57Z",
  "url": "http://arxiv.org/abs/2511.20639v2",
  "pdf_url": "http://arxiv.org/pdf/2511.20639v2.pdf",
  "relevance_score": 83,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto"
}