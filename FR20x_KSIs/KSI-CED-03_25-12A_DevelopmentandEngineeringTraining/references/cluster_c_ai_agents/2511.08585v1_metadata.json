{
  "arxiv_id": "2511.08585v1",
  "title": "Simulating the Visual World with Artificial Intelligence: A Roadmap",
  "authors": [
    "Jingtong Yue",
    "Ziqi Huang",
    "Zhaoxi Chen",
    "Xintao Wang",
    "Pengfei Wan",
    "Ziwei Liu"
  ],
  "published": "2025-11-11T18:59:50Z",
  "url": "http://arxiv.org/abs/2511.08585v1",
  "pdf_url": "http://arxiv.org/pdf/2511.08585v1.pdf",
  "relevance_score": 75,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "The landscape of video generation is shifting, from a focus on generating visually appealing clips to building virtual environments that support interaction and maintain physical plausibility. These developments point toward the emergence of video foundation models that function not only as visual generators but also as implicit world models, models that simulate the physical dynamics, agent-environment interactions, and task planning that govern real or imagined worlds. This survey provides a s"
}