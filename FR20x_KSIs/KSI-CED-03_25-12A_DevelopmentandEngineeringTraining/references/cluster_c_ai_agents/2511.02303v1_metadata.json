{
  "arxiv_id": "2511.02303v1",
  "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation",
  "authors": [
    "Zhiwei Zhang",
    "Xiaomin Li",
    "Yudi Lin",
    "Hui Liu",
    "Ramraj Chandradevan",
    "Linlin Wu",
    "Minhua Lin",
    "Fali Wang",
    "Xianfeng Tang",
    "Qi He",
    "Suhang Wang"
  ],
  "published": "2025-11-04T06:37:31Z",
  "url": "http://arxiv.org/abs/2511.02303v1",
  "pdf_url": "http://arxiv.org/pdf/2511.02303v1.pdf",
  "relevance_score": 87,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large Language Models (LLMs) trained with reinforcement learning and verifiable rewards have achieved strong results on complex reasoning tasks. Recent work extends this paradigm to a multi-agent setting, where a meta-thinking agent proposes plans and monitors progress while a reasoning agent executes subtasks through sequential conversational turns. Despite promising performance, we identify a critical limitation: lazy agent behavior, in which one agent dominates while the other contributes lit"
}