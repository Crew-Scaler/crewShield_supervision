{
  "arxiv_id": "2512.09187v1",
  "title": "WOLF: Werewolf-based Observations for LLM Deception and Falsehoods",
  "authors": [
    "Mrinal Agarwal",
    "Saad Rana",
    "Theo Sundoro",
    "Hermela Berhe",
    "Spencer Kim",
    "Vasu Sharma",
    "Sean O'Brien",
    "Kevin Zhu"
  ],
  "published": "2025-12-09T23:14:20Z",
  "url": "http://arxiv.org/abs/2512.09187v1",
  "pdf_url": "http://arxiv.org/pdf/2512.09187v1.pdf",
  "relevance_score": 78,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Deception is a fundamental challenge for multi-agent reasoning: effective systems must strategically conceal information while detecting misleading behavior in others. Yet most evaluations reduce deception to static classification, ignoring the interactive, adversarial, and longitudinal nature of real deceptive dynamics. Large language models (LLMs) can deceive convincingly but remain weak at detecting deception in peers. We present WOLF, a multi-agent social deduction benchmark based on Werewol"
}