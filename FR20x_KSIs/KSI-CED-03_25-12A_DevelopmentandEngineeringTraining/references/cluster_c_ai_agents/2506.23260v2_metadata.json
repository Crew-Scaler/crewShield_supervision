{
  "arxiv_id": "2506.23260v2",
  "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows",
  "authors": [
    "Mohamed Amine Ferrag",
    "Norbert Tihanyi",
    "Djallel Hamouda",
    "Leandros Maglaras",
    "Abderrahmane Lakas",
    "Merouane Debbah"
  ],
  "published": "2025-06-29T14:32:32Z",
  "url": "http://arxiv.org/abs/2506.23260v2",
  "pdf_url": "http://arxiv.org/pdf/2506.23260v2.pdf",
  "relevance_score": 100,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Autonomous AI agents powered by large language models (LLMs) with structured function-calling interfaces enable real-time data retrieval, computation, and multi-step orchestration. However, the rapid growth of plugins, connectors, and inter-agent protocols has outpaced security practices, leading to brittle integrations that rely on ad-hoc authentication, inconsistent schemas, and weak validation. This survey introduces a unified end-to-end threat model for LLM-agent ecosystems, covering host-to"
}