{
  "arxiv_id": "2401.17459v1",
  "title": "A Preliminary Study on Using Large Language Models in Software Pentesting",
  "authors": [
    "Kumar Shashwat",
    "Francis Hahn",
    "Xinming Ou",
    "Dmitry Goldgof",
    "Lawrence Hall",
    "Jay Ligatti",
    "S. Raj Rajgopalan",
    "Armin Ziaie Tabari"
  ],
  "published": "2024-01-30T21:42:59Z",
  "url": "http://arxiv.org/abs/2401.17459v1",
  "pdf_url": "http://arxiv.org/pdf/2401.17459v1.pdf",
  "relevance_score": 79,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large language models (LLM) are perceived to offer promising potentials for automating security tasks, such as those found in security operation centers (SOCs). As a first step towards evaluating this perceived potential, we investigate the use of LLMs in software pentesting, where the main task is to automatically identify software security vulnerabilities in source code. We hypothesize that an LLM-based AI agent can be improved over time for a specific security task as human operators interact"
}