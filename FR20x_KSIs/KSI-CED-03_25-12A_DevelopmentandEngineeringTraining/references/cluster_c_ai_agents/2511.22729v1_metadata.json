{
  "arxiv_id": "2511.22729v1",
  "title": "Solving Context Window Overflow in AI Agents",
  "authors": [
    "Anton Bulle Labate",
    "Valesca Moura de Sousa",
    "Sandro Rama Fiorini",
    "Leonardo Guerreiro Azevedo",
    "Raphael Melo Thiago",
    "Viviane Torres da Silva"
  ],
  "published": "2025-11-27T19:22:20Z",
  "url": "http://arxiv.org/abs/2511.22729v1",
  "pdf_url": "http://arxiv.org/pdf/2511.22729v1.pdf",
  "relevance_score": 83,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large Language Models (LLMs) have become increasingly capable of interacting with external tools, granting access to specialized knowledge beyond their training data - critical in dynamic, knowledge-intensive domains such as Chemistry and Materials Science. However, large tool outputs can overflow the LLMs' context window, preventing task completion. Existing solutions such as truncation or summarization fail to preserve complete outputs, making them unsuitable for workflows requiring the full d"
}