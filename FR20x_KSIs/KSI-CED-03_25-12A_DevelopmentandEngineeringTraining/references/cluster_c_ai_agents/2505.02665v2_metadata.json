{
  "arxiv_id": "2505.02665v2",
  "title": "A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law",
  "authors": [
    "Qianjun Pan",
    "Wenkai Ji",
    "Yuyang Ding",
    "Junsong Li",
    "Shilian Chen",
    "Junyi Wang",
    "Jie Zhou",
    "Qin Chen",
    "Min Zhang",
    "Yulan Wu",
    "Liang He"
  ],
  "published": "2025-05-05T14:14:59Z",
  "url": "http://arxiv.org/abs/2505.02665v2",
  "pdf_url": "http://arxiv.org/pdf/2505.02665v2.pdf",
  "relevance_score": 78,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "This survey explores recent advancements in reasoning large language models (LLMs) designed to mimic \"slow thinking\" - a reasoning process inspired by human cognition, as described in Kahneman's Thinking, Fast and Slow. These models, like OpenAI's o1, focus on scaling computational resources dynamically during complex tasks, such as math reasoning, visual reasoning, medical diagnosis, and multi-agent debates. We present the development of reasoning LLMs and list their key technologies. By synthe"
}