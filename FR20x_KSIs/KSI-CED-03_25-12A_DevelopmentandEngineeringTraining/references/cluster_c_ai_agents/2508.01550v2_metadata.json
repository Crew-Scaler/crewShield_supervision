{
  "arxiv_id": "2508.01550v2",
  "title": "RepoForge: Training a SOTA Fast-thinking SWE Agent with an End-to-End Data Curation Pipeline Synergizing SFT and RL at Scale",
  "authors": [
    "Zhilong Chen",
    "Chengzong Zhao",
    "Boyuan Chen",
    "Dayi Lin",
    "Yihao Chen",
    "Arthur Leung",
    "Gopi Krishnan Rajbahadur",
    "Gustavo A. Oliva",
    "Haoxiang Zhang",
    "Aaditya Bhatia",
    "Chong Chun Yong",
    "Ahmed E. Hassan"
  ],
  "published": "2025-08-03T02:34:16Z",
  "url": "http://arxiv.org/abs/2508.01550v2",
  "pdf_url": "http://arxiv.org/pdf/2508.01550v2.pdf",
  "relevance_score": 94,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Training software engineering (SWE) LLMs is bottlenecked by expensive infrastructure, inefficient evaluation pipelines, scarce training data, and costly quality control. We present RepoForge, an autonomous, end-to-end pipeline that generates, evaluates, and trains SWE agents at scale. Our key contributions include: (1) RepoForge-8B-Agent, achieving 17.4\\% on SWE-Bench-Verified~\\citep{swebench_verified2024}, establishing new state-of-the-art for $\\leq$8B non-thinking LLMs; (2) 7,304 executable en"
}