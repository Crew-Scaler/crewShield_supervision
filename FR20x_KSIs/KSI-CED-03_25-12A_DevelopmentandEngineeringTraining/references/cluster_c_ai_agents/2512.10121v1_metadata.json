{
  "arxiv_id": "2512.10121v1",
  "title": "Workflow is All You Need: Escaping the \"Statistical Smoothing Trap\" via High-Entropy Information Foraging and Adversarial Pacing",
  "authors": [
    "Zhongjie Jiang"
  ],
  "published": "2025-12-10T22:13:55Z",
  "url": "http://arxiv.org/abs/2512.10121v1",
  "pdf_url": "http://arxiv.org/pdf/2512.10121v1.pdf",
  "relevance_score": 80,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Central to long-form text generation in vertical domains is the \"impossible trinity\" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level "
}