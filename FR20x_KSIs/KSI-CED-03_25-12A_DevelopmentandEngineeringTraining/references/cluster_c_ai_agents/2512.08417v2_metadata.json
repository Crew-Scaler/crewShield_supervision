{
  "arxiv_id": "2512.08417v2",
  "title": "Attention is All You Need to Defend Against Indirect Prompt Injection Attacks in LLMs",
  "authors": [
    "Yinan Zhong",
    "Qianhao Miao",
    "Yanjiao Chen",
    "Jiangyi Deng",
    "Yushi Cheng",
    "Wenyuan Xu"
  ],
  "published": "2025-12-09T09:44:13Z",
  "url": "http://arxiv.org/abs/2512.08417v2",
  "pdf_url": "http://arxiv.org/pdf/2512.08417v2.pdf",
  "relevance_score": 90,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large Language Models (LLMs) have been integrated into many applications (e.g., web agents) to perform more sophisticated tasks. However, LLM-empowered applications are vulnerable to Indirect Prompt Injection (IPI) attacks, where instructions are injected via untrustworthy external data sources. This paper presents Rennervate, a defense framework to detect and prevent IPI attacks. Rennervate leverages attention features to detect the covert injection at a fine-grained token level, enabling preci"
}