{
  "arxiv_id": "2512.11463v1",
  "title": "Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes",
  "authors": [
    "Junghwan Lim",
    "Sungmin Lee",
    "Dongseok Kim",
    "Taehyun Kim",
    "Eunhwan Park",
    "Jeesoo Lee",
    "Jeongdoo Lee",
    "Junhyeok Lee",
    "Wai Ting Cheung",
    "Dahye Choi",
    "Minsu Ha",
    "Jaeheui Her",
    "Jaeyeon Huh",
    "Hanbin Jung",
    "Changjin Kang",
    "Beomgyu Kim",
    "Minjae Kim",
    "Taewhan Kim",
    "Youngrok Kim",
    "Hyukjin Kweon",
    "Haesol Lee",
    "Kungyu Lee",
    "Dongpin Oh",
    "Yeongjae Park",
    "Bokki Ryu",
    "Dongjoo Weon"
  ],
  "published": "2025-12-11T00:51:18Z",
  "url": "http://arxiv.org/abs/2512.11463v1",
  "pdf_url": "http://arxiv.org/pdf/2512.11463v1.pdf",
  "relevance_score": 62,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory-efficient infrastructure for 64K-token contexts "
}