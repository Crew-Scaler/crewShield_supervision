{
  "arxiv_id": "2511.20597v1",
  "title": "BrowseSafe: Understanding and Preventing Prompt Injection Within AI Browser Agents",
  "authors": [
    "Kaiyuan Zhang",
    "Mark Tenenholtz",
    "Kyle Polley",
    "Jerry Ma",
    "Denis Yarats",
    "Ninghui Li"
  ],
  "published": "2025-11-25T18:28:35Z",
  "url": "http://arxiv.org/abs/2511.20597v1",
  "pdf_url": "http://arxiv.org/pdf/2511.20597v1.pdf",
  "relevance_score": 98,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "The integration of artificial intelligence (AI) agents into web browsers introduces security challenges that go beyond traditional web application threat models. Prior work has identified prompt injection as a new attack vector for web agents, yet the resulting impact within real-world environments remains insufficiently understood.\n  In this work, we examine the landscape of prompt injection attacks and synthesize a benchmark of attacks embedded in realistic HTML payloads. Our benchmark goes be"
}