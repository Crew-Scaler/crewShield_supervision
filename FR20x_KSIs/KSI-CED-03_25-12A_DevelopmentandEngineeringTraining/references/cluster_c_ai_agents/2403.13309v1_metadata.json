{
  "arxiv_id": "2403.13309v1",
  "title": "Mapping LLM Security Landscapes: A Comprehensive Stakeholder Risk Assessment Proposal",
  "authors": [
    "Rahul Pankajakshan",
    "Sumitra Biswal",
    "Yuvaraj Govindarajulu",
    "Gilad Gressel"
  ],
  "published": "2024-03-20T05:17:22Z",
  "url": "http://arxiv.org/abs/2403.13309v1",
  "pdf_url": "http://arxiv.org/pdf/2403.13309v1.pdf",
  "relevance_score": 88,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "The rapid integration of Large Language Models (LLMs) across diverse sectors has marked a transformative era, showcasing remarkable capabilities in text generation and problem-solving tasks. However, this technological advancement is accompanied by significant risks and vulnerabilities. Despite ongoing security enhancements, attackers persistently exploit these weaknesses, casting doubts on the overall trustworthiness of LLMs. Compounding the issue, organisations are deploying LLM-integrated sys"
}