{
  "arxiv_id": "2506.23667v1",
  "title": "L0: Reinforcement Learning to Become General Agents",
  "authors": [
    "Junjie Zhang",
    "Jingyi Xi",
    "Zhuoyang Song",
    "Junyu Lu",
    "Yuhua Ke",
    "Ting Sun",
    "Yukun Yang",
    "Jiaxing Zhang",
    "Songxin Zhang",
    "Zejian Xie"
  ],
  "published": "2025-06-30T09:44:32Z",
  "url": "http://arxiv.org/abs/2506.23667v1",
  "pdf_url": "http://arxiv.org/pdf/2506.23667v1.pdf",
  "relevance_score": 96,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Training large language models (LLMs) to act as autonomous agents for multi-turn, long-horizon tasks remains significant challenges in scalability and training efficiency. To address this, we introduce L-Zero (L0), a scalable, end-to-end training pipeline for general-purpose agents. Featuring a low-cost, extensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier for applying reinforcement learning in complex environments. We also introduce NB-Agent, the agent scaffold within L"
}