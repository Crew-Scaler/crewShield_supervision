{
  "arxiv_id": "2512.06710v1",
  "title": "Stochasticity in Agentic Evaluations: Quantifying Inconsistency with Intraclass Correlation",
  "authors": [
    "Zairah Mustahsan",
    "Abel Lim",
    "Megna Anand",
    "Saahil Jain",
    "Bryan McCann"
  ],
  "published": "2025-12-07T07:58:13Z",
  "url": "http://arxiv.org/abs/2512.06710v1",
  "pdf_url": "http://arxiv.org/pdf/2512.06710v1.pdf",
  "relevance_score": 77,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "As large language models become components of larger agentic systems, evaluation reliability becomes critical: unreliable sub-agents introduce brittleness into downstream system behavior. Yet current evaluation practice, reporting a single accuracy number from a single run, obscures the variance underlying these results, making it impossible to distinguish genuine capability improvements from lucky sampling. We propose adopting Intraclass Correlation Coefficient (ICC), a metric from measurement "
}