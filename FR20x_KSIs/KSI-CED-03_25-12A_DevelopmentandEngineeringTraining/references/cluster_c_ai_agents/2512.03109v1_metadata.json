{
  "arxiv_id": "2512.03109v1",
  "title": "E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing",
  "authors": [
    "Shuvom Sadhuka",
    "Drew Prinster",
    "Clara Fannjiang",
    "Gabriele Scalia",
    "Aviv Regev",
    "Hanchen Wang"
  ],
  "published": "2025-12-02T05:59:18Z",
  "url": "http://arxiv.org/abs/2512.03109v1",
  "pdf_url": "http://arxiv.org/pdf/2512.03109v1.pdf",
  "relevance_score": 83,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuato"
}