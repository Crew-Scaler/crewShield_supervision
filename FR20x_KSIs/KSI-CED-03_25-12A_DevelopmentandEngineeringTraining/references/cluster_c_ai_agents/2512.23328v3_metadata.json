{
  "arxiv_id": "2512.23328v3",
  "title": "CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations",
  "authors": [
    "Huan-ang Gao",
    "Zikang Zhang",
    "Tianwei Luo",
    "Kaisen Yang",
    "Xinzhe Juan",
    "Jiahao Qiu",
    "Tianxing Chen",
    "Bingxiang He",
    "Hao Zhao",
    "Hao Zhou",
    "Shilong Liu",
    "Mengdi Wang"
  ],
  "published": "2025-12-29T09:25:56Z",
  "url": "http://arxiv.org/abs/2512.23328v3",
  "pdf_url": "http://arxiv.org/pdf/2512.23328v3.pdf",
  "relevance_score": 76,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large Language Model (LLM) agents, while proficient in the digital realm, face a significant gap in physical-world deployment due to the challenge of forming and maintaining a robust spatial mental model. We identify three core cognitive challenges hindering this transition: spatial reasoning, long-horizon state tracking via mental simulation, and active exploration under partial observation. To isolate and evaluate these faculties, we introduce CubeBench, a novel generative benchmark centered o"
}