{
  "arxiv_id": "2511.23271v1",
  "title": "Behavior-Equivalent Token: Single-Token Replacement for Long Prompts in LLMs",
  "authors": [
    "Jiancheng Dong",
    "Pengyue Jia",
    "Jingyu Peng",
    "Maolin Wang",
    "Yuhao Wang",
    "Lixin Su",
    "Xin Sun",
    "Shuaiqiang Wang",
    "Dawei Yin",
    "Xiangyu Zhao"
  ],
  "published": "2025-11-28T15:22:52Z",
  "url": "http://arxiv.org/abs/2511.23271v1",
  "pdf_url": "http://arxiv.org/pdf/2511.23271v1.pdf",
  "relevance_score": 78,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Carefully engineered system prompts play a critical role in guiding the behavior of LLM agents, but their considerable length introduces significant drawbacks, including increased inference latency, higher computational cost, and reduced effective context length. This raises the question of whether such lengthy prompts can be replaced by a drastically reduced number of tokens while preserving their behavioral effect on downstream tasks. To enable this, we propose a lightweight three-stage traini"
}