{
  "arxiv_id": "2512.06914v1",
  "title": "SoK: Trust-Authorization Mismatch in LLM Agent Interactions",
  "authors": [
    "Guanquan Shi",
    "Haohua Du",
    "Zhiqiang Wang",
    "Xiaoyu Liang",
    "Weiwenpei Liu",
    "Song Bian",
    "Zhenyu Guan"
  ],
  "published": "2025-12-07T16:41:02Z",
  "url": "http://arxiv.org/abs/2512.06914v1",
  "pdf_url": "http://arxiv.org/pdf/2512.06914v1.pdf",
  "relevance_score": 85,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large Language Models (LLMs) are rapidly evolving into autonomous agents capable of interacting with the external world, significantly expanding their capabilities through standardized interaction protocols. However, this paradigm revives the classic cybersecurity challenges of agency and authorizat"
}