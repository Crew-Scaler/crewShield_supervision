{
  "arxiv_id": "2510.14008v2",
  "title": "Stop Reducing Responsibility in LLM-Powered Multi-Agent Systems to Local Alignment",
  "authors": [
    "Jinwei Hu",
    "Yi Dong",
    "Shuang Ao",
    "Zhuoyun Li",
    "Boxuan Wang",
    "Lokesh Singh",
    "Guangliang Cheng",
    "Sarvapali D. Ramchurn",
    "Xiaowei Huang"
  ],
  "published": "2025-10-15T18:39:31Z",
  "url": "http://arxiv.org/abs/2510.14008v2",
  "pdf_url": "http://arxiv.org/pdf/2510.14008v2.pdf",
  "relevance_score": 85,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "LLM-powered Multi-Agent Systems (LLM-MAS) unlock new potentials in distributed reasoning, collaboration, and task generalization but also introduce additional risks due to unguaranteed agreement, cascading uncertainty, and adversarial vulnerabilities. We argue that ensuring responsible behavior in such systems requires a paradigm shift: from local, superficial agent-level alignment to global, systemic agreement. We conceptualize responsibility not as a static constraint but as a lifecycle-wide p"
}