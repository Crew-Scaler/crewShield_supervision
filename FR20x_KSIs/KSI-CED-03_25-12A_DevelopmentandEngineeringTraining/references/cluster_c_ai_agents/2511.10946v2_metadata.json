{
  "arxiv_id": "2511.10946v2",
  "title": "Abstract 3D Perception for Spatial Intelligence in Vision-Language Models",
  "authors": [
    "Yifan Liu",
    "Fangneng Zhan",
    "Kaichen Zhou",
    "Yilun Du",
    "Paul Pu Liang",
    "Hanspeter Pfister"
  ],
  "published": "2025-11-14T04:16:09Z",
  "url": "http://arxiv.org/abs/2511.10946v2",
  "pdf_url": "http://arxiv.org/pdf/2511.10946v2.pdf",
  "relevance_score": 77,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Vision-language models (VLMs) struggle with 3D-related tasks such as spatial cognition and physical understanding, which are crucial for real-world applications like robotics and embodied agents. We attribute this to a modality gap between the 3D tasks and the 2D training of VLM, which led to inefficient retrieval of 3D information from 2D input. To bridge this gap, we introduce SandboxVLM, a simple yet effective framework that leverages abstract bounding boxes to encode geometric structure and "
}