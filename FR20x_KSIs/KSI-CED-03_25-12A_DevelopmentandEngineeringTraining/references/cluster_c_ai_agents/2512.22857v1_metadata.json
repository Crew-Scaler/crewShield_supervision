{
  "arxiv_id": "2512.22857v1",
  "title": "AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning",
  "authors": [
    "Shihao Cai",
    "Runnan Fang",
    "Jialong Wu",
    "Baixuan Li",
    "Xinyu Wang",
    "Yong Jiang",
    "Liangcai Su",
    "Liwen Zhang",
    "Wenbiao Yin",
    "Zhen Zhang",
    "Fuli Feng",
    "Pengjun Xie",
    "Xiaobin Wang"
  ],
  "published": "2025-12-28T09:43:11Z",
  "url": "http://arxiv.org/abs/2512.22857v1",
  "pdf_url": "http://arxiv.org/pdf/2512.22857v1.pdf",
  "relevance_score": 81,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Conducting reinforcement learning (RL) in simulated environments offers a cost-effective and highly scalable way to enhance language-based agents. However, previous work has been limited to semi-automated environment synthesis or tasks lacking sufficient difficulty, offering little breadth or depth. In addition, the instability of simulated users integrated into these environments, along with the heterogeneity across simulated environments, poses further challenges for agentic RL. In this work, "
}