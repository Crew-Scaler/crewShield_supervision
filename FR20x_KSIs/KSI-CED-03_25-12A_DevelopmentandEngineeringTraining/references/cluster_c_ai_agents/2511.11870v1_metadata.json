{
  "arxiv_id": "2511.11870v1",
  "title": "Graph-Based Imitation and Reinforcement Learning for Efficient Benders Decomposition",
  "authors": [
    "Bernard T. Agyeman",
    "Zhe Li",
    "Ilias Mitrai",
    "Prodromos Daoutidis"
  ],
  "published": "2025-11-14T21:00:26Z",
  "url": "http://arxiv.org/abs/2511.11870v1",
  "pdf_url": "http://arxiv.org/pdf/2511.11870v1.pdf",
  "relevance_score": 81,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "This work introduces an end-to-end graph-based agent for accelerating the computational efficiency of Benders Decomposition. The agent's policy is parameterized by a graph neural network which takes as input a bipartite graph representation of the master problem and proposes a candidate solution. The agent is trained using a two-stage approach that combines imitation (IL) and reinforcement learning (RL). IL is used to mimic a solver and obtain a warm-start policy which is then finetuned using RL"
}