{
  "arxiv_id": "2512.09108v1",
  "title": "Evolving Excellence: Automated Optimization of LLM-based Agents",
  "authors": [
    "Paul Brookes",
    "Vardan Voskanyan",
    "Rafail Giavrimis",
    "Matthew Truscott",
    "Mina Ilieva",
    "Chrystalla Pavlou",
    "Alexandru Staicu",
    "Manal Adham",
    "Will Evers- Hood",
    "Jingzhi Gong",
    "Kejia Zhang",
    "Matvey Fedoseev",
    "Vishal Sharma",
    "Roman Bauer",
    "Zheng Wang",
    "Hema Nair",
    "Wei Jie",
    "Tianhua Xu",
    "Aurora Constantin",
    "Leslie Kanthan",
    "Michail Basios"
  ],
  "published": "2025-12-09T20:48:45Z",
  "url": "http://arxiv.org/abs/2512.09108v1",
  "pdf_url": "http://arxiv.org/pdf/2512.09108v1.pdf",
  "relevance_score": 87,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Agentic AI systems built on large language models (LLMs) offer significant potential for automating complex workflows, from software development to customer support. However, LLM agents often underperform due to suboptimal configurations; poorly tuned prompts, tool descriptions, and parameters that typically require weeks of manual refinement. Existing optimization methods either are too complex for general use or treat components in isolation, missing critical interdependencies.\n  We present AR"
}