{
  "arxiv_id": "2512.10931v1",
  "title": "Asynchronous Reasoning: Training-Free Interactive Thinking LLMs",
  "authors": [
    "George Yakushev",
    "Nataliia Babina",
    "Masoud Vahid Dastgerdi",
    "Vyacheslav Zhdanovskiy",
    "Alina Shutova",
    "Denis Kuznedelev"
  ],
  "published": "2025-12-11T18:57:02Z",
  "url": "http://arxiv.org/abs/2512.10931v1",
  "pdf_url": "http://arxiv.org/pdf/2512.10931v1.pdf",
  "relevance_score": 76,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act"
}