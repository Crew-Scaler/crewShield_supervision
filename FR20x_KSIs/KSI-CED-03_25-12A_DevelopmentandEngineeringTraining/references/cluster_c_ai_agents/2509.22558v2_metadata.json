{
  "arxiv_id": "2509.22558v2",
  "title": "StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models",
  "authors": [
    "Chenyu Zhou",
    "Tianyi Xu",
    "Jianghao Lin",
    "Dongdong Ge"
  ],
  "published": "2025-09-26T16:39:10Z",
  "url": "http://arxiv.org/abs/2509.22558v2",
  "pdf_url": "http://arxiv.org/pdf/2509.22558v2.pdf",
  "relevance_score": 61,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large Language Models (LLMs) have shown promising capabilities for solving Operations Research (OR) problems. While reinforcement learning serves as a powerful paradigm for LLM training on OR problems, existing works generally face two key limitations. First, outcome reward suffers from the credit assignment problem, where correct final answers can reinforce flawed reasoning. Second, conventional discriminative process supervision is myopic, failing to evaluate the interdependent steps of OR mod"
}