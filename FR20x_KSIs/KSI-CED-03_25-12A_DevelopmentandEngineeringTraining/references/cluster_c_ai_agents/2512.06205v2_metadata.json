{
  "arxiv_id": "2512.06205v2",
  "title": "On measuring grounding and generalizing grounding problems",
  "authors": [
    "Daniel Quigley",
    "Eric Maynard"
  ],
  "published": "2025-12-05T22:58:47Z",
  "url": "http://arxiv.org/abs/2512.06205v2",
  "pdf_url": "http://arxiv.org/pdf/2512.06205v2.pdf",
  "relevance_score": 79,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational ("
}