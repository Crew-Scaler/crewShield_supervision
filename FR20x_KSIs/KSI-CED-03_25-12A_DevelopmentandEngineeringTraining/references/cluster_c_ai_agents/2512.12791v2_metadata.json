{
  "arxiv_id": "2512.12791v2",
  "title": "Beyond Task Completion: An Assessment Framework for Evaluating Agentic AI Systems",
  "authors": [
    "Sreemaee Akshathala",
    "Bassam Adnan",
    "Mahisha Ramesh",
    "Karthik Vaidhyanathan",
    "Basil Muhammed",
    "Kannan Parthasarathy"
  ],
  "published": "2025-12-14T18:17:40Z",
  "url": "http://arxiv.org/abs/2512.12791v2",
  "pdf_url": "http://arxiv.org/pdf/2512.12791v2.pdf",
  "relevance_score": 85,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Recent advances in agentic AI have shifted the focus from standalone Large Language Models (LLMs) to integrated systems that combine LLMs with tools, memory, and other agents to perform complex tasks. These multi-agent architectures enable coordinated reasoning, planning, and execution across diverse domains, allowing agents to collaboratively automate complex workflows. Despite these advances, evaluation and assessment of LLM agents and the multi-agent systems they constitute remain a fundament"
}