{
  "arxiv_id": "2511.08749v1",
  "title": "Interpretable by Design: Query-Specific Neural Modules for Explainable Reinforcement Learning",
  "authors": [
    "Mehrdad Zakershahrak"
  ],
  "published": "2025-11-11T20:08:32Z",
  "url": "http://arxiv.org/abs/2511.08749v1",
  "pdf_url": "http://arxiv.org/pdf/2511.08749v1.pdf",
  "relevance_score": 75,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Reinforcement learning has traditionally focused on a singular objective: learning policies that select actions to maximize reward. We challenge this paradigm by asking: what if we explicitly architected RL systems as inference engines that can answer diverse queries about their environment? In deterministic settings, trained agents implicitly encode rich knowledge about reachability, distances, values, and dynamics - yet current architectures are not designed to expose this information efficien"
}