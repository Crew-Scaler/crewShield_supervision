{
  "arxiv_id": "2512.04895v1",
  "title": "Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems",
  "authors": [
    "M Zeeshan",
    "Saud Satti"
  ],
  "published": "2025-12-04T15:22:28Z",
  "url": "http://arxiv.org/abs/2512.04895v1",
  "pdf_url": "http://arxiv.org/pdf/2512.04895v1.pdf",
  "relevance_score": 100,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Multimodal Artificial Intelligence (AI) systems, particularly Vision-Language Models (VLMs), have become integral to critical applications ranging from autonomous decision-making to automated document processing. As these systems scale, they rely heavily on preprocessing pipelines to handle diverse inputs efficiently. However, this dependency on standard preprocessing operations, specifically image downscaling, creates a significant yet often overlooked security vulnerability. While intended for"
}