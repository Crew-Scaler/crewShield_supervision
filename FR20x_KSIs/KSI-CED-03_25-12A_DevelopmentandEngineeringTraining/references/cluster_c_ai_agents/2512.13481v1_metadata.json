{
  "arxiv_id": "2512.13481v1",
  "title": "neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings",
  "authors": [
    "Ojas Pungalia",
    "Rashi Upadhyay",
    "Abhishek Mishra",
    "Abhiram H",
    "Tejasvi Alladi",
    "Sujan Yenuganti",
    "Dhruv Kumar"
  ],
  "published": "2025-12-15T16:17:12Z",
  "url": "http://arxiv.org/abs/2512.13481v1",
  "pdf_url": "http://arxiv.org/pdf/2512.13481v1.pdf",
  "relevance_score": 84,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win ove"
}