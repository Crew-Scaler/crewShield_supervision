{
  "arxiv_id": "2506.13841v2",
  "title": "LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning",
  "authors": [
    "Miho Koda",
    "Yu Zheng",
    "Ruixian Ma",
    "Mingyang Sun",
    "Devesh Pansare",
    "Fabio Duarte",
    "Paolo Santi"
  ],
  "published": "2025-06-16T16:23:56Z",
  "url": "http://arxiv.org/abs/2506.13841v2",
  "pdf_url": "http://arxiv.org/pdf/2506.13841v2.pdf",
  "relevance_score": 63,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Recent advances in large language models (LLMs), particularly those enhanced through reinforced post-training, have demonstrated impressive reasoning capabilities, as exemplified by models such as OpenAI o1 and DeepSeek-R1. However, these capabilities are predominantly benchmarked on domains like mathematical problem solving and code generation, leaving open the question of whether such reasoning skills generalize to complex real-world scenarios. In this paper, we introduce LocationReasoner, a b"
}