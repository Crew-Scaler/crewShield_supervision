{
  "arxiv_id": "2510.10073v1",
  "title": "SecureWebArena: A Holistic Security Evaluation Benchmark for LVLM-based Web Agents",
  "authors": [
    "Zonghao Ying",
    "Yangguang Shao",
    "Jianle Gan",
    "Gan Xu",
    "Junjie Shen",
    "Wenxin Zhang",
    "Quanchen Zou",
    "Junzheng Shi",
    "Zhenfei Yin",
    "Mingchuan Zhang",
    "Aishan Liu",
    "Xianglong Liu"
  ],
  "published": "2025-10-11T07:18:12Z",
  "url": "http://arxiv.org/abs/2510.10073v1",
  "pdf_url": "http://arxiv.org/pdf/2510.10073v1.pdf",
  "relevance_score": 97,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Large vision-language model (LVLM)-based web agents are emerging as powerful tools for automating complex online tasks. However, when deployed in real-world environments, they face serious security risks, motivating the design of security evaluation benchmarks. Existing benchmarks provide only partial coverage, typically restricted to narrow scenarios such as user-level prompt manipulation, and thus fail to capture the broad range of agent vulnerabilities. To address this gap, we present \\tool{}"
}