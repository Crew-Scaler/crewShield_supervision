{
  "arxiv_id": "2512.06688v1",
  "title": "PersonaMem-v2: Towards Personalized Intelligence via Learning Implicit User Personas and Agentic Memory",
  "authors": [
    "Bowen Jiang",
    "Yuan Yuan",
    "Maohao Shen",
    "Zhuoqun Hao",
    "Zhangchen Xu",
    "Zichen Chen",
    "Ziyi Liu",
    "Anvesh Rao Vijjini",
    "Jiashu He",
    "Hanchao Yu",
    "Radha Poovendran",
    "Gregory Wornell",
    "Lyle Ungar",
    "Dan Roth",
    "Sihao Chen",
    "Camillo Jose Taylor"
  ],
  "published": "2025-12-07T06:48:23Z",
  "url": "http://arxiv.org/abs/2512.06688v1",
  "pdf_url": "http://arxiv.org/pdf/2512.06688v1.pdf",
  "relevance_score": 85,
  "dimension": "AI Agent Security Architecture",
  "cluster": "C",
  "summary": "Personalization is one of the next milestones in advancing AI capability and alignment. We introduce PersonaMem-v2, the state-of-the-art dataset for LLM personalization that simulates 1,000 realistic user-chatbot interactions on 300+ scenarios, 20,000+ user preferences, and 128k-token context windows, where most user preferences are implicitly revealed to reflect real-world interactions. Using this data, we investigate how reinforcement fine-tuning enables a model to improve its long-context rea"
}