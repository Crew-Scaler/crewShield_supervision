{
  "arxiv_id": "2512.24560",
  "title": "Localized Calibrated Uncertainty in Code Language Models",
  "authors": [
    "David Gros",
    "Prem Devanbu"
  ],
  "published": "2025-12-31T02:00:17Z",
  "url": "http://arxiv.org/abs/2512.24560v1",
  "pdf_url": "https://arxiv.org/pdf/2512.24560v1",
  "relevance_score": 70,
  "dimension": "Adaptation to Rapidly Evolving AI Threat Landscape",
  "cluster": "G",
  "summary": "Large Language models (LLMs) can generate complicated source code from natural language prompts. However, LLMs can generate output that deviates from what the user wants, requiring supervision and editing. To support this process, we offer techniques to localize where generations might be misaligned"
}