{
  "arxiv_id": "2511.15992v1",
  "title": "Detecting Sleeper Agents in Large Language Models via Semantic Drift Analysis",
  "authors": [
    "Shahin Zanbaghi",
    "Ryan Rostampour",
    "Farhan Abid",
    "Salim Al Jarmakani"
  ],
  "published": "2025-11-20T02:42:41Z",
  "url": "http://arxiv.org/abs/2511.15992v1",
  "pdf_url": "http://arxiv.org/pdf/2511.15992v1.pdf",
  "relevance_score": 71,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large Language Models (LLMs) can be backdoored to exhibit malicious behavior under specific deployment conditions while appearing safe during training a phenomenon known as \"sleeper agents.\" Recent work by Hubinger et al. demonstrated that these backdoors persist through safety training, yet no practical detection methods exist. We present a novel dual-method detection system combining semantic drift analysis with canary baseline comparison to identify backdoored LLMs in real-time. Our approach "
}