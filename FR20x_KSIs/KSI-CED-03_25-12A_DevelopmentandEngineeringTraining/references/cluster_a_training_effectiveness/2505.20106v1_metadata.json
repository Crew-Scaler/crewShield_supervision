{
  "arxiv_id": "2505.20106v1",
  "title": "From Data to Modeling: Fully Open-vocabulary Scene Graph Generation",
  "authors": [
    "Zuyao Chen",
    "Jinlin Wu",
    "Zhen Lei",
    "Chang Wen Chen"
  ],
  "published": "2025-05-26T15:11:23Z",
  "url": "http://arxiv.org/abs/2505.20106v1",
  "pdf_url": "http://arxiv.org/pdf/2505.20106v1.pdf",
  "relevance_score": 59,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "We present OvSGTR, a novel transformer-based framework for fully open-vocabulary scene graph generation that overcomes the limitations of traditional closed-set models. Conventional methods restrict both object and relationship recognition to a fixed vocabulary, hindering their applicability to real-world scenarios where novel concepts frequently emerge. In contrast, our approach jointly predicts objects (nodes) and their inter-relationships (edges) beyond predefined categories. OvSGTR leverages"
}