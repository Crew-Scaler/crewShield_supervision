{
  "arxiv_id": "2511.19974v1",
  "title": "Continual Audio Deepfake Detection via Universal Adversarial Perturbation",
  "authors": [
    "Wangjie Li",
    "Lin Li",
    "Qingyang Hong"
  ],
  "published": "2025-11-25T06:41:11Z",
  "url": "http://arxiv.org/abs/2511.19974v1",
  "pdf_url": "http://arxiv.org/pdf/2511.19974v1.pdf",
  "relevance_score": 92,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "The rapid advancement of speech synthesis and voice conversion technologies has raised significant security concerns in multimedia forensics. Although current detection models demonstrate impressive performance, they struggle to maintain effectiveness against constantly evolving deepfake attacks. Additionally, continually fine-tuning these models using historical training data incurs substantial computational and storage costs. To address these limitations, we propose a novel framework that inco"
}