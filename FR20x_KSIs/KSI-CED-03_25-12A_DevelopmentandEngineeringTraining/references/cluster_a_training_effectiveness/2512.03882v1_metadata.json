{
  "arxiv_id": "2512.03882v1",
  "title": "Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models",
  "authors": [
    "Haidong Kang",
    "Wei Wu",
    "Hanling Wang"
  ],
  "published": "2025-12-03T15:34:26Z",
  "url": "http://arxiv.org/abs/2512.03882v1",
  "pdf_url": "http://arxiv.org/pdf/2512.03882v1.pdf",
  "relevance_score": 97,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Few-shot class incremental learning (FSCIL) is a more realistic and challenging paradigm in continual learning to incrementally learn unseen classes and overcome catastrophic forgetting on base classes with only a few training examples. Previous efforts have primarily centered around studying more effective FSCIL approaches. By contrast, less attention was devoted to thinking the security issues in contributing to FSCIL. This paper aims to provide a holistic study of the impact of attacks on FSC"
}