{
  "arxiv_id": "2510.21808v1",
  "title": "Semantic Relation-Enhanced CLIP Adapter for Domain Adaptive Zero-Shot Learning",
  "authors": [
    "Jiaao Yu",
    "Mingjie Han",
    "Jinkun Jiang",
    "Junyu Dong",
    "Tao Gong",
    "Man Lan"
  ],
  "published": "2025-10-21T09:03:30Z",
  "url": "http://arxiv.org/abs/2510.21808v1",
  "pdf_url": "http://arxiv.org/pdf/2510.21808v1.pdf",
  "relevance_score": 87,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "The high cost of data annotation has spurred research on training deep learning models in data-limited scenarios. Existing paradigms, however, fail to balance cross-domain transfer and cross-category generalization, giving rise to the demand for Domain-Adaptive Zero-Shot Learning (DAZSL). Although vision-language models (e.g., CLIP) have inherent advantages in the DAZSL field, current studies do not fully exploit their potential. Applying CLIP to DAZSL faces two core challenges: inefficient cros"
}