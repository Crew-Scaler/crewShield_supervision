{
  "arxiv_id": "2511.11323v1",
  "title": "RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms",
  "authors": [
    "Yitian Kou",
    "Yihe Gu",
    "Chen Zhou",
    "DanDan Zhu",
    "Shuguang Kuai"
  ],
  "published": "2025-11-14T13:59:40Z",
  "url": "http://arxiv.org/abs/2511.11323v1",
  "pdf_url": "http://arxiv.org/pdf/2511.11323v1.pdf",
  "relevance_score": 79,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Navigating human-populated environments without causing discomfort is a critical capability for socially-aware agents. While rule-based approaches offer interpretability through predefined psychological principles, they often lack generalizability and flexibility. Conversely, data-driven methods can learn complex behaviors from large-scale datasets, but are typically inefficient, opaque, and difficult to align with human intuitions. To bridge this gap, we propose RLSLM, a hybrid Reinforcement Le"
}