{
  "arxiv_id": "2503.13814v1",
  "title": "FusDreamer: Label-efficient Remote Sensing World Model for Multimodal Data Classification",
  "authors": [
    "Jinping Wang",
    "Weiwei Song",
    "Hao Chen",
    "Jinchang Ren",
    "Huimin Zhao"
  ],
  "published": "2025-03-18T01:45:51Z",
  "url": "http://arxiv.org/abs/2503.13814v1",
  "pdf_url": "http://arxiv.org/pdf/2503.13814v1.pdf",
  "relevance_score": 74,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "World models significantly enhance hierarchical understanding, improving data integration and learning efficiency. To explore the potential of the world model in the remote sensing (RS) field, this paper proposes a label-efficient remote sensing world model for multimodal data fusion (FusDreamer). The FusDreamer uses the world model as a unified representation container to abstract common and high-level knowledge, promoting interactions across different types of data, \\emph{i.e.}, hyperspectral "
}