{
  "arxiv_id": "2511.11912v1",
  "title": "A Systematic Study of Model Extraction Attacks on Graph Foundation Models",
  "authors": [
    "Haoyan Xu",
    "Ruizhi Qian",
    "Jiate Li",
    "Yushun Dong",
    "Minghao Lin",
    "Hanson Yan",
    "Zhengtao Yao",
    "Qinghua Liu",
    "Junhao Dong",
    "Ruopeng Huang",
    "Yue Zhao",
    "Mengyuan Li"
  ],
  "published": "2025-11-14T22:43:42Z",
  "url": "http://arxiv.org/abs/2511.11912v1",
  "pdf_url": "http://arxiv.org/pdf/2511.11912v1.pdf",
  "relevance_score": 83,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Graph machine learning has advanced rapidly in tasks such as link prediction, anomaly detection, and node classification. As models scale up, pretrained graph models have become valuable intellectual assets because they encode extensive computation and domain expertise. Building on these advances, Graph Foundation Models (GFMs) mark a major step forward by jointly pretraining graph and text encoders on massive and diverse data. This unifies structural and semantic understanding, enables zero-sho"
}