{
  "arxiv_id": "2506.05121v2",
  "title": "The NTNU System at the S&amp;I Challenge 2025 SLA Open Track",
  "authors": [
    "Hong-Yun Lin",
    "Tien-Hong Lo",
    "Yu-Hsuan Fang",
    "Jhen-Ke Lin",
    "Chung-Chun Wang",
    "Hao-Chien Lu",
    "Berlin Chen"
  ],
  "published": "2025-06-05T15:09:23Z",
  "url": "http://arxiv.org/abs/2506.05121v2",
  "pdf_url": "http://arxiv.org/pdf/2506.05121v2.pdf",
  "relevance_score": 68,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "A recent line of research on spoken language assessment (SLA) employs neural models such as BERT and wav2vec 2.0 (W2V) to evaluate speaking proficiency across linguistic and acoustic modalities. Although both models effectively capture features relevant to oral competence, each exhibits modality-specific limitations. BERT-based methods rely on ASR transcripts, which often fail to capture prosodic and phonetic cues for SLA. In contrast, W2V-based methods excel at modeling acoustic features but la"
}