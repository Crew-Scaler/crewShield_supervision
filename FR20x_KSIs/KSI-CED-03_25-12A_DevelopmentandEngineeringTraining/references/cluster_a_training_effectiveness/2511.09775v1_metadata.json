{
  "arxiv_id": "2511.09775v1",
  "title": "Privacy-Preserving Explainable AIoT Application via SHAP Entropy Regularization",
  "authors": [
    "Dilli Prasad Sharma",
    "Xiaowei Sun",
    "Liang Xue",
    "Xiaodong Lin",
    "Pulei Xiong"
  ],
  "published": "2025-11-12T22:13:32Z",
  "url": "http://arxiv.org/abs/2511.09775v1",
  "pdf_url": "http://arxiv.org/pdf/2511.09775v1.pdf",
  "relevance_score": 81,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "The widespread integration of Artificial Intelligence of Things (AIoT) in smart home environments has amplified the demand for transparent and interpretable machine learning models. To foster user trust and comply with emerging regulatory frameworks, the Explainable AI (XAI) methods, particularly post-hoc techniques such as SHapley Additive exPlanations (SHAP), and Local Interpretable Model-Agnostic Explanations (LIME), are widely employed to elucidate model behavior. However, recent studies hav"
}