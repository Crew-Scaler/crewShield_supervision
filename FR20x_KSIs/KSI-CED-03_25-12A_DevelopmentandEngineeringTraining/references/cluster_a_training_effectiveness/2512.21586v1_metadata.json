{
  "arxiv_id": "2512.21586v1",
  "title": "Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations",
  "authors": [
    "Xin Liu",
    "Haoran Li",
    "Dongbin Zhao"
  ],
  "published": "2025-12-25T09:11:14Z",
  "url": "http://arxiv.org/abs/2512.21586v1",
  "pdf_url": "http://arxiv.org/pdf/2512.21586v1.pdf",
  "relevance_score": 80,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Humans can efficiently extract knowledge and learn skills from the videos within only a few trials and errors. However, it poses a big challenge to replicate this learning process for autonomous agents, due to the complexity of visual input, the absence of action or reward signals, and the limitations of interaction steps. In this paper, we propose a novel, unsupervised, and sample-efficient framework to achieve imitation learning from videos (ILV), named Behavior Cloning from Videos via Latent "
}