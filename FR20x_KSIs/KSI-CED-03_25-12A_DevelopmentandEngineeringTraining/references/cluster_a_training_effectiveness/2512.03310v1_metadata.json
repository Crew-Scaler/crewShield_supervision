{
  "arxiv_id": "2512.03310v1",
  "title": "Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs",
  "authors": [
    "Kunj Joshi",
    "David A. Smith"
  ],
  "published": "2025-12-02T23:46:42Z",
  "url": "http://arxiv.org/abs/2512.03310v1",
  "pdf_url": "http://arxiv.org/pdf/2512.03310v1.pdf",
  "relevance_score": 84,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total E"
}