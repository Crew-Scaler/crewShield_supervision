{
  "arxiv_id": "2512.01775v1",
  "title": "How Does RL Post-training Induce Skill Composition? A Case Study on Countdown",
  "authors": [
    "Simon Park",
    "Simran Kaur",
    "Sanjeev Arora"
  ],
  "published": "2025-12-01T15:17:16Z",
  "url": "http://arxiv.org/abs/2512.01775v1",
  "pdf_url": "http://arxiv.org/pdf/2512.01775v1.pdf",
  "relevance_score": 99,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "While reinforcement learning (RL) successfully enhances reasoning in large language models, its role in fostering compositional generalization (the ability to synthesize novel skills from known components) is often conflated with mere length generalization. To this end, we study what RL post-training teaches about skill composition and how the structure of the composition affects the skill transfer. We focus on the Countdown task (given n numbers and a target, form an expression that evaluates t"
}