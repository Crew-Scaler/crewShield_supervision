{
  "arxiv_id": "2505.01694v1",
  "title": "Topology-Aware CLIP Few-Shot Learning",
  "authors": [
    "Dazhi Huang"
  ],
  "published": "2025-05-03T04:58:29Z",
  "url": "http://arxiv.org/abs/2505.01694v1",
  "pdf_url": "http://arxiv.org/pdf/2505.01694v1.pdf",
  "relevance_score": 85,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Efficiently adapting large Vision-Language Models (VLMs) like CLIP for few-shot learning poses challenges in balancing pre-trained knowledge retention and task-specific adaptation. Existing methods often overlook valuable structural information within the VLM's latent space. We introduce a topology-aware tuning approach integrating Representation Topology Divergence (RTD) into the Task Residual (TR) framework. By explicitly aligning the topological structures of visual and text representations u"
}