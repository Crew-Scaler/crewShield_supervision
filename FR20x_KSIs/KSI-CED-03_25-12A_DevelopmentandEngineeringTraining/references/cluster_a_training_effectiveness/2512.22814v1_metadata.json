{
  "arxiv_id": "2512.22814v1",
  "title": "Long-Range Distillation: Distilling 10,000 Years of Simulated Climate into Long Timestep AI Weather Models",
  "authors": [
    "Scott A. Martin",
    "Noah Brenowitz",
    "Dale Durran",
    "Michael Pritchard"
  ],
  "published": "2025-12-28T07:03:20Z",
  "url": "http://arxiv.org/abs/2512.22814v1",
  "pdf_url": "http://arxiv.org/pdf/2512.22814v1.pdf",
  "relevance_score": 72,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Accurate long-range weather forecasting remains a major challenge for AI models, both because errors accumulate over autoregressive rollouts and because reanalysis datasets used for training offer a limited sample of the slow modes of climate variability underpinning predictability. Most AI weather models are autoregressive, producing short lead forecasts that must be repeatedly applied to reach subseasonal-to-seasonal (S2S) or seasonal lead times, often resulting in instability and calibration "
}