{
  "arxiv_id": "2505.10833v5",
  "title": "MergeBench: A Benchmark for Merging Domain-Specialized LLMs",
  "authors": [
    "Yifei He",
    "Siqi Zeng",
    "Yuzheng Hu",
    "Rui Yang",
    "Tong Zhang",
    "Han Zhao"
  ],
  "published": "2025-05-16T04:02:55Z",
  "url": "http://arxiv.org/abs/2505.10833v5",
  "pdf_url": "http://arxiv.org/pdf/2505.10833v5.pdf",
  "relevance_score": 80,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Model merging provides a scalable alternative to multi-task training by combining specialized finetuned models through parameter arithmetic, enabling efficient deployment without the need for joint training or access to all task data. While recent methods have shown promise, existing evaluations are limited in both model scale and task diversity, leaving open questions about their applicability to large, domain-specialized LLMs. To tackle the challenges, we introduce MergeBench, a comprehensive "
}