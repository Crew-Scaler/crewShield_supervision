{
  "arxiv_id": "2512.22414v1",
  "title": "Emergence of Human to Robot Transfer in Vision-Language-Action Models",
  "authors": [
    "Simar Kareer",
    "Karl Pertsch",
    "James Darpinian",
    "Judy Hoffman",
    "Danfei Xu",
    "Sergey Levine",
    "Chelsea Finn",
    "Suraj Nair"
  ],
  "published": "2025-12-27T00:13:11Z",
  "url": "http://arxiv.org/abs/2512.22414v1",
  "pdf_url": "http://arxiv.org/pdf/2512.22414v1.pdf",
  "relevance_score": 62,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Vision-language-action (VLA) models can enable broad open world generalization, but require large and diverse datasets. It is appealing to consider whether some of this data can come from human videos, which cover diverse real-world situations and are easy to obtain. However, it is difficult to train VLAs with human videos alone, and establishing a mapping between humans and robots requires manual engineering and presents a major research challenge. Drawing inspiration from advances in large lan"
}