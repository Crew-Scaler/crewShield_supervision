{
  "arxiv_id": "2511.12722v1",
  "title": "On Robustness of Linear Classifiers to Targeted Data Poisoning",
  "authors": [
    "Nakshatra Gupta",
    "Sumanth Prabhu",
    "Supratik Chakraborty",
    "R Venkatesh"
  ],
  "published": "2025-11-16T18:20:16Z",
  "url": "http://arxiv.org/abs/2511.12722v1",
  "pdf_url": "http://arxiv.org/pdf/2511.12722v1.pdf",
  "relevance_score": 71,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Data poisoning is a training-time attack that undermines the trustworthiness of learned models. In a targeted data poisoning attack, an adversary manipulates the training dataset to alter the classification of a targeted test point. Given the typically large size of training dataset, manual detection of poisoning is difficult. An alternative is to automatically measure a dataset's robustness against such an attack, which is the focus of this paper. We consider a threat model wherein an adversary"
}