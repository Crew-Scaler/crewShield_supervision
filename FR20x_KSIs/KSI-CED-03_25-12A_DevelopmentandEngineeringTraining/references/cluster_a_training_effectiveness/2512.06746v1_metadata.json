{
  "arxiv_id": "2512.06746v1",
  "title": "Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection",
  "authors": [
    "Ruoxin Chen",
    "Jiahui Gao",
    "Kaiqing Lin",
    "Keyue Zhang",
    "Yandan Zhao",
    "Isabel Guan",
    "Taiping Yao",
    "Shouhong Ding"
  ],
  "published": "2025-12-07T09:19:00Z",
  "url": "http://arxiv.org/abs/2512.06746v1",
  "pdf_url": "http://arxiv.org/pdf/2512.06746v1.pdf",
  "relevance_score": 64,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Vision Language Models (VLMs) are increasingly adopted for AI-generated images (AIGI) detection, yet converting VLMs into detectors requires substantial resource, while the resulting models still exhibit severe hallucinations. To probe the core issue, we conduct an empirical analysis and observe two characteristic behaviors: (i) fine-tuning VLMs on high-level semantic supervision strengthens semantic discrimination and well generalize to unseen data; (ii) fine-tuning VLMs on low-level pixel-arti"
}