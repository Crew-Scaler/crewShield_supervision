{
  "arxiv_id": "2511.07049v1",
  "title": "From Pretrain to Pain: Adversarial Vulnerability of Video Foundation Models Without Task Knowledge",
  "authors": [
    "Hui Lu",
    "Yi Yu",
    "Song Xia",
    "Yiming Yang",
    "Deepu Rajan",
    "Boon Poh Ng",
    "Alex Kot",
    "Xudong Jiang"
  ],
  "published": "2025-11-10T12:42:32Z",
  "url": "http://arxiv.org/abs/2511.07049v1",
  "pdf_url": "http://arxiv.org/pdf/2511.07049v1.pdf",
  "relevance_score": 75,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large-scale Video Foundation Models (VFMs) has significantly advanced various video-related tasks, either through task-specific models or Multi-modal Large Language Models (MLLMs). However, the open accessibility of VFMs also introduces critical security risks, as adversaries can exploit full knowledge of the VFMs to launch potent attacks. This paper investigates a novel and practical adversarial threat scenario: attacking downstream models or MLLMs fine-tuned from open-source VFMs, without requ"
}