{
  "arxiv_id": "2512.01865v1",
  "title": "Cross-Lingual Interleaving for Speech Language Models",
  "authors": [
    "Adel Moumen",
    "Guangzhi Sun",
    "Philip C. Woodland"
  ],
  "published": "2025-12-01T16:48:05Z",
  "url": "http://arxiv.org/abs/2512.01865v1",
  "pdf_url": "http://arxiv.org/pdf/2512.01865v1.pdf",
  "relevance_score": 90,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also "
}