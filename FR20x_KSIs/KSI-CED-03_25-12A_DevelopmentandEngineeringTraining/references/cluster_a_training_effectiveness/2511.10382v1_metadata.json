{
  "arxiv_id": "2511.10382v1",
  "title": "Fragile by Design: On the Limits of Adversarial Defenses in Personalized Generation",
  "authors": [
    "Zhen Chen",
    "Yi Zhang",
    "Xiangyu Yin",
    "Chengxuan Qin",
    "Xingyu Zhao",
    "Xiaowei Huang",
    "Wenjie Ruan"
  ],
  "published": "2025-11-13T14:56:25Z",
  "url": "http://arxiv.org/abs/2511.10382v1",
  "pdf_url": "http://arxiv.org/pdf/2511.10382v1.pdf",
  "relevance_score": 58,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Personalized AI applications such as DreamBooth enable the generation of customized content from user images, but also raise significant privacy concerns, particularly the risk of facial identity leakage. Recent defense mechanisms like Anti-DreamBooth attempt to mitigate this risk by injecting adversarial perturbations into user photos to prevent successful personalization. However, we identify two critical yet overlooked limitations of these methods. First, the adversarial examples often exhibi"
}