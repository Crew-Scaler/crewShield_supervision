{
  "arxiv_id": "2512.21132v1",
  "title": "AutoBaxBuilder: Bootstrapping Code Security Benchmarking",
  "authors": [
    "Tobias von Arx",
    "Niels M\u00fcndler",
    "Mark Vero",
    "Maximilian Baader",
    "Martin Vechev"
  ],
  "published": "2025-12-24T12:02:00Z",
  "url": "http://arxiv.org/abs/2512.21132v1",
  "pdf_url": "http://arxiv.org/pdf/2512.21132v1.pdf",
  "relevance_score": 84,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "As LLMs see wide adoption in software engineering, the reliable assessment of the correctness and security of LLM-generated code is crucial. Notably, prior work has demonstrated that security is often overlooked, exposing that LLMs are prone to generating code with security vulnerabilities. These insights were enabled by specialized benchmarks, crafted through significant manual effort by security experts. However, relying on manually-crafted benchmarks is insufficient in the long term, because "
}