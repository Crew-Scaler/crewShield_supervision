{
  "arxiv_id": "2601.00887v1",
  "title": "VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition",
  "authors": [
    "Hongbo Jin",
    "Kuanwei Lin",
    "Wenhao Zhang",
    "Yichen Jin",
    "Ge Li"
  ],
  "published": "2025-12-31T09:25:36Z",
  "url": "http://arxiv.org/abs/2601.00887v1",
  "pdf_url": "http://arxiv.org/pdf/2601.00887v1.pdf",
  "relevance_score": 79,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these"
}