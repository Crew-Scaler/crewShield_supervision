{
  "arxiv_id": "2511.18878v1",
  "title": "Accelerating Reinforcement Learning via Error-Related Human Brain Signals",
  "authors": [
    "Suzie Kim",
    "Hye-Bin Shin",
    "Hyo-Jeong Jang"
  ],
  "published": "2025-11-24T08:33:47Z",
  "url": "http://arxiv.org/abs/2511.18878v1",
  "pdf_url": "http://arxiv.org/pdf/2511.18878v1.pdf",
  "relevance_score": 79,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "In this work, we investigate how implicit neural feed back can accelerate reinforcement learning in complex robotic manipulation settings. While prior electroencephalogram (EEG) guided reinforcement learning studies have primarily focused on navigation or low-dimensional locomotion tasks, we aim to understand whether such neural evaluative signals can improve policy learning in high-dimensional manipulation tasks involving obstacles and precise end-effector control. We integrate error related po"
}