{
  "arxiv_id": "2512.05937v1",
  "title": "Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception",
  "authors": [
    "Anne Sielemann",
    "Valentin Barner",
    "Stefan Wolf",
    "Masoud Roschani",
    "Jens Ziehn",
    "Juergen Beyerer"
  ],
  "published": "2025-12-05T18:25:52Z",
  "url": "http://arxiv.org/abs/2512.05937v1",
  "pdf_url": "http://arxiv.org/pdf/2512.05937v1.pdf",
  "relevance_score": 79,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Common approaches to explainable AI (XAI) for deep learning focus on analyzing the importance of input features on the classification task in a given model: saliency methods like SHAP and GradCAM are used to measure the impact of spatial regions of the input image on the classification result. Combined with ground truth information about the location of the object in the input image (e.g., a binary mask), it is determined whether object pixels had a high impact on the classification result, or w"
}