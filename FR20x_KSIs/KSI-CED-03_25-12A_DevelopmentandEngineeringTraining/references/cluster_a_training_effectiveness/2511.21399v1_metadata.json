{
  "arxiv_id": "2511.21399v1",
  "title": "Training Introspective Behavior: Fine-Tuning Induces Reliable Internal State Detection in a 7B Model",
  "authors": [
    "Joshua Fonseca Rivera"
  ],
  "published": "2025-11-26T13:49:43Z",
  "url": "http://arxiv.org/abs/2511.21399v1",
  "pdf_url": "http://arxiv.org/pdf/2511.21399v1.pdf",
  "relevance_score": 87,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Lindsey (2025) investigates introspective awareness in language models through four experiments, finding that models can sometimes detect and identify injected activation patterns -- but unreliably (~20% success in the best model). We focus on the first of these experiments -- self-report of injected \"thoughts\" -- and ask whether this capability can be directly trained rather than waiting for emergence. Through fine-tuning on transient single-token injections, we transform a 7B parameter model f"
}