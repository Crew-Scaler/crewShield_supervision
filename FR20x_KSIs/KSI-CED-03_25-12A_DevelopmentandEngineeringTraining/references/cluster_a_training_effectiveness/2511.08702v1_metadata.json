{
  "arxiv_id": "2511.08702v1",
  "title": "FAIRPLAI: A Human-in-the-Loop Approach to Fair and Private Machine Learning",
  "authors": [
    "David Sanchez",
    "Holly Lopez",
    "Michelle Buraczyk",
    "Anantaa Kotal"
  ],
  "published": "2025-11-11T19:07:46Z",
  "url": "http://arxiv.org/abs/2511.08702v1",
  "pdf_url": "http://arxiv.org/pdf/2511.08702v1.pdf",
  "relevance_score": 82,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "As machine learning systems move from theory to practice, they are increasingly tasked with decisions that affect healthcare access, financial opportunities, hiring, and public services. In these contexts, accuracy is only one piece of the puzzle - models must also be fair to different groups, protect individual privacy, and remain accountable to stakeholders. Achieving all three is difficult: differential privacy can unintentionally worsen disparities, fairness interventions often rely on sensi"
}