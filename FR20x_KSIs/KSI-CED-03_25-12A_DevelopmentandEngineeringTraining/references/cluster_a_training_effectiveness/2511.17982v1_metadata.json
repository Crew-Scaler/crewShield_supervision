{
  "arxiv_id": "2511.17982v1",
  "title": "Towards Effective, Stealthy, and Persistent Backdoor Attacks Targeting Graph Foundation Models",
  "authors": [
    "Jiayi Luo",
    "Qingyun Sun",
    "Lingjuan Lyu",
    "Ziwei Zhang",
    "Haonan Yuan",
    "Xingcheng Fu",
    "Jianxin Li"
  ],
  "published": "2025-11-22T08:52:09Z",
  "url": "http://arxiv.org/abs/2511.17982v1",
  "pdf_url": "http://arxiv.org/pdf/2511.17982v1.pdf",
  "relevance_score": 83,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Graph Foundation Models (GFMs) are pre-trained on diverse source domains and adapted to unseen targets, enabling broad generalization for graph machine learning. Despite that GFMs have attracted considerable attention recently, their vulnerability to backdoor attacks remains largely underexplored. A compromised GFM can introduce backdoor behaviors into downstream applications, posing serious security risks. However, launching backdoor attacks against GFMs is non-trivial due to three key challeng"
}