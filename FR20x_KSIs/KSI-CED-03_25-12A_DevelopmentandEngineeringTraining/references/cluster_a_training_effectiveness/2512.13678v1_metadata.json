{
  "arxiv_id": "2512.13678v1",
  "title": "Feedforward 3D Editing via Text-Steerable Image-to-3D",
  "authors": [
    "Ziqi Ma",
    "Hongqiao Chen",
    "Yisong Yue",
    "Georgia Gkioxari"
  ],
  "published": "2025-12-15T18:58:55Z",
  "url": "http://arxiv.org/abs/2512.13678v1",
  "pdf_url": "http://arxiv.org/pdf/2512.13678v1.pdf",
  "relevance_score": 62,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward "
}