{
  "arxiv_id": "2511.10008v2",
  "title": "Phantom Menace: Exploring and Enhancing the Robustness of VLA Models Against Physical Sensor Attacks",
  "authors": [
    "Xuancun Lu",
    "Jiaxiang Chen",
    "Shilin Xiao",
    "Zizhi Jin",
    "Zhangrui Chen",
    "Hanwen Yu",
    "Bohan Qian",
    "Ruochen Zhou",
    "Xiaoyu Ji",
    "Wenyuan Xu"
  ],
  "published": "2025-11-13T06:24:28Z",
  "url": "http://arxiv.org/abs/2511.10008v2",
  "pdf_url": "http://arxiv.org/pdf/2511.10008v2.pdf",
  "relevance_score": 74,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Vision-Language-Action (VLA) models revolutionize robotic systems by enabling end-to-end perception-to-action pipelines that integrate multiple sensory modalities, such as visual signals processed by cameras and auditory signals captured by microphones. This multi-modality integration allows VLA models to interpret complex, real-world environments using diverse sensor data streams. Given the fact that VLA-based systems heavily rely on the sensory input, the security of VLA models against physica"
}