{
  "arxiv_id": "2512.18857v1",
  "title": "CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning",
  "authors": [
    "Zijun Gao",
    "Zhikun Xu",
    "Xiao Ye",
    "Ben Zhou"
  ],
  "published": "2025-12-21T19:01:35Z",
  "url": "http://arxiv.org/abs/2512.18857v1",
  "pdf_url": "http://arxiv.org/pdf/2512.18857v1.pdf",
  "relevance_score": 82,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large language models (LLMs) often solve challenging math exercises yet fail to apply the concept right when the problem requires genuine understanding. Popular Reinforcement Learning with Verifiable Rewards (RLVR) pipelines reinforce final answers but provide little fine-grained conceptual signal, so models improve at pattern reuse rather than conceptual applications. We introduce CORE (Concept-Oriented REinforcement), an RL training framework that turns explicit concepts into a controllable su"
}