{
  "arxiv_id": "2511.05867v2",
  "title": "MCP-RiskCue: Can LLM Infer Risk Information From MCP Server System Logs?",
  "authors": [
    "Jiayi Fu",
    "Qiyao Sun"
  ],
  "published": "2025-11-08T05:52:53Z",
  "url": "http://arxiv.org/abs/2511.05867v2",
  "pdf_url": "http://arxiv.org/pdf/2511.05867v2.pdf",
  "relevance_score": 71,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large language models (LLMs) demonstrate strong capabilities in solving complex tasks when integrated with external tools. The Model Context Protocol (MCP) has become a standard interface for enabling such tool-based interactions. However, these interactions introduce substantial security concerns, particularly when the MCP server is compromised or untrustworthy. While prior benchmarks primarily focus on prompt injection attacks or analyze the vulnerabilities of LLM MCP interaction trajectories,"
}