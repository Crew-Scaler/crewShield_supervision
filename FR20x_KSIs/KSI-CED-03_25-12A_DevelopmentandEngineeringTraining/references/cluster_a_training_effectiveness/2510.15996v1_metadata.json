{
  "arxiv_id": "2510.15996v1",
  "title": "Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning",
  "authors": [
    "Ozan K. Tonguz",
    "Federico Taschin"
  ],
  "published": "2025-10-14T08:35:55Z",
  "url": "http://arxiv.org/abs/2510.15996v1",
  "pdf_url": "http://arxiv.org/pdf/2510.15996v1.pdf",
  "relevance_score": 93,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "One of the major problems in Machine Learning (ML) and Artificial Intelligence (AI) is the fact that the probability distribution of the test data in the real world could deviate substantially from the probability distribution of the training data set. When this happens, the predictions of an ML system or an AI agent could involve large errors which is very troublesome and undesirable. While this is a well-known hard problem plaguing the AI and ML systems' accuracy and reliability, in certain ap"
}