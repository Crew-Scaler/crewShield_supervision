{
  "arxiv_id": "2511.18740v1",
  "title": "Multimodal Large Language Models with Adaptive Preference Optimization for Sequential Recommendation",
  "authors": [
    "Yu Wang",
    "Yonghui Yang",
    "Le Wu",
    "Yi Zhang",
    "Richang Hong"
  ],
  "published": "2025-11-24T04:10:46Z",
  "url": "http://arxiv.org/abs/2511.18740v1",
  "pdf_url": "http://arxiv.org/pdf/2511.18740v1.pdf",
  "relevance_score": 64,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Recent advances in Large Language Models (LLMs) have opened new avenues for sequential recommendation by enabling natural language reasoning over user behavior sequences. A common approach formulates recommendation as a language modeling task, where interaction histories are transformed into prompts and user preferences are learned via supervised fine-tuning. However, these methods operate solely in the textual modality and often miss users' fine-grained interests, especially when shaped by rich"
}