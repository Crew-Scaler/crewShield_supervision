{
  "arxiv_id": "2512.07495v1",
  "title": "Amulet: Fast TEE-Shielded Inference for On-Device Model Protection",
  "authors": [
    "Zikai Mao",
    "Lingchen Zhao",
    "Lei Xu",
    "Wentao Dong",
    "Shenyi Zhang",
    "Cong Wang",
    "Qian Wang"
  ],
  "published": "2025-12-08T12:22:51Z",
  "url": "http://arxiv.org/abs/2512.07495v1",
  "pdf_url": "http://arxiv.org/pdf/2512.07495v1.pdf",
  "relevance_score": 85,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "On-device machine learning (ML) introduces new security concerns about model privacy. Storing valuable trained ML models on user devices exposes them to potential extraction by adversaries. The current mainstream solution for on-device model protection is storing the weights and conducting inference within Trusted Execution Environments (TEEs). However, due to limited trusted memory that cannot accommodate the whole model, most existing approaches employ a partitioning strategy, dividing a model"
}