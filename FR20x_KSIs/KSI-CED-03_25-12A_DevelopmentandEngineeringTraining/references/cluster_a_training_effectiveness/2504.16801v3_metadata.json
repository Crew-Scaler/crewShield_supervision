{
  "arxiv_id": "2504.16801v3",
  "title": "Decoupled Global-Local Alignment for Improving Compositional Understanding",
  "authors": [
    "Xiaoxing Hu",
    "Kaicheng Yang",
    "Jun Wang",
    "Haoran Xu",
    "Ziyong Feng",
    "Yupei Wang"
  ],
  "published": "2025-04-23T15:20:53Z",
  "url": "http://arxiv.org/abs/2504.16801v3",
  "pdf_url": "http://arxiv.org/pdf/2504.16801v3.pdf",
  "relevance_score": 80,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Contrastive Language-Image Pre-training (CLIP) has achieved success on multiple downstream tasks by aligning image and text modalities. However, the nature of global contrastive learning limits CLIP's ability to comprehend compositional concepts, such as relations and attributes. Although recent studies employ global hard negative samples to improve compositional understanding, these methods significantly compromise the model's inherent general capabilities by forcibly distancing textual negativ"
}