{
  "arxiv_id": "2511.18833v3",
  "title": "PrismAudio: Decomposed Chain-of-Thoughts and Multi-dimensional Rewards for Video-to-Audio Generation",
  "authors": [
    "Huadai Liu",
    "Kaicheng Luo",
    "Wen Wang",
    "Qian Chen",
    "Peiwen Sun",
    "Rongjie Huang",
    "Xiangang Li",
    "Jieping Ye",
    "Wei Xue"
  ],
  "published": "2025-11-24T07:11:12Z",
  "url": "http://arxiv.org/abs/2511.18833v3",
  "pdf_url": "http://arxiv.org/pdf/2511.18833v3.pdf",
  "relevance_score": 72,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Video-to-Audio (V2A) generation requires balancing four critical perceptual dimensions: semantic consistency, audio-visual temporal synchrony, aesthetic quality, and spatial accuracy; yet existing methods suffer from objective entanglement that conflates competing goals in single loss functions and lack human preference alignment. We introduce PrismAudio, the first framework to integrate Reinforcement Learning into V2A generation with specialized Chain-of-Thought (CoT) planning. Our approach dec"
}