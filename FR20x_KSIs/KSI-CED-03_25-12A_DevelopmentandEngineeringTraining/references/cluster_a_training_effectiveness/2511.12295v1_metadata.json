{
  "arxiv_id": "2511.12295v1",
  "title": "Privacy-Preserving Prompt Injection Detection for LLMs Using Federated Learning and Embedding-Based NLP Classification",
  "authors": [
    "Hasini Jayathilaka"
  ],
  "published": "2025-11-15T17:11:14Z",
  "url": "http://arxiv.org/abs/2511.12295v1",
  "pdf_url": "http://arxiv.org/pdf/2511.12295v1.pdf",
  "relevance_score": 77,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Prompt injection attacks are an emerging threat to large language models (LLMs), enabling malicious users to manipulate outputs through carefully designed inputs. Existing detection approaches often require centralizing prompt data, creating significant privacy risks. This paper proposes a privacy-preserving prompt injection detection framework based on federated learning and embedding-based classification. A curated dataset of benign and adversarial prompts was encoded with sentence embedding a"
}