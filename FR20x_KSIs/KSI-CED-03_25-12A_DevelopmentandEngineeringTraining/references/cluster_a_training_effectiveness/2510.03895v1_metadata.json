{
  "arxiv_id": "2510.03895v1",
  "title": "NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation",
  "authors": [
    "Zheng Huang",
    "Mingyu Liu",
    "Xiaoyi Lin",
    "Muzhi Zhu",
    "Canyu Zhao",
    "Zongze Du",
    "Xiaoman Li",
    "Yiduo Jia",
    "Hao Zhong",
    "Hao Chen",
    "Chunhua Shen"
  ],
  "published": "2025-10-04T18:26:55Z",
  "url": "http://arxiv.org/abs/2510.03895v1",
  "pdf_url": "http://arxiv.org/pdf/2510.03895v1.pdf",
  "relevance_score": 63,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Vision-Language-Action (VLA) models represent a pivotal advance in embodied intelligence, yet they confront critical barriers to real-world deployment, most notably catastrophic forgetting. This issue stems from their overreliance on continuous action sequences or action chunks, which inadvertently create isolated data silos that disrupt knowledge retention across tasks. To tackle these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA) framework: a novel approach that narrows its f"
}