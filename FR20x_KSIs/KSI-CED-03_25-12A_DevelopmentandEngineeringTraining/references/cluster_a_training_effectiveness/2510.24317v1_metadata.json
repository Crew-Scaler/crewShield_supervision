{
  "arxiv_id": "2510.24317v1",
  "title": "Cybersecurity AI Benchmark (CAIBench): A Meta-Benchmark for Evaluating Cybersecurity AI Agents",
  "authors": [
    "Mar\u00eda Sanz-G\u00f3mez",
    "V\u00edctor Mayoral-Vilches",
    "Francesco Balassone",
    "Luis Javier Navarrete-Lozano",
    "Crist\u00f3bal R. J. Veas Chavez",
    "Maite del Mundo de Torres"
  ],
  "published": "2025-10-28T11:36:20Z",
  "url": "http://arxiv.org/abs/2510.24317v1",
  "pdf_url": "http://arxiv.org/pdf/2510.24317v1.pdf",
  "relevance_score": 84,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Cybersecurity spans multiple interconnected domains, complicating the development of meaningful, labor-relevant benchmarks. Existing benchmarks assess isolated skills rather than integrated performance. We find that pre-trained knowledge of cybersecurity in LLMs does not imply attack and defense abilities, revealing a gap between knowledge and capability. To address this limitation, we present the Cybersecurity AI Benchmark (CAIBench), a modular meta-benchmark framework that allows evaluating LL"
}