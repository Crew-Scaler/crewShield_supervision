{
  "arxiv_id": "2511.12046v1",
  "title": "BackWeak: Backdooring Knowledge Distillation Simply with Weak Triggers and Fine-tuning",
  "authors": [
    "Shanmin Wang",
    "Dongdong Zhao"
  ],
  "published": "2025-11-15T05:53:15Z",
  "url": "http://arxiv.org/abs/2511.12046v1",
  "pdf_url": "http://arxiv.org/pdf/2511.12046v1.pdf",
  "relevance_score": 74,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Knowledge Distillation (KD) is essential for compressing large models, yet relying on pre-trained \"teacher\" models downloaded from third-party repositories introduces serious security risks -- most notably backdoor attacks. Existing KD backdoor methods are typically complex and computationally intensive: they employ surrogate student models and simulated distillation to guarantee transferability, and they construct triggers in a way similar to universal adversarial perturbations (UAPs), which be"
}