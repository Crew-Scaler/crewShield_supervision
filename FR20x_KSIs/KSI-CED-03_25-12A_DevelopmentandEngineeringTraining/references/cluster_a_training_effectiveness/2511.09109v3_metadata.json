{
  "arxiv_id": "2511.09109v3",
  "title": "Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning",
  "authors": [
    "Wenda Wei",
    "Yu-An Liu",
    "Ruqing Zhang",
    "Jiafeng Guo",
    "Lixin Su",
    "Shuaiqiang Wang",
    "Dawei Yin",
    "Maarten de Rijke",
    "Xueqi Cheng"
  ],
  "published": "2025-11-12T08:29:39Z",
  "url": "http://arxiv.org/abs/2511.09109v3",
  "pdf_url": "http://arxiv.org/pdf/2511.09109v3.pdf",
  "relevance_score": 91,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Retrieval-augmented generation (RAG) has proven to be effective in mitigating hallucinations in large language models, yet its effectiveness remains limited in complex, multi-step reasoning scenarios. Recent efforts have incorporated search-based interactions into RAG, enabling iterative reasoning with real-time retrieval. Most approaches rely on outcome-based supervision, offering no explicit guidance for intermediate steps. This often leads to reward hacking and degraded response quality. We p"
}