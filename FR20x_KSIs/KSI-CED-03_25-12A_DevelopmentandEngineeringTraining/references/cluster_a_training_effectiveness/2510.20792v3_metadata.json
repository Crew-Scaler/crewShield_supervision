{
  "arxiv_id": "2510.20792v3",
  "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation",
  "authors": [
    "Liang Ye",
    "Shengqin Chen",
    "Jiazhu Dai"
  ],
  "published": "2025-10-23T17:54:17Z",
  "url": "http://arxiv.org/abs/2510.20792v3",
  "pdf_url": "http://arxiv.org/pdf/2510.20792v3.pdf",
  "relevance_score": 82,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "The rapid progress of graph generation has raised new security concerns, particularly regarding backdoor vulnerabilities. While prior work has explored backdoor attacks in image diffusion and unconditional graph generation, conditional, especially text-guided graph generation remains largely unexamined. This paper proposes BadGraph, a backdoor attack method against latent diffusion models for text-guided graph generation. BadGraph leverages textual triggers to poison training data, covertly impl"
}