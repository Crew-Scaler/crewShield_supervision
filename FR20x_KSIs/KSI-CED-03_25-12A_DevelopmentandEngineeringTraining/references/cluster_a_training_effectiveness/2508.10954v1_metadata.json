{
  "arxiv_id": "2508.10954v1",
  "title": "Towards Efficient Prompt-based Continual Learning in Distributed Medical AI",
  "authors": [
    "Gyutae Oh",
    "Jitae Shin"
  ],
  "published": "2025-08-14T06:46:14Z",
  "url": "http://arxiv.org/abs/2508.10954v1",
  "pdf_url": "http://arxiv.org/pdf/2508.10954v1.pdf",
  "relevance_score": 89,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Modern AI models achieve state-of-the-art performance with large-scale, high-quality datasets; however, ethical, social, and institutional constraints in the medical domain severely restrict data sharing, rendering centralized learning nearly impossible. Each institution must incrementally update models using only local data. Traditional training overfits new samples and suffers from catastrophic forgetting, losing previously acquired knowledge. Medical data distributions also shift due to varyi"
}