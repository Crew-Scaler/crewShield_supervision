{
  "arxiv_id": "2511.22751v1",
  "title": "Exact Learning of Arithmetic with Differentiable Agents",
  "authors": [
    "Hristo Papazov",
    "Francesco D'Angelo",
    "Nicolas Flammarion"
  ],
  "published": "2025-11-27T20:51:16Z",
  "url": "http://arxiv.org/abs/2511.22751v1",
  "pdf_url": "http://arxiv.org/pdf/2511.22751v1.pdf",
  "relevance_score": 92,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "We explore the possibility of exact algorithmic learning with gradient-based methods and introduce a differentiable framework capable of strong length generalization on arithmetic tasks. Our approach centers on Differentiable Finite-State Transducers (DFSTs), a Turing-complete model family that avoids the pitfalls of prior architectures by enabling constant-precision, constant-time generation, and end-to-end log-parallel differentiable training. Leveraging policy-trajectory observations from exp"
}