{
  "arxiv_id": "2510.27275v1",
  "title": "Prevalence of Security and Privacy Risk-Inducing Usage of AI-based Conversational Agents",
  "authors": [
    "Kathrin Grosse",
    "Nico Ebert"
  ],
  "published": "2025-10-31T08:35:42Z",
  "url": "http://arxiv.org/abs/2510.27275v1",
  "pdf_url": "http://arxiv.org/pdf/2510.27275v1.pdf",
  "relevance_score": 85,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Recent improvement gains in large language models (LLMs) have lead to everyday usage of AI-based Conversational Agents (CAs). At the same time, LLMs are vulnerable to an array of threats, including jailbreaks and, for example, causing remote code execution when fed specific inputs. As a result, users may unintentionally introduce risks, for example, by uploading malicious files or disclosing sensitive information. However, the extent to which such user behaviors occur and thus potentially facili"
}