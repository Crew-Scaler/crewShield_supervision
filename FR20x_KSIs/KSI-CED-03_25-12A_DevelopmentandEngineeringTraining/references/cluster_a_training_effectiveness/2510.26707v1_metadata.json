{
  "arxiv_id": "2510.26707v1",
  "title": "Value Drifts: Tracing Value Alignment During LLM Post-Training",
  "authors": [
    "Mehar Bhatia",
    "Shravan Nayak",
    "Gaurav Kamath",
    "Marius Mosbach",
    "Karolina Sta\u0144czak",
    "Vered Shwartz",
    "Siva Reddy"
  ],
  "published": "2025-10-30T17:09:09Z",
  "url": "http://arxiv.org/abs/2510.26707v1",
  "pdf_url": "http://arxiv.org/pdf/2510.26707v1.pdf",
  "relevance_score": 79,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "As LLMs occupy an increasingly important role in society, they are more and more confronted with questions that require them not only to draw on their general knowledge but also to align with certain human value systems. Therefore, studying the alignment of LLMs with human values has become a crucial field of inquiry. Prior work, however, mostly focuses on evaluating the alignment of fully trained models, overlooking the training dynamics by which models learn to express human values. In this wo"
}