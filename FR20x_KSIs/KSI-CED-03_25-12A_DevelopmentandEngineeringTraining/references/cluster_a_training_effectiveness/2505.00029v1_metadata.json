{
  "arxiv_id": "2505.00029v1",
  "title": "Keep the General, Inject the Specific: Structured Dialogue Fine-Tuning for Knowledge Injection without Catastrophic Forgetting",
  "authors": [
    "Yijie Hong",
    "Xiaofei Yin",
    "Xinzhong Wang",
    "Yi Tu",
    "Ya Guo",
    "Sufeng Duan",
    "Weiqiang Wang",
    "Lingyong Fang",
    "Depeng Wang",
    "Huijia Zhu"
  ],
  "published": "2025-04-27T18:04:02Z",
  "url": "http://arxiv.org/abs/2505.00029v1",
  "pdf_url": "http://arxiv.org/pdf/2505.00029v1.pdf",
  "relevance_score": 70,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large Vision Language Models have demonstrated impressive versatile capabilities through extensive multimodal pre-training, but face significant limitations when incorporating specialized knowledge domains beyond their training distribution. These models struggle with a fundamental dilemma: direct adaptation approaches that inject domain-specific knowledge often trigger catastrophic forgetting of foundational visual-linguistic abilities. We introduce Structured Dialogue Fine-Tuning (SDFT), an ef"
}