{
  "arxiv_id": "2512.00713v2",
  "title": "Concept-Guided Backdoor Attack on Vision Language Models",
  "authors": [
    "Haoyu Shen",
    "Weimin Lyu",
    "Haotian Xu",
    "Tengfei Ma"
  ],
  "published": "2025-11-30T03:24:23Z",
  "url": "http://arxiv.org/abs/2512.00713v2",
  "pdf_url": "http://arxiv.org/pdf/2512.00713v2.pdf",
  "relevance_score": 72,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Vision-Language Models (VLMs) have achieved impressive progress in multimodal text generation, yet their rapid adoption raises increasing concerns about security vulnerabilities. Existing backdoor attacks against VLMs primarily rely on explicit pixel-level triggers or imperceptible perturbations injected into images. While effective, these approaches reduce stealthiness and remain vulnerable to image-based defenses. We introduce concept-guided backdoor attacks, a new paradigm that operates at th"
}