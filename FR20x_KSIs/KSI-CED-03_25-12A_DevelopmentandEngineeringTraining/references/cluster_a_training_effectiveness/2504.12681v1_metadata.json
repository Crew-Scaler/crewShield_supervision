{
  "arxiv_id": "2504.12681v1",
  "title": "GRAIL: Gradient-Based Adaptive Unlearning for Privacy and Copyright in LLMs",
  "authors": [
    "Kun-Woo Kim",
    "Ji-Hoon Park",
    "Ju-Min Han",
    "Seong-Whan Lee"
  ],
  "published": "2025-04-17T06:16:32Z",
  "url": "http://arxiv.org/abs/2504.12681v1",
  "pdf_url": "http://arxiv.org/pdf/2504.12681v1.pdf",
  "relevance_score": 89,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large Language Models (LLMs) trained on extensive datasets often learn sensitive information, which raises significant social and legal concerns under principles such as the \"Right to be forgotten.\" Retraining entire models from scratch to remove undesired information is both costly and impractical. Furthermore, existing single-domain unlearning methods fail to address multi-domain scenarios, where knowledge is interwoven across domains such as privacy and copyright, creating overlapping represe"
}