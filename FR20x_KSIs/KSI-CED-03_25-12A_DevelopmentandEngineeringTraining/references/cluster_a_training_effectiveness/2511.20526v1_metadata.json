{
  "arxiv_id": "2511.20526v1",
  "title": "Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam",
  "authors": [
    "Xinran Wang",
    "Boran Zhu",
    "Shujuan Zhou",
    "Ziwen Long",
    "Dehua Zhou",
    "Shu Zhang"
  ],
  "published": "2025-11-25T17:31:25Z",
  "url": "http://arxiv.org/abs/2511.20526v1",
  "pdf_url": "http://arxiv.org/pdf/2511.20526v1.pdf",
  "relevance_score": 66,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Background: As large language models (LLMs) become increasingly integrated into digital health education and assessment workflows, their capabilities in supporting high-stakes, domain-specific certification tasks remain underexplored.In China, the national pharmacist licensure exam serves as a standardized benchmark for evaluating pharmacists' clinical and theoretical competencies. Objective: This study aimed to compare the performance of two LLMs: ChatGPT-4o and DeepSeek-R1 on real questions fr"
}