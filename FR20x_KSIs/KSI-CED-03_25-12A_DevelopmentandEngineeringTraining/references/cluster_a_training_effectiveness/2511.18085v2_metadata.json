{
  "arxiv_id": "2511.18085v2",
  "title": "Continually Evolving Skill Knowledge in Vision Language Action Model",
  "authors": [
    "Yuxuan Wu",
    "Guangming Wang",
    "Zhiheng Yang",
    "Maoqing Yao",
    "Brian Sheil",
    "Hesheng Wang"
  ],
  "published": "2025-11-22T15:00:08Z",
  "url": "http://arxiv.org/abs/2511.18085v2",
  "pdf_url": "http://arxiv.org/pdf/2511.18085v2.pdf",
  "relevance_score": 86,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models leverage massive pretraining data to support diverse manipulation tasks, but they still depend heavily on task-specific fine-tuning, revealing a lack of continual learning capability. Existing continual learning methods are also resource-intensive to scale to VLA models. We propose Stellar VLA, a knowledge-driven continual learning framework with two variants: "
}