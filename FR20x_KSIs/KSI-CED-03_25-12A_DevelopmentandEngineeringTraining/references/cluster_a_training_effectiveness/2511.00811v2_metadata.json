{
  "arxiv_id": "2511.00811v2",
  "title": "Equilibrium Policy Generalization: A Reinforcement Learning Framework for Cross-Graph Zero-Shot Generalization in Pursuit-Evasion Games",
  "authors": [
    "Runyu Lu",
    "Peng Zhang",
    "Ruochuan Shi",
    "Yuanheng Zhu",
    "Dongbin Zhao",
    "Yang Liu",
    "Dong Wang",
    "Cesare Alippi"
  ],
  "published": "2025-11-02T05:45:27Z",
  "url": "http://arxiv.org/abs/2511.00811v2",
  "pdf_url": "http://arxiv.org/pdf/2511.00811v2.pdf",
  "relevance_score": 87,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Equilibrium learning in adversarial games is an important topic widely examined in the fields of game theory and reinforcement learning (RL). Pursuit-evasion game (PEG), as an important class of real-world games from the fields of robotics and security, requires exponential time to be accurately solved. When the underlying graph structure varies, even the state-of-the-art RL methods require recomputation or at least fine-tuning, which can be time-consuming and impair real-time applicability. Thi"
}