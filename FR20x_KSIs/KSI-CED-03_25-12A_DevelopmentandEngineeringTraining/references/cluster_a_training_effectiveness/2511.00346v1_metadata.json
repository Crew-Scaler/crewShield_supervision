{
  "arxiv_id": "2511.00346v1",
  "title": "Exploiting Latent Space Discontinuities for Building Universal LLM Jailbreaks and Data Extraction Attacks",
  "authors": [
    "Kayua Oleques Paim",
    "Rodrigo Brandao Mansilha",
    "Diego Kreutz",
    "Muriel Figueredo Franco",
    "Weverton Cordeiro"
  ],
  "published": "2025-11-01T01:19:12Z",
  "url": "http://arxiv.org/abs/2511.00346v1",
  "pdf_url": "http://arxiv.org/pdf/2511.00346v1.pdf",
  "relevance_score": 82,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "The rapid proliferation of Large Language Models (LLMs) has raised significant concerns about their security against adversarial attacks. In this work, we propose a novel approach to crafting universal jailbreaks and data extraction attacks by exploiting latent space discontinuities, an architectural vulnerability related to the sparsity of training data. Unlike previous methods, our technique generalizes across various models and interfaces, proving highly effective in seven state-of-the-art LL"
}