{
  "arxiv_id": "2502.01472v3",
  "title": "FALCON: Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment for Large Language Model",
  "authors": [
    "Jinwei Hu",
    "Zhenglin Huang",
    "Xiangyu Yin",
    "Wenjie Ruan",
    "Guangliang Cheng",
    "Yi Dong",
    "Xiaowei Huang"
  ],
  "published": "2025-02-03T16:05:15Z",
  "url": "http://arxiv.org/abs/2502.01472v3",
  "pdf_url": "http://arxiv.org/pdf/2502.01472v3.pdf",
  "relevance_score": 90,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large language models have been widely applied, but can inadvertently encode sensitive or harmful information, raising significant safety concerns. Machine unlearning has emerged to alleviate this concern; however, existing training-time unlearning approaches, relying on coarse-grained loss combinations, have limitations in precisely separating knowledge and balancing removal effectiveness with model utility. In contrast, we propose Fine-grained Activation manipuLation by Contrastive Orthogonal "
}