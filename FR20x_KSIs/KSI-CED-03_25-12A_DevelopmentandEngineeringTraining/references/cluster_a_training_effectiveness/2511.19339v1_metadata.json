{
  "arxiv_id": "2511.19339v1",
  "title": "POUR: A Provably Optimal Method for Unlearning Representations via Neural Collapse",
  "authors": [
    "Anjie Le",
    "Can Peng",
    "Yuyuan Liu",
    "J. Alison Noble"
  ],
  "published": "2025-11-24T17:38:53Z",
  "url": "http://arxiv.org/abs/2511.19339v1",
  "pdf_url": "http://arxiv.org/pdf/2511.19339v1.pdf",
  "relevance_score": 93,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "In computer vision, machine unlearning aims to remove the influence of specific visual concepts or training images without retraining from scratch. Studies show that existing approaches often modify the classifier while leaving internal representations intact, resulting in incomplete forgetting. In this work, we extend the notion of unlearning to the representation level, deriving a three-term interplay between forgetting efficacy, retention fidelity, and class separation. Building on Neural Col"
}