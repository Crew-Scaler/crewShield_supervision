{
  "arxiv_id": "2511.20937v1",
  "title": "ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction",
  "authors": [
    "Qineng Wang",
    "Wenlong Huang",
    "Yu Zhou",
    "Hang Yin",
    "Tianwei Bao",
    "Jianwen Lyu",
    "Weiyu Liu",
    "Ruohan Zhang",
    "Jiajun Wu",
    "Li Fei-Fei",
    "Manling Li"
  ],
  "published": "2025-11-26T00:06:02Z",
  "url": "http://arxiv.org/abs/2511.20937v1",
  "pdf_url": "http://arxiv.org/pdf/2511.20937v1.pdf",
  "relevance_score": 66,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) w"
}