{
  "arxiv_id": "2511.21568v1",
  "title": "RoParQ: Paraphrase-Aware Alignment of Large Language Models Towards Robustness to Paraphrased Questions",
  "authors": [
    "Minjoon Choi"
  ],
  "published": "2025-11-26T16:40:53Z",
  "url": "http://arxiv.org/abs/2511.21568v1",
  "pdf_url": "http://arxiv.org/pdf/2511.21568v1.pdf",
  "relevance_score": 64,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large Language Models (LLMs) often exhibit inconsistent behavior when answering paraphrased questions, suggesting a reliance on surface-level patterns rather than true semantic understanding. To address this limitation, we introduce RoParQ, a benchmark specifically constructed to evaluate cross-paraphrase consistency in closed-book multiple-choice QA. This benchmark is derived from standard datasets by generating paraphrases via proprietary models and selectively retaining examples that elicit i"
}