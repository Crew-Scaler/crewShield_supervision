{
  "arxiv_id": "2511.22434v1",
  "title": "FastFHE: Packing-Scalable and Depthwise-Separable CNN Inference Over FHE",
  "authors": [
    "Wenbo Song",
    "Xinxin Fan",
    "Quanliang Jing",
    "Shaoye Luo",
    "Wenqi Wei",
    "Chi Lin",
    "Yunfeng Lu",
    "Ling Liu"
  ],
  "published": "2025-11-27T13:14:42Z",
  "url": "http://arxiv.org/abs/2511.22434v1",
  "pdf_url": "http://arxiv.org/pdf/2511.22434v1.pdf",
  "relevance_score": 82,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "The deep learning (DL) has been penetrating daily life in many domains, how to keep the DL model inference secure and sample privacy in an encrypted environment has become an urgent and increasingly important issue for various security-critical applications. To date, several approaches have been proposed based on the Residue Number System variant of the Cheon-Kim-Kim-Song (RNS-CKKS) scheme. However, they all suffer from high latency, which severely limits the applications in real-world tasks. Cu"
}