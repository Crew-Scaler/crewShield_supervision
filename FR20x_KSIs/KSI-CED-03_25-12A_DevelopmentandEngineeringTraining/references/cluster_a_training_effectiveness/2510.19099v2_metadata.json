{
  "arxiv_id": "2510.19099v2",
  "title": "What Makes a Good Curriculum? Disentangling the Effects of Data Ordering on LLM Mathematical Reasoning",
  "authors": [
    "Yaning Jia",
    "Chunhui Zhang",
    "Xingjian Diao",
    "Xiangchi Yuan",
    "Zhongyu Ouyang",
    "Chiyu Ma",
    "Soroush Vosoughi"
  ],
  "published": "2025-10-21T21:43:38Z",
  "url": "http://arxiv.org/abs/2510.19099v2",
  "pdf_url": "http://arxiv.org/pdf/2510.19099v2.pdf",
  "relevance_score": 88,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Curriculum learning (CL) - ordering training data from easy to hard - has become a popular strategy for improving reasoning in large language models (LLMs). Yet prior work employs disparate difficulty metrics and training setups, leaving open fundamental questions: When does curriculum help? Which direction - forward or reverse - is better? And does the answer depend on what we measure? We address these questions through a unified offline evaluation framework that decomposes curriculum difficult"
}