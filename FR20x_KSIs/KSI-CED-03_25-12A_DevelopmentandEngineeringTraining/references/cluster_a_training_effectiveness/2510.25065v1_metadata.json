{
  "arxiv_id": "2510.25065v1",
  "title": "Reasoning-Aware GRPO using Process Mining",
  "authors": [
    "Taekhyun Park",
    "Yongjae Lee",
    "Hyerim Bae"
  ],
  "published": "2025-10-29T01:07:45Z",
  "url": "http://arxiv.org/abs/2510.25065v1",
  "pdf_url": "http://arxiv.org/pdf/2510.25065v1.pdf",
  "relevance_score": 86,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Reinforcement learning (RL)-based post-training has been crucial for enabling multi-step reasoning in large reasoning models (LRMs), yet current reward schemes are typically outcome-centric. We propose PM4GRPO, a reasoning-aware Group Relative Policy Optimization (GRPO) that augments standard answer/format rewards with signals over the reasoning procedure. To this end, process mining techniques are utilized to compute a scalar conformance reward that measures how closely a policy model's reasoni"
}