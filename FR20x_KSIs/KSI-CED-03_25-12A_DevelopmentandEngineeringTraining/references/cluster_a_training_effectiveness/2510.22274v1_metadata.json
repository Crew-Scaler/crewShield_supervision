{
  "arxiv_id": "2510.22274v1",
  "title": "SecureLearn -- An Attack-agnostic Defense for Multiclass Machine Learning Against Data Poisoning Attacks",
  "authors": [
    "Anum Paracha",
    "Junaid Arshad",
    "Mohamed Ben Farah",
    "Khalid Ismail"
  ],
  "published": "2025-10-25T12:35:45Z",
  "url": "http://arxiv.org/abs/2510.22274v1",
  "pdf_url": "http://arxiv.org/pdf/2510.22274v1.pdf",
  "relevance_score": 89,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Data poisoning attacks are a potential threat to machine learning (ML) models, aiming to manipulate training datasets to disrupt their performance. Existing defenses are mostly designed to mitigate specific poisoning attacks or are aligned with particular ML algorithms. Furthermore, most defenses are developed to secure deep neural networks or binary classifiers. However, traditional multiclass classifiers need attention to be secure from data poisoning attacks, as these models are significant i"
}