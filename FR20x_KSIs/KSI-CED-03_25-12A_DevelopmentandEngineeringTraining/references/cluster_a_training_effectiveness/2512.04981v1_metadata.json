{
  "arxiv_id": "2512.04981v1",
  "title": "Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models",
  "authors": [
    "NaHyeon Park",
    "Namin An",
    "Kunhee Kim",
    "Soyeon Yoon",
    "Jiahao Huo",
    "Hyunjung Shim"
  ],
  "published": "2025-12-04T16:52:45Z",
  "url": "http://arxiv.org/abs/2512.04981v1",
  "pdf_url": "http://arxiv.org/pdf/2512.04981v1.pdf",
  "relevance_score": 62,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Large vision-language model (LVLM) based text-to-image (T2I) systems have become the dominant paradigm in image generation, yet whether they amplify social biases remains insufficiently understood. In this paper, we show that LVLM-based models produce markedly more socially biased images than non-LVLM-based models. We introduce a 1,024 prompt benchmark spanning four levels of linguistic complexity and evaluate demographic bias across multiple attributes in a systematic manner. Our analysis ident"
}