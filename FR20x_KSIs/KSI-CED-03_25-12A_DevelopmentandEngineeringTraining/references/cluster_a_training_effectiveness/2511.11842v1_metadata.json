{
  "arxiv_id": "2511.11842v1",
  "title": "On the Trade-Off Between Transparency and Security in Adversarial Machine Learning",
  "authors": [
    "Lucas Fenaux",
    "Christopher Srinivasa",
    "Florian Kerschbaum"
  ],
  "published": "2025-11-14T20:05:50Z",
  "url": "http://arxiv.org/abs/2511.11842v1",
  "pdf_url": "http://arxiv.org/pdf/2511.11842v1.pdf",
  "relevance_score": 100,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Transparency and security are both central to Responsible AI, but they may conflict in adversarial settings. We investigate the strategic effect of transparency for agents through the lens of transferable adversarial example attacks. In transferable adversarial example attacks, attackers maliciously perturb their inputs using surrogate models to fool a defender's target model. These models can be defended or undefended, with both players having to decide which to use. Using a large-scale empiric"
}