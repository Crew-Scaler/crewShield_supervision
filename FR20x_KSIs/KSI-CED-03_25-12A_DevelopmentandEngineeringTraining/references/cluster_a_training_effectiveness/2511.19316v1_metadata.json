{
  "arxiv_id": "2511.19316v1",
  "title": "Evaluating Dataset Watermarking for Fine-tuning Traceability of Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach",
  "authors": [
    "Xincheng Wang",
    "Hanchi Sun",
    "Wenjun Sun",
    "Kejun Xue",
    "Wangqiu Zhou",
    "Jianbo Zhang",
    "Wei Sun",
    "Dandan Zhu",
    "Xiongkuo Min",
    "Jun Jia",
    "Zhijun Fang"
  ],
  "published": "2025-11-24T17:11:00Z",
  "url": "http://arxiv.org/abs/2511.19316v1",
  "pdf_url": "http://arxiv.org/pdf/2511.19316v1.pdf",
  "relevance_score": 97,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "Recent fine-tuning techniques for diffusion models enable them to reproduce specific image sets, such as particular faces or artistic styles, but also introduce copyright and security risks. Dataset watermarking has been proposed to ensure traceability by embedding imperceptible watermarks into training images, which remain detectable in outputs even after fine-tuning. However, current methods lack a unified evaluation framework. To address this, this paper establishes a general threat model and"
}