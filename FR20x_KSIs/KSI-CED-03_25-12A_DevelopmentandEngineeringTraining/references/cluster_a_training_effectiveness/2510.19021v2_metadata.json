{
  "arxiv_id": "2510.19021v2",
  "title": "Category learning in deep neural networks: Information content and geometry of internal representations",
  "authors": [
    "Laurent Bonnasse-Gahot",
    "Jean-Pierre Nadal"
  ],
  "published": "2025-10-21T19:02:51Z",
  "url": "http://arxiv.org/abs/2510.19021v2",
  "pdf_url": "http://arxiv.org/pdf/2510.19021v2.pdf",
  "relevance_score": 83,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "In humans and other animals, category learning enhances discrimination between stimuli close to the category boundary. This phenomenon, called categorical perception, was also empirically observed in artificial neural networks trained on classification tasks. In previous modeling works based on neuroscience data, we show that this expansion/compression is a necessary outcome of efficient learning. Here we extend our theoretical framework to artificial networks. We show that minimizing the Bayes "
}