{
  "arxiv_id": "2512.05707v1",
  "title": "Evaluating Concept Filtering Defenses against Child Sexual Abuse Material Generation by Text-to-Image Models",
  "authors": [
    "Ana-Maria Cretu",
    "Klim Kireev",
    "Amro Abdalla",
    "Wisdom Obinna",
    "Raphael Meier",
    "Sarah Adel Bargal",
    "Elissa M. Redmiles",
    "Carmela Troncoso"
  ],
  "published": "2025-12-05T13:34:05Z",
  "url": "http://arxiv.org/abs/2512.05707v1",
  "pdf_url": "http://arxiv.org/pdf/2512.05707v1.pdf",
  "relevance_score": 76,
  "dimension": "Training Effectiveness Measurement",
  "cluster": "A",
  "summary": "We evaluate the effectiveness of child filtering to prevent the misuse of text-to-image (T2I) models to create child sexual abuse material (CSAM). First, we capture the complexity of preventing CSAM generation using a game-based security definition. Second, we show that current detection methods cannot remove all children from a dataset. Third, using an ethical proxy for CSAM (a child wearing glasses, hereafter, CWG), we show that even when only a small percentage of child images are left in the"
}