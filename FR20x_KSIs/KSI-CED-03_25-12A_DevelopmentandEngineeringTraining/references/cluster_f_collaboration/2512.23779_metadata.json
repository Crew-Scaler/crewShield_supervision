{
  "arxiv_id": "2512.23779",
  "title": "Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark",
  "authors": [
    "Manu",
    "Yi Guo",
    "Jo Plested",
    "Tim Lynar",
    "Kanchana Thilakarathna",
    "Nirhoshan Sivaroopan",
    "Jack Yang",
    "Wangli Yang"
  ],
  "published": "2025-12-29T13:42:08Z",
  "url": "http://arxiv.org/abs/2512.23779v1",
  "pdf_url": "https://arxiv.org/pdf/2512.23779v1",
  "relevance_score": 90,
  "dimension": "AI Threat Recognition and Incident Response",
  "cluster": "F",
  "summary": "Large language models (LLMs) can be driven into over-generation, emitting thousands of tokens before producing an end-of-sequence (EOS) token. This degrades answer quality, inflates latency and cost, and can be weaponized as a denial-of-service (DoS) attack. Recent work has begun to study DoS-style "
}