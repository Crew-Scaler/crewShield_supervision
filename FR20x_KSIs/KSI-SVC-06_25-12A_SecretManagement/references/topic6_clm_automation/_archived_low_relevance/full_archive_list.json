[
  {
    "title": "RetryGuard: Preventing Self-Inflicted Retry Storms in Cloud Microservices Applications",
    "authors": [
      "Jhonatan Tavori",
      "Anat Bremler-Barr",
      "Hanoch Levy",
      "Ofek Lavi"
    ],
    "published": "2025-11-28T15:31:25Z",
    "abstract": "Modern cloud applications are built on independent, diverse microservices, offering scalability, flexibility, and usage-based billing. However, the structural design of these varied services, along with their reliance on auto-scalers for dynamic internet traffic, introduces significant coordination challenges. As we demonstrate in this paper, common default retry patterns used between misaligned services can turn into retry storms which drive up resource usage and costs, leading to self-inflicted Denial-of-Wallet (DoW) scenarios. To overcome these problems we introduce RetryGuard, a distributed framework for productive control of retry patterns across interdependent microservices. By managing retry policy on a per-service basis and making parallel decisions, RetryGuard prevents retry storms, curbs resource contention, and mitigates escalating operational costs. RetryGuard makes its decisions based on an analytic model that captures the relationships among retries, throughput (rejections), delays, and costs. Experimental results show that RetryGuard significantly reduces resource usage and costs compared to AWS standard and advanced retry policies. We further demonstrate its scalability and superior performance in a more complex Kubernetes deployment with the Istio service mesh, where it achieves substantial improvements.",
    "arxiv_id": "http://arxiv.org/abs/2511.23278v1",
    "pdf_link": "https://arxiv.org/pdf/2511.23278v1",
    "categories": [
      "cs.NI",
      "cs.CR",
      "cs.DC"
    ],
    "affiliation": "N/A",
    "relevance_score": 80
  },
  {
    "title": "Reproducible Builds and Insights from an Independent Verifier for Arch Linux",
    "authors": [
      "Joshua Drexel",
      "Esther Hänggi",
      "Iyán Méndez Veiga"
    ],
    "published": "2025-05-27T18:14:36Z",
    "abstract": "Supply chain attacks have emerged as a prominent cybersecurity threat in recent years. Reproducible and bootstrappable builds have the potential to reduce such attacks significantly. In combination with independent, exhaustive and periodic source code audits, these measures can effectively eradicate compromises in the building process. In this paper we introduce both concepts, we analyze the achievements over the last ten years and explain the remaining challenges. We contribute to the reproducible builds effort by setting up a rebuilder and verifier instance to test the reproducibility of Arch Linux packages. Using the results from this instance, we uncover an unnoticed and security-relevant packaging issue affecting 16 packages related to Certbot, the recommended software to install TLS certificates from Let's Encrypt, making them unreproducible. Additionally, we find the root cause of unreproduciblity in the source code of fwupd, a critical software used to update device firmware on Linux devices, and submit an upstream patch to fix it.",
    "arxiv_id": "http://arxiv.org/abs/2505.21642v1",
    "pdf_link": "https://arxiv.org/pdf/2505.21642v1",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 75
  },
  {
    "title": "Q-RAN: Quantum-Resilient O-RAN Architecture",
    "authors": [
      "Vipin Rathi",
      "Lakshya Chopra",
      "Madhav Agarwal",
      "Nitin Rajput",
      "Kriish Sharma",
      "Sushant Mundepi",
      "Shivam Gangwar",
      "Rudraksh Rawal",
      "Jishan"
    ],
    "published": "2025-10-22T18:57:44Z",
    "abstract": "The telecommunications industry faces a dual transformation: the architectural shift toward Open Radio Access Networks (O-RAN) and the emerging threat from quantum computing. O-RAN disaggregated, multi-vendor architecture creates a larger attack surface vulnerable to crypt-analytically relevant quantum computers(CRQCs) that will break current public key cryptography. The Harvest Now, Decrypt Later (HNDL) attack strategy makes this threat immediate, as adversaries can intercept encrypted data today for future decryption. This paper presents Q-RAN, a comprehensive quantum-resistant security framework for O-RAN networks using NIST-standardized Post-Quantum Cryptography (PQC). We detail the implementation of ML-KEM (FIPS 203) and ML-DSA (FIPS 204), integrated with Quantum Random Number Generators (QRNG) for cryptographic entropy. The solution deploys PQ-IPsec, PQ-DTLS, and PQ-mTLS protocols across all O-RAN interfaces, anchored by a centralized Post-Quantum Certificate Authority (PQ-CA) within the SMO framework. This work provides a complete roadmap for securing disaggregated O-RAN ecosystems against quantum adversaries.",
    "arxiv_id": "http://arxiv.org/abs/2510.19968v1",
    "pdf_link": "https://arxiv.org/pdf/2510.19968v1",
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.NI"
    ],
    "affiliation": "N/A",
    "relevance_score": 70
  },
  {
    "title": "SafeTree: Expressive Tree Policies for Microservices",
    "authors": [
      "Karuna Grewal",
      "P. Brighten Godfrey",
      "Justin Hsu"
    ],
    "published": "2025-08-22T18:57:16Z",
    "abstract": "A microservice-based application is composed of multiple self-contained components called microservices, and controlling inter-service communication is important for enforcing safety properties. Presently, inter-service communication is configured using microservice deployment tools. However, such tools only support a limited class of single-hop policies, which can be overly permissive because they ignore the rich service tree structure of microservice calls. Policies that can express the service tree structure can offer development and security teams more fine-grained control over communication patterns.   To this end, we design an expressive policy language to specify service tree structures, and we develop a visibly pushdown automata-based dynamic enforcement mechanism to enforce service tree policies. Our technique is non-invasive: it does not require any changes to service implementations, and does not require access to microservice code. To realize our method, we build a runtime monitor on top of a service mesh, an emerging network infrastructure layer that can control inter-service communication during deployment. In particular, we employ the programmable network traffic filtering capabilities of Istio, a popular service mesh implementation, to implement an online and distributed monitor. Our experiments show that our monitor can enforce rich safety properties while adding minimal latency overhead on the order of milliseconds.",
    "arxiv_id": "http://arxiv.org/abs/2508.16746v1",
    "pdf_link": "https://arxiv.org/pdf/2508.16746v1",
    "categories": [
      "cs.PL"
    ],
    "affiliation": "N/A",
    "relevance_score": 65
  },
  {
    "title": "Post-Quantum Cryptography and Quantum-Safe Security: A Comprehensive Survey",
    "authors": [
      "Gaurab Chhetri",
      "Shriyank Somvanshi",
      "Pavan Hebli",
      "Shamyo Brotee",
      "Subasish Das"
    ],
    "published": "2025-10-12T04:00:01Z",
    "abstract": "Post-quantum cryptography (PQC) is moving from evaluation to deployment as NIST finalizes standards for ML-KEM, ML-DSA, and SLH-DSA. This survey maps the space from foundations to practice. We first develop a taxonomy across lattice-, code-, hash-, multivariate-, isogeny-, and MPC-in-the-Head families, summarizing security assumptions, cryptanalysis, and standardization status. We then compare performance and communication costs using representative, implementation-grounded measurements, and review hardware acceleration (AVX2, FPGA/ASIC) and implementation security with a focus on side-channel resistance. Building upward, we examine protocol integration (TLS, DNSSEC), PKI and certificate hygiene, and deployment in constrained and high-assurance environments (IoT, cloud, finance, blockchain). We also discuss complementarity with quantum technologies (QKD, QRNGs) and the limits of near-term quantum computing. Throughout, we emphasize crypto-agility, hybrid migration, and evidence-based guidance for operators. We conclude with open problems spanning parameter agility, leakage-resilient implementations, and domain-specific rollout playbooks. This survey aims to be a practical reference for researchers and practitioners planning quantum-safe systems, bridging standards, engineering, and operations.",
    "arxiv_id": "http://arxiv.org/abs/2510.10436v1",
    "pdf_link": "https://arxiv.org/pdf/2510.10436v1",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 65
  },
  {
    "title": "Fine-grained CDN Delegation",
    "authors": [
      "Ethan Thompson",
      "Ali Sadeghi Jahromi",
      "AbdelRahman Abdou"
    ],
    "published": "2025-10-11T03:24:29Z",
    "abstract": "The use of Content Delivery Networks (CDNs) has significantly increased over the past decade, with approximately 55 million websites currently relying on CDN services. Emerging solutions, such as Delegated Credentials (RFC 9345), lack fine-grained definitions of many critical aspects of delegation, such as the length of delegation chains, revocation mechanism, permitted operations, and a well-defined scope for said delegation. We present Delegation Certificates (DeCerts), which modify X.509 certificate standard and add new extensions to enable fine-grained CDN delegation. DeCerts allow domain owners to specify delegated and non-delegated subdomains, and control the depth of delegation extended by CDNs, which provides flexibility in delegation management. But more importantly, DeCerts are built on a new principle which provides full autonomy to domain owners-domain owners can issue DeCerts fully independent of Certificate Authorities (CAs), and thus have greater flexibility in policy control, including revocation methods. Such level of flexibility would be hard to match if CAs where to issue such certificates. Revoking a DeCert revokes delegation. We discuss multiple revocation mechanisms for a DeCerts balancing security, performance, and delegator control. We modify Firefox to support DeCert (i.e., proper validation) as a proof-of-concept, and test it to demonstrate the feasibility, compatibility of DeCerts with browsers and TLS/HTTPS protocols. DeCerts enhance the security, scalability, and manageability of CDN delegation, offering a practical solution for Internet services.",
    "arxiv_id": "http://arxiv.org/abs/2510.09983v1",
    "pdf_link": "https://arxiv.org/pdf/2510.09983v1",
    "categories": [
      "cs.NI"
    ],
    "affiliation": "N/A",
    "relevance_score": 60
  },
  {
    "title": "Secure Command, Control and Communications Systems (C3) for Army UxVs",
    "authors": [
      "T. Rebolo",
      "A. Grilo",
      "C. Ribeiro"
    ],
    "published": "2025-11-26T21:53:17Z",
    "abstract": "Unmanned Vehicles (UxVs) are increasingly used in modern military operations for reconnaissance, surveillance, and strike missions, enhancing situational awareness while reducing risk to personnel. Their affordability and rapid deployment have encouraged the adoption of commercial solutions. However, many rely on insecure protocols such as MAVLink, which lack authentication and encryption mechanisms. This paper designed, implemented, and evaluated a new secure command-and-control architecture that ensures confidentiality, integrity, and authentication (CIA) while supporting real-time control delegation between Ground Control Stations (GCSs). The proposed solution, named New Command and Control System (NC2S), enforces a zero-trust model integrating hierarchical credential-based privileges to regulate access and control among Tactical Commanders (TC), GCSs, and UxVs. It employs mutual Transport Layer Security (mTLS) with Elliptic Curve Digital Signature Algorithm (ECDSA) certificates and Elliptic Curve Diffie-Hellman (ECDH) key exchange, while message integrity is ensured through Hash-based Message Authentication Codes (HMAC). Multiple lightweight protocols were developed for credential management, key renewal, and control handover. The NC2S prototype was experimentally validated over Wi-Fi and Rohde&Schwarz HR-5000H tactical radios. Results showed that HR-5000H links introduce latencies roughly two orders of magnitude higher than broadband technologies (e.g., Wi-Fi or 5G&Beyond technologies) but are still able to maintain stable communication with minimal message loss, making them suitable for the NC2S links among TC terminals and GCSs.",
    "arxiv_id": "http://arxiv.org/abs/2511.21936v1",
    "pdf_link": "https://arxiv.org/pdf/2511.21936v1",
    "categories": [
      "cs.NI",
      "eess.SY"
    ],
    "affiliation": "N/A",
    "relevance_score": 60
  },
  {
    "title": "Hard-Earned Lessons in Access Control at Scale: Enforcing Identity and Policy Across Trust Boundaries with Reverse Proxies and mTLS",
    "authors": [
      "Sanjay Singh",
      "Mitendra Mahto"
    ],
    "published": "2025-08-03T17:32:11Z",
    "abstract": "In today's enterprise environment, traditional access methods such as Virtual Private Networks (VPNs) and application-specific Single Sign-On (SSO) often fall short when it comes to securely scaling access for a distributed and dynamic workforce. This paper presents our experience implementing a modern, Zero Trust-aligned architecture that leverages a reverse proxy integrated with Mutual TLS (mTLS) and centralized SSO, along with the key challenges we encountered and lessons learned during its deployment and scaling. This multidimensional solution involves both per-device and per-user authentication, centralized enforcement of security policies, and comprehensive observability, hence enabling organizations to deliver secure and seamless access to their internal applications.",
    "arxiv_id": "http://arxiv.org/abs/2508.01863v1",
    "pdf_link": "https://arxiv.org/pdf/2508.01863v1",
    "categories": [
      "cs.CR",
      "cs.NI",
      "cs.SE"
    ],
    "affiliation": "N/A",
    "relevance_score": 60
  },
  {
    "title": "ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh",
    "authors": [
      "Ahsan Farabi",
      "Israt Khandaker",
      "Jayed Ahsan",
      "Ibrahim Khalil Shanto",
      "Nusrat Jahan",
      "Md Jarif Khan"
    ],
    "published": "2025-08-07T12:35:12Z",
    "abstract": "Academic credential fraud threatens educational integrity, especially in developing countries like Bangladesh, where verification methods are primarily manual and inefficient. To address this challenge, we present ShikkhaChain, a blockchain-powered certificate management platform designed to securely issue, verify, and revoke academic credentials in a decentralized and tamper-proof manner. Built on Ethereum smart contracts and utilizing IPFS for off-chain storage, the platform offers a transparent, scalable solution accessible through a React-based DApp with MetaMask integration. ShikkhaChain enables role-based access for governments, regulators, institutions, and public verifiers, allowing QR-based validation and on-chain revocation tracking. Our prototype demonstrates enhanced trust, reduced verification time, and improved international credibility for Bangladeshi degrees, promoting a more reliable academic and employment ecosystem.",
    "arxiv_id": "http://arxiv.org/abs/2508.05334v2",
    "pdf_link": "https://arxiv.org/pdf/2508.05334v2",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 55
  },
  {
    "title": "Upgrade or Switch: Do We Need a Next-Gen Trusted Architecture for the Internet of AI Agents?",
    "authors": [
      "Ramesh Raskar",
      "Pradyumna Chari",
      "Jared James Grogan",
      "Mahesh Lambe",
      "Robert Lincourt",
      "Raghu Bala",
      "Aditi Joshi",
      "Abhishek Singh",
      "Ayush Chopra",
      "Rajesh Ranjan",
      "Shailja Gupta",
      "Dimitris Stripelis",
      "Maria Gorskikh",
      "Sichao Wang"
    ],
    "published": "2025-06-13T17:55:38Z",
    "abstract": "The emerging Internet of AI Agents challenges existing web infrastructure designed for human-scale, reactive interactions. Unlike traditional web resources, autonomous AI agents initiate actions, maintain persistent state, spawn sub-agents, and negotiate directly with peers: demanding millisecond-level discovery, instant credential revocation, and cryptographic behavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes whether to upgrade existing infrastructure or implement purpose-built index architectures for autonomous agents. We identify critical failure points: DNS propagation (24-48 hours vs. required milliseconds), certificate revocation unable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate for agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2) Switch options, (3) Hybrid index/registries. Drawing parallels to dialup-to-broadband transitions, we find that agent requirements constitute qualitative, and not incremental, changes. While upgrades offer compatibility and faster deployment, clean-slate solutions provide better performance but require longer for adoption. Our analysis suggests hybrid approaches will emerge, with centralized indexes for critical agents and federated meshes for specialized use cases.",
    "arxiv_id": "http://arxiv.org/abs/2506.12003v2",
    "pdf_link": "https://arxiv.org/pdf/2506.12003v2",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.MA"
    ],
    "affiliation": "N/A",
    "relevance_score": 55
  },
  {
    "title": "Network Hexagons Under Attack: Secure Crowdsourcing of Geo-Referenced Data",
    "authors": [
      "Okemawo Obadofin",
      "Joao Barros"
    ],
    "published": "2025-06-05T21:27:10Z",
    "abstract": "A critical requirement for modern-day Intelligent Transportation Systems (ITS) is the ability to collect geo-referenced data from connected vehicles and mobile devices in a safe, secure and anonymous way. The Nexagon protocol, which builds on the IETF Locator/ID Separation Protocol (LISP) and the Hierarchical Hexagonal Clustering (H3) geo-spatial indexing system, offers a promising framework for dynamic, privacy-preserving data aggregation. Seeking to address the critical security and privacy vulnerabilities that persist in its current specification, we apply the STRIDE and LINDDUN threat modelling frameworks and prove among other that the Nexagon protocol is susceptible to user re-identification, session linkage, and sparse-region attacks. To address these challenges, we propose an enhanced security architecture that combines public key infrastructure (PKI) with ephemeral pseudonym certificates. Our solution guarantees user and device anonymity through randomized key rotation and adaptive geospatial resolution, thereby effectively mitigating re-identification and surveillance risks in sparse environments. A prototype implementation over a microservice-based overlay network validates the approach and underscores its readiness for real-world deployment. Our results show that it is possible to achieve the required level of security without increasing latency by more than 25% or reducing the throughput by more than 7%.",
    "arxiv_id": "http://arxiv.org/abs/2506.05601v1",
    "pdf_link": "https://arxiv.org/pdf/2506.05601v1",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "affiliation": "N/A",
    "relevance_score": 55
  },
  {
    "title": "Analysis of the Security Design, Engineering, and Implementation of the SecureDNA System",
    "authors": [
      "Alan T. Sherman",
      "Jeremy J. Romanik Romano",
      "Edward Zieglar",
      "Enis Golaszewski",
      "Jonathan D. Fuchs",
      "William E. Byrd"
    ],
    "published": "2025-12-10T01:39:52Z",
    "abstract": "We analyze security aspects of the SecureDNA system regarding its system design, engineering, and implementation. This system enables DNA synthesizers to screen order requests against a database of hazards. By applying novel cryptography, the system aims to keep order requests and the database of hazards secret. Discerning the detailed operation of the system in part from source code (Version 1.0.8), our analysis examines key management, certificate infrastructure, authentication, and rate-limiting mechanisms. We also perform the first formal-methods analysis of the mutual authentication, basic request, and exemption-handling protocols.   Without breaking the cryptography, our main finding is that SecureDNA's custom mutual authentication protocol SCEP achieves only one-way authentication: the hazards database and keyservers never learn with whom they communicate. This structural weakness violates the principle of defense in depth and enables an adversary to circumvent rate limits that protect the secrecy of the hazards database, if the synthesizer connects with a malicious or corrupted keyserver or hashed database. We point out an additional structural weakness that also violates the principle of defense in depth: inadequate cryptographic bindings prevent the system from detecting if responses, within a TLS channel, from the hazards database were modified. Consequently, if a synthesizer were to reconnect with the database over the same TLS session, an adversary could replay and swap responses from the database without breaking TLS. Although the SecureDNA implementation does not allow such reconnections, it would be stronger security engineering to avoid the underlying structural weakness. We identify these vulnerabilities and suggest and verify mitigations, including adding strong bindings. Software Version 1.1.0 fixes SCEP with our proposed SCEP+ protocol.",
    "arxiv_id": "http://arxiv.org/abs/2512.09233v1",
    "pdf_link": "https://arxiv.org/pdf/2512.09233v1",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 55
  },
  {
    "title": "Towards a Decentralized IoT Onboarding for Smart Homes Using Consortium Blockchain",
    "authors": [
      "Narges Dadkhah",
      "Khan Reaz",
      "Gerhard Wunder"
    ],
    "published": "2025-08-29T10:05:22Z",
    "abstract": "The increasing adoption of smart home devices and IoT-based security systems presents significant opportunities to enhance convenience, safety, and risk management for homeowners and service providers. However, secure onboarding-provisioning credentials and establishing trust with cloud platforms-remains a considerable challenge. Traditional onboarding methods often rely on centralized Public Key Infrastructure (PKI) models and manufacturer-controlled keys, which introduce security risks and limit the user's digital sovereignty. These limitations hinder the widespread deployment of scalable IoT solutions. This paper presents a novel onboarding framework that builds upon existing network-layer onboarding techniques and extends them to the application layer to address these challenges. By integrating consortium blockchain technology, we propose a decentralized onboarding mechanism that enhances transparency, security, and monitoring for smart home architectures. The architecture supports device registration, key revocation, access control management, and risk detection through event-driven alerts across dedicated blockchain channels and smart contracts. To evaluate the framework, we formally model the protocol using the Tamarin Prover under the Dolev-Yao adversary model. The analysis focuses on authentication, token integrity, key confidentiality, and resilience over public channels. A prototype implementation demonstrates the system's viability in smart home settings, with verification completing in 0.34 seconds, highlighting its scalability and suitability for constrained devices and diverse stakeholders. Additionally, performance evaluation shows that the blockchain-based approach effectively handles varying workloads, maintains high throughput and low latency, and supports near real-time IoT data processing.",
    "arxiv_id": "http://arxiv.org/abs/2508.21480v1",
    "pdf_link": "https://arxiv.org/pdf/2508.21480v1",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "affiliation": "N/A",
    "relevance_score": 55
  },
  {
    "title": "Context Lineage Assurance for Non-Human Identities in Critical Multi-Agent Systems",
    "authors": [
      "Sumana Malkapuram",
      "Sameera Gangavarapu",
      "Kailashnath Reddy Kavalakuntla",
      "Ananya Gangavarapu"
    ],
    "published": "2025-09-22T20:59:51Z",
    "abstract": "The proliferation of autonomous software agents necessitates rigorous frameworks for establishing secure and verifiable agent-to-agent (A2A) interactions, particularly when such agents are instantiated as non-human identities(NHIs). We extend the A2A paradigm [1 , 2] by introducing a cryptographically grounded mechanism for lineage verification, wherein the provenance and evolution of NHIs are anchored in append-only Merkle tree structures modeled after Certificate Transparency (CT) logs. Unlike traditional A2A models that primarily secure point-to-point interactions, our approach enables both agents and external verifiers to cryptographically validate multi-hop provenance, thereby ensuring the integrity of the entire call chain.   A federated proof server acts as an auditor across one or more Merkle logs, aggregating inclusion proofs and consistency checks into compact, signed attestations that external parties can verify without access to the full execution trace. In parallel, we augment the A2A agent card to incorporate explicit identity verification primitives, enabling both peer agents and human approvers to authenticate the legitimacy of NHI representations in a standardized manner. Together, these contributions establish a cohesive model that integrates identity attestation, lineage verification, and independent proof auditing, thereby advancing the security posture of inter-agent ecosystems and providing a foundation for robust governance of NHIs in regulated environments such as FedRAMP.",
    "arxiv_id": "http://arxiv.org/abs/2509.18415v1",
    "pdf_link": "https://arxiv.org/pdf/2509.18415v1",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 55
  },
  {
    "title": "A Login Page Transparency and Visual Similarity Based Zero Day Phishing Defense Protocol",
    "authors": [
      "Gaurav Varshney",
      "Akanksha Raj",
      "Divya Sangwan",
      "Sharif Abuadbba",
      "Rina Mishra",
      "Yansong Gao"
    ],
    "published": "2025-07-13T10:15:36Z",
    "abstract": "Phishing is a prevalent cyberattack that uses look-alike websites to deceive users into revealing sensitive information. Numerous efforts have been made by the Internet community and security organizations to detect, prevent, or train users to avoid falling victim to phishing attacks. Most of this research over the years has been highly diverse and application-oriented, often serving as standalone solutions for HTTP clients, servers, or third parties. However, limited work has been done to develop a comprehensive or proactive protocol-oriented solution to effectively counter phishing attacks. Inspired by the concept of certificate transparency, which allows certificates issued by Certificate Authorities (CAs) to be publicly verified by clients, thereby enhancing transparency, we propose a concept called Page Transparency (PT) for the web. The proposed PT requires login pages that capture users' sensitive information to be publicly logged via PLS and made available to web clients for verification. The pages are verified to be logged using cryptographic proofs. Since all pages are logged on a PLS and visually compared with existing pages through a comprehensive visual page-matching algorithm, it becomes impossible for an attacker to register a deceptive look-alike page on the PLS and receive the cryptographic proof required for client verification. All implementations occur on the client side, facilitated by the introduction of a new HTTP PT header, eliminating the need for platform-specific changes or the installation of third-party solutions for phishing prevention.",
    "arxiv_id": "http://arxiv.org/abs/2507.09564v1",
    "pdf_link": "https://arxiv.org/pdf/2507.09564v1",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 55
  },
  {
    "title": "Pruning the Tree: Rethinking RPKI Architecture From The Ground Up",
    "authors": [
      "Haya Schulmann",
      "Niklas Vogel"
    ],
    "published": "2025-07-02T08:24:50Z",
    "abstract": "Resource Public Key Infrastructure (RPKI) is a critical security mechanism for BGP, but the complexity of its architecture is a growing concern as its adoption scales. Current RPKI design heavily reuses legacy PKI components, such as X.509 EE-certificates, ASN.1 encoding, and XML-based repository protocols, which introduce excessive cryptographic validation, redundant metadata, and inefficiencies in both storage and processing. We show that these design choices, although based on established standards, create significant performance bottlenecks, increase the vulnerability surface, and hinder scalability for wide-scale Internet deployment.   In this paper, we perform the first systematic analysis of the root causes of complexity in RPKI's design and experimentally quantify their real-world impact. We show that over 70\\% of validation time in RPKI relying parties is spent on certificate parsing and signature verification, much of it unnecessary. Building on this insight, we introduce the improved RPKI (iRPKI), a backwards-compatible redesign that preserves all security guarantees while substantially reducing protocol overhead. iRPKI eliminates EE-certificates and ROA signatures, merges revocation and integrity objects, replaces verbose encodings with Protobuf, and restructures repository metadata for more efficient access. We experimentally demonstrate that our implementation of iRPKI in the Routinator validator achieves a 20x speed-up of processing time, 18x improvement of bandwidth requirements and 8x reduction in cache memory footprint, while also eliminating classes of vulnerabilities that have led to at least 10 vulnerabilities in RPKI software. iRPKI significantly increases the feasibility of deploying RPKI at scale in the Internet, and especially in constrained environments. Our design may be deployed incrementally without impacting existing operations.",
    "arxiv_id": "http://arxiv.org/abs/2507.01465v2",
    "pdf_link": "https://arxiv.org/pdf/2507.01465v2",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 50
  },
  {
    "title": "Overcoming DNSSEC Islands of Security: A TLS and IP-Based Certificate Solution",
    "authors": [
      "Aduma Rishith",
      "Aditya Kulkarni",
      "Tamal Das",
      "Vivek Balachandran"
    ],
    "published": "2025-09-10T08:02:07Z",
    "abstract": "The Domain Name System (DNS) serves as the backbone of the Internet, primarily translating domain names to IP addresses. Over time, various enhancements have been introduced to strengthen the integrity of DNS. Among these, DNSSEC stands out as a leading cryptographic solution. It protects against attacks (such as DNS spoofing) by establishing a chain of trust throughout the DNS nameserver hierarchy. However, DNSSEC's effectiveness is compromised when there is a break in this chain, resulting in \"Islands of Security\", where domains can authenticate locally but not across hierarchical levels, leading to a loss of trust and validation between them. Leading approaches to addressing these issues were centralized, with a single authority maintaining some kind of bulletin board. This approach requires significantly more infrastructure and places excessive trust in the entity responsible for managing it properly. In this paper, we propose a decentralized approach to addressing gaps in DNSSEC's chain of trust, commonly referred to as \"Islands of Security\". We leverage TLS and IP-based certificates to enable end-to-end authentication between hierarchical levels, eliminating the need for uniform DNSSEC deployment across every level of the DNS hierarchy. This approach enhances the overall integrity of DNSSEC, while reducing dependence on registrars for maintaining signature records to verify the child nameserver's authenticity. By offering a more flexible and efficient solution, our method strengthens DNS security and streamlines deployment across diverse environments.",
    "arxiv_id": "http://arxiv.org/abs/2509.08364v2",
    "pdf_link": "https://arxiv.org/pdf/2509.08364v2",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 50
  },
  {
    "title": "Bidirectional TLS Handshake Caching for Constrained Industrial IoT Scenarios",
    "authors": [
      "Jörn Bodenhausen",
      "Simon Mangel",
      "Thomas Vogt",
      "Martin Henze"
    ],
    "published": "2025-08-05T11:00:41Z",
    "abstract": "While TLS has become the de-facto standard for end-to-end security, its use to secure critical communication in evolving industrial IoT scenarios is severely limited by prevalent resource constraints of devices and networks. Most notably, the TLS handshake to establish secure connections incurs significant bandwidth and processing overhead that often cannot be handled in constrained environments. To alleviate this situation, we present BiTHaC which realizes bidirectional TLS handshake caching by exploiting that significant parts of repeated TLS handshakes, especially certificates, are static. Thus, redundant information neither needs to be transmitted nor corresponding computations performed, saving valuable bandwidth and processing resources. By implementing BiTHaC for wolfSSL, we show that we can reduce the bandwidth consumption of TLS handshakes by up to 61.1% and the computational overhead by up to 8.5%, while incurring only well-manageable memory overhead and preserving the strict security guarantees of TLS.",
    "arxiv_id": "http://arxiv.org/abs/2508.03321v1",
    "pdf_link": "https://arxiv.org/pdf/2508.03321v1",
    "categories": [
      "cs.NI",
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 50
  },
  {
    "title": "A Comprehensive Framework for Building Highly Secure, Network-Connected Devices: Chip to App",
    "authors": [
      "Khan Reaz",
      "Gerhard Wunder"
    ],
    "published": "2025-01-23T14:44:34Z",
    "abstract": "The rapid expansion of connected devices has amplified the need for robust and scalable security frameworks. This paper proposes a holistic approach to securing network-connected devices, covering essential layers: hardware, firmware, communication, and application. At the hardware level, we focus on secure key management, reliable random number generation, and protecting critical assets. Firmware security is addressed through mechanisms like cryptographic integrity validation and secure boot processes. For secure communication, we emphasize TLS 1.3 and optimized cipher suites tailored for both standard and resource-constrained devices. To overcome the challenges of IoT, compact digital certificates, such as CBOR, are recommended to reduce overhead and enhance performance. Additionally, the paper explores forward-looking solutions, including post-quantum cryptography, to future-proof systems against emerging threats. This framework provides actionable guidelines for manufacturers and system administrators to build secure devices that maintain confidentiality, integrity, and availability throughout their lifecycle.",
    "arxiv_id": "http://arxiv.org/abs/2501.13716v1",
    "pdf_link": "https://arxiv.org/pdf/2501.13716v1",
    "categories": [
      "cs.NI",
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 50
  },
  {
    "title": "An Efficient TLS 1.3 Handshake Protocol with VC Certificate Type",
    "authors": [
      "Leonardo Perugini",
      "Andrea Vesco"
    ],
    "published": "2024-07-17T13:18:16Z",
    "abstract": "The paper presents a step forward in the design and implementation of a Transport Layer Security (TLS) handshake protocol that enables the use of Verifiable Credential (VC) while maintaining full compliance with RFC-8446 and preserving all the security features of TLS 1.3. The improvement over our previous work lies in the handshake design, which now only uses messages already defined for TLS 1.3. The design has an incredibly positive impact on the implementation, as we made minimal changes to the OpenSSL library and relied mostly on a novel external provider to handle VC and Decentralized IDentifier (DID) related operations. The experimental results prove the feasibility of the design and show comparable performance to the original solution based on Public Key Infrastructure (PKI) and X.509 certificates. These results pave the way for the adoption of Self-Sovereign Identity in large-scale Internet of Things (IoT) systems, with a clear benefit in terms of reducing the cost of identity management.",
    "arxiv_id": "http://arxiv.org/abs/2407.12536v3",
    "pdf_link": "https://arxiv.org/pdf/2407.12536v3",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 50
  },
  {
    "title": "Decentralized PKI Framework for Data Integrity in Spatial Crowdsourcing Drone Services",
    "authors": [
      "Junaid Akram",
      "Ali Anaissi"
    ],
    "published": "2024-07-01T00:55:07Z",
    "abstract": "In the domain of spatial crowdsourcing drone services, which includes tasks like delivery, surveillance, and data collection, secure communication is paramount. The Public Key Infrastructure (PKI) ensures this by providing a system for digital certificates that authenticate the identities of entities involved, securing data and command transmissions between drones and their operators. However, the centralized trust model of traditional PKI, dependent on Certificate Authorities (CAs), presents a vulnerability due to its single point of failure, risking security breaches. To counteract this, the paper presents D2XChain, a blockchain-based PKI framework designed for the Internet of Drone Things (IoDT). By decentralizing the CA infrastructure, D2XChain eliminates this single point of failure, thereby enhancing the security and reliability of drone communications. Fully compatible with the X.509 standard, it integrates seamlessly with existing PKI systems, supporting all key operations such as certificate registration, validation, verification, and revocation in a distributed manner. This innovative approach not only strengthens the defense of drone services against various security threats but also showcases its practical application through deployment on a private Ethereum testbed, representing a significant advancement in addressing the unique security challenges of drone-based services and ensuring their trustworthy operation in critical tasks.",
    "arxiv_id": "http://arxiv.org/abs/2407.00876v1",
    "pdf_link": "https://arxiv.org/pdf/2407.00876v1",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 45
  },
  {
    "title": "eSapiens's DEREK Module: Deep Extraction & Reasoning Engine for Knowledge with LLMs",
    "authors": [
      "Isaac Shi",
      "Zeyuan Li",
      "Fan Liu",
      "Wenli Wang",
      "Lewei He",
      "Yang Yang",
      "Tianyu Shi"
    ],
    "published": "2025-07-13T05:54:01Z",
    "abstract": "We present the DEREK (Deep Extraction & Reasoning Engine for Knowledge) Module, a secure and scalable Retrieval-Augmented Generation pipeline designed specifically for enterprise document question answering. Designed and implemented by eSapiens, the system ingests heterogeneous content (PDF, Office, web), splits it into 1,000-token overlapping chunks, and indexes them in a hybrid HNSW+BM25 store. User queries are refined by GPT-4o, retrieved via combined vector+BM25 search, reranked with Cohere, and answered by an LLM using CO-STAR prompt engineering. A LangGraph verifier enforces citation overlap, regenerating answers until every claim is grounded. On four LegalBench subsets, 1000-token chunks improve Recall@50 by approximately 1 pp and hybrid+rerank boosts Precision@10 by approximately 7 pp; the verifier raises TRACe Utilization above 0.50 and limits unsupported statements to less than 3%. All components run in containers, enforce end-to-end TLS 1.3 and AES-256. These results demonstrate that the DEREK module delivers accurate, traceable, and production-ready document QA with minimal operational overhead. The module is designed to meet enterprise demands for secure, auditable, and context-faithful retrieval, providing a reliable baseline for high-stakes domains such as legal and finance.",
    "arxiv_id": "http://arxiv.org/abs/2507.15863v1",
    "pdf_link": "https://arxiv.org/pdf/2507.15863v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 45
  },
  {
    "title": "Managed TLS Under Migration: Authentication Authority Across CDN and Hosting Transitions",
    "authors": [
      "Daniyal Ganiuly",
      "Nurzhau Bolatbek",
      "Assel Smaiyl"
    ],
    "published": "2025-12-07T22:52:52Z",
    "abstract": "Managed TLS has become a common approach for deploying HTTPS, with platforms generating and storing private keys and automating certificate issuance on behalf of domain operators. This model simplifies operational management but shifts control of authentication material from the domain owner to the platform. The implications of this shift during provider transitions remain insufficiently examined. This study investigates how managed TLS platforms behave when a domain is moved away from the platform that originally issued and stored its certificate. A controlled measurement environment was used to monitor multiple platforms after migration. Each platform was observed for the full remaining lifetime of the certificate that had been active during delegation. The measurements show that platforms continue to serve the same certificate until it expires, even after DNS resolvers direct traffic toward new infrastructure. No platform revoked, replaced, or retired the certificate, and no new certificate was issued after delegation ended. Direct connections to the previous platform continued to complete TLS handshakes with the stale certificate, which confirms that authentication capability persisted independently of DNS state. These findings indicate that authentication authority remains with the previous platform for the entire lifetime of certificates issued during the delegation period. The gap between DNS control and control of authentication material introduces a window in which multiple environments can authenticate the same domain. As managed TLS adoption grows, clearer mechanisms for key retirement and certificate invalidation are needed to ensure that the authentication authority follows operational authority during transitions.",
    "arxiv_id": "http://arxiv.org/abs/2512.07033v1",
    "pdf_link": "https://arxiv.org/pdf/2512.07033v1",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "affiliation": "N/A",
    "relevance_score": 45
  },
  {
    "title": "Locating and Mitigating Gradient Conflicts in Point Cloud Domain Adaptation via Saliency Map Skewness",
    "authors": [
      "Jiaqi Tang",
      "Yinsong Xu",
      "Qingchao Chen"
    ],
    "published": "2025-04-22T11:16:19Z",
    "abstract": "Object classification models utilizing point cloud data are fundamental for 3D media understanding, yet they often struggle with unseen or out-of-distribution (OOD) scenarios. Existing point cloud unsupervised domain adaptation (UDA) methods typically employ a multi-task learning (MTL) framework that combines primary classification tasks with auxiliary self-supervision tasks to bridge the gap between cross-domain feature distributions. However, our further experiments demonstrate that not all gradients from self-supervision tasks are beneficial and some may negatively impact the classification performance. In this paper, we propose a novel solution, termed Saliency Map-based Data Sampling Block (SM-DSB), to mitigate these gradient conflicts. Specifically, our method designs a new scoring mechanism based on the skewness of 3D saliency maps to estimate gradient conflicts without requiring target labels. Leveraging this, we develop a sample selection strategy that dynamically filters out samples whose self-supervision gradients are not beneficial for the classification. Our approach is scalable, introducing modest computational overhead, and can be integrated into all the point cloud UDA MTL frameworks. Extensive evaluations demonstrate that our method outperforms state-of-the-art approaches. In addition, we provide a new perspective on understanding the UDA problem through back-propagation analysis.",
    "arxiv_id": "http://arxiv.org/abs/2504.15796v1",
    "pdf_link": "https://arxiv.org/pdf/2504.15796v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 40
  },
  {
    "title": "CRSet: Private Non-Interactive Verifiable Credential Revocation",
    "authors": [
      "Felix Hoops",
      "Jonas Gebele",
      "Florian Matthes"
    ],
    "published": "2025-01-28T17:23:45Z",
    "abstract": "Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases because they may leak the issuer's activity, which in turn leaks internal business metrics. For instance, staff fluctuation through the revocation of employee IDs. We identify the protection of issuer activity as a key gap and propose a formal definition for a corresponding characteristic of a revocation mechanism. Then, we introduce CRSet, a non-interactive mechanism that trades some space efficiency to reach these privacy characteristics. For that, we provide a proof sketch. Issuers periodically encode revocation data and publish it via Ethereum blob-carrying transactions, ensuring secure and private availability. Relying Parties (RPs) can download it to perform revocation checks locally. Sticking to a non-interactive design also makes adoption easier because it requires no changes to wallet agents and exchange protocols. We also implement and empirically evaluate CRSet, finding its real-world behavior to match expectations. One Ethereum blob fits revocation data for about 170k VCs.",
    "arxiv_id": "http://arxiv.org/abs/2501.17089v3",
    "pdf_link": "https://arxiv.org/pdf/2501.17089v3",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "Two Birds with One Stone: Multi-Task Detection and Attribution of LLM-Generated Text",
    "authors": [
      "Zixin Rao",
      "Youssef Mohamed",
      "Shang Liu",
      "Zeyan Liu"
    ],
    "published": "2025-08-19T18:23:30Z",
    "abstract": "Large Language Models (LLMs), such as GPT-4 and Llama, have demonstrated remarkable abilities in generating natural language. However, they also pose security and integrity challenges. Existing countermeasures primarily focus on distinguishing AI-generated content from human-written text, with most solutions tailored for English. Meanwhile, authorship attribution--determining which specific LLM produced a given text--has received comparatively little attention despite its importance in forensic analysis. In this paper, we present DA-MTL, a multi-task learning framework that simultaneously addresses both text detection and authorship attribution. We evaluate DA-MTL on nine datasets and four backbone models, demonstrating its strong performance across multiple languages and LLM sources. Our framework captures each task's unique characteristics and shares insights between them, which boosts performance in both tasks. Additionally, we conduct a thorough analysis of cross-modal and cross-lingual patterns and assess the framework's robustness against adversarial obfuscation techniques. Our findings offer valuable insights into LLM behavior and the generalization of both detection and authorship attribution.",
    "arxiv_id": "http://arxiv.org/abs/2508.14190v1",
    "pdf_link": "https://arxiv.org/pdf/2508.14190v1",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "Robust-Multi-Task Gradient Boosting",
    "authors": [
      "Seyedsaman Emami",
      "Gonzalo Martínez-Muñoz",
      "Daniel Hernández-Lobato"
    ],
    "published": "2025-07-15T15:31:12Z",
    "abstract": "Multi-task learning (MTL) has shown effectiveness in exploiting shared information across tasks to improve generalization. MTL assumes tasks share similarities that can improve performance. In addition, boosting algorithms have demonstrated exceptional performance across diverse learning problems, primarily due to their ability to focus on hard-to-learn instances and iteratively reduce residual errors. This makes them a promising approach for learning multi-task problems. However, real-world MTL scenarios often involve tasks that are not well-aligned (known as outlier or adversarial tasks), which do not share beneficial similarities with others and can, in fact, deteriorate the performance of the overall model. To overcome this challenge, we propose Robust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that explicitly models and adapts to task heterogeneity during training. R-MTGB structures the learning process into three sequential blocks: (1) learning shared patterns, (2) partitioning tasks into outliers and non-outliers with regularized parameters, and (3) fine-tuning task-specific predictors. This architecture enables R-MTGB to automatically detect and penalize outlier tasks while promoting effective knowledge transfer among related tasks. Our method integrates these mechanisms seamlessly within gradient boosting, allowing robust handling of noisy or adversarial tasks without sacrificing accuracy. Extensive experiments on both synthetic benchmarks and real-world datasets demonstrate that our approach successfully isolates outliers, transfers knowledge, and consistently reduces prediction errors for each task individually, and achieves overall performance gains across all tasks. These results highlight robustness, adaptability, and reliable convergence of R-MTGB in challenging MTL environments.",
    "arxiv_id": "http://arxiv.org/abs/2507.11411v3",
    "pdf_link": "https://arxiv.org/pdf/2507.11411v3",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "Merging Smarter, Generalizing Better: Enhancing Model Merging on OOD Data",
    "authors": [
      "Bingjie Zhang",
      "Hongkang Li",
      "Changlong Shi",
      "Guowei Rong",
      "He Zhao",
      "Dongsheng Wang",
      "Dandan Guo",
      "Meng Wang"
    ],
    "published": "2025-06-10T11:34:23Z",
    "abstract": "Multi-task learning (MTL) concurrently trains a model on diverse task datasets to exploit common features, thereby improving overall performance across the tasks. Recent studies have dedicated efforts to merging multiple independent model parameters into a unified model for MTL, thus circumventing the need for training data and expanding the scope of applicable scenarios of MTL. However, current approaches to model merging predominantly concentrate on enhancing performance within in-domain (ID) datasets, often overlooking their efficacy on out-of-domain (OOD) datasets. In this work, we proposed LwPTV (Layer-wise Pruning Task Vector) by building a saliency score, measuring the redundancy of parameters in task vectors. Designed in this way ours can achieve mask vector for each task and thus perform layer-wise pruning on the task vectors, only keeping the pre-trained model parameters at the corresponding layer in merged model. Owing to its flexibility, our method can be seamlessly integrated with most of existing model merging methods to improve their performance on OOD tasks. Extensive experiments demonstrate that the application of our method results in substantial enhancements in OOD performance while preserving the ability on ID tasks.",
    "arxiv_id": "http://arxiv.org/abs/2506.09093v2",
    "pdf_link": "https://arxiv.org/pdf/2506.09093v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "Multi-task Learning with Active Learning for Arabic Offensive Speech Detection",
    "authors": [
      "Aisha Alansari",
      "Hamzah Luqman"
    ],
    "published": "2025-06-03T11:17:03Z",
    "abstract": "The rapid growth of social media has amplified the spread of offensive, violent, and vulgar speech, which poses serious societal and cybersecurity concerns. Detecting such content in Arabic text is particularly complex due to limited labeled data, dialectal variations, and the language's inherent complexity. This paper proposes a novel framework that integrates multi-task learning (MTL) with active learning to enhance offensive speech detection in Arabic social media text. By jointly training on two auxiliary tasks, violent and vulgar speech, the model leverages shared representations to improve the detection accuracy of the offensive speech. Our approach dynamically adjusts task weights during training to balance the contribution of each task and optimize performance. To address the scarcity of labeled data, we employ an active learning strategy through several uncertainty sampling techniques to iteratively select the most informative samples for model training. We also introduce weighted emoji handling to better capture semantic cues. Experimental results on the OSACT2022 dataset show that the proposed framework achieves a state-of-the-art macro F1-score of 85.42%, outperforming existing methods while using significantly fewer fine-tuning samples. The findings of this study highlight the potential of integrating MTL with active learning for efficient and accurate offensive language detection in resource-constrained settings.",
    "arxiv_id": "http://arxiv.org/abs/2506.02753v1",
    "pdf_link": "https://arxiv.org/pdf/2506.02753v1",
    "categories": [
      "cs.CL"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "Leveraging Multi-Task Learning for Multi-Label Power System Security Assessment",
    "authors": [
      "Muhy Eddin Za'ter",
      "Amir Sajad",
      "Bri-Mathias Hodge"
    ],
    "published": "2025-05-09T17:36:59Z",
    "abstract": "This paper introduces a novel approach to the power system security assessment using Multi-Task Learning (MTL), and reformulating the problem as a multi-label classification task. The proposed MTL framework simultaneously assesses static, voltage, transient, and small-signal stability, improving both accuracy and interpretability with respect to the most state of the art machine learning methods. It consists of a shared encoder and multiple decoders, enabling knowledge transfer between stability tasks. Experiments on the IEEE 68-bus system demonstrate a measurable superior performance of the proposed method compared to the extant state-of-the-art approaches.",
    "arxiv_id": "http://arxiv.org/abs/2505.06207v1",
    "pdf_link": "https://arxiv.org/pdf/2505.06207v1",
    "categories": [
      "eess.SY",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "FW-Merging: Scaling Model Merging with Frank-Wolfe Optimization",
    "authors": [
      "Hao Mark Chen",
      "Shell Xu Hu",
      "Wayne Luk",
      "Timothy Hospedales",
      "Hongxiang Fan"
    ],
    "published": "2025-03-16T21:07:05Z",
    "abstract": "Model merging has emerged as a promising approach for multi-task learning (MTL), offering a data-efficient alternative to conventional fine-tuning. However, with the rapid development of the open-source AI ecosystem and the increasing availability of fine-tuned foundation models, existing model merging methods face two key limitations: (i) They are primarily designed for in-house fine-tuned models, making them less adaptable to diverse model sources with partially unknown model and task information, (ii) They struggle to scale effectively when merging numerous model checkpoints. To address these challenges, we formulate model merging as a constrained optimization problem and introduce a novel approach: Frank-Wolfe Merging (FW-Merging). Inspired by Frank-Wolfe optimization, our approach iteratively selects the most relevant model in the pool to minimize a linear approximation of the objective function and then executes a local merging similar to the Frank-Wolfe update. The objective function is designed to capture the desired behavior of the target-merged model, while the fine-tuned candidate models define the constraint set. More importantly, FW-Merging serves as an orthogonal technique for existing merging methods, seamlessly integrating with them to further enhance accuracy performance. Our experiments show that FW-Merging scales across diverse model sources, remaining stable with 16 irrelevant models and improving by 15.3% with 16 relevant models on 20 CV tasks, while maintaining constant memory overhead, unlike the linear overhead of data-informed merging methods. Compared with the state-of-the-art approaches, FW-Merging surpasses the data-free merging method by 32.8% and outperforms the data-informed Adamerging by 8.39% when merging 20 ViT models. Our code is open-sourced at github.com/hmarkc/FW-Merging.",
    "arxiv_id": "http://arxiv.org/abs/2503.12649v3",
    "pdf_link": "https://arxiv.org/pdf/2503.12649v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "From Canopy to Ground via ForestGen3D: Learning Cross-Domain Generation of 3D Forest Structure from Aerial-to-Terrestrial LiDAR",
    "authors": [
      "Juan Castorena",
      "E. Louise Loudermilk",
      "Scott Pokswinski",
      "Rodman Linn"
    ],
    "published": "2025-09-19T18:39:50Z",
    "abstract": "The 3D structure of living and non-living components in ecosystems plays a critical role in determining ecological processes and feedbacks from both natural and human-driven disturbances. Anticipating the effects of wildfire, drought, disease, or atmospheric deposition depends on accurate characterization of 3D vegetation structure, yet widespread measurement remains prohibitively expensive and often infeasible. We introduce ForestGen3D, a novel generative modeling framework that synthesizes high-fidelity 3D forest structure using only aerial LiDAR (ALS) inputs. ForestGen3D is based on conditional denoising diffusion probabilistic models (DDPMs) trained on co-registered ALS/TLS (terrestrial LiDAR) data. The model learns to generate TLS-like 3D point clouds conditioned on sparse ALS observations, effectively reconstructing occluded sub-canopy detail at scale. To ensure ecological plausibility, we introduce a geometric containment prior based on the convex hull of ALS observations and provide theoretical and empirical guarantees that generated structures remain spatially consistent. We evaluate ForestGen3D at tree, plot, and landscape scales using real-world data from mixed conifer ecosystems, and show that it produces high-fidelity reconstructions that closely match TLS references in terms of geometric similarity and biophysical metrics, such as tree height, DBH, crown diameter and crown volume. Additionally, we demonstrate that the containment property can serve as a practical proxy for generation quality in settings where TLS ground truth is unavailable. Our results position ForestGen3D as a scalable tool for ecological modeling, wildfire simulation, and structural fuel characterization in ALS-only environments.",
    "arxiv_id": "http://arxiv.org/abs/2509.16346v1",
    "pdf_link": "https://arxiv.org/pdf/2509.16346v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "Scalable and Site-Specific Frequency Tuning of Two-Level System Defects in Superconducting Qubit Arrays",
    "authors": [
      "Larry Chen",
      "Kan-Heng Lee",
      "Chuan-Hong Liu",
      "Brian Marinelli",
      "Ravi K. Naik",
      "Ziqi Kang",
      "Noah Goss",
      "Hyunseong Kim",
      "David I. Santiago",
      "Irfan Siddiqi"
    ],
    "published": "2025-03-06T18:49:46Z",
    "abstract": "State-of-the-art superconducting quantum processors containing tens to hundreds of qubits have demonstrated the building blocks for realizing fault-tolerant quantum computation. Nonetheless, a fundamental barrier to scaling further is the prevalence of fluctuating quantum two-level system (TLS) defects that can couple resonantly to qubits, causing excess decoherence and enhanced gate errors. Here we introduce a scalable architecture for site-specific and in-situ manipulation of TLS frequencies out of the spectral vicinity of our qubits. Our method is resource efficient, combining TLS frequency tuning and universal single qubit control into a single on-chip control line per qubit. We independently control each qubit's dissipative environment to dynamically improve both qubit coherence times and single qubit gate fidelities -- with a constant time overhead that does not scale with the device size. Over a period of 40 hours across 6 qubits, we demonstrate a $36\\%$ improvement in average single qubit error rates and a $17\\%$ improvement in average energy relaxation times. Critically, we realize a 4-fold suppression in the occurrence of TLS-induced performance outliers, and a complete reduction of simultaneous outlier events. These results mark a significant step toward overcoming the challenges that TLS defects pose to scaling superconducting quantum processors.",
    "arxiv_id": "http://arxiv.org/abs/2503.04702v1",
    "pdf_link": "https://arxiv.org/pdf/2503.04702v1",
    "categories": [
      "quant-ph"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "DID Link: Authentication in TLS with Decentralized Identifiers and Verifiable Credentials",
    "authors": [
      "Sandro Rodriguez Garzon",
      "Dennis Natusch",
      "Artur Philipp",
      "Axel Küpper",
      "Hans Joachim Einsiedler",
      "Daniela Schneider"
    ],
    "published": "2024-05-13T08:03:32Z",
    "abstract": "Authentication in TLS is predominately carried out with X.509 digital certificates issued by certificate authorities (CA). The centralized nature of current public key infrastructures, however, comes along with severe risks, such as single points of failure and susceptibility to cyber-attacks, potentially undermining the security and trustworthiness of the entire system. With Decentralized Identifiers (DID) alongside distributed ledger technology, it becomes technically feasible to prove ownership of a unique identifier without requiring an attestation of the proof's public key by a centralized and therefore vulnerable CA. This article presents DID Link, a novel authentication scheme for TLS 1.3 that empowers entities to authenticate in a TLS-compliant way with self-issued X.509 certificates that are equipped with ledger-anchored DIDs instead of CA-issued identifiers. It facilitates the exchange of tamper-proof and 3rd-party attested claims in the form of DID-bound Verifiable Credentials after the TLS handshake to complete the authentication with a full identification of the communication partner. A prototypical implementation shows comparable TLS handshake durations of DID Link if verification material is cached and reasonable prolongations if it is obtained from a ledger. The significant speed improvement of the resulting TLS channel over a widely used, DID-based alternative transport protocol on the application layer demonstrates the potential of DID Link to become a viable solution for the establishment of secure and trustful end-to-end communication links with decentrally managed digital identities.",
    "arxiv_id": "http://arxiv.org/abs/2405.07533v4",
    "pdf_link": "https://arxiv.org/pdf/2405.07533v4",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "DomainLynx: Leveraging Large Language Models for Enhanced Domain Squatting Detection",
    "authors": [
      "Daiki Chiba",
      "Hiroki Nakano",
      "Takashi Koide"
    ],
    "published": "2024-10-02T23:32:09Z",
    "abstract": "Domain squatting poses a significant threat to Internet security, with attackers employing increasingly sophisticated techniques. This study introduces DomainLynx, an innovative compound AI system leveraging Large Language Models (LLMs) for enhanced domain squatting detection. Unlike existing methods focusing on predefined patterns for top-ranked domains, DomainLynx excels in identifying novel squatting techniques and protecting less prominent brands. The system's architecture integrates advanced data processing, intelligent domain pairing, and LLM-powered threat assessment. Crucially, DomainLynx incorporates specialized components that mitigate LLM hallucinations, ensuring reliable and context-aware detection. This approach enables efficient analysis of vast security data from diverse sources, including Certificate Transparency logs, Passive DNS records, and zone files. Evaluated on a curated dataset of 1,649 squatting domains, DomainLynx achieved 94.7\\% accuracy using Llama-3-70B. In a month-long real-world test, it detected 34,359 squatting domains from 2.09 million new domains, outperforming baseline methods by 2.5 times. This research advances Internet security by providing a versatile, accurate, and adaptable tool for combating evolving domain squatting threats. DomainLynx's approach paves the way for more robust, AI-driven cybersecurity solutions, enhancing protection for a broader range of online entities and contributing to a safer digital ecosystem.",
    "arxiv_id": "http://arxiv.org/abs/2410.02095v3",
    "pdf_link": "https://arxiv.org/pdf/2410.02095v3",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "Anomaly Detection in Certificate Transparency Logs",
    "authors": [
      "Richard Ostertág",
      "Martin Stanek"
    ],
    "published": "2024-05-08T16:43:50Z",
    "abstract": "We propose an anomaly detection technique for X.509 certificates utilizing Isolation Forest. This method can be beneficial when compliance testing with X.509 linters proves unsatisfactory, and we seek to identify anomalies beyond standards compliance. The technique is validated on a sample of certificates from Certificate Transparency logs.",
    "arxiv_id": "http://arxiv.org/abs/2405.05206v1",
    "pdf_link": "https://arxiv.org/pdf/2405.05206v1",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 35
  },
  {
    "title": "Streamlining Plug-and-Charge Authorization for Electric Vehicles with OAuth2 and OIDC",
    "authors": [
      "Jonas Primbs",
      "Dustin Kern",
      "Michael Menth",
      "Christoph Krauß"
    ],
    "published": "2025-01-24T11:01:28Z",
    "abstract": "The Plug-and-Charge (PnC) process defined by ISO 15118 standardizes automated Electric Vehicle (EV) charging by enabling automatic installation of credentials and use for authentication between EV and Charge Point (CP). However, the current credential installation process is non-uniform, relies on a complex Public Key Infrastructure (PKI), lacks support for fine-grained authorization parameters, and is not very user-friendly. In this paper, we propose a streamlined approach to the initial charging authorization process by leveraging the OAuth Device Authorization Grant and Rich Authorization Requests. The proposed solution reduces technical complexity, simplifies credential installation, introduces flexible authorization constraints (e.g., time- and cost-based), and facilitates payment through OpenID Connect (OIDC). We present a proof-of-concept implementation along with performance evaluations and conduct a symbolic protocol verification using the Tamarin prover. Furthermore, our approach solves the issue of OAuth's cross-device authorization, making it suitable as a formally proven blueprint in contexts beyond EV charging.",
    "arxiv_id": "http://arxiv.org/abs/2501.14397v2",
    "pdf_link": "https://arxiv.org/pdf/2501.14397v2",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "A Simple Framework for Secure Key Leasing",
    "authors": [
      "Fuyuki Kitagawa",
      "Tomoyuki Morimae",
      "Takashi Yamakawa"
    ],
    "published": "2024-10-04T13:24:03Z",
    "abstract": "Secure key leasing (a.k.a. key-revocable cryptography) enables us to lease a cryptographic key as a quantum state in such a way that the key can be later revoked in a verifiable manner. We propose a simple framework for constructing cryptographic primitives with secure key leasing via the certified deletion property of BB84 states. Based on our framework, we obtain the following schemes.   - A public key encryption scheme with secure key leasing that has classical revocation based on any IND-CPA secure public key encryption scheme. Prior works rely on either quantum revocation or stronger assumptions such as the quantum hardness of the learning with errors (LWE) problem.   - A pseudorandom function with secure key leasing that has classical revocation based on one-way functions. Prior works rely on stronger assumptions such as the quantum hardness of the LWE problem.   - A digital signature scheme with secure key leasing that has classical revocation based on the quantum hardness of the short integer solution (SIS) problem. Our construction has static signing keys, i.e., the state of a signing key almost does not change before and after signing. Prior constructions either rely on non-static signing keys or indistinguishability obfuscation to achieve a stronger goal of copy-protection.   In addition, all of our schemes remain secure even if a verification key for revocation is leaked after the adversary submits a valid certificate of deletion. To our knowledge, all prior constructions are totally broken in this setting. Moreover, in our view, our security proofs are much simpler than those for existing schemes.",
    "arxiv_id": "http://arxiv.org/abs/2410.03413v2",
    "pdf_link": "https://arxiv.org/pdf/2410.03413v2",
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Token-based Vehicular Security System (TVSS): Scalable, Secure, Low-latency Public Key Infrastructure for Connected Vehicles",
    "authors": [
      "Abdulrahman Bin Rabiah",
      "Anas Alsoliman",
      "Yugarshi Shashwat",
      "Silas Richelson",
      "Nael Abu-Ghazaleh"
    ],
    "published": "2024-02-28T14:35:52Z",
    "abstract": "Connected and Autonomous vehicles stand to drastically improve the safety and efficiency of the transportation system in the near future while also reducing pollution. These systems leverage communication to coordinate among vehicles and infrastructure in service of a number of safety and efficiency driver assist and even fully autonomous applications. Attackers can compromise these systems in a number of ways including by falsifying communication messages, making it critical to support security mechanisms that can operate and scale in dynamic scenarios. Towards this end, we present TVSS, a new VPKI system which improves drastically over prior work in the area (including over SCMS; the US department of transportation standard for VPKI). TVSS leverages the idea of unforgeable tokens to enable rapid verification at the road side units (RSUs), which are part of the road infrastructure at the edge of the network. This edge based solution enables agile authentication by avoiding the need for back-end servers during the potentially short contact time between a moving vehicle and the infrastructure. It also results in several security advantages: (1) Scalable Revocation: it greatly simplifies the revocation problem, a difficult problem in large scale certificate systems; and (2) Faster Refresh: Vehicles interact more frequently with the system to refresh their credentials, improving the privacy of the system. We provide a construction of the system and formally prove its security. Field experiments on a test-bed we develop consisting of on-board units (OBUs) and RSUs shows substantial reduction in the latency of refreshing credentials compared to SCMS, allowing the system to work even with smaller window of connectivity when vehicles are moving at higher speeds. Notably, we are able to execute the bottleneck operation of our scheme with a stationary RSU while traveling at highway speeds .",
    "arxiv_id": "http://arxiv.org/abs/2402.18365v1",
    "pdf_link": "https://arxiv.org/pdf/2402.18365v1",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Secure, Robust, and Energy-Efficient Authenticated Data Sharing in UAV-Assisted 6G Networks",
    "authors": [
      "Atefeh Mohseni Ejiyeh"
    ],
    "published": "2024-02-17T21:20:30Z",
    "abstract": "This paper confronts the pressing challenges of sixth-generation (6G) wireless communication networks by harnessing the unique capabilities of Unmanned Aerial Vehicles (UAVs). With the ambitious promises of 6G, including ultra-reliable 1 Tbps data delivery and ultra-low latency, the demand for innovative solutions becomes imperative. Traditional terrestrial base stations, though effective, exhibit limitations in scenarios requiring ubiquitous connectivity, prompting the integration of UAVs. In response to these challenges, we introduce a comprehensive solution. This involves UAVs collaboratively downloading desired content from service providers, and subsequently establishing secure connections with users for efficient content exchange. Accordingly, we introduce two new protocols: a collaborative group data downloading scheme among UAVs called SeGDS, and SeDDS for secure direct data sharing through out-of-band autonomous Device-to-Device (D2D) communication. Leveraging certificateless signcryption and certificateless multi-receiver encryption, these protocols offer lightweight, certificate-free solutions with features such as user revocation, non-repudiation, and mutual authentication. Prioritizing high availability, the proposed protocols effectively detect Denial of Service (DoS) and free riding attacks. A thorough evaluation underscores the superiority of the proposed protocols in both security and efficiency over existing models; SeDDS reduces overall computation by 3x, imposing a lighter communication load on UAVs, while SeGDS meets swarm UAV security requirements, reducing communication costs by 4x with low computation cost.",
    "arxiv_id": "http://arxiv.org/abs/2402.11382v1",
    "pdf_link": "https://arxiv.org/pdf/2402.11382v1",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Model Merging via Multi-Teacher Knowledge Distillation",
    "authors": [
      "Seyed Arshan Dalili",
      "Mehrdad Mahdavi"
    ],
    "published": "2025-12-24T17:10:44Z",
    "abstract": "Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model's contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a \"cross-task heterogeneity\" term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model's excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging.",
    "arxiv_id": "http://arxiv.org/abs/2512.21288v1",
    "pdf_link": "https://arxiv.org/pdf/2512.21288v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Simplifying Multi-Task Architectures Through Task-Specific Normalization",
    "authors": [
      "Mihai Suteu",
      "Ovidiu Serban"
    ],
    "published": "2025-12-23T15:02:12Z",
    "abstract": "Multi-task learning (MTL) aims to leverage shared knowledge across tasks to improve generalization and parameter efficiency, yet balancing resources and mitigating interference remain open challenges. Architectural solutions often introduce elaborate task-specific modules or routing schemes, increasing complexity and overhead. In this work, we show that normalization layers alone are sufficient to address many of these challenges. Simply replacing shared normalization with task-specific variants already yields competitive performance, questioning the need for complex designs. Building on this insight, we propose Task-Specific Sigmoid Batch Normalization (TS$σ$BN), a lightweight mechanism that enables tasks to softly allocate network capacity while fully sharing feature extractors. TS$σ$BN improves stability across CNNs and Transformers, matching or exceeding performance on NYUv2, Cityscapes, CelebA, and PascalContext, while remaining highly parameter-efficient. Moreover, its learned gates provide a natural framework for analyzing MTL dynamics, offering interpretable insights into capacity allocation, filter specialization, and task relationships. Our findings suggest that complex MTL architectures may be unnecessary and that task-specific normalization offers a simple, interpretable, and efficient alternative.",
    "arxiv_id": "http://arxiv.org/abs/2512.20420v1",
    "pdf_link": "https://arxiv.org/pdf/2512.20420v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "No One Left Behind: How to Exploit the Incomplete and Skewed Multi-Label Data for Conversion Rate Prediction",
    "authors": [
      "Qinglin Jia",
      "Zhaocheng Du",
      "Chuhan Wu",
      "Huifeng Guo",
      "Ruiming Tang",
      "Shuting Shi",
      "Muyu Zhang"
    ],
    "published": "2025-12-15T13:14:20Z",
    "abstract": "In most real-world online advertising systems, advertisers typically have diverse customer acquisition goals. A common solution is to use multi-task learning (MTL) to train a unified model on post-click data to estimate the conversion rate (CVR) for these diverse targets. In practice, CVR prediction often encounters missing conversion data as many advertisers submit only a subset of user conversion actions due to privacy or other constraints, making the labels of multi-task data incomplete. If the model is trained on all available samples where advertisers submit user conversion actions, it may struggle when deployed to serve a subset of advertisers targeting specific conversion actions, as the training and deployment data distributions are mismatched. While considerable MTL efforts have been made, a long-standing challenge is how to effectively train a unified model with the incomplete and skewed multi-label data. In this paper, we propose a fine-grained Knowledge transfer framework for Asymmetric Multi-Label data (KAML). We introduce an attribution-driven masking strategy (ADM) to better utilize data with asymmetric multi-label data in training. However, the more relaxed masking in ADM is a double-edged sword: it provides additional training signals but also introduces noise due to skewed data. To address this, we propose a hierarchical knowledge extraction mechanism (HKE) to model the sample discrepancy within the target task tower. Finally, to maximize the utility of unlabeled samples, we incorporate ranking loss strategy to further enhance our model. The effectiveness of KAML has been demonstrated through comprehensive evaluations on offline industry datasets and online A/B tests, which show significant performance improvements over existing MTL baselines.",
    "arxiv_id": "http://arxiv.org/abs/2512.13300v1",
    "pdf_link": "https://arxiv.org/pdf/2512.13300v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Task-Specific Sparse Feature Masks for Molecular Toxicity Prediction with Chemical Language Models",
    "authors": [
      "Kwun Sy Lee",
      "Jiawei Chen",
      "Fuk Sheng Ford Chung",
      "Tianyu Zhao",
      "Zhenyuan Chen",
      "Debby D. Wang"
    ],
    "published": "2025-12-12T09:41:04Z",
    "abstract": "Reliable in silico molecular toxicity prediction is a cornerstone of modern drug discovery, offering a scalable alternative to experimental screening. However, the black-box nature of state-of-the-art models remains a significant barrier to adoption, as high-stakes safety decisions demand verifiable structural insights alongside predictive performance. To address this, we propose a novel multi-task learning (MTL) framework designed to jointly enhance accuracy and interpretability. Our architecture integrates a shared chemical language model with task-specific attention modules. By imposing an L1 sparsity penalty on these modules, the framework is constrained to focus on a minimal set of salient molecular fragments for each distinct toxicity endpoint. The resulting framework is trained end-to-end and is readily adaptable to various transformer-based backbones. Evaluated on the ClinTox, SIDER, and Tox21 benchmark datasets, our approach consistently outperforms both single-task and standard MTL baselines. Crucially, the sparse attention weights provide chemically intuitive visualizations that reveal the specific fragments influencing predictions, thereby enhancing insight into the model's decision-making process.",
    "arxiv_id": "http://arxiv.org/abs/2512.11412v1",
    "pdf_link": "https://arxiv.org/pdf/2512.11412v1",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "q-bio.BM"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "NexusFlow: Unifying Disparate Tasks under Partial Supervision via Invertible Flow Networks",
    "authors": [
      "Fangzhou Lin",
      "Yuping Wang",
      "Yuliang Guo",
      "Zixun Huang",
      "Xinyu Huang",
      "Haichong Zhang",
      "Kazunori Yamada",
      "Zhengzhong Tu",
      "Liu Ren",
      "Ziming Zhang"
    ],
    "published": "2025-12-06T02:51:19Z",
    "abstract": "Partially Supervised Multi-Task Learning (PS-MTL) aims to leverage knowledge across tasks when annotations are incomplete. Existing approaches, however, have largely focused on the simpler setting of homogeneous, dense prediction tasks, leaving the more realistic challenge of learning from structurally diverse tasks unexplored. To this end, we introduce NexusFlow, a novel, lightweight, and plug-and-play framework effective in both settings. NexusFlow introduces a set of surrogate networks with invertible coupling layers to align the latent feature distributions of tasks, creating a unified representation that enables effective knowledge transfer. The coupling layers are bijective, preserving information while mapping features into a shared canonical space. This invertibility avoids representational collapse and enables alignment across structurally different tasks without reducing expressive capacity. We first evaluate NexusFlow on the core challenge of domain-partitioned autonomous driving, where dense map reconstruction and sparse multi-object tracking are supervised in different geographic regions, creating both structural disparity and a strong domain gap. NexusFlow sets a new state-of-the-art result on nuScenes, outperforming strong partially supervised baselines. To demonstrate generality, we further test NexusFlow on NYUv2 using three homogeneous dense prediction tasks, segmentation, depth, and surface normals, as a representative N-task PS-MTL scenario. NexusFlow yields consistent gains across all tasks, confirming its broad applicability.",
    "arxiv_id": "http://arxiv.org/abs/2512.06251v1",
    "pdf_link": "https://arxiv.org/pdf/2512.06251v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Developing Fairness-Aware Task Decomposition to Improve Equity in Post-Spinal Fusion Complication Prediction",
    "authors": [
      "Yining Yuan",
      "J. Ben Tamo",
      "Wenqi Shi",
      "Yishan Zhong",
      "Micky C. Nnamdi",
      "B. Randall Brenn",
      "Steven W. Hwang",
      "May D. Wang"
    ],
    "published": "2025-11-29T19:06:07Z",
    "abstract": "Fairness in clinical prediction models remains a persistent challenge, particularly in high-stakes applications such as spinal fusion surgery for scoliosis, where patient outcomes exhibit substantial heterogeneity. Many existing fairness approaches rely on coarse demographic adjustments or post-hoc corrections, which fail to capture the latent structure of clinical populations and may unintentionally reinforce bias. We propose FAIR-MTL, a fairness-aware multitask learning framework designed to provide equitable and fine-grained prediction of postoperative complication severity.   Instead of relying on explicit sensitive attributes during model training, FAIR-MTL employs a data-driven subgroup inference mechanism. We extract a compact demographic embedding, and apply k-means clustering to uncover latent patient subgroups that may be differentially affected by traditional models. These inferred subgroup labels determine task routing within a shared multitask architecture. During training, subgroup imbalance is mitigated through inverse-frequency weighting, and regularization prevents overfitting to smaller groups.   Applied to postoperative complication prediction with four severity levels, FAIR-MTL achieves an AUC of 0.86 and an accuracy of 75%, outperforming single-task baselines while substantially reducing bias. For gender, the demographic parity difference decreases to 0.055 and equalized odds to 0.094; for age, these values reduce to 0.056 and 0.148, respectively. Model interpretability is ensured through SHAP and Gini importance analyses, which consistently highlight clinically meaningful predictors such as hemoglobin, hematocrit, and patient weight. Our findings show that incorporating unsupervised subgroup discovery into a multitask framework enables more equitable, interpretable, and clinically actionable predictions for surgical risk stratification.",
    "arxiv_id": "http://arxiv.org/abs/2512.00598v1",
    "pdf_link": "https://arxiv.org/pdf/2512.00598v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "FairMT: Fairness for Heterogeneous Multi-Task Learning",
    "authors": [
      "Guanyu Hu",
      "Tangzheng Lian",
      "Na Yan",
      "Dimitrios Kollias",
      "Xinyu Yang",
      "Oya Celiktutan",
      "Siyang Song",
      "Zeyu Fu"
    ],
    "published": "2025-11-29T12:44:51Z",
    "abstract": "Fairness in machine learning has been extensively studied in single-task settings, while fair multi-task learning (MTL), especially with heterogeneous tasks (classification, detection, regression) and partially missing labels, remains largely unexplored. Existing fairness methods are predominantly classification-oriented and fail to extend to continuous outputs, making a unified fairness objective difficult to formulate. Further, existing MTL optimization is structurally misaligned with fairness: constraining only the shared representation, allowing task heads to absorb bias and leading to uncontrolled task-specific disparities. Finally, most work treats fairness as a zero-sum trade-off with utility, enforcing symmetric constraints that achieve parity by degrading well-served groups. We introduce FairMT, a unified fairness-aware MTL framework that accommodates all three task types under incomplete supervision. At its core is an Asymmetric Heterogeneous Fairness Constraint Aggregation mechanism, which consolidates task-dependent asymmetric violations into a unified fairness constraint. Utility and fairness are jointly optimized via a primal--dual formulation, while a head-aware multi-objective optimization proxy provides a tractable descent geometry that explicitly accounts for head-induced anisotropy. Across three homogeneous and heterogeneous MTL benchmarks encompassing diverse modalities and supervision regimes, FairMT consistently achieves substantial fairness gains while maintaining superior task utility. Code will be released upon paper acceptance.",
    "arxiv_id": "http://arxiv.org/abs/2512.00469v1",
    "pdf_link": "https://arxiv.org/pdf/2512.00469v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Multi-Task Temporal Fusion Transformer for Joint Sales and Inventory Forecasting in Amazon E-Commerce Supply Chain",
    "authors": [
      "Zheqi Hu",
      "Yiwen Hu",
      "Hanwu Li"
    ],
    "published": "2025-11-29T07:43:28Z",
    "abstract": "Efficient inventory management and accurate sales forecasting are critical challenges in large-scale e-commerce platforms such as Amazon, where stockouts and overstocking can lead to substantial financial losses and operational inefficiencies. Traditional single-task forecasting models, which focus solely on sales or inventory, often fail to capture the complex temporal dependencies and cross-task interactions that characterize real-world supply chain dynamics. To address this limitation, this study proposes a Multi-Task Temporal Fusion Transformer (TFT-MTL) framework designed for joint sales and inventory forecasting within the Amazon e-commerce ecosystem. The model integrates heterogeneous data sources, including historical sales records, warehouse inventory levels, pricing, promotions, and event-driven factors such as holidays and Prime Day campaigns, through a unified deep learning architecture. A shared encoder captures long-term temporal patterns, while task-specific decoder heads predict sales volume, inventory turnover, and stockout probability simultaneously. Experiments on large-scale real-world datasets demonstrate that the proposed TFT-MTL model significantly outperforms baseline methods such as LSTM, GRU, and single-task TFT. Compared with the single-task TFT model, the proposed approach achieves a 6.2% reduction in Sales RMSE, a 12.7% decrease in Sales MAPE, a 6.4% reduction in Inventory RMSE, and a 12.4% decrease in Inventory MAPE. These results confirm the model's ability to effectively capture multi-dimensional dependencies across supply chain variables. The proposed framework provides an interpretable, data-driven decision support tool for optimizing Amazon's inventory scheduling and demand planning strategies.",
    "arxiv_id": "http://arxiv.org/abs/2512.00370v1",
    "pdf_link": "https://arxiv.org/pdf/2512.00370v1",
    "categories": [
      "cs.CE"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Co-Training Vision Language Models for Remote Sensing Multi-task Learning",
    "authors": [
      "Qingyun Li",
      "Shuran Ma",
      "Junwei Luo",
      "Yi Yu",
      "Yue Zhou",
      "Fengxiang Wang",
      "Xudong Lu",
      "Xiaoxing Wang",
      "Xin He",
      "Yushi Chen",
      "Xue Yang",
      "Junchi Yan"
    ],
    "published": "2025-11-26T10:55:07Z",
    "abstract": "With Transformers achieving outstanding performance on individual remote sensing (RS) tasks, we are now approaching the realization of a unified model that excels across multiple tasks through multi-task learning (MTL). Compared to single-task approaches, MTL methods offer improved generalization, enhanced scalability, and greater practical applicability. Recently, vision language models (VLMs) have achieved promising results in RS image understanding, grounding, and ultra-high-resolution (UHR) image reasoning, respectively. Moreover, the unified text-based interface demonstrates significant potential for MTL. Hence, in this work, we present RSCoVLM, a simple yet flexible VLM baseline for RS MTL. Firstly, we create the data curation engine, including data acquisition, offline processing and integrating, as well as online loading and weighting. This data engine effectively addresses complex RS data enviroment and generates flexible vision-language conversations. Furthermore, we propose a unified dynamic-resolution strategy to address the diverse image scales inherent in RS imagery. For UHR images, we introduce the Zoom-in Chain mechanism together with its corresponding dataset, LRS-VQA-Zoom. The strategies are flexible and effectively mitigate the computational burdens. Additionally, we significantly enhance the model's object detection capability and propose a novel evaluation protocol that ensures fair comparison between VLMs and conventional detection models. Extensive experiments demonstrate that RSCoVLM achieves state-of-the-art performance across diverse tasks, outperforming existing RS VLMs and even rivaling specialized expert models. All the training and evaluating tools, model weights, and datasets have been fully open-sourced to support reproducibility. We expect that this baseline will promote further progress toward general-purpose RS models.",
    "arxiv_id": "http://arxiv.org/abs/2511.21272v1",
    "pdf_link": "https://arxiv.org/pdf/2511.21272v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Collaborative Management for Chronic Diseases and Depression: A Double Heterogeneity-based Multi-Task Learning Method",
    "authors": [
      "Yidong Chai",
      "Haoxin Liu",
      "Jiaheng Xie",
      "Chaopeng Wang",
      "Xiao Fang"
    ],
    "published": "2025-11-20T14:15:27Z",
    "abstract": "Wearable sensor technologies and deep learning are transforming healthcare management. Yet, most health sensing studies focus narrowly on physical chronic diseases. This overlooks the critical need for joint assessment of comorbid physical chronic diseases and depression, which is essential for collaborative chronic care. We conceptualize multi-disease assessment, including both physical diseases and depression, as a multi-task learning (MTL) problem, where each disease assessment is modeled as a task. This joint formulation leverages inter-disease relationships to improve accuracy, but it also introduces the challenge of double heterogeneity: chronic diseases differ in their manifestation (disease heterogeneity), and patients with the same disease show varied patterns (patient heterogeneity). To address these issues, we first adopt existing techniques and propose a base method. Given the limitations of the base method, we further propose an Advanced Double Heterogeneity-based Multi-Task Learning (ADH-MTL) method that improves the base method through three innovations: (1) group-level modeling to support new patient predictions, (2) a decomposition strategy to reduce model complexity, and (3) a Bayesian network that explicitly captures dependencies while balancing similarities and differences across model components. Empirical evaluations on real-world wearable sensor data demonstrate that ADH-MTL significantly outperforms existing baselines, and each of its innovations is shown to be effective. This study contributes to health information systems by offering a computational solution for integrated physical and mental healthcare and provides design principles for advancing collaborative chronic disease management across the pre-treatment, treatment, and post-treatment phases.",
    "arxiv_id": "http://arxiv.org/abs/2511.16398v1",
    "pdf_link": "https://arxiv.org/pdf/2511.16398v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Incremental Maintenance of DatalogMTL Materialisations",
    "authors": [
      "Kaiyue Zhao",
      "Dingqi Chen",
      "Shaoyu Wang",
      "Pan Hu"
    ],
    "published": "2025-11-15T11:45:19Z",
    "abstract": "DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling efficient dynamic updates, a crucial requirement for real-world applications that involve frequent data updates. In this work, we propose DRedMTL, an incremental reasoning algorithm for DatalogMTL with bounded intervals. Our algorithm builds upon the classical DRed algorithm, which incrementally updates the materialisation of a Datalog program. Unlike a Datalog materialisation which is in essence a finite set of facts, a DatalogMTL materialisation has to be represented as a finite set of facts plus periodic intervals indicating how the full materialisation can be constructed through unfolding. To cope with this, our algorithm is equipped with specifically designed operators to efficiently handle such periodic representations of DatalogMTL materialisations. We have implemented this approach and tested it on several publicly available datasets. Experimental results show that DRedMTL often significantly outperforms rematerialisation, sometimes by orders of magnitude.",
    "arxiv_id": "http://arxiv.org/abs/2511.12169v2",
    "pdf_link": "https://arxiv.org/pdf/2511.12169v2",
    "categories": [
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "MultiTab: A Scalable Foundation for Multitask Learning on Tabular Data",
    "authors": [
      "Dimitrios Sinodinos",
      "Jack Yi Wei",
      "Narges Armanfard"
    ],
    "published": "2025-11-13T05:09:06Z",
    "abstract": "Tabular data is the most abundant data type in the world, powering systems in finance, healthcare, e-commerce, and beyond. As tabular datasets grow and span multiple related targets, there is an increasing need to exploit shared task information for improved multitask generalization. Multitask learning (MTL) has emerged as a powerful way to improve generalization and efficiency, yet most existing work focuses narrowly on large-scale recommendation systems, leaving its potential in broader tabular domains largely underexplored. Also, existing MTL approaches for tabular data predominantly rely on multi-layer perceptron-based backbones, which struggle to capture complex feature interactions and often fail to scale when data is abundant, a limitation that transformer architectures have overcome in other domains. Motivated by this, we introduce MultiTab-Net, the first multitask transformer architecture specifically designed for large tabular data. MultiTab-Net employs a novel multitask masked-attention mechanism that dynamically models feature-feature dependencies while mitigating task competition. Through extensive experiments, we show that MultiTab-Net consistently achieves higher multitask gain than existing MTL architectures and single-task transformers across diverse domains including large-scale recommendation data, census-like socioeconomic data, and physics datasets, spanning a wide range of task counts, task types, and feature modalities. In addition, we contribute MultiTab-Bench, a generalized multitask synthetic dataset generator that enables systematic evaluation of multitask dynamics by tuning task count, task correlations, and relative task complexity. Our code is publicly available at https://github.com/Armanfard-Lab/MultiTab.",
    "arxiv_id": "http://arxiv.org/abs/2511.09970v1",
    "pdf_link": "https://arxiv.org/pdf/2511.09970v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Multi-Task Learning Based on Support Vector Machines and Twin Support Vector Machines: A Comprehensive Survey",
    "authors": [
      "Fatemeh Bazikar",
      "Hossein Moosaei",
      "Atefeh Hemmati",
      "Panos M. Pardalos"
    ],
    "published": "2025-10-30T11:35:05Z",
    "abstract": "Multi-task learning (MTL) enables simultaneous training across related tasks, leveraging shared information to improve generalization, efficiency, and robustness, especially in data-scarce or high-dimensional scenarios. While deep learning dominates recent MTL research, Support Vector Machines (SVMs) and Twin SVMs (TWSVMs) remain relevant due to their interpretability, theoretical rigor, and effectiveness with small datasets.   This chapter surveys MTL approaches based on SVM and TWSVM, highlighting shared representations, task regularization, and structural coupling strategies. Special attention is given to emerging TWSVM extensions for multi-task settings, which show promise but remain underexplored. We compare these models in terms of theoretical properties, optimization strategies, and empirical performance, and discuss applications in fields such as computer vision, natural language processing, and bioinformatics.   Finally, we identify research gaps and outline future directions for building scalable, interpretable, and reliable margin-based MTL frameworks. This work provides a comprehensive resource for researchers and practitioners interested in SVM- and TWSVM-based multi-task learning.",
    "arxiv_id": "http://arxiv.org/abs/2510.26392v1",
    "pdf_link": "https://arxiv.org/pdf/2510.26392v1",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "VISAT: Benchmarking Adversarial and Distribution Shift Robustness in Traffic Sign Recognition with Visual Attributes",
    "authors": [
      "Simon Yu",
      "Peilin Yu",
      "Hongbo Zheng",
      "Huajie Shao",
      "Han Zhao",
      "Lui Sha"
    ],
    "published": "2025-10-29T18:31:21Z",
    "abstract": "We present VISAT, a novel open dataset and benchmarking suite for evaluating model robustness in the task of traffic sign recognition with the presence of visual attributes. Built upon the Mapillary Traffic Sign Dataset (MTSD), our dataset introduces two benchmarks that respectively emphasize robustness against adversarial attacks and distribution shifts. For our adversarial attack benchmark, we employ the state-of-the-art Projected Gradient Descent (PGD) method to generate adversarial inputs and evaluate their impact on popular models. Additionally, we investigate the effect of adversarial attacks on attribute-specific multi-task learning (MTL) networks, revealing spurious correlations among MTL tasks. The MTL networks leverage visual attributes (color, shape, symbol, and text) that we have created for each traffic sign in our dataset. For our distribution shift benchmark, we utilize ImageNet-C's realistic data corruption and natural variation techniques to perform evaluations on the robustness of both base and MTL models. Moreover, we further explore spurious correlations among MTL tasks through synthetic alterations of traffic sign colors using color quantization techniques. Our experiments focus on two major backbones, ResNet-152 and ViT-B/32, and compare the performance between base and MTL models. The VISAT dataset and benchmarking framework contribute to the understanding of model robustness for traffic sign recognition, shedding light on the challenges posed by adversarial attacks and distribution shifts. We believe this work will facilitate advancements in developing more robust models for real-world applications in autonomous driving and cyber-physical systems.",
    "arxiv_id": "http://arxiv.org/abs/2510.26833v1",
    "pdf_link": "https://arxiv.org/pdf/2510.26833v1",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "NTKMTL: Mitigating Task Imbalance in Multi-Task Learning from Neural Tangent Kernel Perspective",
    "authors": [
      "Xiaohan Qin",
      "Xiaoxing Wang",
      "Ning Liao",
      "Junchi Yan"
    ],
    "published": "2025-10-21T03:29:40Z",
    "abstract": "Multi-Task Learning (MTL) enables a single model to learn multiple tasks simultaneously, leveraging knowledge transfer among tasks for enhanced generalization, and has been widely applied across various domains. However, task imbalance remains a major challenge in MTL. Although balancing the convergence speeds of different tasks is an effective approach to address this issue, it is highly challenging to accurately characterize the training dynamics and convergence speeds of multiple tasks within the complex MTL system. To this end, we attempt to analyze the training dynamics in MTL by leveraging Neural Tangent Kernel (NTK) theory and propose a new MTL method, NTKMTL. Specifically, we introduce an extended NTK matrix for MTL and adopt spectral analysis to balance the convergence speeds of multiple tasks, thereby mitigating task imbalance. Based on the approximation via shared representation, we further propose NTKMTL-SR, achieving training efficiency while maintaining competitive performance. Extensive experiments demonstrate that our methods achieve state-of-the-art performance across a wide range of benchmarks, including both multi-task supervised learning and multi-task reinforcement learning. Source code is available at https://github.com/jianke0604/NTKMTL.",
    "arxiv_id": "http://arxiv.org/abs/2510.18258v1",
    "pdf_link": "https://arxiv.org/pdf/2510.18258v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "A Deep Multi-Task Learning Approach to Impulsive Noise Parameter Estimation",
    "authors": [
      "Abdullahi Mohammad",
      "Bdah Eya",
      "Bassant Selim"
    ],
    "published": "2025-10-14T06:14:36Z",
    "abstract": "Impulsive noise poses a significant challenge to the reliability of wireless communication systems, necessitating accurate estimation of its statistical parameters for effective mitigation. This paper introduces a multitask learning (MTL) framework based on a CNN-LSTM architecture enhanced with an attention mechanism for the joint estimation of impulsive noise parameters. The proposed model leverages a unified weighted-loss function to enable simultaneous learning of multiple parameters within a shared representation space, improving learning efficiency and generalization across related tasks. Experimental results show that the proposed MTL framework achieves stable convergence, faster training, and enhanced scalability with modest computational overhead. Benchmarking against conventional single-task learning (STL) models confirms its favorable complexity-performance trade-off and significant memory savings, indicating the effectiveness of the MTL approach for real-time impulsive noise parameter estimation in wireless systems.",
    "arxiv_id": "http://arxiv.org/abs/2510.12179v1",
    "pdf_link": "https://arxiv.org/pdf/2510.12179v1",
    "categories": [
      "eess.SP"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Multi-Task Learning with Feature-Similarity Laplacian Graphs for Predicting Alzheimer's Disease Progression",
    "authors": [
      "Zixiang Xu",
      "Menghui Zhou",
      "Jun Qi",
      "Xuanhan Fan",
      "Yun Yang",
      "Po Yang"
    ],
    "published": "2025-10-12T03:55:42Z",
    "abstract": "Alzheimer's Disease (AD) is the most prevalent neurodegenerative disorder in aging populations, posing a significant and escalating burden on global healthcare systems. While Multi-Tusk Learning (MTL) has emerged as a powerful computational paradigm for modeling longitudinal AD data, existing frameworks do not account for the time-varying nature of feature correlations. To address this limitation, we propose a novel MTL framework, named Feature Similarity Laplacian graph Multi-Task Learning (MTL-FSL). Our framework introduces a novel Feature Similarity Laplacian (FSL) penalty that explicitly models the time-varying relationships between features. By simultaneously considering temporal smoothness among tasks and the dynamic correlations among features, our model enhances both predictive accuracy and biological interpretability. To solve the non-smooth optimization problem arising from our proposed penalty terms, we adopt the Alternating Direction Method of Multipliers (ADMM) algorithm. Experiments conducted on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset demonstrate that our proposed MTL-FSL framework achieves state-of-the-art performance, outperforming various baseline methods. The implementation source can be found at https://github.com/huatxxx/MTL-FSL.",
    "arxiv_id": "http://arxiv.org/abs/2510.10433v1",
    "pdf_link": "https://arxiv.org/pdf/2510.10433v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning",
    "authors": [
      "Pîrvu Mihai-Cristian",
      "Marius Leordeanu"
    ],
    "published": "2025-10-11T07:05:34Z",
    "abstract": "The computer vision domain has greatly benefited from an abundance of data across many modalities to improve on various visual tasks. Recently, there has been a lot of focus on self-supervised pre-training methods through Masked Autoencoders (MAE) \\cite{he2022masked,bachmann2022multimae}, usually used as a first step before optimizing for a downstream task, such as classification or regression. This is very useful as it doesn't require any manually labeled data. In this work, we introduce Probabilistic Hyper-Graphs using Masked Autoencoders (PHG-MAE): a novel model that unifies the classical work on neural graphs \\cite{leordeanu2021semi} with the modern approach of masked autoencoders under a common theoretical framework. Through random masking of entire modalities, not just patches, the model samples from the distribution of hyper-edges on each forward pass. Additionally, the model adapts the standard MAE algorithm by combining pre-training and fine-tuning into a single training loop. Moreover, our approach enables the creation of inference-time ensembles which, through aggregation, boost the final prediction performance and consistency. Lastly, we show that we can apply knowledge distillation on top of the ensembles with little loss in performance, even with models that have fewer than 1M parameters. While our work mostly focuses on outdoor UAV scenes that contain multiple world interpretations and modalities, the same steps can be followed in other similar domains, such as autonomous driving or indoor robotics. In order to streamline the process of integrating external pre-trained experts for computer vision multi-modal multi-task learning (MTL) scenarios, we developed a data-pipeline software. Using this tool, we have created and released a fully-automated extension of the Dronescapes dataset. All the technical details, code and reproduction steps are publicly released.",
    "arxiv_id": "http://arxiv.org/abs/2510.10068v2",
    "pdf_link": "https://arxiv.org/pdf/2510.10068v2",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Adaptive Shared Experts with LoRA-Based Mixture of Experts for Multi-Task Learning",
    "authors": [
      "Minghao Yang",
      "Ren Togo",
      "Guang Li",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "published": "2025-10-01T06:49:19Z",
    "abstract": "Mixture-of-Experts (MoE) has emerged as a powerful framework for multi-task learning (MTL). However, existing MoE-MTL methods often rely on single-task pretrained backbones and suffer from redundant adaptation and inefficient knowledge sharing during the transition from single-task to multi-task learning (STL to MTL). To address these limitations, we propose adaptive shared experts (ASE) within a low-rank adaptation (LoRA) based MoE, where shared experts are assigned router-computed gating weights jointly normalized with sparse experts. This design facilitates STL to MTL transition, enhances expert specialization, and cooperation. Furthermore, we incorporate fine-grained experts by increasing the number of LoRA experts while proportionally reducing their rank, enabling more effective knowledge sharing under a comparable parameter budget. Extensive experiments on the PASCAL-Context benchmark, under unified training settings, demonstrate that ASE consistently improves performance across diverse configurations and validates the effectiveness of fine-grained designs for MTL.",
    "arxiv_id": "http://arxiv.org/abs/2510.00570v1",
    "pdf_link": "https://arxiv.org/pdf/2510.00570v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Multi-Task Equation Discovery",
    "authors": [
      "S C Bee",
      "N Dervilis",
      "K Worden",
      "L A Bull"
    ],
    "published": "2025-09-29T18:56:40Z",
    "abstract": "Equation discovery provides a grey-box approach to system identification by uncovering governing dynamics directly from observed data. However, a persistent challenge lies in ensuring that identified models generalise across operating conditions rather than over-fitting to specific datasets. This work investigates this issue by applying a Bayesian relevance vector machine (RVM) within a multi-task learning (MTL) framework for simultaneous parameter identification across multiple datasets. In this formulation, responses from the same structure under different excitation levels are treated as related tasks that share model parameters but retain task-specific noise characteristics. A simulated single degree-of-freedom oscillator with linear and cubic stiffness provided the case study, with datasets generated under three excitation regimes. Standard single-task RVM models were able to reproduce system responses but often failed to recover the true governing terms when excitations insufficiently stimulated non-linear dynamics. By contrast, the MTL-RVM combined information across tasks, improving parameter recovery for weakly and moderately excited datasets, while maintaining strong performance under high excitation. These findings demonstrate that multi-task Bayesian inference can mitigate over-fitting and promote generalisation in equation discovery. The approach is particularly relevant to structural health monitoring, where varying load conditions reveal complementary aspects of system physics.",
    "arxiv_id": "http://arxiv.org/abs/2509.25400v1",
    "pdf_link": "https://arxiv.org/pdf/2509.25400v1",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Revisit the Imbalance Optimization in Multi-task Learning: An Experimental Analysis",
    "authors": [
      "Yihang Guo",
      "Tianyuan Yu",
      "Liang Bai",
      "Yanming Guo",
      "Yirun Ruan",
      "William Li",
      "Weishi Zheng"
    ],
    "published": "2025-09-28T14:40:06Z",
    "abstract": "Multi-task learning (MTL) aims to build general-purpose vision systems by training a single network to perform multiple tasks jointly. While promising, its potential is often hindered by \"unbalanced optimization\", where task interference leads to subpar performance compared to single-task models. To facilitate research in MTL, this paper presents a systematic experimental analysis to dissect the factors contributing to this persistent problem. Our investigation confirms that the performance of existing optimization methods varies inconsistently across datasets, and advanced architectures still rely on costly grid-searched loss weights. Furthermore, we show that while powerful Vision Foundation Models (VFMs) provide strong initialization, they do not inherently resolve the optimization imbalance, and merely increasing data quantity offers limited benefits. A crucial finding emerges from our analysis: a strong correlation exists between the optimization imbalance and the norm of task-specific gradients. We demonstrate that this insight is directly applicable, showing that a straightforward strategy of scaling task losses according to their gradient norms can achieve performance comparable to that of an extensive and computationally expensive grid search. Our comprehensive analysis suggests that understanding and controlling gradient dynamics is a more direct path to stable MTL than developing increasingly complex methods.",
    "arxiv_id": "http://arxiv.org/abs/2509.23915v1",
    "pdf_link": "https://arxiv.org/pdf/2509.23915v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Efficient Domain-Adaptive Multi-Task Dense Prediction with Vision Foundation Models",
    "authors": [
      "Beomseok Kang",
      "Niluthpol Chowdhury Mithun",
      "Mikhail Sizintsev",
      "Han-Pang Chiu",
      "Supun Samarasekera"
    ],
    "published": "2025-09-28T04:02:36Z",
    "abstract": "Multi-task dense prediction, which aims to jointly solve tasks like semantic segmentation and depth estimation, is crucial for robotics applications but suffers from domain shift when deploying models in new environments. While unsupervised domain adaptation (UDA) addresses this challenge for single tasks, existing multi-task UDA methods primarily rely on adversarial learning approaches that are less effective than recent self-training techniques. In this paper, we introduce FAMDA, a simple yet effective UDA framework that bridges this gap by leveraging Vision Foundation Models (VFMs) as powerful teachers. Our approach integrates Segmentation and Depth foundation models into a self-training paradigm to generate high-quality pseudo-labels for the target domain, effectively distilling their robust generalization capabilities into a single, efficient student network. Extensive experiments show that FAMDA achieves state-of-the-art (SOTA) performance on standard synthetic-to-real UDA multi-task learning (MTL) benchmarks and a challenging new day-to-night adaptation task. Our framework enables the training of highly efficient models; a lightweight variant achieves SOTA accuracy while being more than 10$\\times$ smaller than foundation models, highlighting FAMDA's suitability for creating domain-adaptive and efficient models for resource-constrained robotics applications.",
    "arxiv_id": "http://arxiv.org/abs/2509.23626v1",
    "pdf_link": "https://arxiv.org/pdf/2509.23626v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Surgical Video Understanding with Label Interpolation",
    "authors": [
      "Garam Kim",
      "Tae Kyeong Jeong",
      "Juyoun Park"
    ],
    "published": "2025-09-23T08:49:07Z",
    "abstract": "Robot-assisted surgery (RAS) has become a critical paradigm in modern surgery, promoting patient recovery and reducing the burden on surgeons through minimally invasive approaches. To fully realize its potential, however, a precise understanding of the visual data generated during surgical procedures is essential. Previous studies have predominantly focused on single-task approaches, but real surgical scenes involve complex temporal dynamics and diverse instrument interactions that limit comprehensive understanding. Moreover, the effective application of multi-task learning (MTL) requires sufficient pixel-level segmentation data, which are difficult to obtain due to the high cost and expertise required for annotation. In particular, long-term annotations such as phases and steps are available for every frame, whereas short-term annotations such as surgical instrument segmentation and action detection are provided only for key frames, resulting in a significant temporal-spatial imbalance. To address these challenges, we propose a novel framework that combines optical flow-based segmentation label interpolation with multi-task learning. optical flow estimated from annotated key frames is used to propagate labels to adjacent unlabeled frames, thereby enriching sparse spatial supervision and balancing temporal and spatial information for training. This integration improves both the accuracy and efficiency of surgical scene understanding and, in turn, enhances the utility of RAS.",
    "arxiv_id": "http://arxiv.org/abs/2509.18802v1",
    "pdf_link": "https://arxiv.org/pdf/2509.18802v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "On Syntactical Simplification of Temporal Operators in Negation-free MTL",
    "authors": [
      "Mathijs van Noort",
      "Femke Ongenae",
      "Pieter Bonte"
    ],
    "published": "2025-09-12T11:19:41Z",
    "abstract": "Temporal reasoning in dynamic, data-intensive environments increasingly demands expressive yet tractable logical frameworks. Traditional approaches often rely on negation to express absence or contradiction. In such contexts, Negation-as-Failure is commonly used to infer negative information from the lack of positive evidence. However, open and distributed systems such as IoT networks or the Semantic Web Negation-as-Failure semantics become unreliable due to incomplete and asynchronous data. This has led to a growing interest in negation-free fragments of temporal rule-based systems, which preserve monotonicity and enable scalable reasoning.   This paper investigates the expressive power of negation-free MTL, a temporal logic framework designed for rule-based reasoning over time. We show that the \"always\" operators of MTL, often treated as syntactic sugar for combinations of other temporal constructs, can be eliminated using \"once\", \"since\" and \"until\" operators. Remarkably, even the \"once\" operators can be removed, yielding a fragment based solely on \"until\" and \"since\". These results challenge the assumption that negation is necessary for expressing universal temporal constraints, and reveal a robust fragment capable of capturing both existential and invariant temporal patterns. Furthermore, the results induce a reduction in the syntax of MTL, which in turn can provide benefits for both theoretical study as well as implementation efforts.",
    "arxiv_id": "http://arxiv.org/abs/2509.10146v1",
    "pdf_link": "https://arxiv.org/pdf/2509.10146v1",
    "categories": [
      "cs.LO"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Joint Learning using Mixture-of-Expert-Based Representation for Enhanced Speech Generation and Robust Emotion Recognition",
    "authors": [
      "Jing-Tong Tzeng",
      "Carlos Busso",
      "Chi-Chun Lee"
    ],
    "published": "2025-09-10T10:18:56Z",
    "abstract": "Speech emotion recognition (SER) plays a critical role in building emotion-aware speech systems, but its performance degrades significantly under noisy conditions. Although speech enhancement (SE) can improve robustness, it often introduces artifacts that obscure emotional cues and adds computational overhead to the pipeline. Multi-task learning (MTL) offers an alternative by jointly optimizing SE and SER tasks. However, conventional shared-backbone models frequently suffer from gradient interference and representational conflicts between tasks. To address these challenges, we propose the Sparse Mixture-of-Experts Representation Integration Technique (Sparse MERIT), a flexible MTL framework that applies frame-wise expert routing over self-supervised speech representations. Sparse MERIT incorporates task-specific gating networks that dynamically select from a shared pool of experts for each frame, enabling parameter-efficient and task-adaptive representation learning. Experiments on the MSP-Podcast corpus show that Sparse MERIT consistently outperforms baseline models on both SER and SE tasks. Under the most challenging condition of -5 dB signal-to-noise ratio (SNR), Sparse MERIT improves SER F1-macro by an average of 12.0% over a baseline relying on a SE pre-processing strategy, and by 3.4% over a naive MTL baseline, with statistical significance on unseen noise conditions. For SE, Sparse MERIT improves segmental SNR (SSNR) by 28.2% over the SE pre-processing baseline and by 20.0% over the naive MTL baseline. These results demonstrate that Sparse MERIT provides robust and generalizable performance for both emotion recognition and enhancement tasks in noisy environments.",
    "arxiv_id": "http://arxiv.org/abs/2509.08470v1",
    "pdf_link": "https://arxiv.org/pdf/2509.08470v1",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "GCond: Gradient Conflict Resolution via Accumulation-based Stabilization for Large-Scale Multi-Task Learning",
    "authors": [
      "Evgeny Alves Limarenko",
      "Anastasiia Alexandrovna Studenikina"
    ],
    "published": "2025-09-08T22:02:22Z",
    "abstract": "In multi-task learning (MTL), gradient conflict poses a significant challenge. Effective methods for addressing this problem, including PCGrad, CAGrad, and GradNorm, in their original implementations are computationally demanding, which significantly limits their application in modern large models and transformers. We propose Gradient Conductor (GCond), a method that builds upon PCGrad principles by combining them with gradient accumulation and an adaptive arbitration mechanism. We evaluated GCond on self-supervised learning tasks using MobileNetV3-Small and ConvNeXt architectures on the ImageNet 1K dataset and a combined head and neck CT scan dataset, comparing the proposed method against baseline linear combinations and state-of-the-art gradient conflict resolution methods. The stochastic mode of GCond achieved a two-fold computational speedup while maintaining optimization quality, and demonstrated superior performance across all evaluated metrics, achieving lower L1 and SSIM losses compared to other methods on both datasets. GCond exhibited high scalability, being successfully applied to both compact models (MobileNetV3-Small) and large architectures (ConvNeXt-tiny and ConvNeXt-Base). It also showed compatibility with modern optimizers such as AdamW and Lion/LARS. Therefore, GCond offers a scalable and efficient solution to the problem of gradient conflicts in multi-task learning.",
    "arxiv_id": "http://arxiv.org/abs/2509.07252v1",
    "pdf_link": "https://arxiv.org/pdf/2509.07252v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Robust and Adaptive Spectral Method for Representation Multi-Task Learning with Contamination",
    "authors": [
      "Yian Huang",
      "Yang Feng",
      "Zhiliang Ying"
    ],
    "published": "2025-09-08T11:41:30Z",
    "abstract": "Representation-based multi-task learning (MTL) improves efficiency by learning a shared structure across tasks, but its practical application is often hindered by contamination, outliers, or adversarial tasks. Most existing methods and theories assume a clean or near-clean setting, failing when contamination is significant. This paper tackles representation MTL with an unknown and potentially large contamination proportion, while also allowing for heterogeneity among inlier tasks. We introduce a Robust and Adaptive Spectral method (RAS) that can distill the shared inlier representation effectively and efficiently, while requiring no prior knowledge of the contamination level or the true representation dimension. Theoretically, we provide non-asymptotic error bounds for both the learned representation and the per-task parameters. These bounds adapt to inlier task similarity and outlier structure, and guarantee that RAS performs at least as well as single-task learning, thus preventing negative transfer. We also extend our framework to transfer learning with corresponding theoretical guarantees for the target task. Extensive experiments confirm our theory, showcasing the robustness and adaptivity of RAS, and its superior performance in regimes with up to 80\\% task contamination.",
    "arxiv_id": "http://arxiv.org/abs/2509.06575v1",
    "pdf_link": "https://arxiv.org/pdf/2509.06575v1",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Predicting Movie Success with Multi-Task Learning: A Hybrid Framework Combining GPT-Based Sentiment Analysis and SIR Propagation",
    "authors": [
      "Wenlan Xie"
    ],
    "published": "2025-09-02T20:27:26Z",
    "abstract": "This study presents a hybrid framework for predicting movie success. The framework integrates multi-task learning (MTL), GPT-based sentiment analysis, and Susceptible-Infected-Recovered (SIR) propagation modeling. The study examines limitations in existing approaches. It models static production attributes, information dissemination, and audience sentiment at the same time. The framework uses 5,840 films from 2004 to 2024 and approximate 300,000 user reviews. It shows predictive performance with classification accuracy of 0.964 and regression metrics of MAE 0.388. Ablation analysis indicates component interactions. Selective feature combinations perform better than the comprehensive model. This result questions assumptions about feature integration. The model shows virality patterns between successful and unsuccessful films. Innovations include epidemiological modeling for information diffusion, multidimensional sentiment features from GPT-based analysis, and a shared representation architecture that optimizes multiple success metrics. The framework provides applications in the film production lifecycle. It also contributes to understanding how audience engagement leads to commercial outcomes.",
    "arxiv_id": "http://arxiv.org/abs/2509.02809v2",
    "pdf_link": "https://arxiv.org/pdf/2509.02809v2",
    "categories": [
      "cs.SI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Improving Interpretability in Alzheimer's Prediction via Joint Learning of ADAS-Cog Scores",
    "authors": [
      "Nur Amirah Abd Hamid",
      "Mohd Shahrizal Rusli",
      "Muhammad Thaqif Iman Mohd Taufek",
      "Mohd Ibrahim Shapiai",
      "Daphne Teck Ching Lai"
    ],
    "published": "2025-08-25T02:56:11Z",
    "abstract": "Accurate prediction of clinical scores is critical for early detection and prognosis of Alzheimers disease (AD). While existing approaches primarily focus on forecasting the ADAS-Cog global score, they often overlook the predictive value of its sub-scores (13 items), which capture domain-specific cognitive decline. In this study, we propose a multi task learning (MTL) framework that jointly predicts the global ADAS-Cog score and its sub-scores (13 items) at Month 24 using baseline MRI and longitudinal clinical scores from baseline and Month 6. The main goal is to examine how each sub scores particularly those associated with MRI features contribute to the prediction of the global score, an aspect largely neglected in prior MTL studies. We employ Vision Transformer (ViT) and Swin Transformer architectures to extract imaging features, which are fused with longitudinal clinical inputs to model cognitive progression. Our results show that incorporating sub-score learning improves global score prediction. Subscore level analysis reveals that a small subset especially Q1 (Word Recall), Q4 (Delayed Recall), and Q8 (Word Recognition) consistently dominates the predicted global score. However, some of these influential sub-scores exhibit high prediction errors, pointing to model instability. Further analysis suggests that this is caused by clinical feature dominance, where the model prioritizes easily predictable clinical scores over more complex MRI derived features. These findings emphasize the need for improved multimodal fusion and adaptive loss weighting to achieve more balanced learning. Our study demonstrates the value of sub score informed modeling and provides insights into building more interpretable and clinically robust AD prediction frameworks. (Github repo provided)",
    "arxiv_id": "http://arxiv.org/abs/2508.17619v1",
    "pdf_link": "https://arxiv.org/pdf/2508.17619v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "A Weighted Vision Transformer-Based Multi-Task Learning Framework for Predicting ADAS-Cog Scores",
    "authors": [
      "Nur Amirah Abd Hamid",
      "Mohd Ibrahim Shapiai",
      "Daphne Teck Ching Lai"
    ],
    "published": "2025-08-25T02:43:48Z",
    "abstract": "Prognostic modeling is essential for forecasting future clinical scores and enabling early detection of Alzheimers disease (AD). While most existing methods focus on predicting the ADAS-Cog global score, they often overlook the predictive value of its 13 sub-scores, which reflect distinct cognitive domains. Some sub-scores may exert greater influence on determining global scores. Assigning higher loss weights to these clinically meaningful sub-scores can guide the model to focus on more relevant cognitive domains, enhancing both predictive accuracy and interpretability. In this study, we propose a weighted Vision Transformer (ViT)-based multi-task learning (MTL) framework to jointly predict the ADAS-Cog global score using baseline MRI scans and its 13 sub-scores at Month 24. Our framework integrates ViT as a feature extractor and systematically investigates the impact of sub-score-specific loss weighting on model performance. Results show that our proposed weighting strategies are group-dependent: strong weighting improves performance for MCI subjects with more heterogeneous MRI patterns, while moderate weighting is more effective for CN subjects with lower variability. Our findings suggest that uniform weighting underutilizes key sub-scores and limits generalization. The proposed framework offers a flexible, interpretable approach to AD prognosis using end-to-end MRI-based learning. (Github repo link will be provided after review)",
    "arxiv_id": "http://arxiv.org/abs/2508.17613v1",
    "pdf_link": "https://arxiv.org/pdf/2508.17613v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Tensorized Multi-Task Learning for Personalized Modeling of Heterogeneous Individuals with High-Dimensional Data",
    "authors": [
      "Elif Konyar",
      "Mostafa Reisi Gahrooei",
      "Kamran Paynabar"
    ],
    "published": "2025-08-21T15:55:50Z",
    "abstract": "Effective modeling of heterogeneous subpopulations presents a significant challenge due to variations in individual characteristics and behaviors. This paper proposes a novel approach to address this issue through multi-task learning (MTL) and low-rank tensor decomposition techniques. Our MTL approach aims to enhance personalized modeling by leveraging shared structures among similar tasks while accounting for distinct subpopulation-specific variations. We introduce a framework where low-rank decomposition decomposes the collection of task model parameters into a low-rank structure that captures commonalities and variations across tasks and subpopulations. This approach allows for efficient learning of personalized models by sharing knowledge between similar tasks while preserving the unique characteristics of each subpopulation. Experimental results in simulation and case study datasets demonstrate the superior performance of the proposed method compared to several benchmarks, particularly in scenarios with high variability among subpopulations. The proposed framework not only improves prediction accuracy but also enhances interpretability by revealing underlying patterns that contribute to the personalization of models.",
    "arxiv_id": "http://arxiv.org/abs/2508.15676v1",
    "pdf_link": "https://arxiv.org/pdf/2508.15676v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "TriForecaster: A Mixture of Experts Framework for Multi-Region Electric Load Forecasting with Tri-dimensional Specialization",
    "authors": [
      "Zhaoyang Zhu",
      "Zhipeng Zeng",
      "Qiming Chen",
      "Linxiao Yang",
      "Peiyuan Liu",
      "Weiqi Chen",
      "Liang Sun"
    ],
    "published": "2025-08-13T12:34:15Z",
    "abstract": "Electric load forecasting is pivotal for power system operation, planning and decision-making. The rise of smart grids and meters has provided more detailed and high-quality load data at multiple levels of granularity, from home to bus and cities. Motivated by similar patterns of loads across different cities in a province in eastern China, in this paper we focus on the Multi-Region Electric Load Forecasting (MRELF) problem, targeting accurate short-term load forecasting for multiple sub-regions within a large region. We identify three challenges for MRELF, including regional variation, contextual variation, and temporal variation. To address them, we propose TriForecaster, a new framework leveraging the Mixture of Experts (MoE) approach within a Multi-Task Learning (MTL) paradigm to overcome these challenges. TriForecaster features RegionMixer and Context-Time Specializer (CTSpecializer) layers, enabling dynamic cooperation and specialization of expert models across regional, contextual, and temporal dimensions. Based on evaluation on four real-world MRELF datasets with varied granularity, TriForecaster outperforms state-of-the-art models by achieving an average forecast error reduction of 22.4\\%, thereby demonstrating its flexibility and broad applicability. In particular, the deployment of TriForecaster on the eForecaster platform in eastern China exemplifies its practical utility, effectively providing city-level, short-term load forecasts for 17 cities, supporting a population exceeding 110 million and daily electricity usage over 100 gigawatt-hours.",
    "arxiv_id": "http://arxiv.org/abs/2508.09753v1",
    "pdf_link": "https://arxiv.org/pdf/2508.09753v1",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Federated Multi-Objective Learning with Controlled Pareto Frontiers",
    "authors": [
      "Jiansheng Rao",
      "Jiayi Li",
      "Zhizhi Gong",
      "Soummya Kar",
      "Haoxuan Li"
    ],
    "published": "2025-08-07T14:15:12Z",
    "abstract": "Federated learning (FL) is a widely adopted paradigm for privacy-preserving model training, but FedAvg optimise for the majority while under-serving minority clients. Existing methods such as federated multi-objective learning (FMOL) attempts to import multi-objective optimisation (MOO) into FL. However, it merely delivers task-wise Pareto-stationary points, leaving client fairness to chance. In this paper, we introduce Conically-Regularised FMOL (CR-FMOL), the first federated MOO framework that enforces client-wise Pareto optimality through a novel preference-cone constraint. After local federated multi-gradient descent averaging (FMGDA) / federated stochastic multi-gradient descent averaging (FSMGDA) steps, each client transmits its aggregated task-loss vector as an implicit preference; the server then solves a cone-constrained Pareto-MTL sub-problem centred at the uniform vector, producing a descent direction that is Pareto-stationary for every client within its cone. Experiments on non-IID benchmarks show that CR-FMOL enhances client fairness, and although the early-stage performance is slightly inferior to FedAvg, it is expected to achieve comparable accuracy given sufficient training rounds.",
    "arxiv_id": "http://arxiv.org/abs/2508.05424v3",
    "pdf_link": "https://arxiv.org/pdf/2508.05424v3",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning",
    "authors": [
      "Jinda Liu",
      "Bo Cheng",
      "Yi Chang",
      "Yuan Wu"
    ],
    "published": "2025-08-07T07:02:55Z",
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large Language Models (LLMs). In practice, LLMs are often required to handle a diverse set of tasks from multiple domains, a scenario naturally addressed by multi-task learning (MTL). Within this MTL context, a prevailing trend involves LoRA variants with multiple adapters or heads, which advocate for structural diversity to capture task-specific knowledge. Our findings present a direct challenge to this paradigm. We first show that a simplified multi-head architecture with high inter-head similarity substantially outperforms complex multi-adapter and multi-head systems. This leads us to question the multi-component paradigm itself, and we further demonstrate that a standard single-adapter LoRA, with a sufficiently increased rank, also achieves highly competitive performance. These results lead us to a new hypothesis: effective MTL generalization hinges on learning robust shared representations, not isolating task-specific features. To validate this, we propose Align-LoRA, which incorporates an explicit loss to align task representations within the shared adapter space. Experiments confirm that Align-LoRA significantly surpasses all baselines, establishing a simpler yet more effective paradigm for adapting LLMs to multiple tasks. The code is available at https://github.com/jinda-liu/Align-LoRA.",
    "arxiv_id": "http://arxiv.org/abs/2508.05078v1",
    "pdf_link": "https://arxiv.org/pdf/2508.05078v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Momentum-integrated Multi-task Stock Recommendation with Converge-based Optimization",
    "authors": [
      "Hao Wang",
      "Jingshu Peng",
      "Yanyan Shen",
      "Xujia Li",
      "Lei Chen"
    ],
    "published": "2025-08-05T09:04:38Z",
    "abstract": "Stock recommendation is critical in Fintech applications, which use price series and alternative information to estimate future stock performance. Although deep learning models are prevalent in stock recommendation systems, traditional time-series forecasting training often fails to capture stock trends and rankings simultaneously, which are essential consideration factors for investors. To tackle this issue, we introduce a Multi-Task Learning (MTL) framework for stock recommendation, \\textbf{M}omentum-\\textbf{i}ntegrated \\textbf{M}ulti-task \\textbf{Stoc}k \\textbf{R}ecommendation with Converge-based Optimization (\\textbf{MiM-StocR}). To improve the model's ability to capture short-term trends, we novelly invoke a momentum line indicator in model training. To prioritize top-performing stocks and optimize investment allocation, we propose a list-wise ranking loss function called Adaptive-k ApproxNDCG. Moreover, due to the volatility and uncertainty of the stock market, existing MTL frameworks face overfitting issues when applied to stock time series. To mitigate this issue, we introduce the Converge-based Quad-Balancing (CQB) method. We conducted extensive experiments on three stock benchmarks: SEE50, CSI 100, and CSI 300. MiM-StocR outperforms state-of-the-art MTL baselines across both ranking and profitable evaluations.",
    "arxiv_id": "http://arxiv.org/abs/2509.10461v1",
    "pdf_link": "https://arxiv.org/pdf/2509.10461v1",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "A Survey on Deep Multi-Task Learning in Connected Autonomous Vehicles",
    "authors": [
      "Jiayuan Wang",
      "Farhad Pourpanah",
      "Q. M. Jonathan Wu",
      "Ning Zhang"
    ],
    "published": "2025-07-29T22:17:28Z",
    "abstract": "Connected autonomous vehicles (CAVs) must simultaneously perform multiple tasks, such as object detection, semantic segmentation, depth estimation, trajectory prediction, motion prediction, and behaviour prediction, to ensure safe and reliable navigation in complex environments. Vehicle-to-everything (V2X) communication enables cooperative driving among CAVs, thereby mitigating the limitations of individual sensors, reducing occlusions, and improving perception over long distances. Traditionally, these tasks are addressed using distinct models, which leads to high deployment costs, increased computational overhead, and challenges in achieving real-time performance. Multi-task learning (MTL) has recently emerged as a promising solution that enables the joint learning of multiple tasks within a single unified model. This offers improved efficiency and resource utilization. To the best of our knowledge, this survey is the first comprehensive review focused on MTL in the context of CAVs. We begin with an overview of CAVs and MTL to provide foundational background. We then explore the application of MTL across key functional modules, including perception, prediction, planning, control, and multi-agent collaboration. Finally, we discuss the strengths and limitations of existing methods, identify key research gaps, and provide directions for future research aimed at advancing MTL methodologies for CAV systems.",
    "arxiv_id": "http://arxiv.org/abs/2508.00917v1",
    "pdf_link": "https://arxiv.org/pdf/2508.00917v1",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning",
    "authors": [
      "Zedong Wang",
      "Siyuan Li",
      "Dan Xu"
    ],
    "published": "2025-07-28T17:59:28Z",
    "abstract": "Despite the promise of Multi-Task Learning in leveraging complementary knowledge across tasks, existing multi-task optimization (MTO) techniques remain fixated on resolving conflicts via optimizer-centric loss scaling and gradient manipulation strategies, yet fail to deliver consistent gains. In this paper, we argue that the shared representation space, where task interactions naturally occur, offers rich information and potential for operations complementary to existing optimizers, especially for facilitating the inter-task complementarity, which is rarely explored in MTO. This intuition leads to Rep-MTL, which exploits the representation-level task saliency to quantify interactions between task-specific optimization and shared representation learning. By steering these saliencies through entropy-based penalization and sample-wise cross-task alignment, Rep-MTL aims to mitigate negative transfer by maintaining the effective training of individual tasks instead pure conflict-solving, while explicitly promoting complementary information sharing. Experiments are conducted on four challenging MTL benchmarks covering both task-shift and domain-shift scenarios. The results show that Rep-MTL, even paired with the basic equal weighting policy, achieves competitive performance gains with favorable efficiency. Beyond standard performance metrics, Power Law exponent analysis demonstrates Rep-MTL's efficacy in balancing task-specific learning and cross-task sharing. The project page is available at HERE.",
    "arxiv_id": "http://arxiv.org/abs/2507.21049v1",
    "pdf_link": "https://arxiv.org/pdf/2507.21049v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Multi-Task Dense Prediction Fine-Tuning with Mixture of Fine-Grained Experts",
    "authors": [
      "Yangyang Xu",
      "Xi Ye",
      "Duo Su"
    ],
    "published": "2025-07-25T08:59:30Z",
    "abstract": "Multi-task learning (MTL) for dense prediction has shown promising results but still faces challenges in balancing shared representations with task-specific specialization. In this paper, we introduce a novel Fine-Grained Mixture of Experts (FGMoE) architecture that explores MoE-based MTL models through a combination of three key innovations and fine-tuning. First, we propose intra-task experts that partition along intermediate hidden dimensions of MLPs, enabling finer decomposition of task information while maintaining parameter efficiency. Second, we introduce shared experts that consolidate common information across different contexts of the same task, reducing redundancy, and allowing routing experts to focus on unique aspects. Third, we design a global expert that facilitates adaptive knowledge transfer across tasks based on both input feature and task requirements, promoting beneficial information sharing while preventing harmful interference. In addition, we use the fine-tuning approach to improve parameter efficiency only by training the parameters of the decoder. Extensive experimental results show that the proposed FGMoE uses fewer parameters and significantly outperforms current MoE-based competitive MTL models on two dense prediction datasets (\\textit{i.e.,} NYUD-v2, PASCAL-Context) in various metrics.",
    "arxiv_id": "http://arxiv.org/abs/2507.19077v1",
    "pdf_link": "https://arxiv.org/pdf/2507.19077v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Balancing Semantic Relevance and Engagement in Related Video Recommendations",
    "authors": [
      "Amit Jaspal",
      "Feng Zhang",
      "Wei Chang",
      "Sumit Kumar",
      "Yubo Wang",
      "Roni Mittleman",
      "Qifan Wang",
      "Weize Mao"
    ],
    "published": "2025-07-12T21:04:25Z",
    "abstract": "Related video recommendations commonly use collaborative filtering (CF) driven by co-engagement signals, often resulting in recommendations lacking semantic coherence and exhibiting strong popularity bias. This paper introduces a novel multi-objective retrieval framework, enhancing standard two-tower models to explicitly balance semantic relevance and user engagement. Our approach uniquely combines: (a) multi-task learning (MTL) to jointly optimize co-engagement and semantic relevance, explicitly prioritizing topical coherence; (b) fusion of multimodal content features (textual and visual embeddings) for richer semantic understanding; and (c) off-policy correction (OPC) via inverse propensity weighting to effectively mitigate popularity bias. Evaluation on industrial-scale data and a two-week live A/B test reveals our framework's efficacy. We observed significant improvements in semantic relevance (from 51% to 63% topic match rate), a reduction in popular item distribution (-13.8% popular video recommendations), and a +0.04% improvement in our topline user engagement metric. Our method successfully achieves better semantic coherence, balanced engagement, and practical scalability for real-world deployment.",
    "arxiv_id": "http://arxiv.org/abs/2507.09403v1",
    "pdf_link": "https://arxiv.org/pdf/2507.09403v1",
    "categories": [
      "cs.IR",
      "cs.MM"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation",
    "authors": [
      "Hao Ban",
      "Gokul Ram Subramani",
      "Kaiyi Ji"
    ],
    "published": "2025-07-10T16:06:02Z",
    "abstract": "Multi-task learning (MTL) enables a joint model to capture commonalities across multiple tasks, reducing computation costs and improving data efficiency. However, a major challenge in MTL optimization is task conflicts, where the task gradients differ in direction or magnitude, limiting model performance compared to single-task counterparts. Sharpness-aware minimization (SAM) minimizes task loss while simultaneously reducing the sharpness of the loss landscape. Our empirical observations show that SAM effectively mitigates task conflicts in MTL. Motivated by these findings, we explore integrating SAM into MTL but face two key challenges. While both the average loss gradient and individual task gradients-referred to as global and local information-contribute to SAM, how to combine them remains unclear. Moreover, directly computing each task gradient introduces significant computational and memory overheads. To address these challenges, we propose SAMO, a lightweight \\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization approach, that leverages a joint global-local perturbation. The local perturbations are approximated using only forward passes and are layerwise normalized to improve efficiency. Extensive experiments on a suite of multi-task benchmarks demonstrate both the effectiveness and efficiency of our method. Code is available at https://github.com/OptMN-Lab/SAMO.",
    "arxiv_id": "http://arxiv.org/abs/2507.07883v3",
    "pdf_link": "https://arxiv.org/pdf/2507.07883v3",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision Foundation Models and Multi-Task Learning",
    "authors": [
      "Tianwei Mu",
      "Feiyu Duan",
      "Bo Zhou",
      "Dan Xue",
      "Manhong Huang"
    ],
    "published": "2025-07-10T09:29:26Z",
    "abstract": "This paper presents a novel few-shot cross-domain anomaly detection framework, Nexus Vision Transformer for Anomaly Detection (NexViTAD), based on vision foundation models, which effectively addresses domain-shift challenges in industrial anomaly detection through innovative shared subspace projection mechanisms and multi-task learning (MTL) module. The main innovations include: (1) a hierarchical adapter module that adaptively fuses complementary features from Hiera and DINO-v2 pre-trained models, constructing more robust feature representations; (2) a shared subspace projection strategy that enables effective cross-domain knowledge transfer through bottleneck dimension constraints and skip connection mechanisms; (3) a MTL Decoder architecture supports simultaneous processing of multiple source domains, significantly enhancing model generalization capabilities; (4) an anomaly score inference method based on Sinkhorn-K-means clustering, combined with Gaussian filtering and adaptive threshold processing for precise pixel level. Valuated on the MVTec AD dataset, NexViTAD delivers state-of-the-art performance with an AUC of 97.5%, AP of 70.4%, and PRO of 95.2% in the target domains, surpassing other recent models, marking a transformative advance in cross-domain defect detection.",
    "arxiv_id": "http://arxiv.org/abs/2507.07579v1",
    "pdf_link": "https://arxiv.org/pdf/2507.07579v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning",
    "authors": [
      "Wooseong Jeong",
      "Kuk-Jin Yoon"
    ],
    "published": "2025-07-10T07:13:22Z",
    "abstract": "Multi-Task Learning (MTL) enables multiple tasks to be learned within a shared network, but differences in objectives across tasks can cause negative transfer, where the learning of one task degrades another task's performance. While pre-trained transformers significantly improve MTL performance, their fixed network capacity and rigid structure limit adaptability. Previous dynamic network architectures attempt to address this but are inefficient as they directly convert shared parameters into task-specific ones. We propose Dynamic Token Modulation and Expansion (DTME-MTL), a framework applicable to any transformer-based MTL architecture. DTME-MTL enhances adaptability and reduces overfitting by identifying gradient conflicts in token space and applying adaptive solutions based on conflict type. Unlike prior methods that mitigate negative transfer by duplicating network parameters, DTME-MTL operates entirely in token space, enabling efficient adaptation without excessive parameter growth. Extensive experiments demonstrate that DTME-MTL consistently improves multi-task performance with minimal computational overhead, offering a scalable and effective solution for enhancing transformer-based MTL models.",
    "arxiv_id": "http://arxiv.org/abs/2507.07485v2",
    "pdf_link": "https://arxiv.org/pdf/2507.07485v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Improving vulnerability type prediction and line-level detection via adversarial training-based data augmentation and multi-task learning",
    "authors": [
      "Siyu Chen",
      "Jiongyi Yang",
      "Xiang Chen",
      "Menglin Zheng",
      "Minnan Wei",
      "Xiaolin Ju"
    ],
    "published": "2025-06-30T05:47:09Z",
    "abstract": "Context: Software vulnerabilities pose a significant threat to modern software systems, as evidenced by the growing number of reported vulnerabilities and cyberattacks. These escalating trends underscore the urgent need for effective approaches that can automatically detect and understand software vulnerabilities. Objective: However, the scarcity of labeled samples and the class imbalance issue in vulnerability datasets present significant challenges for both Vulnerability Type Prediction (VTP) and Line-level Vulnerability Detection (LVD), especially for rare yet critical vulnerability types. Moreover, most existing studies treat VTP and LVD as independent tasks, overlooking their inherent correlation, which limits the potential to leverage shared semantic patterns across tasks. Methods: To address these limitations, we propose a unified approach that integrates Embedding-Layer Driven Adversarial Training (EDAT) with Multi-task Learning (MTL). Specifically, EDAT enhances model robustness by introducing adversarial perturbations to identifier embeddings, guided by semantic importance. Meanwhile, MTL improves overall performance by leveraging shared representations and inter-task correlations between VTP and LVD. Results: Extensive experiments demonstrate that our proposed approach outperforms state-of-the-art baselines on both VTP and LVD tasks. For VTP, it yields notable improvements in accuracy, precision, recall, and F1-score, particularly in identifying rare vulnerability types. Similarly, for LVD, our approach enhances line-level detection accuracy while significantly reducing false positives. Conclusion: Our study demonstrates that combining EDAT with MTL provides a unified solution that improves performance on both tasks and warrants further investigation.",
    "arxiv_id": "http://arxiv.org/abs/2506.23534v1",
    "pdf_link": "https://arxiv.org/pdf/2506.23534v1",
    "categories": [
      "cs.SE"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?",
    "authors": [
      "Gautam Siddharth Kashyap",
      "Manaswi Kulahara",
      "Nipun Joshi",
      "Usman Naseem"
    ],
    "published": "2025-06-25T10:50:33Z",
    "abstract": "Remote sensing datasets offer significant promise for tackling key classification tasks such as land-use categorization, object presence detection, and rural/urban classification. However, many existing studies tend to focus on narrow tasks or datasets, which limits their ability to generalize across various remote sensing classification challenges. To overcome this, we propose a novel model, SpatialNet-ViT, leveraging the power of Vision Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach combines spatial awareness with contextual understanding, improving both classification accuracy and scalability. Additionally, techniques like data augmentation, transfer learning, and multi-task learning are employed to enhance model robustness and its ability to generalize across diverse datasets",
    "arxiv_id": "http://arxiv.org/abs/2506.22501v1",
    "pdf_link": "https://arxiv.org/pdf/2506.22501v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "TEM^3-Learning: Time-Efficient Multimodal Multi-Task Learning for Advanced Assistive Driving",
    "authors": [
      "Wenzhuo Liu",
      "Yicheng Qiao",
      "Zhen Wang",
      "Qiannan Guo",
      "Zilong Chen",
      "Meihua Zhou",
      "Xinran Li",
      "Letian Wang",
      "Zhiwei Li",
      "Huaping Liu",
      "Wenshuo Wang"
    ],
    "published": "2025-06-22T16:12:27Z",
    "abstract": "Multi-task learning (MTL) can advance assistive driving by exploring inter-task correlations through shared representations. However, existing methods face two critical limitations: single-modality constraints limiting comprehensive scene understanding and inefficient architectures impeding real-time deployment. This paper proposes TEM^3-Learning (Time-Efficient Multimodal Multi-task Learning), a novel framework that jointly optimizes driver emotion recognition, driver behavior recognition, traffic context recognition, and vehicle behavior recognition through a two-stage architecture. The first component, the mamba-based multi-view temporal-spatial feature extraction subnetwork (MTS-Mamba), introduces a forward-backward temporal scanning mechanism and global-local spatial attention to efficiently extract low-cost temporal-spatial features from multi-view sequential images. The second component, the MTL-based gated multimodal feature integrator (MGMI), employs task-specific multi-gating modules to adaptively highlight the most relevant modality features for each task, effectively alleviating the negative transfer problem in MTL. Evaluation on the AIDE dataset, our proposed model achieves state-of-the-art accuracy across all four tasks, maintaining a lightweight architecture with fewer than 6 million parameters and delivering an impressive 142.32 FPS inference speed. Rigorous ablation studies further validate the effectiveness of the proposed framework and the independent contributions of each module. The code is available on https://github.com/Wenzhuo-Liu/TEM3-Learning.",
    "arxiv_id": "http://arxiv.org/abs/2506.18084v1",
    "pdf_link": "https://arxiv.org/pdf/2506.18084v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Black-Box Privacy Attacks on Shared Representations in Multitask Learning",
    "authors": [
      "John Abascal",
      "Nicolás Berrios",
      "Alina Oprea",
      "Jonathan Ullman",
      "Adam Smith",
      "Matthew Jagielski"
    ],
    "published": "2025-06-19T16:56:41Z",
    "abstract": "Multitask learning (MTL) has emerged as a powerful paradigm that leverages similarities among multiple learning tasks, each with insufficient samples to train a standalone model, to solve them simultaneously while minimizing data sharing across users and organizations. MTL typically accomplishes this goal by learning a shared representation that captures common structure among the tasks by embedding data from all tasks into a common feature space. Despite being designed to be the smallest unit of shared information necessary to effectively learn patterns across multiple tasks, these shared representations can inadvertently leak sensitive information about the particular tasks they were trained on.   In this work, we investigate what information is revealed by the shared representations through the lens of inference attacks. Towards this, we propose a novel, black-box task-inference threat model where the adversary, given the embedding vectors produced by querying the shared representation on samples from a particular task, aims to determine whether that task was present when training the shared representation. We develop efficient, purely black-box attacks on machine learning models that exploit the dependencies between embeddings from the same task without requiring shadow models or labeled reference data. We evaluate our attacks across vision and language domains for multiple use cases of MTL and demonstrate that even with access only to fresh task samples rather than training data, a black-box adversary can successfully infer a task's inclusion in training. To complement our experiments, we provide theoretical analysis of a simplified learning setting and show a strict separation between adversaries with training samples and fresh samples from the target task's distribution.",
    "arxiv_id": "http://arxiv.org/abs/2506.16460v1",
    "pdf_link": "https://arxiv.org/pdf/2506.16460v1",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "CALM: Consensus-Aware Localized Merging for Multi-Task Learning",
    "authors": [
      "Kunda Yan",
      "Min Zhang",
      "Sen Cui",
      "Zikun Qu",
      "Bo Jiang",
      "Feng Liu",
      "Changshui Zhang"
    ],
    "published": "2025-06-16T12:19:45Z",
    "abstract": "Model merging aims to integrate the strengths of multiple fine-tuned models into a unified model while preserving task-specific capabilities. Existing methods, represented by task arithmetic, are typically classified into global- and local-aware methods. However, global-aware methods inevitably cause parameter interference, while local-aware methods struggle to maintain the effectiveness of task-specific details in the merged model. To address these limitations, we propose a Consensus-Aware Localized Merging (CALM) method which incorporates localized information aligned with global task consensus, ensuring its effectiveness post-merging. CALM consists of three key components: (1) class-balanced entropy minimization sampling, providing a more flexible and reliable way to leverage unsupervised data; (2) an efficient-aware framework, selecting a small set of tasks for sequential merging with high scalability; (3) a consensus-aware mask optimization, aligning localized binary masks with global task consensus and merging them conflict-free. Experiments demonstrate the superiority and robustness of our CALM, significantly outperforming existing methods and achieving performance close to traditional MTL.",
    "arxiv_id": "http://arxiv.org/abs/2506.13406v1",
    "pdf_link": "https://arxiv.org/pdf/2506.13406v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Gradient Similarity Surgery in Multi-Task Deep Learning",
    "authors": [
      "Thomas Borsani",
      "Andrea Rosani",
      "Giuseppe Nicosia",
      "Giuseppe Di Fatta"
    ],
    "published": "2025-06-06T14:40:50Z",
    "abstract": "The multi-task learning ($MTL$) paradigm aims to simultaneously learn multiple tasks within a single model capturing higher-level, more general hidden patterns that are shared by the tasks. In deep learning, a significant challenge in the backpropagation training process is the design of advanced optimisers to improve the convergence speed and stability of the gradient descent learning rule. In particular, in multi-task deep learning ($MTDL$) the multitude of tasks may generate potentially conflicting gradients that would hinder the concurrent convergence of the diverse loss functions. This challenge arises when the gradients of the task objectives have either different magnitudes or opposite directions, causing one or a few to dominate or to interfere with each other, thus degrading the training process. Gradient surgery methods address the problem explicitly dealing with conflicting gradients by adjusting the overall gradient trajectory. This work introduces a novel gradient surgery method, the Similarity-Aware Momentum Gradient Surgery (SAM-GS), which provides an effective and scalable approach based on a gradient magnitude similarity measure to guide the optimisation process. The SAM-GS surgery adopts gradient equalisation and modulation of the first-order momentum. A series of experimental tests have shown the effectiveness of SAM-GS on synthetic problems and $MTL$ benchmarks. Gradient magnitude similarity plays a crucial role in regularising gradient aggregation in $MTDL$ for the optimisation of the learning process.",
    "arxiv_id": "http://arxiv.org/abs/2506.06130v1",
    "pdf_link": "https://arxiv.org/pdf/2506.06130v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "MTL-KD: Multi-Task Learning Via Knowledge Distillation for Generalizable Neural Vehicle Routing Solver",
    "authors": [
      "Yuepeng Zheng",
      "Fu Luo",
      "Zhenkun Wang",
      "Yaoxin Wu",
      "Yu Zhou"
    ],
    "published": "2025-06-03T14:35:36Z",
    "abstract": "Multi-Task Learning (MTL) in Neural Combinatorial Optimization (NCO) is a promising approach to train a unified model capable of solving multiple Vehicle Routing Problem (VRP) variants. However, existing Reinforcement Learning (RL)-based multi-task methods can only train light decoder models on small-scale problems, exhibiting limited generalization ability when solving large-scale problems. To overcome this limitation, this work introduces a novel multi-task learning method driven by knowledge distillation (MTL-KD), which enables the efficient training of heavy decoder models with strong generalization ability. The proposed MTL-KD method transfers policy knowledge from multiple distinct RL-based single-task models to a single heavy decoder model, facilitating label-free training and effectively improving the model's generalization ability across diverse tasks. In addition, we introduce a flexible inference strategy termed Random Reordering Re-Construction (R3C), which is specifically adapted for diverse VRP tasks and further boosts the performance of the multi-task model. Experimental results on 6 seen and 10 unseen VRP variants with up to 1000 nodes indicate that our proposed method consistently achieves superior performance on both uniform and real-world benchmarks, demonstrating robust generalization abilities.",
    "arxiv_id": "http://arxiv.org/abs/2506.02935v4",
    "pdf_link": "https://arxiv.org/pdf/2506.02935v4",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Enhancing Customer Service Chatbots with Context-Aware NLU through Selective Attention and Multi-task Learning",
    "authors": [
      "Subhadip Nandi",
      "Neeraj Agrawal",
      "Anshika Singh",
      "Priyanka Bhatt"
    ],
    "published": "2025-06-02T15:24:28Z",
    "abstract": "Customer service chatbots are conversational systems aimed at addressing customer queries, often by directing them to automated workflows. A crucial aspect of this process is the classification of the customer's intent. Presently, most intent classification models for customer care utilise only customer query for intent prediction. This may result in low-accuracy models, which cannot handle ambiguous queries. An ambiguous query like \"I didn't receive my package\" could indicate a delayed order, or an order that was delivered but the customer failed to receive it. Resolution of each of these scenarios requires the execution of very different sequence of steps. Utilizing additional information, such as the customer's order delivery status, in the right manner can help identify the intent for such ambiguous queries. In this paper, we have introduced a context-aware NLU model that incorporates both, the customer query and contextual information from the customer's order status for predicting customer intent. A novel selective attention module is used to extract relevant context features. We have also proposed a multi-task learning paradigm for the effective utilization of different label types available in our training data. Our suggested method, Multi-Task Learning Contextual NLU with Selective Attention Weighted Context (MTL-CNLU-SAWC), yields a 4.8% increase in top 2 accuracy score over the baseline model which only uses user queries, and a 3.5% improvement over existing state-of-the-art models that combine query and context. We have deployed our model to production for Walmart's customer care domain. Accurate intent prediction through MTL-CNLU-SAWC helps to better direct customers to automated workflows, thereby significantly reducing escalations to human agents, leading to almost a million dollars in yearly savings for the company.",
    "arxiv_id": "http://arxiv.org/abs/2506.01781v1",
    "pdf_link": "https://arxiv.org/pdf/2506.01781v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "FastCAR: Fast Classification And Regression for Task Consolidation in Multi-Task Learning to Model a Continuous Property Variable of Detected Object Class",
    "authors": [
      "Anoop Kini",
      "Andreas Jansche",
      "Timo Bernthaler",
      "Gerhard Schneider"
    ],
    "published": "2025-05-30T20:31:06Z",
    "abstract": "FastCAR is a novel task consolidation approach in Multi-Task Learning (MTL) for a classification and a regression task, despite the non-triviality of task heterogeneity with only a subtle correlation. The approach addresses the classification of a detected object (occupying the entire image frame) and regression for modeling a continuous property variable (for instances of an object class), a crucial use case in science and engineering. FastCAR involves a label transformation approach that is amenable for use with only a single-task regression network architecture. FastCAR outperforms traditional MTL model families, parametrized in the landscape of architecture and loss weighting schemes, when learning both tasks are collectively considered (classification accuracy of 99.54%, regression mean absolute percentage error of 2.4%). The experiments performed used \"Advanced Steel Property Dataset\" contributed by us https://github.com/fastcandr/AdvancedSteel-Property-Dataset. The dataset comprises 4536 images of 224x224 pixels, annotated with discrete object classes and its hardness property that can take continuous values. Our proposed FastCAR approach for task consolidation achieves training time efficiency (2.52x quicker) and reduced inference latency (55% faster) than benchmark MTL networks.",
    "arxiv_id": "http://arxiv.org/abs/2506.00208v1",
    "pdf_link": "https://arxiv.org/pdf/2506.00208v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Multi-task Learning for Heterogeneous Multi-source Block-Wise Missing Data",
    "authors": [
      "Yang Sui",
      "Qi Xu",
      "Yang Bai",
      "Annie Qu"
    ],
    "published": "2025-05-30T09:52:03Z",
    "abstract": "Multi-task learning (MTL) has emerged as an imperative machine learning tool to solve multiple learning tasks simultaneously and has been successfully applied to healthcare, marketing, and biomedical fields. However, in order to borrow information across different tasks effectively, it is essential to utilize both homogeneous and heterogeneous information. Among the extensive literature on MTL, various forms of heterogeneity are presented in MTL problems, such as block-wise, distribution, and posterior heterogeneity. Existing methods, however, struggle to tackle these forms of heterogeneity simultaneously in a unified framework. In this paper, we propose a two-step learning strategy for MTL which addresses the aforementioned heterogeneity. First, we impute the missing blocks using shared representations extracted from homogeneous source across different tasks. Next, we disentangle the mappings between input features and responses into a shared component and a task-specific component, respectively, thereby enabling information borrowing through the shared component. Our numerical experiments and real-data analysis from the ADNI database demonstrate the superior MTL performance of the proposed method compared to other competing methods.",
    "arxiv_id": "http://arxiv.org/abs/2505.24413v1",
    "pdf_link": "https://arxiv.org/pdf/2505.24413v1",
    "categories": [
      "cs.LG",
      "stat.CO"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Multi-task Learning for Heterogeneous Data via Integrating Shared and Task-Specific Encodings",
    "authors": [
      "Yang Sui",
      "Qi Xu",
      "Yang Bai",
      "Annie Qu"
    ],
    "published": "2025-05-30T06:58:42Z",
    "abstract": "Multi-task learning (MTL) has become an essential machine learning tool for addressing multiple learning tasks simultaneously and has been effectively applied across fields such as healthcare, marketing, and biomedical research. However, to enable efficient information sharing across tasks, it is crucial to leverage both shared and heterogeneous information. Despite extensive research on MTL, various forms of heterogeneity, including distribution and posterior heterogeneity, present significant challenges. Existing methods often fail to address these forms of heterogeneity within a unified framework. In this paper, we propose a dual-encoder framework to construct a heterogeneous latent factor space for each task, incorporating a task-shared encoder to capture common information across tasks and a task-specific encoder to preserve unique task characteristics. Additionally, we explore the intrinsic similarity structure of the coefficients corresponding to learned latent factors, allowing for adaptive integration across tasks to manage posterior heterogeneity. We introduce a unified algorithm that alternately learns the task-specific and task-shared encoders and coefficients. In theory, we investigate the excess risk bound for the proposed MTL method using local Rademacher complexity and apply it to a new but related task. Through simulation studies, we demonstrate that the proposed method outperforms existing data integration methods across various settings. Furthermore, the proposed method achieves superior predictive performance for time to tumor doubling across five distinct cancer types in PDX data.",
    "arxiv_id": "http://arxiv.org/abs/2505.24281v1",
    "pdf_link": "https://arxiv.org/pdf/2505.24281v1",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "DeepChest: Dynamic Gradient-Free Task Weighting for Effective Multi-Task Learning in Chest X-ray Classification",
    "authors": [
      "Youssef Mohamed",
      "Noran Mohamed",
      "Khaled Abouhashad",
      "Feilong Tang",
      "Sara Atito",
      "Shoaib Jameel",
      "Imran Razzak",
      "Ahmed B. Zaky"
    ],
    "published": "2025-05-29T16:08:26Z",
    "abstract": "While Multi-Task Learning (MTL) offers inherent advantages in complex domains such as medical imaging by enabling shared representation learning, effectively balancing task contributions remains a significant challenge. This paper addresses this critical issue by introducing DeepChest, a novel, computationally efficient and effective dynamic task-weighting framework specifically designed for multi-label chest X-ray (CXR) classification. Unlike existing heuristic or gradient-based methods that often incur substantial overhead, DeepChest leverages a performance-driven weighting mechanism based on effective analysis of task-specific loss trends. Given a network architecture (e.g., ResNet18), our model-agnostic approach adaptively adjusts task importance without requiring gradient access, thereby significantly reducing memory usage and achieving a threefold increase in training speed. It can be easily applied to improve various state-of-the-art methods. Extensive experiments on a large-scale CXR dataset demonstrate that DeepChest not only outperforms state-of-the-art MTL methods by 7% in overall accuracy but also yields substantial reductions in individual task losses, indicating improved generalization and effective mitigation of negative transfer. The efficiency and performance gains of DeepChest pave the way for more practical and robust deployment of deep learning in critical medical diagnostic applications. The code is publicly available at https://github.com/youssefkhalil320/DeepChest-MTL",
    "arxiv_id": "http://arxiv.org/abs/2505.23595v1",
    "pdf_link": "https://arxiv.org/pdf/2505.23595v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Speech as a Multimodal Digital Phenotype for Multi-Task LLM-based Mental Health Prediction",
    "authors": [
      "Mai Ali",
      "Christopher Lucasius",
      "Tanmay P. Patel",
      "Madison Aitken",
      "Jacob Vorstman",
      "Peter Szatmari",
      "Marco Battaglia",
      "Deepa Kundur"
    ],
    "published": "2025-05-28T04:07:17Z",
    "abstract": "Speech is a noninvasive digital phenotype that can offer valuable insights into mental health conditions, but it is often treated as a single modality. In contrast, we propose the treatment of patient speech data as a trimodal multimedia data source for depression detection. This study explores the potential of large language model-based architectures for speech-based depression prediction in a multimodal regime that integrates speech-derived text, acoustic landmarks, and vocal biomarkers. Adolescent depression presents a significant challenge and is often comorbid with multiple disorders, such as suicidal ideation and sleep disturbances. This presents an additional opportunity to integrate multi-task learning (MTL) into our study by simultaneously predicting depression, suicidal ideation, and sleep disturbances using the multimodal formulation. We also propose a longitudinal analysis strategy that models temporal changes across multiple clinical interactions, allowing for a comprehensive understanding of the conditions' progression. Our proposed approach, featuring trimodal, longitudinal MTL is evaluated on the Depression Early Warning dataset. It achieves a balanced accuracy of 70.8%, which is higher than each of the unimodal, single-task, and non-longitudinal methods.",
    "arxiv_id": "http://arxiv.org/abs/2505.23822v3",
    "pdf_link": "https://arxiv.org/pdf/2505.23822v3",
    "categories": [
      "cs.CL",
      "cs.MM"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Measuring Fine-Grained Relatedness in Multitask Learning via Data Attribution",
    "authors": [
      "Yiwen Tu",
      "Ziqi Liu",
      "Jiaqi W. Ma",
      "Weijing Tang"
    ],
    "published": "2025-05-27T17:13:31Z",
    "abstract": "Measuring task relatedness and mitigating negative transfer remain a critical open challenge in Multitask Learning (MTL). This work extends data attribution -- which quantifies the influence of individual training data points on model predictions -- to MTL setting for measuring task relatedness. We propose the MultiTask Influence Function (MTIF), a method that adapts influence functions to MTL models with hard or soft parameter sharing. Compared to conventional task relatedness measurements, MTIF provides a fine-grained, instance-level relatedness measure beyond the entire-task level. This fine-grained relatedness measure enables a data selection strategy to effectively mitigate negative transfer in MTL. Through extensive experiments, we demonstrate that the proposed MTIF efficiently and accurately approximates the performance of models trained on data subsets. Moreover, the data selection strategy enabled by MTIF consistently improves model performance in MTL. Our work establishes a novel connection between data attribution and MTL, offering an efficient and fine-grained solution for measuring task relatedness and enhancing MTL models.",
    "arxiv_id": "http://arxiv.org/abs/2505.21438v1",
    "pdf_link": "https://arxiv.org/pdf/2505.21438v1",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "D4+: Emergent Adversarial Driving Maneuvers with Approximate Functional Optimization",
    "authors": [
      "Diego Ortiz Barbosa",
      "Luis Burbano",
      "Carlos Hernandez",
      "Zengxiang Lei",
      "Younghee Park",
      "Satish Ukkusuri",
      "Alvaro A Cardenas"
    ],
    "published": "2025-05-20T05:22:03Z",
    "abstract": "Intelligent mechanisms implemented in autonomous vehicles, such as proactive driving assist and collision alerts, reduce traffic accidents. However, verifying their correct functionality is difficult due to complex interactions with the environment. This problem is exacerbated in adversarial environments, where an attacker can control the environment surrounding autonomous vehicles to exploit vulnerabilities.   To preemptively identify vulnerabilities in these systems, in this paper, we implement a scenario-based framework with a formal method to identify the impact of malicious drivers interacting with autonomous vehicles. The formalization of the evaluation requirements utilizes metric temporal logic (MTL) to identify a safety condition that we want to test. Our goal is to find, through a rigorous testing approach, any trace that violates this MTL safety specification. Our results can help designers identify the range of safe operational behaviors that prevent malicious drivers from exploiting the autonomous features of modern vehicles.",
    "arxiv_id": "http://arxiv.org/abs/2505.13942v1",
    "pdf_link": "https://arxiv.org/pdf/2505.13942v1",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer and Swin-Unet",
    "authors": [
      "Kodai Hirata",
      "Tsuyoshi Okita"
    ],
    "published": "2025-05-09T16:54:26Z",
    "abstract": "This paper proposes a method MTL-Swin-Unet which is multi-task learning using transformers for classification and semantic segmentation. For spurious-correlation problems, this method allows us to enhance the image representation with two other image representations: representation obtained by semantic segmentation and representation obtained by image reconstruction. In our experiments, the proposed method outperformed in F-value measure than other classifiers when the test data included slices from the same patient (no covariate shift). Similarly, when the test data did not include slices from the same patient (covariate shift setting), the proposed method outperformed in AUC measure.",
    "arxiv_id": "http://arxiv.org/abs/2505.06185v2",
    "pdf_link": "https://arxiv.org/pdf/2505.06185v2",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "MTL-UE: Learning to Learn Nothing for Multi-Task Learning",
    "authors": [
      "Yi Yu",
      "Song Xia",
      "Siyuan Yang",
      "Chenqi Kong",
      "Wenhan Yang",
      "Shijian Lu",
      "Yap-Peng Tan",
      "Alex C. Kot"
    ],
    "published": "2025-05-08T14:26:00Z",
    "abstract": "Most existing unlearnable strategies focus on preventing unauthorized users from training single-task learning (STL) models with personal data. Nevertheless, the paradigm has recently shifted towards multi-task data and multi-task learning (MTL), targeting generalist and foundation models that can handle multiple tasks simultaneously. Despite their growing importance, MTL data and models have been largely neglected while pursuing unlearnable strategies. This paper presents MTL-UE, the first unified framework for generating unlearnable examples for multi-task data and MTL models. Instead of optimizing perturbations for each sample, we design a generator-based structure that introduces label priors and class-wise feature embeddings which leads to much better attacking performance. In addition, MTL-UE incorporates intra-task and inter-task embedding regularization to increase inter-class separation and suppress intra-class variance which enhances the attack robustness greatly. Furthermore, MTL-UE is versatile with good supports for dense prediction tasks in MTL. It is also plug-and-play allowing integrating existing surrogate-dependent unlearnable methods with little adaptation. Extensive experiments show that MTL-UE achieves superior attacking performance consistently across 4 MTL datasets, 3 base UE methods, 5 model backbones, and 5 MTL task-weighting strategies.",
    "arxiv_id": "http://arxiv.org/abs/2505.05279v1",
    "pdf_link": "https://arxiv.org/pdf/2505.05279v1",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "NN-Based Joint Mitigation of IQ Imbalance and PA Nonlinearity With Multiple States",
    "authors": [
      "Yundi Zhang",
      "Wendong Cheng",
      "Li Chen"
    ],
    "published": "2025-05-07T12:48:44Z",
    "abstract": "Joint mitigation of IQ imbalance and PA nonlinearity is important for improving the performance of radio frequency (RF) transmitters. In this paper, we propose a new neural network (NN) model, which can be used for joint digital pre-distortion (DPD) of non-ideal IQ modulators and PAs in a transmitter with multiple operating states. The model is based on the methodology of multi-task learning (MTL). In this model, the hidden layers of the main NN are shared by all signal states, and the output layer's weights and biases are dynamically generated by another NN. The experimental results show that the proposed model can effectively perform joint DPD for IQ-PA systems, and it achieves better overall performance within multiple signal states than the existing methods.",
    "arxiv_id": "http://arxiv.org/abs/2505.04373v1",
    "pdf_link": "https://arxiv.org/pdf/2505.04373v1",
    "categories": [
      "eess.SY"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Tri-MTL: A Triple Multitask Learning Approach for Respiratory Disease Diagnosis",
    "authors": [
      "June-Woo Kim",
      "Sanghoon Lee",
      "Miika Toikkanen",
      "Daehwan Hwang",
      "Kyunghoon Kim"
    ],
    "published": "2025-05-06T09:25:15Z",
    "abstract": "Auscultation remains a cornerstone of clinical practice, essential for both initial evaluation and continuous monitoring. Clinicians listen to the lung sounds and make a diagnosis by combining the patient's medical history and test results. Given this strong association, multitask learning (MTL) can offer a compelling framework to simultaneously model these relationships, integrating respiratory sound patterns with disease manifestations. While MTL has shown considerable promise in medical applications, a significant research gap remains in understanding the complex interplay between respiratory sounds, disease manifestations, and patient metadata attributes. This study investigates how integrating MTL with cutting-edge deep learning architectures can enhance both respiratory sound classification and disease diagnosis. Specifically, we extend recent findings regarding the beneficial impact of metadata on respiratory sound classification by evaluating its effectiveness within an MTL framework. Our comprehensive experiments reveal significant improvements in both lung sound classification and diagnostic performance when the stethoscope information is incorporated into the MTL architecture.",
    "arxiv_id": "http://arxiv.org/abs/2505.06271v1",
    "pdf_link": "https://arxiv.org/pdf/2505.06271v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "GeoERM: Geometry-Aware Multi-Task Representation Learning on Riemannian Manifolds",
    "authors": [
      "Aoran Chen",
      "Yang Feng"
    ],
    "published": "2025-05-05T18:56:16Z",
    "abstract": "Multi-Task Learning (MTL) seeks to boost statistical power and learning efficiency by discovering structure shared across related tasks. State-of-the-art MTL representation methods, however, usually treat the latent representation matrix as a point in ordinary Euclidean space, ignoring its often non-Euclidean geometry, thus sacrificing robustness when tasks are heterogeneous or even adversarial. We propose GeoERM, a geometry-aware MTL framework that embeds the shared representation on its natural Riemannian manifold and optimizes it via explicit manifold operations. Each training cycle performs (i) a Riemannian gradient step that respects the intrinsic curvature of the search space, followed by (ii) an efficient polar retraction to remain on the manifold, guaranteeing geometric fidelity at every iteration. The procedure applies to a broad class of matrix-factorized MTL models and retains the same per-iteration cost as Euclidean baselines. Across a set of synthetic experiments with task heterogeneity and on a wearable-sensor activity-recognition benchmark, GeoERM consistently improves estimation accuracy, reduces negative transfer, and remains stable under adversarial label noise, outperforming leading MTL and single-task alternatives.",
    "arxiv_id": "http://arxiv.org/abs/2505.02972v1",
    "pdf_link": "https://arxiv.org/pdf/2505.02972v1",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Efficient Knowledge Transfer in Multi-Task Learning through Task-Adaptive Low-Rank Representation",
    "authors": [
      "Xiao Zhang",
      "Kangsheng Wang",
      "Tianyu Hu",
      "Huimin Ma"
    ],
    "published": "2025-04-20T06:33:19Z",
    "abstract": "Pre-trained language models (PLMs) demonstrate remarkable intelligence but struggle with emerging tasks unseen during training in real-world applications. Training separate models for each new task is usually impractical. Multi-task learning (MTL) addresses this challenge by transferring shared knowledge from source tasks to target tasks. As an dominant parameter-efficient fine-tuning method, prompt tuning (PT) enhances MTL by introducing an adaptable vector that captures task-specific knowledge, which acts as a prefix to the original prompt that preserves shared knowledge, while keeping PLM parameters frozen. However, PT struggles to effectively capture the heterogeneity of task-specific knowledge due to its limited representational capacity. To address this challenge, we propose Task-Adaptive Low-Rank Representation (TA-LoRA), an MTL method built on PT, employing the low-rank representation to model task heterogeneity and a fast-slow weights mechanism where the slow weight encodes shared knowledge, while the fast weight captures task-specific nuances, avoiding the mixing of shared and task-specific knowledge, caused by training low-rank representations from scratch. Moreover, a zero-initialized attention mechanism is introduced to minimize the disruption of immature low-rank components on original prompts during warm-up epochs. Experiments on 16 tasks demonstrate that TA-LoRA achieves state-of-the-art performance in full-data and few-shot settings while maintaining superior parameter efficiency.",
    "arxiv_id": "http://arxiv.org/abs/2505.00009v1",
    "pdf_link": "https://arxiv.org/pdf/2505.00009v1",
    "categories": [
      "cs.CL"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Analyzing Feedback Mechanisms in AI-Generated MCQs: Insights into Readability, Lexical Properties, and Levels of Challenge",
    "authors": [
      "Antoun Yaacoub",
      "Zainab Assaghir",
      "Lionel Prevost",
      "Jérôme Da-Rugna"
    ],
    "published": "2025-04-19T09:20:52Z",
    "abstract": "Artificial Intelligence (AI)-generated feedback in educational settings has garnered considerable attention due to its potential to enhance learning outcomes. However, a comprehensive understanding of the linguistic characteristics of AI-generated feedback, including readability, lexical richness, and adaptability across varying challenge levels, remains limited. This study delves into the linguistic and structural attributes of feedback generated by Google's Gemini 1.5-flash text model for computer science multiple-choice questions (MCQs). A dataset of over 1,200 MCQs was analyzed, considering three difficulty levels (easy, medium, hard) and three feedback tones (supportive, neutral, challenging). Key linguistic metrics, such as length, readability scores (Flesch-Kincaid Grade Level), vocabulary richness, and lexical density, were computed and examined. A fine-tuned RoBERTa-based multi-task learning (MTL) model was trained to predict these linguistic properties, achieving a Mean Absolute Error (MAE) of 2.0 for readability and 0.03 for vocabulary richness. The findings reveal significant interaction effects between feedback tone and question difficulty, demonstrating the dynamic adaptation of AI-generated feedback within diverse educational contexts. These insights contribute to the development of more personalized and effective AI-driven feedback mechanisms, highlighting the potential for improved learning outcomes while underscoring the importance of ethical considerations in their design and deployment.",
    "arxiv_id": "http://arxiv.org/abs/2504.21013v1",
    "pdf_link": "https://arxiv.org/pdf/2504.21013v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Towards Human-Centered Early Prediction Models for Academic Performance in Real-World Contexts",
    "authors": [
      "Han Zhang",
      "Yiyi Ren",
      "Paula S. Nurius",
      "Jennifer Mankoff",
      "Anind K. Dey"
    ],
    "published": "2025-04-16T16:40:56Z",
    "abstract": "Supporting student success requires collaboration among multiple stakeholders. Researchers have explored machine learning models for academic performance prediction; yet key challenges remain in ensuring these models are interpretable, equitable, and actionable within real-world educational support systems. First, many models prioritize predictive accuracy but overlook human-centered machine learning principles, limiting trust among students and reducing their usefulness for educators and institutional decision-makers. Second, most models require at least a month of data before making reliable predictions, delaying opportunities for early intervention. Third, current models primarily rely on sporadically collected, classroom-derived data, missing broader behavioral patterns that could provide more continuous and actionable insights. To address these gaps, we present three modeling approaches-LR, 1D-CNN, and MTL-1D-CNN-to classify students as low or high academic performers. We evaluate them based on explainability, fairness, and generalizability to assess their alignment with key social values. Using behavioral and self-reported data collected within the first week of two Spring terms, we demonstrate that these models can identify at-risk students as early as week one. However, trade-offs across human-centered machine learning principles highlight the complexity of designing predictive models that effectively support multi-stakeholder decision-making and intervention strategies. We discuss these trade-offs and their implications for different stakeholders, outlining how predictive models can be integrated into student support systems. Finally, we examine broader socio-technical challenges in deploying these models and propose future directions for advancing human-centered, collaborative academic prediction systems.",
    "arxiv_id": "http://arxiv.org/abs/2504.12236v2",
    "pdf_link": "https://arxiv.org/pdf/2504.12236v2",
    "categories": [
      "cs.HC"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "xMTF: A Formula-Free Model for Reinforcement-Learning-Based Multi-Task Fusion in Recommender Systems",
    "authors": [
      "Yang Cao",
      "Changhao Zhang",
      "Xiaoshuang Chen",
      "Kaiqiao Zhan",
      "Ben Wang"
    ],
    "published": "2025-04-08T04:28:22Z",
    "abstract": "Recommender systems need to optimize various types of user feedback, e.g., clicks, likes, and shares. A typical recommender system handling multiple types of feedback has two components: a multi-task learning (MTL) module, predicting feedback such as click-through rate and like rate; and a multi-task fusion (MTF) module, integrating these predictions into a single score for item ranking. MTF is essential for ensuring user satisfaction, as it directly influences recommendation outcomes. Recently, reinforcement learning (RL) has been applied to MTF tasks to improve long-term user satisfaction. However, existing RL-based MTF methods are formula-based methods, which only adjust limited coefficients within pre-defined formulas. The pre-defined formulas restrict the RL search space and become a bottleneck for MTF. To overcome this, we propose a formula-free MTF framework. We demonstrate that any suitable fusion function can be expressed as a composition of single-variable monotonic functions, as per the Sprecher Representation Theorem. Leveraging this, we introduce a novel learnable monotonic fusion cell (MFC) to replace pre-defined formulas. We call this new MFC-based model eXtreme MTF (xMTF). Furthermore, we employ a two-stage hybrid (TSH) learning strategy to train xMTF effectively. By expanding the MTF search space, xMTF outperforms existing methods in extensive offline and online experiments.",
    "arxiv_id": "http://arxiv.org/abs/2504.05669v1",
    "pdf_link": "https://arxiv.org/pdf/2504.05669v1",
    "categories": [
      "cs.IR"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Continual Optimization with Symmetry Teleportation for Multi-Task Learning",
    "authors": [
      "Zhipeng Zhou",
      "Ziqiao Meng",
      "Pengcheng Wu",
      "Peilin Zhao",
      "Chunyan Miao"
    ],
    "published": "2025-03-06T02:58:09Z",
    "abstract": "Multi-task learning (MTL) is a widely explored paradigm that enables the simultaneous learning of multiple tasks using a single model. Despite numerous solutions, the key issues of optimization conflict and task imbalance remain under-addressed, limiting performance. Unlike existing optimization-based approaches that typically reweight task losses or gradients to mitigate conflicts or promote progress, we propose a novel approach based on Continual Optimization with Symmetry Teleportation (COST). During MTL optimization, when an optimization conflict arises, we seek an alternative loss-equivalent point on the loss landscape to reduce conflict. Specifically, we utilize a low-rank adapter (LoRA) to facilitate this practical teleportation by designing convergent, loss-invariant objectives. Additionally, we introduce a historical trajectory reuse strategy to continually leverage the benefits of advanced optimizers. Extensive experiments on multiple mainstream datasets demonstrate the effectiveness of our approach. COST is a plug-and-play solution that enhances a wide range of existing MTL methods. When integrated with state-of-the-art methods, COST achieves superior performance.",
    "arxiv_id": "http://arxiv.org/abs/2503.04046v1",
    "pdf_link": "https://arxiv.org/pdf/2503.04046v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Semi-Supervised 3D Segmentation for Type-B Aortic Dissection with Slim UNETR",
    "authors": [
      "Denis Mikhailapov",
      "Vladimir Berikov"
    ],
    "published": "2025-12-19T14:14:41Z",
    "abstract": "Convolutional neural networks (CNN) for multi-class segmentation of medical images are widely used today. Especially models with multiple outputs that can separately predict segmentation classes (regions) without relying on a probabilistic formulation of the segmentation of regions. These models allow for more precise segmentation by tailoring the network's components to each class (region). They have a common encoder part of the architecture but branch out at the output layers, leading to improved accuracy.   These methods are used to diagnose type B aortic dissection (TBAD), which requires accurate segmentation of aortic structures based on the ImageTBDA dataset, which contains 100 3D computed tomography angiography (CTA) images. These images identify three key classes: true lumen (TL), false lumen (FL), and false lumen thrombus (FLT) of the aorta, which is critical for diagnosis and treatment decisions. In the dataset, 68 examples have a false lumen, while the remaining 32 do not, creating additional complexity for pathology detection.   However, implementing these CNN methods requires a large amount of high-quality labeled data. Obtaining accurate labels for the regions of interest can be an expensive and time-consuming process, particularly for 3D data. Semi-supervised learning methods allow models to be trained by using both labeled and unlabeled data, which is a promising approach for overcoming the challenge of obtaining accurate labels. However, these learning methods are not well understood for models with multiple outputs.   This paper presents a semi-supervised learning method for models with multiple outputs. The method is based on the additional rotations and flipping, and does not assume the probabilistic nature of the model's responses. This makes it a universal approach, which is especially important for architectures that involve separate segmentation.",
    "arxiv_id": "http://arxiv.org/abs/2512.17610v1",
    "pdf_link": "https://arxiv.org/pdf/2512.17610v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Physical properties of new delafossite triangular-lattice compounds TlErSe$_2$ and TlTmSe$_2$",
    "authors": [
      "Bastian Rubrecht",
      "Ellen Häußler",
      "Mirtha Pillaca",
      "Pritam Bhattacharyya",
      "Liviu Hozoi",
      "Artem Nosenko",
      "Dmitri V. Efremov",
      "Bernd Büchner",
      "Anja U. B. Wolter",
      "Thomas Doert"
    ],
    "published": "2025-12-12T15:06:46Z",
    "abstract": "Delafossite compounds containing rare-earth ions have been proven to be an ideal platform to investigate frustrated magnetic ground states. Here, we discuss two triangular-lattice antiferromagnets, TlErSe$_2$ and TlTmSe$_2$, as potential candidates for hosting exotic quantum states. Powder X-ray diffraction data analysis of the black-color polycrystalline Tl$RE$Se$_2$ ($RE$: Er and Tm) samples confirms the phase purity. Both materials crystallize in the trigonal $α$-NaFeO$_2$ structure ($R\\overline{3}m$) with lattice parameters $a$ = 4.1070(4) Å and $c$ = 23.1472(1) Å for the erbium compound and $a$ = 4.0916(1) Å and $c$ = 23.1483(2) Å for the thulium compound. Magnetic susceptibility measurements show an effective moment of $μ_{\\text{eff}} = 9.6(2) μ_B$/f.u. ($7.5(1) μ_B$/f.u.) for TlErSe$_2$ (TlTmSe$_2$) for temperatures above 200 K. While $^3$He specific-heat measurements reveal long-range magnetic order below $T_N = 0.42 $K for TlErSe$_2$, no sign of long-range magnetic order was observed for TlTmSe$_2$. Based on our results, we map out the T-H phase diagram for polycrystalline TlErSe$_2$ and discuss the striking difference in the magnetic behavior of TlTmSe$_2$ based on our ab initio quantum chemical calculations.",
    "arxiv_id": "http://arxiv.org/abs/2512.11627v1",
    "pdf_link": "https://arxiv.org/pdf/2512.11627v1",
    "categories": [
      "cond-mat.str-el"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Restrictive Hierarchical Semantic Segmentation for Stratified Tooth Layer Detection",
    "authors": [
      "Ryan Banks",
      "Camila Lindoni Azevedo",
      "Hongying Tang",
      "Yunpeng Li"
    ],
    "published": "2025-12-08T19:15:08Z",
    "abstract": "Accurate understanding of anatomical structures is essential for reliably staging certain dental diseases. A way of introducing this within semantic segmentation models is by utilising hierarchy-aware methodologies. However, existing hierarchy-aware segmentation methods largely encode anatomical structure through the loss functions, providing weak and indirect supervision. We introduce a general framework that embeds an explicit anatomical hierarchy into semantic segmentation by coupling a recurrent, level-wise prediction scheme with restrictive output heads and top-down feature conditioning. At each depth of the class tree, the backbone is re-run on the original image concatenated with logits from the previous level. Child class features are conditioned using Feature-wise Linear Modulation of their parent class probabilities, to modulate child feature spaces for fine grained detection. A probabilistic composition rule enforces consistency between parent and descendant classes. Hierarchical loss combines per-level class weighted Dice and cross entropy loss and a consistency term loss, ensuring parent predictions are the sum of their children. We validate our approach on our proposed dataset, TL-pano, containing 194 panoramic radiographs with dense instance and semantic segmentation annotations, of tooth layers and alveolar bone. Utilising UNet and HRNet as donor models across a 5-fold cross validation scheme, the hierarchical variants consistently increase IoU, Dice, and recall, particularly for fine-grained anatomies, and produce more anatomically coherent masks. However, hierarchical variants also demonstrated increased recall over precision, implying increased false positives. The results demonstrate that explicit hierarchical structuring improves both performance and clinical plausibility, especially in low data dental imaging regimes.",
    "arxiv_id": "http://arxiv.org/abs/2512.07984v3",
    "pdf_link": "https://arxiv.org/pdf/2512.07984v3",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Bordism from quasi-isomorphism",
    "authors": [
      "Noah Porcelli",
      "Ivan Smith"
    ],
    "published": "2025-09-25T21:00:20Z",
    "abstract": "Let $X$ be a graded Liouville domain. Fix a pair of infinite loop spaces $Ψ= (Θ\\to Φ)$ living over $(BO \\to BU)$. This determines a spectral Fukaya category $\\mathcal{F}(X;Ψ)$ whenever $TX$ lifts to $Φ$, containing closed exact Lagrangians $L$ for which $TL$ lifts compatibly to $Θ$; and by Bott periodicity and index theory, a Thom spectrum $R$ with bordism theory $R_*$.   Suppose that $L$ and $K$ are quasi-isomorphic in the Fukaya category over $\\mathbb{Z}$. We prove that:   (a) if both lift to $\\mathcal{F}(X;Ψ)$, then there is a rank one $R$-local system $ξ: L \\to BGL_1(R)$ over $L$ so that $(L,ξ)$ and $K$ are quasi-isomorphic in the spectral Fukaya category;   (b) when $X$ is polarised and $Ψ= (BO \\times F \\to BO)$, if only $K$ lifts to $\\mathcal{F}(X;Ψ)$, then the composition $L \\to B^2GL_1(R)$ of the stable Gauss map of $L$ and the delooped $J$-homomorphism is nullhomotopic.   Combined with the computation of the open-closed fundamental class associated to $(L,ξ)$ in \\cite{PS3}, these results have applications to bordism and stable homotopy types of quasi-isomorphic Lagrangians, to Hamiltonian monodromy groups, and to smooth structures on nearby Lagrangians.   A key ingredient in the proofs is a new form of obstruction theory for flow categories `lying over' a manifold $L$, closely related to a `spectral Viterbo restriction functor' also introduced here.",
    "arxiv_id": "http://arxiv.org/abs/2509.21587v1",
    "pdf_link": "https://arxiv.org/pdf/2509.21587v1",
    "categories": [
      "math.SG",
      "math.AT",
      "math.KT"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Open-closed maps and spectral local systems",
    "authors": [
      "Noah Porcelli",
      "Ivan Smith"
    ],
    "published": "2025-09-25T19:44:55Z",
    "abstract": "Let $X$ be a graded Liouville domain. Fix a pair of infinite loop spaces $Ψ= (Θ\\to Φ)$ living over $(BO \\to BU)$. This determines a spectral Fukaya category $\\mathcal{F}(X;Ψ)$ whenever $TX$ lifts to $Φ$, containing closed exact Lagrangians $L$ for which $TL$ lifts compatibly to $Θ$; and by Bott periodicity and index theory, a Thom spectrum $R$ with bordism theory $R_*$.   This paper has two main goals: we incorporate rank one spectral local systems $ξ: L \\to BGL_1(R)$ into the spectral category; and we prove that the bordism class $[(L,ξ)]$ defined by the open-closed map differs from the class $[L]$ by a multiplicative two-torsion element in $R^0(L)^{\\times}$ determined by an action of the stable homotopy class of the Hopf map $η\\in π_1^{st}$ on $ξ$. Methods include a twisting construction associating flow categories to spectral local systems, and a model for the open-closed map incorporating Schlichtkrull's construction of the trace map $BGL_1(R) \\subseteq K(R) \\to R$.   The companion paper \\cite{PS4} shows that (for Lagrangians which themselves admit spectral lifts) one can lift quasi-isomorphisms from $\\mathbb{Z}$ to $Ψ$ at the cost of introducing rank one local systems. Together with the open-closed computation given here, this gives an essentially complete picture of the bordism-theoretic consequences of quasi-isomorphism in the classical exact Fukaya category.",
    "arxiv_id": "http://arxiv.org/abs/2509.21483v1",
    "pdf_link": "https://arxiv.org/pdf/2509.21483v1",
    "categories": [
      "math.SG",
      "math.AT",
      "math.KT"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Verifiable Natural Language to Linear Temporal Logic Translation: A Benchmark Dataset and Evaluation Suite",
    "authors": [
      "William H English",
      "Chase Walker",
      "Dominic Simon",
      "Sumit Kumar Jha",
      "Rickard Ewetz"
    ],
    "published": "2025-07-01T15:41:57Z",
    "abstract": "Empirical evaluation of state-of-the-art natural-language (NL) to temporal-logic (TL) translation systems reveals near-perfect performance on existing benchmarks. However, current studies measure only the accuracy of the translation of NL logic into formal TL, ignoring a system's capacity to ground atomic propositions into new scenarios or environments. This is a critical feature, necessary for the verification of resulting formulas in a concrete state space. Consequently, most NL-to-TL translation frameworks propose their own bespoke dataset in which the correct grounding is known a-priori, inflating performance metrics and neglecting the need for extensible, domain-general systems. In this paper, we introduce the Verifiable Linear Temporal Logic Benchmark ( VLTL-Bench), a unifying benchmark that measures verification and verifiability of automated NL-to-LTL translation. The dataset consists of four unique state spaces and thousands of diverse natural language specifications and corresponding formal specifications in temporal logic. Moreover, the benchmark contains sample traces to validate the temporal logic expressions. While the benchmark directly supports end-to-end evaluation, we observe that many frameworks decompose the process into i) lifting, ii) grounding, iii) translation, and iv) verification. The benchmark provides ground truths after each of these steps to enable researches to improve and evaluate different substeps of the overall problem. To encourage methodologically sound advances in verifiable NL-to-LTL translation approaches, we release VLTL-Bench here: https://www.kaggle.com/datasets/dubascudes/vltl bench.",
    "arxiv_id": "http://arxiv.org/abs/2507.00877v2",
    "pdf_link": "https://arxiv.org/pdf/2507.00877v2",
    "categories": [
      "eess.SY",
      "cs.CL"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Multi-modal wound classification using wound image and location by Xception and Gaussian Mixture Recurrent Neural Network (GMRNN)",
    "authors": [
      "Ramin Mousa",
      "Ehsan Matbooe",
      "Hakimeh Khojasteh",
      "Amirali Bengari",
      "Mohammadmahdi Vahediahmar"
    ],
    "published": "2025-05-12T21:44:03Z",
    "abstract": "The effective diagnosis of acute and hard-to-heal wounds is crucial for wound care practitioners to provide effective patient care. Poor clinical outcomes are often linked to infection, peripheral vascular disease, and increasing wound depth, which collectively exacerbate these comorbidities. However, diagnostic tools based on Artificial Intelligence (AI) speed up the interpretation of medical images and improve early detection of disease. In this article, we propose a multi-modal AI model based on transfer learning (TL), which combines two state-of-the-art architectures, Xception and GMRNN, for wound classification. The multi-modal network is developed by concatenating the features extracted by a transfer learning algorithm and location features to classify the wound types of diabetic, pressure, surgical, and venous ulcers. The proposed method is comprehensively compared with deep neural networks (DNN) for medical image analysis. The experimental results demonstrate a notable wound-class classifications (containing only diabetic, pressure, surgical, and venous) vary from 78.77 to 100\\% in various experiments. The results presented in this study showcase the exceptional accuracy of the proposed methodology in accurately classifying the most commonly occurring wound types using wound images and their corresponding locations.",
    "arxiv_id": "http://arxiv.org/abs/2505.08086v1",
    "pdf_link": "https://arxiv.org/pdf/2505.08086v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "CACTUS: An Open Dataset and Framework for Automated Cardiac Assessment and Classification of Ultrasound Images Using Deep Transfer Learning",
    "authors": [
      "Hanae Elmekki",
      "Ahmed Alagha",
      "Hani Sami",
      "Amanda Spilkin",
      "Antonela Mariel Zanuttini",
      "Ehsan Zakeri",
      "Jamal Bentahar",
      "Lyes Kadem",
      "Wen-Fang Xie",
      "Philippe Pibarot",
      "Rabeb Mizouni",
      "Hadi Otrok",
      "Shakti Singh",
      "Azzam Mourad"
    ],
    "published": "2025-03-07T17:29:04Z",
    "abstract": "Cardiac ultrasound (US) scanning is a commonly used techniques in cardiology to diagnose the health of the heart and its proper functioning. Therefore, it is necessary to consider ways to automate these tasks and assist medical professionals in classifying and assessing cardiac US images. Machine learning (ML) techniques are regarded as a prominent solution due to their success in numerous applications aimed at enhancing the medical field, including addressing the shortage of echography technicians. However, the limited availability of medical data presents a significant barrier to applying ML in cardiology, particularly regarding US images of the heart. This paper addresses this challenge by introducing the first open graded dataset for Cardiac Assessment and ClassificaTion of UltraSound (CACTUS), which is available online. This dataset contains images obtained from scanning a CAE Blue Phantom and representing various heart views and different quality levels, exceeding the conventional cardiac views typically found in the literature. Additionally, the paper introduces a Deep Learning (DL) framework consisting of two main components. The first component classifies cardiac US images based on the heart view using a Convolutional Neural Network (CNN). The second component uses Transfer Learning (TL) to fine-tune the knowledge from the first component and create a model for grading and assessing cardiac images. The framework demonstrates high performance in both classification and grading, achieving up to 99.43% accuracy and as low as 0.3067 error, respectively. To showcase its robustness, the framework is further fine-tuned using new images representing additional cardiac views and compared to several other state-of-the-art architectures. The framework's outcomes and performance in handling real-time scans were also assessed using a questionnaire answered by cardiac experts.",
    "arxiv_id": "http://arxiv.org/abs/2503.05604v1",
    "pdf_link": "https://arxiv.org/pdf/2503.05604v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Verifying QUIC implementations using Ivy",
    "authors": [
      "Christophe Crochet",
      "Tom Rousseaux",
      "J-F Sambon",
      "Maxime Piraux",
      "Axel Legay"
    ],
    "published": "2025-03-03T10:17:43Z",
    "abstract": "QUIC is a new transport protocol combining the reliability and congestion control features of TCP with the security features of TLS. One of the main challenges with QUIC is to guarantee that any of its implementation follows the IETF specification. This challenge is particularly appealing as the specification is written in textual language, and hence may contain ambiguities. In a recent work, McMillan and Zuck proposed a formal representation of part of draft-18 of the IETF specification. They also showed that this representation made it possible to efficiently generate tests to stress four implementations of QUIC. Our first contribution is to complete and extend the formal representation from draft-18 to draft-29. Our second contribution is to test seven implementations of both QUIC client and server. Our last contribution is to show that our tool can highlight ambiguities in the QUIC specification, for which we suggest paths to corrections",
    "arxiv_id": "http://arxiv.org/abs/2503.01374v1",
    "pdf_link": "https://arxiv.org/pdf/2503.01374v1",
    "categories": [
      "cs.NI",
      "cs.SE"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Optimizing Datasets for Code Summarization: Is Code-Comment Coherence Enough?",
    "authors": [
      "Antonio Vitale",
      "Antonio Mastropaolo",
      "Rocco Oliveto",
      "Massimiliano Di Penta",
      "Simone Scalabrino"
    ],
    "published": "2025-02-11T15:02:19Z",
    "abstract": "Automated code summarization is a long-standing goal for code comprehension. This task automatically generates documentation using a given method. Deep Learning (DL)-based approaches have been proven beneficial for various software engineering (SE) tasks, including this one. Most state-of-the-art datasets for code summarization are automatically mined from GitHub and, thus, might contain erroneous or sub-optimal examples. Previous work showed that using a simple rule-based approach for removing noisy instances allows for a tangible reduction of the training set size while not reducing the effectiveness of the trained models. Motivated by this finding, we conjecture that it is possible to further reduce the dataset size by removing instances that contain different issues. In this paper, we explore the extent to which code-comment coherence, a specific quality attribute of code summaries, can be used to optimize code summarization datasets. Specifically, we hypothesize that removing incoherent code-comment pairs might positively impact the effectiveness of the models. To do this, we rely on SIDE, a recently introduced metric for code-summary coherence. We examine multiple selectivity levels of training instances from two state-of-the-art datasets (TL-CodeSum and Funcom) and evaluate the resulting models on three manually curated test sets. The results show that even halving the training set sizes does not significantly affect the model's ability to generate summaries. However, when comparing the most restrictive selection strategy with a simpler one that randomly selects the training instances, we observe that the resulting accuracy of the model also does not change. This result suggests that (i) current datasets contain many irrelevant examples, and (ii) different quality attributes should be explored for optimizing code summarization datasets.",
    "arxiv_id": "http://arxiv.org/abs/2502.07611v1",
    "pdf_link": "https://arxiv.org/pdf/2502.07611v1",
    "categories": [
      "cs.SE"
    ],
    "affiliation": "N/A",
    "relevance_score": 30
  },
  {
    "title": "Enhancing Speech Emotion Recognition with Multi-Task Learning and Dynamic Feature Fusion",
    "authors": [
      "Honghong Wang",
      "Jing Deng",
      "Fanqin Meng",
      "Rong Zheng"
    ],
    "published": "2025-08-25T10:32:24Z",
    "abstract": "This study investigates fine-tuning self-supervised learn ing (SSL) models using multi-task learning (MTL) to enhance   speech emotion recognition (SER). The framework simultane ously handles four related tasks: emotion recognition, gender   recognition, speaker verification, and automatic speech recog nition. An innovative co-attention module is introduced to dy namically capture the interactions between features from the   primary emotion classification task and auxiliary tasks, en abling context-aware fusion. Moreover, We introduce the Sam ple Weighted Focal Contrastive (SWFC) loss function to ad dress class imbalance and semantic confusion by adjusting sam ple weights for difficult and minority samples. The method is   validated on the Categorical Emotion Recognition task of the   Speech Emotion Recognition in Naturalistic Conditions Chal lenge, showing significant performance improvements.",
    "arxiv_id": "http://arxiv.org/abs/2508.17878v1",
    "pdf_link": "https://arxiv.org/pdf/2508.17878v1",
    "categories": [
      "cs.SD"
    ],
    "affiliation": "N/A",
    "relevance_score": 25
  },
  {
    "title": "Exploring Reliable PPG Authentication on Smartwatches in Daily Scenarios",
    "authors": [
      "Jiankai Tang",
      "Jiacheng Liu",
      "Renling Tong",
      "Kai Zhu",
      "Zhe Li",
      "Xin Yi",
      "Junliang Xing",
      "Yuanchun Shi",
      "Yuntao Wang"
    ],
    "published": "2025-03-31T10:25:48Z",
    "abstract": "Photoplethysmography (PPG) Sensors, widely deployed in smartwatches, offer a simple and non-invasive authentication approach for daily use. However, PPG authentication faces reliability issues due to motion artifacts from physical activity and physiological variability over time. To address these challenges, we propose MTL-RAPID, an efficient and reliable PPG authentication model, that employs a multitask joint training strategy, simultaneously assessing signal quality and verifying user identity. The joint optimization of these two tasks in MTL-RAPID results in a structure that outperforms models trained on individual tasks separately, achieving stronger performance with fewer parameters. In our comprehensive user studies regarding motion artifacts (N = 30), time variations (N = 32), and user preferences (N = 16), MTL-RAPID achieves a best AUC of 99.2\\% and an EER of 3.5\\%, outperforming existing baselines. We opensource our PPG authentication dataset along with the MTL-RAPID model to facilitate future research on GitHub.",
    "arxiv_id": "http://arxiv.org/abs/2503.23930v1",
    "pdf_link": "https://arxiv.org/pdf/2503.23930v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 25
  },
  {
    "title": "An Effective Reflection Mode Measurement for Hanger-Coupled Microwave Resonators",
    "authors": [
      "John R. Pitten",
      "Nicholas Materise",
      "Wei-Ren Syong",
      "Jorge Ramirez",
      "Douglas Bennett",
      "Corey Rae H. McRae"
    ],
    "published": "2025-07-18T22:53:56Z",
    "abstract": "Superconducting microwave resonators are used to study two-level system (TLS) loss in superconducting quantum devices. Fano asymmetry, characterized by a nonzero asymmetry angle $φ$ in the diameter correction method (DCM), results from the coupling schemes used to measure these devices, including the commonly used hanger method. $φ$ is an additional fitting parameter which contains no physically interesting information and can obscure device parameters of interest. The tee-junction symmetry nominally present in these resonator devices provides an avenue for the elimination of Fano asymmetry using calibrated measurement. We show that the eigenvalue associated with the common mode excitation of the resonator is an effective reflection mode (ERM) which has no Fano asymmetry. Our analysis reveals the cause of Fano asymmetry as interference between common and differential modes. Practically, we obtain the ERM from a linear combination of calibrated reflection and transmission measurements. We utilize a 3D aluminum cavity to experimentally demonstrate the validity and flexibility of this model. To extend the usefulness of this symmetry analysis, we apply perturbation theory to recover the ERM in a multiplexed coplanar waveguide resonator device and experimentally demonstrate quantitative agreement in the extracted $Q_i^{-1}$ between hanger mode and ERM measurements. We observe a five-fold reduction in uncertainty from the ERM compared to the standard hanger mode at the lowest measured power, -160 dBm delivered to the device. This method could facilitate an increase in throughput of low-power superconducting resonator measurements by up to a factor of 25, as well as allow the extraction of critical parameters from otherwise unfittable device data.",
    "arxiv_id": "http://arxiv.org/abs/2507.14394v1",
    "pdf_link": "https://arxiv.org/pdf/2507.14394v1",
    "categories": [
      "quant-ph"
    ],
    "affiliation": "N/A",
    "relevance_score": 25
  },
  {
    "title": "Pseudo Labels-based Neural Speech Enhancement for the AVSR Task in the MISP-Meeting Challenge",
    "authors": [
      "Longjie Luo",
      "Shenghui Lu",
      "Lin Li",
      "Qingyang Hong"
    ],
    "published": "2025-05-30T10:33:54Z",
    "abstract": "This paper presents our system for the MISP-Meeting Challenge Track 2. The primary difficulty lies in the dataset, which contains strong background noise, reverberation, overlapping speech, and diverse meeting topics. To address these issues, we (a) designed G-SpatialNet, a speech enhancement (SE) model to improve Guided Source Separation (GSS) signals; (b) proposed TLS, a framework comprising time alignment, level alignment, and signal-to-noise ratio filtering, to generate signal-level pseudo labels for real-recorded far-field audio data, thereby facilitating SE models' training; and (c) explored fine-tuning strategies, data augmentation, and multimodal information to enhance the performance of pre-trained Automatic Speech Recognition (ASR) models in meeting scenarios. Finally, our system achieved character error rates (CERs) of 5.44% and 9.52% on the Dev and Eval sets, respectively, with relative improvements of 64.8% and 52.6% over the baseline, securing second place.",
    "arxiv_id": "http://arxiv.org/abs/2505.24446v2",
    "pdf_link": "https://arxiv.org/pdf/2505.24446v2",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "affiliation": "N/A",
    "relevance_score": 25
  },
  {
    "title": "A Radiometric Correction based Optical Modeling Approach to Removing Reflection Noise in TLS Point Clouds of Urban Scenes",
    "authors": [
      "Li Fang",
      "Tianyu Li",
      "Yanghong Lin",
      "Shudong Zhou",
      "Wei Yao"
    ],
    "published": "2024-07-03T06:17:41Z",
    "abstract": "Point clouds are vital in computer vision tasks such as 3D reconstruction, autonomous driving, and robotics. However, TLS-acquired point clouds often contain virtual points from reflective surfaces, causing disruptions. This study presents a reflection noise elimination algorithm for TLS point clouds. Our innovative reflection plane detection algorithm, based on geometry-optical models and physical properties, identifies and categorizes reflection points per optical reflection theory. We've adapted the LSFH feature descriptor to retain reflection features, mitigating interference from symmetrical architectural structures. By incorporating the Hausdorff feature distance, the algorithm enhances resilience to ghosting and deformation, improving virtual point detection accuracy. Extensive experiments on the 3DRN benchmark dataset, featuring diverse urban environments with virtual TLS reflection noise, show our algorithm improves precision and recall rates for 3D points in reflective regions by 57.03\\% and 31.80\\%, respectively. Our method achieves a 9.17\\% better outlier detection rate and 5.65\\% higher accuracy than leading methods. Access the 3DRN dataset at (https://github.com/Tsuiky/3DRN).",
    "arxiv_id": "http://arxiv.org/abs/2407.02830v1",
    "pdf_link": "https://arxiv.org/pdf/2407.02830v1",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "affiliation": "N/A",
    "relevance_score": 25
  },
  {
    "title": "3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding",
    "authors": [
      "Xiaoye Wang",
      "Chen Tang",
      "Xiangyu Yue",
      "Wei-Hong Li"
    ],
    "published": "2025-11-25T18:59:34Z",
    "abstract": "This paper addresses the challenge of training a single network to jointly perform multiple dense prediction tasks, such as segmentation and depth estimation, i.e., multi-task learning (MTL). Current approaches mainly capture cross-task relations in the 2D image space, often leading to unstructured features lacking 3D-awareness. We argue that 3D-awareness is vital for modeling cross-task correlations essential for comprehensive scene understanding. We propose to address this problem by integrating correlations across views, i.e., cost volume, as geometric consistency in the MTL network. Specifically, we introduce a lightweight Cross-view Module (CvM), shared across tasks, to exchange information across views and capture cross-view correlations, integrated with a feature from MTL encoder for multi-task predictions. This module is architecture-agnostic and can be applied to both single and multi-view data. Extensive results on NYUv2 and PASCAL-Context demonstrate that our method effectively injects geometric consistency into existing MTL methods to improve performance.",
    "arxiv_id": "http://arxiv.org/abs/2511.20646v1",
    "pdf_link": "https://arxiv.org/pdf/2511.20646v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "AttnRegDeepLab: A Two-Stage Decoupled Framework for Interpretable Embryo Fragmentation Grading",
    "authors": [
      "Ming-Jhe Lee"
    ],
    "published": "2025-11-23T13:50:49Z",
    "abstract": "Embryo fragmentation is a morphological indicator critical for evaluating developmental potential in In Vitro Fertilization (IVF). However, manual grading is subjective and inefficient, while existing deep learning solutions often lack clinical explainability or suffer from accumulated errors in segmentation area estimation. To address these issues, this study proposes AttnRegDeepLab (Attention-Guided Regression DeepLab), a framework characterized by dual-branch Multi-Task Learning (MTL). A vanilla DeepLabV3+ decoder is modified by integrating Attention Gates into its skip connections, explicitly suppressing cytoplasmic noise to preserve contour details. Furthermore, a Multi-Scale Regression Head is introduced with a Feature Injection mechanism to propagate global grading priors into the segmentation task, rectifying systematic quantification errors. A 2-stage decoupled training strategy is proposed to address the gradient conflict in MTL. Also, a range-based loss is designed to leverage weakly labeled data. Our method achieves robust grading precision while maintaining excellent segmentation accuracy (Dice coefficient =0.729), in contrast to the end-to-end counterpart that might minimize grading error at the expense of contour integrity. This work provides a clinically interpretable solution that balances visual fidelity and quantitative precision.",
    "arxiv_id": "http://arxiv.org/abs/2511.18454v2",
    "pdf_link": "https://arxiv.org/pdf/2511.18454v2",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "CMI-MTL: Cross-Mamba interaction based multi-task learning for medical visual question answering",
    "authors": [
      "Qiangguo Jin",
      "Xianyao Zheng",
      "Hui Cui",
      "Changming Sun",
      "Yuqi Fang",
      "Cong Cong",
      "Ran Su",
      "Leyi Wei",
      "Ping Xuan",
      "Junbo Wang"
    ],
    "published": "2025-11-03T09:05:16Z",
    "abstract": "Medical visual question answering (Med-VQA) is a crucial multimodal task in clinical decision support and telemedicine. Recent self-attention based methods struggle to effectively handle cross-modal semantic alignments between vision and language. Moreover, classification-based methods rely on predefined answer sets. Treating this task as a simple classification problem may make it unable to adapt to the diversity of free-form answers and overlook the detailed semantic information of free-form answers. In order to tackle these challenges, we introduce a Cross-Mamba Interaction based Multi-Task Learning (CMI-MTL) framework that learns cross-modal feature representations from images and texts. CMI-MTL comprises three key modules: fine-grained visual-text feature alignment (FVTA), cross-modal interleaved feature representation (CIFR), and free-form answer-enhanced multi-task learning (FFAE). FVTA extracts the most relevant regions in image-text pairs through fine-grained visual-text feature alignment. CIFR captures cross-modal sequential interactions via cross-modal interleaved feature representation. FFAE leverages auxiliary knowledge from open-ended questions through free-form answer-enhanced multi-task learning, improving the model's capability for open-ended Med-VQA. Experimental results show that CMI-MTL outperforms the existing state-of-the-art methods on three Med-VQA datasets: VQA-RAD, SLAKE, and OVQA. Furthermore, we conduct more interpretability experiments to prove the effectiveness. The code is publicly available at https://github.com/BioMedIA-repo/CMI-MTL.",
    "arxiv_id": "http://arxiv.org/abs/2511.01357v1",
    "pdf_link": "https://arxiv.org/pdf/2511.01357v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "MTMD: A Multi-Task Multi-Domain Framework for Unified Ad Lightweight Ranking at Pinterest",
    "authors": [
      "Xiao Yang",
      "Peifeng Yin",
      "Abe Engle",
      "Jinfeng Zhuang",
      "Ling Leng"
    ],
    "published": "2025-10-10T20:46:19Z",
    "abstract": "The lightweight ad ranking layer, living after the retrieval stage and before the fine ranker, plays a critical role in the success of a cascaded ad recommendation system. Due to the fact that there are multiple optimization tasks depending on the ad domain, e.g., Click Through Rate (CTR) for click ads and Conversion Rate (CVR) for conversion ads, as well as multiple surfaces where an ad is served (home feed, search, or related item recommendation) with diverse ad products (shopping or standard ad); it is an essentially challenging problem in industry on how to do joint holistic optimization in the lightweight ranker, such that the overall platform's value, advertiser's value, and user's value are maximized.   Deep Neural Network (DNN)-based multitask learning (MTL) can handle multiple goals naturally, with each prediction head mapping to a particular optimization goal. However, in practice, it is unclear how to unify data from different surfaces and ad products into a single model. It is critical to learn domain-specialized knowledge and explicitly transfer knowledge between domains to make MTL effective. We present a Multi-Task Multi-Domain (MTMD) architecture under the classic Two-Tower paradigm, with the following key contributions: 1) handle different prediction tasks, ad products, and ad serving surfaces in a unified framework; 2) propose a novel mixture-of-expert architecture to learn both specialized knowledge each domain and common knowledge shared between domains; 3) propose a domain adaption module to encourage knowledge transfer between experts; 4) constrain the modeling of different prediction tasks. MTMD improves the offline loss value by 12% to 36%, mapping to 2% online reduction in cost per click. We have deployed this single MTMD framework into production for Pinterest ad recommendation replacing 9 production models.",
    "arxiv_id": "http://arxiv.org/abs/2510.09857v1",
    "pdf_link": "https://arxiv.org/pdf/2510.09857v1",
    "categories": [
      "cs.IR",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Direct Routing Gradient (DRGrad): A Personalized Information Surgery for Multi-Task Learning (MTL) Recommendations",
    "authors": [
      "Yuguang Liu",
      "Yiyun Miao",
      "Luyao Xia"
    ],
    "published": "2025-10-04T01:28:32Z",
    "abstract": "Multi-task learning (MTL) has emerged as a successful strategy in industrial-scale recommender systems, offering significant advantages such as capturing diverse users' interests and accurately detecting different behaviors like ``click\" or ``dwell time\". However, negative transfer and the seesaw phenomenon pose challenges to MTL models due to the complex and often contradictory task correlations in real-world recommendations. To address the problem while making better use of personalized information, we propose a personalized Direct Routing Gradient framework (DRGrad), which consists of three key components: router, updater and personalized gate network. DRGrad judges the stakes between tasks in the training process, which can leverage all valid gradients for the respective task to reduce conflicts. We evaluate the efficiency of DRGrad on complex MTL using a real-world recommendation dataset with 15 billion samples. The results show that DRGrad's superior performance over competing state-of-the-art MTL models, especially in terms of AUC (Area Under the Curve) metrics, indicating that it effectively manages task conflicts in multi-task learning environments without increasing model complexity, while also addressing the deficiencies in noise processing. Moreover, experiments on the public Census-income dataset and Synthetic dataset, have demonstrated the capability of DRGrad in judging and routing the stakes between tasks with varying degrees of correlation and personalization.",
    "arxiv_id": "http://arxiv.org/abs/2510.09643v1",
    "pdf_link": "https://arxiv.org/pdf/2510.09643v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Facilitating Cognitive Accessibility with LLMs: A Multi-Task Approach to Easy-to-Read Text Generation",
    "authors": [
      "François Ledoyen",
      "Gaël Dias",
      "Jeremie Pantin",
      "Alexis Lechervy",
      "Fabrice Maurel",
      "Youssef Chahir"
    ],
    "published": "2025-10-01T08:44:05Z",
    "abstract": "Simplifying complex texts is essential for ensuring equitable access to information, especially for individuals with cognitive impairments. The Easy-to-Read (ETR) initiative offers a framework for making content accessible to the neurodivergent population, but the manual creation of such texts remains time-consuming and resource-intensive. In this work, we investigate the potential of large language models (LLMs) to automate the generation of ETR content. To address the scarcity of aligned corpora and the specificity of ETR constraints, we propose a multi-task learning (MTL) approach that trains models jointly on text summarization, text simplification, and ETR generation. We explore two different strategies: multi-task retrieval-augmented generation (RAG) for in-context learning, and MTL-LoRA for parameter-efficient fine-tuning. Our experiments with Mistral-7B and LLaMA-3-8B, based on ETR-fr, a new high-quality dataset, demonstrate the benefits of multi-task setups over single-task baselines across all configurations. Moreover, results show that the RAG-based strategy enables generalization in out-of-domain settings, while MTL-LoRA outperforms all learning strategies within in-domain configurations.",
    "arxiv_id": "http://arxiv.org/abs/2510.00662v1",
    "pdf_link": "https://arxiv.org/pdf/2510.00662v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "DiBS-MTL: Transformation-Invariant Multitask Learning with Direction Oracles",
    "authors": [
      "Surya Murthy",
      "Kushagra Gupta",
      "Mustafa O. Karabag",
      "David Fridovich-Keil",
      "Ufuk Topcu"
    ],
    "published": "2025-09-28T15:57:06Z",
    "abstract": "Multitask learning (MTL) algorithms typically rely on schemes that combine different task losses or their gradients through weighted averaging. These methods aim to find Pareto stationary points by using heuristics that require access to task loss values, gradients, or both. In doing so, a central challenge arises because task losses can be arbitrarily, nonaffinely scaled relative to one another, causing certain tasks to dominate training and degrade overall performance. A recent advance in cooperative bargaining theory, the Direction-based Bargaining Solution (DiBS), yields Pareto stationary solutions immune to task domination because of its invariance to monotonic nonaffine task loss transformations. However, the convergence behavior of DiBS in nonconvex MTL settings is currently not understood. To this end, we prove that under standard assumptions, a subsequence of DiBS iterates converges to a Pareto stationary point when task losses are possibly nonconvex, and propose DiBS-MTL, a computationally efficient adaptation of DiBS to the MTL setting. Finally, we validate DiBS-MTL empirically on standard MTL benchmarks, showing that it achieves competitive performance with state-of-the-art methods while maintaining robustness to nonaffine monotonic transformations that significantly degrade the performance of existing approaches, including prior bargaining-inspired MTL methods. Code available at https://github.com/suryakmurthy/dibs-mtl.",
    "arxiv_id": "http://arxiv.org/abs/2509.23948v1",
    "pdf_link": "https://arxiv.org/pdf/2509.23948v1",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Quantum-Enhanced Multi-Task Learning with Learnable Weighting for Pharmacokinetic and Toxicity Prediction",
    "authors": [
      "Han Zhang",
      "Fengji Ma",
      "Jiamin Su",
      "Xinyue Yang",
      "Lei Wang",
      "Wen-Cai Ye",
      "Li Liu"
    ],
    "published": "2025-09-04T18:33:40Z",
    "abstract": "Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity) plays a crucial role in drug discovery and development, accelerating the screening and optimization of new drugs. Existing methods primarily rely on single-task learning (STL), which often fails to fully exploit the complementarities between tasks. Besides, it requires more computational resources while training and inference of each task independently. To address these issues, we propose a new unified Quantum-enhanced and task-Weighted Multi-Task Learning (QW-MTL) framework, specifically designed for ADMET classification tasks. Built upon the Chemprop-RDKit backbone, QW-MTL adopts quantum chemical descriptors to enrich molecular representations with additional information about the electronic structure and interactions. Meanwhile, it introduces a novel exponential task weighting scheme that combines dataset-scale priors with learnable parameters to achieve dynamic loss balancing across tasks. To the best of our knowledge, this is the first work to systematically conduct joint multi-task training across all 13 Therapeutics Data Commons (TDC) classification benchmarks, using leaderboard-style data splits to ensure a standardized and realistic evaluation setting. Extensive experimental results show that QW-MTL significantly outperforms single-task baselines on 12 out of 13 tasks, achieving high predictive performance with minimal model complexity and fast inference, demonstrating the effectiveness and efficiency of multi-task molecular learning enhanced by quantum-informed features and adaptive task weighting.",
    "arxiv_id": "http://arxiv.org/abs/2509.04601v1",
    "pdf_link": "https://arxiv.org/pdf/2509.04601v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task",
    "authors": [
      "JungHo Jung",
      "Junhyun Lee"
    ],
    "published": "2025-09-04T17:21:36Z",
    "abstract": "End-to-end speech-to-text translation typically suffers from the scarcity of paired speech-text data. One way to overcome this shortcoming is to utilize the bitext data from the Machine Translation (MT) task and perform Multi-Task Learning (MTL). In this paper, we formulate MTL from a regularization perspective and explore how sequences can be regularized within and across modalities. By thoroughly investigating the effect of consistency regularization (different modality) and R-drop (same modality), we show how they respectively contribute to the total regularization. We also demonstrate that the coefficient of MT loss serves as another source of regularization in the MTL setting. With these three sources of regularization, we introduce the optimal regularization contour in the high-dimensional space, called the regularization horizon. Experiments show that tuning the hyperparameters within the regularization horizon achieves near state-of-the-art performance on the MuST-C dataset.",
    "arxiv_id": "http://arxiv.org/abs/2509.09701v1",
    "pdf_link": "https://arxiv.org/pdf/2509.09701v1",
    "categories": [
      "cs.CL"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "DivMerge: A divergence-based model merging method for multi-tasking",
    "authors": [
      "Brahim Touayouch",
      "Loïc Fosse",
      "Géraldine Damnati",
      "Gwénolé Lecorvé"
    ],
    "published": "2025-09-02T09:04:41Z",
    "abstract": "Multi-task learning (MTL) is often achieved by merging datasets before fine-tuning, but the growing availability of fine-tuned models has led to new approaches such as model merging via task arithmetic. A major challenge in this setting is task interference, which worsens as the number of tasks increases. We propose a method that merges models trained on different tasks into a single model, maintaining strong performance across all tasks. Our approach leverages Jensen-Shannon divergence to guide the merging process without requiring additional labelled data, and automatically balances task importance. Unlike existing methods, our approach remains robust as the number of tasks grows and consistently outperforms prior work.",
    "arxiv_id": "http://arxiv.org/abs/2509.02108v3",
    "pdf_link": "https://arxiv.org/pdf/2509.02108v3",
    "categories": [
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Achieving detailed medial temporal lobe segmentation with upsampled isotropic training from implicit neural representation",
    "authors": [
      "Yue Li",
      "Pulkit Khandelwal",
      "Rohit Jena",
      "Long Xie",
      "Michael Duong",
      "Amanda E. Denning",
      "Christopher A. Brown",
      "Laura E. M. Wisse",
      "Sandhitsu R. Das",
      "David A. Wolk",
      "Paul A. Yushkevich"
    ],
    "published": "2025-08-24T00:37:03Z",
    "abstract": "Imaging biomarkers in magnetic resonance imaging (MRI) are important tools for diagnosing, tracking and treating Alzheimer's disease (AD). Neurofibrillary tau pathology in AD is closely linked to neurodegeneration and generally follows a pattern of spread in the brain, with early stages involving subregions of the medial temporal lobe (MTL). Accurate segmentation of MTL subregions is needed to extract granular biomarkers of AD progression. MTL subregions are often imaged using T2-weighted (T2w) MRI scans that are highly anisotropic due to constraints of MRI physics and image acquisition, making it difficult to reliably model MTL subregions geometrically and extract morphological measures, such as thickness. In this study, we used an implicit neural representation method to combine isotropic T1-weighted (T1w) and anisotropic T2w MRI to upsample an atlas set of expert-annotated MTL subregions, establishing a multi-modality, high-resolution training set of isotropic data for automatic segmentation with the nnU-Net framework. In an independent test set, the morphological measures extracted using this isotropic model showed stronger effect sizes than models trained on anisotropic in distinguishing participants with mild cognitive impairment (MCI) and cognitively unimpaired individuals. In test-retest analysis, morphological measures extracted using the isotropic model had greater stability. This study demonstrates improved reliability of MRI-derived MTL subregion biomarkers without additional atlas annotation effort, which may more accurately quantify and track the relationship between AD pathology and brain atrophy for monitoring disease progression.",
    "arxiv_id": "http://arxiv.org/abs/2508.17171v2",
    "pdf_link": "https://arxiv.org/pdf/2508.17171v2",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Hierarchy-Consistent Learning and Adaptive Loss Balancing for Hierarchical Multi-Label Classification",
    "authors": [
      "Ruobing Jiang",
      "Mengzhe Liu",
      "Haobing Liu",
      "Yanwei Yu"
    ],
    "published": "2025-08-19T02:15:41Z",
    "abstract": "Hierarchical Multi-Label Classification (HMC) faces critical challenges in maintaining structural consistency and balancing loss weighting in Multi-Task Learning (MTL). In order to address these issues, we propose a classifier called HCAL based on MTL integrated with prototype contrastive learning and adaptive task-weighting mechanisms. The most significant advantage of our classifier is semantic consistency including both prototype with explicitly modeling label and feature aggregation from child classes to parent classes. The other important advantage is an adaptive loss-weighting mechanism that dynamically allocates optimization resources by monitoring task-specific convergence rates. It effectively resolves the \"one-strong-many-weak\" optimization bias inherent in traditional MTL approaches. To further enhance robustness, a prototype perturbation mechanism is formulated by injecting controlled noise into prototype to expand decision boundaries. Additionally, we formalize a quantitative metric called Hierarchical Violation Rate (HVR) as to evaluate hierarchical consistency and generalization. Extensive experiments across three datasets demonstrate both the higher classification accuracy and reduced hierarchical violation rate of the proposed classifier over baseline models.",
    "arxiv_id": "http://arxiv.org/abs/2508.13452v1",
    "pdf_link": "https://arxiv.org/pdf/2508.13452v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data",
    "authors": [
      "Lalitesh Morishetti",
      "Abhay Kumar",
      "Jonathan Scott",
      "Kaushiki Nag",
      "Gunjan Sharma",
      "Shanu Vashishtha",
      "Rahul Sridhar",
      "Rohit Chatter",
      "Kannan Achan"
    ],
    "published": "2025-08-13T09:15:08Z",
    "abstract": "In this paper, we present a novel model architecture for optimizing personalized product search ranking using a multi-task learning (MTL) framework. Our approach uniquely integrates tabular and non-tabular data, leveraging a pre-trained TinyBERT model for semantic embeddings and a novel sampling technique to capture diverse customer behaviors. We evaluate our model against several baselines, including XGBoost, TabNet, FT-Transformer, DCN-V2, and MMoE, focusing on their ability to handle mixed data types and optimize personalized ranking. Additionally, we propose a scalable relevance labeling mechanism based on click-through rates, click positions, and semantic similarity, offering an alternative to traditional human-annotated labels. Experimental results show that combining non-tabular data with advanced embedding techniques in multi-task learning paradigm significantly enhances model performance. Ablation studies further underscore the benefits of incorporating relevance labels, fine-tuning TinyBERT layers, and TinyBERT query-product embedding interactions. These results demonstrate the effectiveness of our approach in achieving improved personalized product search ranking.",
    "arxiv_id": "http://arxiv.org/abs/2508.09636v1",
    "pdf_link": "https://arxiv.org/pdf/2508.09636v1",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Cyberbullying Detection via Aggression-Enhanced Prompting",
    "authors": [
      "Aisha Saeid",
      "Anu Sabu",
      "Girish A. Koushik",
      "Ferrante Neri",
      "Diptesh Kanojia"
    ],
    "published": "2025-08-08T14:46:05Z",
    "abstract": "Detecting cyberbullying on social media remains a critical challenge due to its subtle and varied expressions. This study investigates whether integrating aggression detection as an auxiliary task within a unified training framework can enhance the generalisation and performance of large language models (LLMs) in cyberbullying detection. Experiments are conducted on five aggression datasets and one cyberbullying dataset using instruction-tuned LLMs. We evaluated multiple strategies: zero-shot, few-shot, independent LoRA fine-tuning, and multi-task learning (MTL). Given the inconsistent results of MTL, we propose an enriched prompt pipeline approach in which aggression predictions are embedded into cyberbullying detection prompts to provide contextual augmentation. Preliminary results show that the enriched prompt pipeline consistently outperforms standard LoRA fine-tuning, indicating that aggression-informed context significantly boosts cyberbullying detection. This study highlights the potential of auxiliary tasks, such as aggression detection, to improve the generalisation of LLMs for safety-critical applications on social networks.",
    "arxiv_id": "http://arxiv.org/abs/2508.06360v2",
    "pdf_link": "https://arxiv.org/pdf/2508.06360v2",
    "categories": [
      "cs.CL"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Practical Multi-Task Learning for Rare Conversions in Ad Tech",
    "authors": [
      "Yuval Dishi",
      "Ophir Friedler",
      "Yonatan Karni",
      "Natalia Silberstein",
      "Yulia Stolin"
    ],
    "published": "2025-07-27T07:28:27Z",
    "abstract": "We present a Multi-Task Learning (MTL) approach for improving predictions for rare (e.g., <1%) conversion events in online advertising. The conversions are classified into \"rare\" or \"frequent\" types based on historical statistics. The model learns shared representations across all signals while specializing through separate task towers for each type. The approach was tested and fully deployed to production, demonstrating consistent improvements in both offline (0.69% AUC lift) and online KPI performance metric (2% Cost per Action reduction).",
    "arxiv_id": "http://arxiv.org/abs/2507.20161v1",
    "pdf_link": "https://arxiv.org/pdf/2507.20161v1",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Smooth-Distill: A Self-distillation Framework for Multitask Learning with Wearable Sensor Data",
    "authors": [
      "Hoang-Dieu Vu",
      "Duc-Nghia Tran",
      "Quang-Tu Pham",
      "Hieu H. Pham",
      "Nicolas Vuillerme",
      "Duc-Tan Tran"
    ],
    "published": "2025-06-27T06:51:51Z",
    "abstract": "This paper introduces Smooth-Distill, a novel self-distillation framework designed to simultaneously perform human activity recognition (HAR) and sensor placement detection using wearable sensor data. The proposed approach utilizes a unified CNN-based architecture, MTL-net, which processes accelerometer data and branches into two outputs for each respective task. Unlike conventional distillation methods that require separate teacher and student models, the proposed framework utilizes a smoothed, historical version of the model itself as the teacher, significantly reducing training computational overhead while maintaining performance benefits. To support this research, we developed a comprehensive accelerometer-based dataset capturing 12 distinct sleep postures across three different wearing positions, complementing two existing public datasets (MHealth and WISDM). Experimental results show that Smooth-Distill consistently outperforms alternative approaches across different evaluation scenarios, achieving notable improvements in both human activity recognition and device placement detection tasks. This method demonstrates enhanced stability in convergence patterns during training and exhibits reduced overfitting compared to traditional multitask learning baselines. This framework contributes to the practical implementation of knowledge distillation in human activity recognition systems, offering an effective solution for multitask learning with accelerometer data that balances accuracy and training efficiency. More broadly, it reduces the computational cost of model training, which is critical for scenarios requiring frequent model updates or training on resource-constrained platforms. The code and model are available at https://github.com/Kuan2vn/smooth\\_distill.",
    "arxiv_id": "http://arxiv.org/abs/2507.00061v1",
    "pdf_link": "https://arxiv.org/pdf/2507.00061v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Multimodal Mixture of Low-Rank Experts for Sentiment Analysis and Emotion Recognition",
    "authors": [
      "Shuo Zhang",
      "Jinsong Zhang",
      "Zhejun Zhang",
      "Lei Li"
    ],
    "published": "2025-05-20T09:46:56Z",
    "abstract": "Multi-task learning (MTL) enables the efficient transfer of extra knowledge acquired from other tasks. The high correlation between multimodal sentiment analysis (MSA) and multimodal emotion recognition (MER) supports their joint training. However, existing methods primarily employ hard parameter sharing, ignoring parameter conflicts caused by complex task correlations. In this paper, we present a novel MTL method for MSA and MER, termed Multimodal Mixture of Low-Rank Experts (MMoLRE). MMoLRE utilizes shared and task-specific experts to distinctly model common and unique task characteristics, thereby avoiding parameter conflicts. Additionally, inspired by low-rank structures in the Mixture of Experts (MoE) framework, we design low-rank expert networks to reduce parameter and computational overhead as the number of experts increases. Extensive experiments on the CMU-MOSI and CMU-MOSEI benchmarks demonstrate that MMoLRE achieves state-of-the-art performance on the MSA task and competitive results on the MER task.",
    "arxiv_id": "http://arxiv.org/abs/2505.14143v1",
    "pdf_link": "https://arxiv.org/pdf/2505.14143v1",
    "categories": [
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "End-to-End Multi-Task Policy Learning from NMPC for Quadruped Locomotion",
    "authors": [
      "Anudeep Sajja",
      "Shahram Khorshidi",
      "Sebastian Houben",
      "Maren Bennewitz"
    ],
    "published": "2025-05-13T13:46:35Z",
    "abstract": "Quadruped robots excel in traversing complex, unstructured environments where wheeled robots often fail. However, enabling efficient and adaptable locomotion remains challenging due to the quadrupeds' nonlinear dynamics, high degrees of freedom, and the computational demands of real-time control. Optimization-based controllers, such as Nonlinear Model Predictive Control (NMPC), have shown strong performance, but their reliance on accurate state estimation and high computational overhead makes deployment in real-world settings challenging. In this work, we present a Multi-Task Learning (MTL) framework in which expert NMPC demonstrations are used to train a single neural network to predict actions for multiple locomotion behaviors directly from raw proprioceptive sensor inputs. We evaluate our approach extensively on the quadruped robot Go1, both in simulation and on real hardware, demonstrating that it accurately reproduces expert behavior, allows smooth gait switching, and simplifies the control pipeline for real-time deployment. Our MTL architecture enables learning diverse gaits within a unified policy, achieving high $R^{2}$ scores for predicted joint targets across all tasks.",
    "arxiv_id": "http://arxiv.org/abs/2505.08574v1",
    "pdf_link": "https://arxiv.org/pdf/2505.08574v1",
    "categories": [
      "cs.RO"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Imaging Biomarkers for Neurodegenerative Diseases from Detailed Segmentation of Medial Temporal Lobe Subregions on in vivo Brain MRI Using Upsampling Strategy Guided by High-resolution ex vivo MRI",
    "authors": [
      "Yue Li",
      "Pulkit Khandelwal",
      "Long Xie",
      "Laura E. M. Wisse",
      "Amanda E. Denning",
      "Christopher A. Brown",
      "Emily McGrew",
      "Sydney A. Lim",
      "Niyousha Sadeghpour",
      "Sadhana Ravikumar",
      "Ranjit Ittyerah",
      "Eunice Chung",
      "Daniel T. Ohm",
      "Nidhi S. Mundada",
      "María Mercedes Íñiguez de Onzoño Martín",
      "María del Mar Arroyo Jiménez",
      "Monica Mũnoz",
      "Maria del Pilar Marcos Rabal",
      "David J. Irwin",
      "Edward B. Lee",
      "Ricardo Insausti",
      "Sandhitsu R. Das",
      "David A. Wolk",
      "Paul A. Yushkevich"
    ],
    "published": "2025-04-25T15:54:03Z",
    "abstract": "The medial temporal lobe (MTL) is a region impacted extensively and non-uniformly in early stages of Alzheimer's disease (AD). Regional MTL morphometric measures extracted from magnetic resonance imaging (MRI) are supportive features for the diagnosis of AD and related disorders (ADRD). Different MRI modalities have distinct advantages for MTL morphometry. Anisotropic T2-weighted (T2w) MRI is preferred for hippocampal subfields due to its higher contrast between hippocampal layers. Isotropic T1-weighted (T1w) MRI is beneficial for thickness calculation of extra-hippocampal subregions due to its stable image quality and isotropic resolution. We propose a multi-modality MTL segmentation algorithm that bridges the T1w and T2w modalities by bringing both to a nearly isotropic voxel space. Guided by high-resolution ex vivo 9.4T MRI, an upsampling model was designed for the ground truth segmentations. Combined with non-local means upsampling, this model was used to construct a nearly iso-tropic T1w and T2w MTL subregion segmentation training set, which was used to train a nnUNet model. Morphometric biomarkers extracted by this model were compared to those extracted using conventional models operating in anisotropic spaces on downstream tasks. Biomarkers extracted using the proposed model had greater ability to discriminate between individuals with mild cognitive impairment and cognitively unimpaired; and had great-er longitudinal stability. These findings suggest that the biomarkers derived from T1w and T2w MRI unsampled to nearly isotropic resolution have sig-nificant potential for improving disease diagnosis and monitoring disease progression in ADRD.",
    "arxiv_id": "http://arxiv.org/abs/2504.18442v2",
    "pdf_link": "https://arxiv.org/pdf/2504.18442v2",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "DG-STMTL: A Novel Graph Convolutional Network for Multi-Task Spatio-Temporal Traffic Forecasting",
    "authors": [
      "Wanna Cui",
      "Peizheng Wang",
      "Faliang Yin"
    ],
    "published": "2025-04-10T15:00:20Z",
    "abstract": "Spatio-temporal traffic prediction is crucial in intelligent transportation systems. The key challenge of accurate prediction is how to model the complex spatio-temporal dependencies and adapt to the inherent dynamics in data. Traditional Graph Convolutional Networks (GCNs) often struggle with static adjacency matrices that introduce domain bias or learnable matrices that may be overfitting to specific patterns. This challenge becomes more complex when considering Multi-Task Learning (MTL). While MTL has the potential to enhance prediction accuracy through task synergies, it can also face significant hurdles due to task interference. To overcome these challenges, this study introduces a novel MTL framework, Dynamic Group-wise Spatio-Temporal Multi-Task Learning (DG-STMTL). DG-STMTL proposes a hybrid adjacency matrix generation module that combines static matrices with dynamic ones through a task-specific gating mechanism. We also introduce a group-wise GCN module to enhance the modelling capability of spatio-temporal dependencies. We conduct extensive experiments on two real-world datasets to evaluate our method. Results show that our method outperforms other state-of-the-arts, indicating its effectiveness and robustness.",
    "arxiv_id": "http://arxiv.org/abs/2504.07822v2",
    "pdf_link": "https://arxiv.org/pdf/2504.07822v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Injecting Imbalance Sensitivity for Multi-Task Learning",
    "authors": [
      "Zhipeng Zhou",
      "Liu Liu",
      "Peilin Zhao",
      "Wei Gong"
    ],
    "published": "2025-03-11T03:11:54Z",
    "abstract": "Multi-task learning (MTL) has emerged as a promising approach for deploying deep learning models in real-life applications. Recent studies have proposed optimization-based learning paradigms to establish task-shared representations in MTL. However, our paper empirically argues that these studies, specifically gradient-based ones, primarily emphasize the conflict issue while neglecting the potentially more significant impact of imbalance/dominance in MTL. In line with this perspective, we enhance the existing baseline method by injecting imbalance-sensitivity through the imposition of constraints on the projected norms. To demonstrate the effectiveness of our proposed IMbalance-sensitive Gradient (IMGrad) descent method, we evaluate it on multiple mainstream MTL benchmarks, encompassing supervised learning tasks as well as reinforcement learning. The experimental results consistently demonstrate competitive performance.",
    "arxiv_id": "http://arxiv.org/abs/2503.08006v1",
    "pdf_link": "https://arxiv.org/pdf/2503.08006v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Systems for detecting and measuring backgrounds with the SABRE South experiment",
    "authors": [
      "L. J. Milligan"
    ],
    "published": "2025-11-20T15:27:17Z",
    "abstract": "The SABRE (Sodium iodide with Active Background REjection) experiment aims to detect an annual rate modulation from dark matter interactions in ultra-high purity NaI(Tl) crystals which will provide a model independent test of the signal observed by DAMA/LIBRA. SABRE will consist of two separate detectors in the Northern and Southern hemispheres. SABRE South will be located in the newly completed Stawell Underground Physics Laboratory (SUPL), the first deep underground laboratory in the southern hemisphere. The combination of SABRE North and South is intended to disentangle seasonal or site-related effects from the dark matter-like modulated signal. Measuring and understanding backgrounds is essential for the reliability and consistent performance of these searches, and as the first large detector in SUPL SABRE South will also be used to measure backgrounds from radiogenic and cosmogenic sources. The SABRE South veto system is designed to detect the signals generated by radiation and cosmic rays using a 12 kL linear alkyl-benzene (LAB) based liquid scintillator (LS) detector contained in a steel vessel and instrumented with 18 Hamamatsu R5912 photomultiplier tubes (PMTs), alongside a plane of 8 plastic scintillator modules (instrumented with 2 R13089 PMTs) located above the vessel to reliably detect muons from cosmic-rays with a position resolution of 5 cm.",
    "arxiv_id": "http://arxiv.org/abs/2511.16462v1",
    "pdf_link": "https://arxiv.org/pdf/2511.16462v1",
    "categories": [
      "hep-ex"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Ab-initio study of structural, vibrational and non-linear optical properties of (TiO2)-(Tl2O)-(TeO2) glasses",
    "authors": [
      "Raghvender Raghvender",
      "Assil Bouzid",
      "Evgenii M. Roginskii",
      "David Hamani",
      "Olivier Noguera",
      "Philippe Thomas",
      "Olivier Masson"
    ],
    "published": "2025-10-17T06:14:02Z",
    "abstract": "This paper reports on a systematic first-principles molecular dynamics investigation of binary (TlO$_{0.5}$)$_{y}$-(TeO$_2$)$_{1-y}$ and ternary $(TiO$_{2}$)$_{x}$-(TlO$_{0.5}$)$_{y}$-(TeO$_2$)_{1-x-y}$ tellurite glasses. The obtained structural models are validated against available measured X-ray pair distribution functions. In the binary system, increasing TlO$_{0.5}$ content induces network depolymerization through the reduction of Te coordination number, the substitution of Te-O-Te linkages with Te=O$^{-}$...Tl$^{+}$ units, and the proliferation of non-bridging oxygens. In addition, rings analysis demonstrates a loss of the network connectivity via the opening of small n-membered rings. In contrast, TiO$_2$ acts as a network former in ternary glasses, preserving Te coordination number, and promoting a high fraction of bridging oxygens. Ti atoms induces a network repolymerization that manifests through the formation of smaller Ti-containing n-membered rings thereby balancing the strong effect of Tl$_2$O modifier. Beside the structural analysis, we also computed Raman spectra and non-linear optical properties on the obtained large periodic models. Our results reproduce experimental trends in Raman band shifts with composition, while nonlinear optical calculations show that <$χ^{(3)}$> remains stable with TlO$_{0.5}$ addition in binary glasses, consistent with experiment. In the case of ternary systems, we find that the inclusion of a small fraction of TiO$_2$ preserves the high optical nonlinearity of the TeO$_2$ network while maintaining the overall network connectivity. These results establish a predictive framework for tailoring the atomic structure and nonlinear optical response of tellurite glasses through the controlled interplay of modifiers nature and concentration.",
    "arxiv_id": "http://arxiv.org/abs/2510.15343v1",
    "pdf_link": "https://arxiv.org/pdf/2510.15343v1",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "A Logic of Sattestation",
    "authors": [
      "Aaron D. Jaggard",
      "Paul Syverson",
      "Catherine Meadows"
    ],
    "published": "2024-05-03T01:48:07Z",
    "abstract": "We introduce a logic for reasoning about contextual trust for web addresses, provide a Kripke semantics for it, and prove its soundness under reasonable assumptions about principals' policies.   Self-Authenticating Traditional Addresses (SATAs) are valid DNS addresses or URLs that are generally meaningful -- to both humans and web infrastructure -- and contain a commitment to a public key in the address itself. Trust in web addresses is currently established via domain name registration, TLS certificates, and other hierarchical elements of the internet infrastructure. SATAs support such structural roots of trust but also complementary contextual roots associated with descriptive properties. The existing structural roots leave web connections open to a variety of well-documented and significant hijack vulnerabilities. Contextual trust roots provide, among other things, stronger resistance to such vulnerabilities.   We also consider labeled SATAs, which include descriptive properties such as that a SATA is an address for a news organization, a site belonging to a particular government or company, a site with information about a certain topic, etc. Our logic addresses both trust in the bound together identity of the address and trust in the binding of labels to it. Our logic allows reasoning about delegation of trust with respect to specified labels, relationships between labels that provide more or less specific information, and the interaction between these two aspects.   In addition to soundness, we prove that if a principal trusts a particular identity (possibly with label), then either this trust is initially assumed, or there is a trust chain of delegations to this from initial trust assumptions. We also present an algorithm that effectively derives all possible trust statements from the set of initial trust assumptions and show it to be sound, complete, and terminating.",
    "arxiv_id": "http://arxiv.org/abs/2405.01809v1",
    "pdf_link": "https://arxiv.org/pdf/2405.01809v1",
    "categories": [
      "cs.CR",
      "cs.LO"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Current Affairs: A Security Measurement Study of CCS EV Charging Deployments",
    "authors": [
      "Marcell Szakály",
      "Sebastian Köhler",
      "Ivan Martinovic"
    ],
    "published": "2024-04-09T22:12:39Z",
    "abstract": "Since its introduction in 2012, the Combined Charging System (CCS) has emerged as the leading technology for EV fast charging in Europe, North America and parts of Asia. The charging communication of CCS is defined by the ISO 15118 standards, which have been improved over the years. Most notably, in 2014, important security features such as Transport Layer Security (TLS) and usability enhancements such as Plug and Charge were introduced.   In this paper, we conduct the first measurement study of publicly deployed CCS DC charging stations to capture the state of deployment for different protocol versions and to better understand the attack surface of the EV charging infrastructure. In our evaluation, we examine 325 chargers manufactured between April 2013 and June 2023, and installed as late as May 2024 by 26 manufacturers across 4 European countries. We find that only 12% of the charging stations we analyzed implement TLS at all, leaving all others vulnerable to attacks that have already been demonstrated many years ago. We observe an increasing trend in support for ISO 15118-2 over the years, reaching 70% of chargers manufactured in 2023. We further notice that most chargers use a decade-old firmware for their HomePlug modems, which could contain vulnerabilities that have been patched since. Finally, we discuss design flaws with the Public Key Infrastructure system used in EV charging, and propose changes to improve the adoption and availability of TLS.",
    "arxiv_id": "http://arxiv.org/abs/2404.06635v2",
    "pdf_link": "https://arxiv.org/pdf/2404.06635v2",
    "categories": [
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "A Practical Implementation of Customized Scrum-Based Agile Framework in Aerospace Software Development Under DO-178C Constraints",
    "authors": [
      "Malik Muhammad Umer"
    ],
    "published": "2025-11-18T07:45:34Z",
    "abstract": "The increasing complexity of aerospace systems requires development processes that balance agility with stringent safety and certification demands. This study presents an empirically validated Scrum-based Agile framework tailored for DO-178C compliant, safety-critical aerospace software. The framework adapts core Scrum roles, artifacts, and events to meet certification, verification, and independence objectives. Key enhancements include a multi-disciplinary product ownership model, dual compliance-and-functionality acceptance criteria, independent testing and documentation teams, and dedicated certification liaisons. The approach was evaluated through two comparable aerospace projects-one using the customized Agile process and the other a traditional Waterfall model. Results showed significant improvements: a 76% reduction in Total Effort per Requirement, 75% faster Defect Detection, 78% faster Defect Resolution, and over 50% lower Defect Density, while maintaining full compliance with DO-178C Design Assurance Level A. These findings demonstrate that Agile practices and regulatory compliance can coexist effectively when supported by disciplined tailoring and proactive engagement with certification authorities. The study also notes challenges, including increased V&V effort due to recurring Sprint activities and refactoring inherent to iterative development. Nonetheless, it identifies substantial opportunities for further gains through workflow automation, CI/CD practices, and automated documentation, verification, and configuration management. Future research should expand validation of this framework across the aerospace domain and other safety-critical industries with similar certification requirements.",
    "arxiv_id": "http://arxiv.org/abs/2511.14215v1",
    "pdf_link": "https://arxiv.org/pdf/2511.14215v1",
    "categories": [
      "cs.SE"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Advocate -- Trustworthy Evidence in Cloud Systems",
    "authors": [
      "Sebastian Werner",
      "Sepideh Masoudi",
      "Fernando Castillo",
      "Fabian Piper",
      "Jonathan Heiss"
    ],
    "published": "2024-10-17T12:09:26Z",
    "abstract": "The rapid evolution of cloud-native applications, characterized by dynamic, interconnected services, presents significant challenges for maintaining trustworthy and auditable systems, especially in sensitive contexts, such as finance or healthcare. Traditional methods of verification and certification are often inadequate due to the fast-past and dynamic development practices common in cloud computing. This paper introduces Advocate, a novel agent-based system designed to generate verifiable evidence of cloud-native application operations. By integrating with existing infrastructure tools, such as Kubernetes and distributed tracing systems, Advocate captures, authenticates, and stores evidence trails in a tamper-resistant manner. This approach not only supports the auditing process but also allows for privacy-preserving evidence aggregation. Advocate's extensible architecture facilitates its deployment in diverse environments, enabling the verification and adherence to policies and enhance trust in cloud services.",
    "arxiv_id": "http://arxiv.org/abs/2410.13477v1",
    "pdf_link": "https://arxiv.org/pdf/2410.13477v1",
    "categories": [
      "cs.DC",
      "cs.CR"
    ],
    "affiliation": "N/A",
    "relevance_score": 20
  },
  {
    "title": "Thermal cycling -- evidence for a generalized tunneling model and a tool to distinguish noise sources in quantum circuits",
    "authors": [
      "Yigal Reiss",
      "Moshe Schechter"
    ],
    "published": "2024-10-25T19:04:04Z",
    "abstract": "Structural two level systems (TLSs) ubiquitous in amorphous solids are dramatically sensitive to thermal cycling to about $20$K and then back to low temperature, a process upon which the excitation energy of most TLSs is significantly changed. Using Monte Carlo simulations we demonstrate that this phenomenon is not contained within the standard tunneling model, but is well explained by a model that includes an additional set of TLSs that are pseudo-gapped at low energies, yet possess strong strain interaction through which they generate significant dynamical disorder upon thermal cycling. Our results provide additional support for the broad applicability of the Two-TLS model to amorphous solids at low temperatures, bringing us closer to a comprehensive understanding of the universal behavior of phonon attenuation in these materials. With regard to quantum superconducting circuits, our results suggest thermal cycling as a unique protocol to distinguish TLS noise from other noise sources. Possible relation of the Two-TLS model to ionizing radiation effects on long-time fluctuations in qubit relaxation times and on TLS scrambling is discussed.",
    "arxiv_id": "http://arxiv.org/abs/2410.19930v2",
    "pdf_link": "https://arxiv.org/pdf/2410.19930v2",
    "categories": [
      "cond-mat.dis-nn",
      "quant-ph"
    ],
    "affiliation": "N/A",
    "relevance_score": 15
  },
  {
    "title": "Transmission Line Defect Detection Based on UAV Patrol Images and Vision-language Pretraining",
    "authors": [
      "Ke Zhang",
      "Zhaoye Zheng",
      "Yurong Guo",
      "Jiacun Wang",
      "Jiyuan Yang",
      "Yangjie Xiao"
    ],
    "published": "2024-11-18T08:32:51Z",
    "abstract": "Unmanned aerial vehicle (UAV) patrol inspection has emerged as a predominant approach in transmission line monitoring owing to its cost-effectiveness. Detecting defects in transmission lines is a critical task during UAV patrol inspection. However, due to imaging distance and shooting angles, UAV patrol images often suffer from insufficient defect-related visual information, which has an adverse effect on detection accuracy. In this article, we propose a novel method for detecting defects in UAV patrol images, which is based on vision-language pretraining for transmission line (VLP-TL) and a progressive transfer strategy (PTS). Specifically, VLP-TL contains two novel pretraining tasks tailored for the transmission line scenario, aimimg at pretraining an image encoder with abundant knowledge acquired from both visual and linguistic information. Transferring the pretrained image encoder to the defect detector as its backbone can effectively alleviate the insufficient visual information problem. In addition, the PTS further improves transfer performance by progressively bridging the gap between pretraining and downstream defection detection. Experimental results demonstrate that the proposed method significantly improves defect detection accuracy by jointly utilizing multimodal information, overcoming the limitations of insufficient defect-related visual information provided by UAV patrol images.",
    "arxiv_id": "http://arxiv.org/abs/2411.11370v2",
    "pdf_link": "https://arxiv.org/pdf/2411.11370v2",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 10
  },
  {
    "title": "IRADCAL: A Monolithic Inorganic Scintillator And Thin Scintillators To Measure Low Energy Electron, Proton And Heavy Ion Albedo Spectrums From Lunar Surface",
    "authors": [
      "A. B. Alpat",
      "A. Bozkurt",
      "G. Bartolini",
      "R. Bayram",
      "A. I. Shah",
      "L. Salvi",
      "Y. Bakis",
      "E. Huseyinoglu",
      "T. Wusimanjiang",
      "H. Raheem",
      "D. Dolek",
      "N. Ciccarella",
      "S. Gigli"
    ],
    "published": "2024-11-17T21:21:40Z",
    "abstract": "The Moon is directly exposed to various space radiation types: Solar Wind (ions between 0.5 to 10 keV and lower energy electrons), Solar Energetic Particles (SEPs, ranging from 10 keV to several hundred MeV ions and electrons), Galactic Cosmic Rays (GCRs) and Anomalous Cosmic Rays (ACRs, ranging from 1 to 100 MeV particles). Monitoring SEPs and GCRs is critical to assess the lunar radiation environment in preparation for the return of humans to the Moon and to understand related radiation risks. As part of the Turkish Lunar Mission (TLM), a small acceptance particle detector is being developed to measure the albedo electron, proton, and heavy ion fluxes backscattered from the lunar surface. In low lunar orbit, the detector FoV will look at the Moon surface. The IRADCAL detectors consist of several layers, from top to down: a Multi-Layer Insulator (MLI); a thin plastic scintillator (S1) seen by four Silicon Photomultipliers (SIPMs), placed to form a cross on light guide surrounding the scintillator (S1); a 26x26x70 mm3 CsI(Tl) crystal scintillator (S2) and a thin crystal scintillator seen by four SIPMs (S3). The detector is designed to measure contained proton energy spectrum from 400 keV to 150 MeV, electron from 50 keV to 10 MeV and heavy ions (up to the CNO group) with energies up to 20 MeV/n. IRADCAL will provide two dE/dX values from two thin scintillators, Etot or dE/dX from thick scintillator, and dE/E ratios for particle identification. A multi-layer perceptron is being developed by using deep neural network algorithm to estimate the Depth of Interaction (DoI). S1 provides level 1 trigger and hit position, which, combined with DoI point, will help determine if a particle is escaping from the sides and to separate up/down-going particles. The thicker S3 will help identify whether the event is fully contained. It will fit in 2U CubeSat with 2.5 kg and 15 Watts of power required.",
    "arxiv_id": "http://arxiv.org/abs/2411.11178v1",
    "pdf_link": "https://arxiv.org/pdf/2411.11178v1",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "affiliation": "N/A",
    "relevance_score": 10
  },
  {
    "title": "Radiopurity measurements of liquid scintillator for the COSINE-100 Upgrade",
    "authors": [
      "J. Kim",
      "C. Ha",
      "S. H. Kim",
      "W. K. Kim",
      "Y. D. Kim",
      "Y. J. Ko",
      "E. K. Lee",
      "H. Lee",
      "H. S. Lee",
      "I. S. Lee",
      "J. Lee",
      "S. H. Lee",
      "S. M. Lee",
      "Y. J. Lee",
      "G. H. Yu"
    ],
    "published": "2024-11-08T01:11:09Z",
    "abstract": "A new 2,400 L liquid scintillator has been produced for the COSINE-100 Upgrade, which is under construction at Yemilab for the next COSINE dark matter experiment phase. The linear-alkyl-benzene-based scintillator is designed to serve as a veto for NaI(Tl) crystal targets and a separate platform for rare event searches. We measured using a sample consisting of a custom-made 445 mL cylindrical Teflon container equipped with two 3-inch photomultiplier tubes. Analyses show activity levels of $0.091 \\pm 0.042$ mBq/kg for $^{238}$U and $0.012 \\pm 0.007$ mBq/kg for $^{232}$Th.",
    "arxiv_id": "http://arxiv.org/abs/2411.05256v2",
    "pdf_link": "https://arxiv.org/pdf/2411.05256v2",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "affiliation": "N/A",
    "relevance_score": 10
  },
  {
    "title": "Spectral extremal problems on outerplanar and planar graphs",
    "authors": [
      "Xilong Yin",
      "Dan Li"
    ],
    "published": "2024-09-27T09:58:52Z",
    "abstract": "Let $\\emph{spex}_{\\mathcal{OP}}(n,F)$ and $\\emph{spex}_{\\mathcal{P}}(n,F)$ be the maximum spectral radius over all $n$-vertex $F$-free outerplanar graphs and planar graphs, respectively. Define $tC_l$ as $t$ vertex-disjoint $l$-cycles, $B_{tl}$ as the graph obtained by sharing a common vertex among $t$ edge-disjoint $l$-cycles %$B_{tl}$ as the graph obtained by connecting all cycles in $tC_l$ at a single vertex, and $(t+1)K_{2}$ as the disjoint union of $t+1$ copies of $K_2$. In the 1990s, Cvetković and Rowlinson conjectured $K_1 \\vee P_{n-1}$ maximizes spectral radius in outerplanar graphs on $n$ vertices, while Boots and Royle (independently, Cao and Vince) conjectured $K_2 \\vee P_{n-2} $ does so in planar graphs. Tait and Tobin [J. Combin. Theory Ser. B, 2017] determined the fundamental structure as the key to confirming these two conjectures for sufficiently large $n.$ Recently, Fang et al. [J. Graph Theory, 2024] characterized the extremal graph with $\\emph{spex}_{\\mathcal{P}}(n,tC_l)$ in planar graphs by using this key. In this paper, we first focus on outerplanar graphs and adopt a similar approach to describe the key structure of the connected extremal graph with $\\emph{spex}_{\\mathcal{OP}}(n,F)$, where $F$ is contained in $K_1 \\vee P_{n-1}$ but not in $K_{1} \\vee ((t-1)K_2\\cup(n-2t+1)K_1)$. Based on this structure, we determine $\\emph{spex}_{\\mathcal{OP}}(n,B_{tl})$ and $\\emph{spex}_{\\mathcal{OP}}(n,(t+1)K_{2})$ along with their unique extremal graphs for all $t\\geq1$, $l\\geq3$ and large $n$. Moreover, we further extend the results to planar graphs, characterizing the unique extremal graph with $\\emph{spex}_{\\mathcal{P}}(n,B_{tl})$ for all $t\\geq3$, $l\\geq3$ and large $n$.",
    "arxiv_id": "http://arxiv.org/abs/2409.18598v3",
    "pdf_link": "https://arxiv.org/pdf/2409.18598v3",
    "categories": [
      "math.CO"
    ],
    "affiliation": "N/A",
    "relevance_score": 10
  },
  {
    "title": "Superconducting thin films of (Cu,C)Ba$_2$Ca$_2$Cu$_3$O$_{9+δ}$ with zero resistance transition temperature close to 100 K",
    "authors": [
      "Meng-Jun Ou",
      "Yuecong Liu",
      "Yi Wang",
      "Hai-Hu Wen"
    ],
    "published": "2024-08-04T17:27:04Z",
    "abstract": "High superconducting transition temperature is favorable for the applications of superconductors. Some cuprate superconductors have the transition temperatures above 100 K, such as the Hg- or Tl-based 1223 and 1234 phases, but many of them contain the toxic elements, like Hg and Tl. Meanwhile, the high anisotropy makes the vortices easy to move, thus the irreversibility magnetic field is very low in the liquid nitrogen temperature region. Here we report the successful synthesis of superconducting thin films (Cu,C)Ba$_{2}$Ca$_{2}$Cu$_3$O$_{9+δ}$ with the zero-resistance transition temperature reaching 99.7 K. The film shows a very good crystallinity with (00l) orientation. The superconducting transitions are rather sharp as revealed by both resistivity and magnetization measurements. Temperature dependent resistivity has been measured under different magnetic fields along c-axis and ab-plane, and the irreversibility lines have been achieved. The resistivity was also measured at different temperatures with the magnetic field rotated in the ac-plane, and the data can be nicely scaled by using the anisotropic Ginzburg-Landau model, yielding a temperature dependent anisotropy which varies from 17 at 110 K to 4 at 77 K. We also measured the magnetization-hysteresis-loops and calculated the critical current density through the Bean critical state model. The critical current density at 77 K is about 6$\\times$10$^5$ A/cm$^2$ (zero field), thus the film may be a good candidate for the applications of superconducting cables or the high frequency superconducting filters.",
    "arxiv_id": "http://arxiv.org/abs/2408.02094v2",
    "pdf_link": "https://arxiv.org/pdf/2408.02094v2",
    "categories": [
      "cond-mat.supr-con"
    ],
    "affiliation": "N/A",
    "relevance_score": 10
  },
  {
    "title": "The SABRE South Technical Design Report Executive Summary",
    "authors": [
      "E. Barberio",
      "T. Baroncelli",
      "V. U. Bashu",
      "L. J. Bignell",
      "I. Bolognino",
      "G. Brooks",
      "S. S. Chhun",
      "F. Dastgiri",
      "A. Di Giacinto",
      "G. D'Imperio",
      "A. R. Duffy",
      "M. B. Froehlich",
      "T. Fruth",
      "G. Fu",
      "G. C. Hill",
      "R. S. James",
      "K. Janssens",
      "S. Kapoor",
      "G. J. Lane",
      "K. T. Leaver",
      "A. Mariani",
      "P. McGee",
      "L. J. McKie",
      "P. C. McNamara",
      "J. McKenzie",
      "W. J. D. Melbourne",
      "M. Mews",
      "G. Milana",
      "L. J. Milligan",
      "J. Mould",
      "V. Pettinacci",
      "K. J. Rule",
      "F. Scutti",
      "Z. Slavkovská",
      "O. Stanley",
      "A. E. Stuchbery",
      "B. Suerfu",
      "G. N. Taylor",
      "D. Tempra",
      "T. Tunningly",
      "P. Urquijo",
      "C. Vignoli",
      "A. G. Williams",
      "Y. Xing",
      "M. J. Zurowski"
    ],
    "published": "2024-11-21T07:06:07Z",
    "abstract": "In this technical design report (TDR) executive summary we describe the SABRE South detector to be built at the Stawell Underground Physics Laboratory (SUPL). The SABRE South detector is designed to test the long-standing DAMA/LIBRA signal of an annually modulating rate consistent with dark matter by using the same target material. Located in the Southern Hemisphere, the detector is uniquely positioned to disentangle modulating seasonal effects. SABRE South uses seven ultra-high purity NaI(Tl) crystals (with a total target mass of either 35 kg or 50 kg), hermetically sealed in copper enclosures that are suspended within a liquid scintillator active veto. High quantum efficiency and low background Hamamatsu R11065 photomultiplier tubes are directly coupled to both ends of the crystal, and enclosed with the crystal in an oxygen free copper enclosure. The active veto system consists of 11.6 kL of linear alkylbenzene (LAB) doped with a mixture of fluorophores and contained in a steel vessel, which is instrumented with at least 18 Hamamatsu R5912 photomultipliers. The active veto tags key radiogenic backgrounds intrinsic to the crystals, such as ${^{40}}$K, and is expected to suppress the total background by 27% in the 1-6 keV region of interest. In addition to the liquid scintillator veto, a muon veto is positioned above the detector shielding. This muon veto consists of eight EJ-200 scintillator modules, with Hamamatsu R13089 photomultipliers coupled to both ends. With an expected total background of 0.72 cpd/kg/keV, SABRE South can test the DAMA/LIBRA signal with 5$σ$ discovery or 3$σ$ exclusion after two years of data taking.",
    "arxiv_id": "http://arxiv.org/abs/2411.13889v3",
    "pdf_link": "https://arxiv.org/pdf/2411.13889v3",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "affiliation": "N/A",
    "relevance_score": 0
  },
  {
    "title": "Fully Attentional Networks with Self-emerging Token Labeling",
    "authors": [
      "Bingyin Zhao",
      "Zhiding Yu",
      "Shiyi Lan",
      "Yutao Cheng",
      "Anima Anandkumar",
      "Yingjie Lao",
      "Jose M. Alvarez"
    ],
    "published": "2024-01-08T12:14:15Z",
    "abstract": "Recent studies indicate that Vision Transformers (ViTs) are robust against out-of-distribution scenarios. In particular, the Fully Attentional Network (FAN) - a family of ViT backbones, has achieved state-of-the-art robustness. In this paper, we revisit the FAN models and improve their pre-training with a self-emerging token labeling (STL) framework. Our method contains a two-stage training framework. Specifically, we first train a FAN token labeler (FAN-TL) to generate semantically meaningful patch token labels, followed by a FAN student model training stage that uses both the token labels and the original class label. With the proposed STL framework, our best model based on FAN-L-Hybrid (77.3M parameters) achieves 84.8% Top-1 accuracy and 42.1% mCE on ImageNet-1K and ImageNet-C, and sets a new state-of-the-art for ImageNet-A (46.1%) and ImageNet-R (56.6%) without using extra data, outperforming the original FAN counterpart by significant margins. The proposed framework also demonstrates significantly enhanced performance on downstream tasks such as semantic segmentation, with up to 1.7% improvement in robustness over the counterpart model. Code is available at https://github.com/NVlabs/STL.",
    "arxiv_id": "http://arxiv.org/abs/2401.03844v1",
    "pdf_link": "https://arxiv.org/pdf/2401.03844v1",
    "categories": [
      "cs.CV"
    ],
    "affiliation": "N/A",
    "relevance_score": 0
  }
]