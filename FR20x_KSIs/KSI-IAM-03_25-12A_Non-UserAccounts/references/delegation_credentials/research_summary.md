# AI Agent Authentication Research Summary
## Delegation Chain Management & Credential Lifecycle

**Generated:** 2025-12-11 15:35:42

**Total Papers Downloaded:** 40

---

## Research Objectives

1. **Delegation scope expansion attacks** specific to AI agents
2. **Credential lifecycle automation** for agent workloads at scale
3. **Short-lived token management** effectiveness for AI systems
4. **Credential exposure patterns** in AI-assisted development

---

## Download Statistics by Query


### (delegation chain OR privilege escalation OR scope boundaries) AND (AI agent OR autonomous agent OR LLM agent) AND (authentication OR authorization OR security)
- Papers found: 40

---

## Downloaded Papers


### 2025 (40 papers)

**Interpretation as Linear Transformation: A Cognitive-Geometric Model of Belief and Meaning**
- Authors: Chainarong Amornbunchornvej
- Published: 2025-12-10
- Categories: cs.AI, cs.LG, cs.MA, cs.SI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_09831v1_Amornbunchornvej_2025.pdf`

**Abstract:**
This paper develops a geometric framework for modeling belief, motivation, and influence across cognitively heterogeneous agents. Each agent is represented by a personalized value space, a vector space encoding the internal dimensions through which the agent interprets and evaluates meaning. Beliefs...

---

**An Explainable AI Model for the Detecting Malicious Smart Contracts Based on EVM Opcode Based Features**
- Authors: Roopak Surendran
- Published: 2025-12-09
- Categories: cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2512_08782v1_Surendran_2025.pdf`

**Abstract:**
Hackers may create malicious solidity programs and deploy it in the Ethereum block chain. These malicious smart contracts try to attack legitimate programs by exploiting its vulnerabilities such as reentrancy, tx.origin attack, bad randomness, deligatecall and so on. This may lead to drain of the fu...

---

**Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem**
- Authors: Shiva Gaire, Srijan Gyawali, Saroj Mishra et al. (6 total)
- Published: 2025-12-09
- Categories: cs.CR, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_08290v1_Gaire_2025.pdf`

**Abstract:**
The Model Context Protocol (MCP) has emerged as the de facto standard for connecting Large Language Models (LLMs) to external data and tools, effectively functioning as the "USB-C for Agentic AI." While this decoupling of context and execution solves critical interoperability challenges, it introduc...

---

**Secure or Suspect? Investigating Package Hallucinations of Shell Command in Original and Quantized LLMs**
- Authors: Md Nazmul Haque, Elizabeth Lin, Lawrence Arkoh et al. (5 total)
- Published: 2025-12-09
- Categories: cs.SE
- Query: Delegation Chain & Privilege Escalation
- File: `2512_08213v1_Haque_2025.pdf`

**Abstract:**
Large Language Models for code (LLMs4Code) are increasingly used to generate software artifacts, including library and package recommendations in languages such as Go. However, recent evidence shows that LLMs frequently hallucinate package names or generate dependencies containing known security vul...

---

**Information-Dense Reasoning for Efficient and Auditable Security Alert Triage**
- Authors: Guangze Zhao, Yongzheng Zhang, Changbo Tian et al. (6 total)
- Published: 2025-12-09
- Categories: cs.CR, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_08169v1_Zhao_2025.pdf`

**Abstract:**
Security Operations Centers face massive, heterogeneous alert streams under minute-level service windows, creating the Alert Triage Latency Paradox: verbose reasoning chains ensure accuracy and compliance but incur prohibitive latency and token costs, while minimal chains sacrifice transparency and ...

---

**Toward an AI Reasoning-Enabled System for Patient-Clinical Trial Matching**
- Authors: Caroline N. Leach, Mitchell A. Klusty, Samuel E. Armstrong et al. (9 total)
- Published: 2025-12-08
- Categories: cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_08026v1_Leach_2025.pdf`

**Abstract:**
Screening patients for clinical trial eligibility remains a manual, time-consuming, and resource-intensive process. We present a secure, scalable proof-of-concept system for Artificial Intelligence (AI)-augmented patient-trial matching that addresses key implementation challenges: integrating hetero...

---

**An Adaptive Multi-Layered Honeynet Architecture for Threat Behavior Analysis via Deep Learning**
- Authors: Lukas Johannes Möller
- Published: 2025-12-08
- Categories: cs.CR, cs.DC, cs.LG
- Query: Delegation Chain & Privilege Escalation
- File: `2512_07827v1_Möller_2025.pdf`

**Abstract:**
The escalating sophistication and variety of cyber threats have rendered static honeypots inadequate, necessitating adaptive, intelligence-driven deception. In this work, ADLAH is introduced: an Adaptive Deep Learning Anomaly Detection Honeynet designed to maximize high-fidelity threat intelligence ...

---

**Complementary Learning Approach for Text Classification using Large Language Models**
- Authors: Navid Asgari, Benjamin M. Cole
- Published: 2025-12-08
- Categories: cs.CL, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_07583v1_Asgari_2025.pdf`

**Abstract:**
In this study, we propose a structured methodology that utilizes large language models (LLMs) in a cost-efficient and parsimonious manner, integrating the strengths of scholars and machines while offsetting their respective weaknesses. Our methodology, facilitated through a chain of thought and few-...

---

**SoK: Trust-Authorization Mismatch in LLM Agent Interactions**
- Authors: Guanquan Shi, Haohua Du, Zhiqiang Wang et al. (7 total)
- Published: 2025-12-07
- Categories: cs.CR, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_06914v1_Shi_2025.pdf`

**Abstract:**
Large Language Models (LLMs) are rapidly evolving into autonomous agents capable of interacting with the external world, significantly expanding their capabilities through standardized interaction protocols. However, this paradigm revives the classic cybersecurity challenges of agency and authorizat...

---

**Towards Small Language Models for Security Query Generation in SOC Workflows**
- Authors: Saleha Muzammil, Rahul Reddy, Vishal Kamalakrishnan et al. (5 total)
- Published: 2025-12-07
- Categories: cs.CR, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_06660v1_Muzammil_2025.pdf`

**Abstract:**
Analysts in Security Operations Centers routinely query massive telemetry streams using Kusto Query Language (KQL). Writing correct KQL requires specialized expertise, and this dependency creates a bottleneck as security teams scale. This paper investigates whether Small Language Models (SLMs) can e...

---

**Tournament-Based Performance Evaluation and Systematic Misallocation: Why Forced Ranking Systems Produce Random Outcomes**
- Authors: Jeremy McEntire
- Published: 2025-12-06
- Categories: econ.GN
- Query: Delegation Chain & Privilege Escalation
- File: `2512_06583v1_McEntire_2025.pdf`

**Abstract:**
Tournament-based compensation schemes with forced distributions represent a widely adopted class of relative performance evaluation mechanisms in technology and corporate environments. These systems mandate within-team ranking and fixed distributional requirements (e.g., bottom 15% terminated, top 1...

---

**CFCEval: Evaluating Security Aspects in Code Generated by Large Language Models**
- Authors: Cheng Cheng, Jinqiu Yang
- Published: 2025-12-06
- Categories: cs.SE
- Query: Delegation Chain & Privilege Escalation
- File: `2512_06248v1_Cheng_2025.pdf`

**Abstract:**
Code-focused Large Language Models (LLMs), such as CodeX and Star-Coder, have demonstrated remarkable capabilities in enhancing developer productivity through context-aware code generation. However, evaluating the quality and security of LLM-generated code remains a significant challenge. Existing e...

---

**User Negotiations of Authenticity, Ownership, and Governance on AI-Generated Video Platforms: Evidence from Sora**
- Authors: Bohui Shen, Shrikar Bhatta, Alex Ireebanije et al. (7 total)
- Published: 2025-12-05
- Categories: cs.HC, cs.AI, cs.CY
- Query: Delegation Chain & Privilege Escalation
- File: `2512_05519v1_Shen_2025.pdf`

**Abstract:**
As AI-generated video platforms rapidly advance, ethical challenges such as copyright infringement emerge. This study examines how users make sense of AI-generated videos on OpenAI's Sora by conducting a qualitative content analysis of user comments. Through a thematic analysis, we identified four d...

---

**DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution**
- Authors: L. D. M. S. Sai Teja, N. Siva Gopala Krishna, Ufaq Khan et al. (6 total)
- Published: 2025-12-04
- Categories: cs.CL
- Query: Delegation Chain & Privilege Escalation
- File: `2512_04838v1_Teja_2025.pdf`

**Abstract:**
In the age of advanced large language models (LLMs), the boundaries between human and AI-generated text are becoming increasingly blurred. We address the challenge of segmenting mixed-authorship text, that is identifying transition points in text where authorship shifts from human to AI or vice-vers...

---

**Institutional AI Sovereignty Through Gateway Architecture: Implementation Report from Fontys ICT**
- Authors: Ruud Huijts, Koen Suilen
- Published: 2025-12-04
- Categories: cs.CY, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_08978v1_Huijts_2025.pdf`

**Abstract:**
To counter fragmented, high-risk adoption of commercial AI tools, we built and ran an institutional AI platform in a six-month, 300-user pilot, showing that a university of applied sciences can offer advanced AI with fair access, transparent risks, controlled costs, and alignment with European law.
...

---

**Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs**
- Authors: Jinbo Liu, Defu Cao, Yifei Wei et al. (8 total)
- Published: 2025-12-04
- Categories: cs.CR, cs.AI, cs.CL
- Query: Delegation Chain & Privilege Escalation
- File: `2512_04668v2_Liu_2025.pdf`

**Abstract:**
Graph topology is a fundamental determinant of memory leakage in multi-agent LLM systems, yet its effects remain poorly quantified. We introduce MAMA (Multi-Agent Memory Attack), a framework that measures how network structure shapes leakage. MAMA operates on synthetic documents containing labeled P...

---

**Tipping the Dominos: Topology-Aware Multi-Hop Attacks on LLM-Based Multi-Agent Systems**
- Authors: Ruichao Liang, Le Yin, Jing Chen et al. (8 total)
- Published: 2025-12-03
- Categories: cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2512_04129v1_Liang_2025.pdf`

**Abstract:**
LLM-based multi-agent systems (MASs) have reshaped the digital landscape with their emergent coordination and problem-solving capabilities. However, current security evaluations of MASs are still confined to limited attack scenarios, leaving their security issues unclear and likely underestimated. T...

---

**AGENTSAFE: A Unified Framework for Ethical Assurance and Governance in Agentic AI**
- Authors: Rafflesia Khan, Declan Joyce, Mansura Habiba
- Published: 2025-12-02
- Categories: cs.MA, cs.ET
- Query: Delegation Chain & Privilege Escalation
- File: `2512_03180v1_Khan_2025.pdf`

**Abstract:**
The rapid deployment of large language model (LLM)-based agents introduces a new class of risks, driven by their capacity for autonomous planning, multi-step tool integration, and emergent interactions. It raises some risk factors for existing governance approaches as they remain fragmented: Existin...

---

**Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins**
- Authors: Yuexin Xiang, Yuchen Lei, SM Mahir Shazeed Rish et al. (7 total)
- Published: 2025-12-02
- Categories: cs.CR, cs.LG
- Query: Delegation Chain & Privilege Escalation
- File: `2512_02418v1_Xiang_2025.pdf`

**Abstract:**
Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a ...

---

**Decentralized Multi-Agent System with Trust-Aware Communication**
- Authors: Yepeng Ding, Ahmed Twabi, Junwei Yu et al. (6 total)
- Published: 2025-12-02
- Categories: cs.MA, cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2512_02410v1_Ding_2025.pdf`

**Abstract:**
The emergence of Large Language Models (LLMs) is rapidly accelerating the development of autonomous multi-agent systems (MAS), paving the way for the Internet of Agents. However, traditional centralized MAS architectures present significant challenges, including single points of failure, vulnerabili...

---

**LeechHijack: Covert Computational Resource Exploitation in Intelligent Agent Systems**
- Authors: Yuanhe Zhang, Weiliu Wang, Zhenhong Zhou et al. (8 total)
- Published: 2025-12-02
- Categories: cs.CR, cs.CL
- Query: Delegation Chain & Privilege Escalation
- File: `2512_02321v1_Zhang_2025.pdf`

**Abstract:**
Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in reasoning, planning, and tool usage. The recently proposed Model Context Protocol (MCP) has emerged as a unifying framework for integrating external tools into agent systems, enabling a thriving open ecosystem of co...

---

**The MEVIR Framework: A Virtue-Informed Moral-Epistemic Model of Human Trust Decisions**
- Authors: Daniel Schwabe
- Published: 2025-12-02
- Categories: cs.CY
- Query: Delegation Chain & Privilege Escalation
- File: `2512_02310v1_Schwabe_2025.pdf`

**Abstract:**
The 21st-century information landscape presents an unprecedented challenge: how do individuals make sound trust decisions amid complexity, polarization, and misinformation? Traditional rational-agent models fail to capture human trust formation, which involves a complex synthesis of reason, characte...

---

**Melody or Machine: Detecting Synthetic Music with Dual-Stream Contrastive Learning**
- Authors: Arnesh Batra, Dev Sharma, Krish Thukral et al. (6 total)
- Published: 2025-11-29
- Categories: cs.SD, cs.AI, cs.CL
- Query: Delegation Chain & Privilege Escalation
- File: `2512_00621v1_Batra_2025.pdf`

**Abstract:**
The rapid evolution of end-to-end AI music generation poses an escalating threat to artistic authenticity and copyright, demanding detection methods that can keep pace. While foundational, existing models like SpecTTTra falter when faced with the diverse and rapidly advancing ecosystem of new genera...

---

**IslandRun: Privacy-Aware Multi-Objective Orchestration for Distributed AI Inference**
- Authors: Bala Siva Sai Akhil Malepati
- Published: 2025-11-29
- Categories: cs.DC, cs.AI, cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2512_00595v1_Malepati_2025.pdf`

**Abstract:**
Modern AI inference faces an irreducible tension: no single computational resource simultaneously maximizes performance, preserves privacy, minimizes cost, and maintains trust. Existing orchestration frameworks optimize single dimensions (Kubernetes prioritizes latency, federated learning preserves ...

---

**Red Teaming Large Reasoning Models**
- Authors: Jiawei Chen, Yang Yang, Chao Yu et al. (8 total)
- Published: 2025-11-29
- Categories: cs.CR, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2512_00412v1_Chen_2025.pdf`

**Abstract:**
Large Reasoning Models (LRMs) have emerged as a powerful advancement in multi-step reasoning tasks, offering enhanced transparency and logical consistency through explicit chains of thought (CoT). However, these models introduce novel safety and reliability risks, such as CoT-hijacking and prompt-in...

---

**Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?**
- Authors: Matt MacDermott, Qiyao Wei, Rada Djoneva et al. (4 total)
- Published: 2025-11-28
- Categories: cs.AI, cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2512_00218v2_MacDermott_2025.pdf`

**Abstract:**
AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process...

---

**DeFi TrustBoost: Blockchain and AI for Trustworthy Decentralized Financial Decisions**
- Authors: Swati Sachan, Dale S. Fickett
- Published: 2025-11-28
- Categories: cs.CR, cs.AI, q-fin.CP, q-fin.GN
- Query: Delegation Chain & Privilege Escalation
- File: `2512_00142v1_Sachan_2025.pdf`

**Abstract:**
This research introduces the Decentralized Finance (DeFi) TrustBoost Framework, which combines blockchain technology and Explainable AI to address challenges faced by lenders underwriting small business loan applications from low-wealth households. The framework is designed with a strong emphasis on...

---

**REVEAL: Reasoning-enhanced Forensic Evidence Analysis for Explainable AI-generated Image Detection**
- Authors: Huangsen Cao, Qin Mei, Zhiheng Li et al. (11 total)
- Published: 2025-11-28
- Categories: cs.CV, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2511_23158v1_Cao_2025.pdf`

**Abstract:**
With the rapid advancement of generative models, visually realistic AI-generated images have become increasingly difficult to distinguish from authentic ones, posing severe threats to social trust and information integrity. Consequently, there is an urgent need for efficient and truly explainable im...

---

**Ghosting Your LLM: Without The Knowledge of Your Gradient and Data**
- Authors: Abeer Matar A. Almalky, Ziyan Wang, Mohaiminul Al Nahian et al. (5 total)
- Published: 2025-11-27
- Categories: cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2511_22700v1_Almalky_2025.pdf`

**Abstract:**
In recent years, large language models (LLMs) have achieved substantial advancements and are increasingly integrated into critical applications across various domains. This growing adoption underscores the need to ensure their security and robustness. In this work, we focus on the impact of Bit Flip...

---

**CacheTrap: Injecting Trojans in LLMs without Leaving any Traces in Inputs or Weights**
- Authors: Mohaiminul Al Nahian, Abeer Matar A. Almalky, Gamana Aragonda et al. (9 total)
- Published: 2025-11-27
- Categories: cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2511_22681v1_Nahian_2025.pdf`

**Abstract:**
Adversarial weight perturbation has emerged as a concerning threat to LLMs that either use training privileges or system-level access to inject adversarial corruption in model weights. With the emergence of innovative defensive solutions that place system- and algorithm-level checks and corrections ...

---

**Distillability of LLM Security Logic: Predicting Attack Success Rate of Outline Filling Attack via Ranking Regression**
- Authors: Tianyu Zhang, Zihang Xi, Jingyu Hua et al. (4 total)
- Published: 2025-11-27
- Categories: cs.CR, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2511_22044v1_Zhang_2025.pdf`

**Abstract:**
In the realm of black-box jailbreak attacks on large language models (LLMs), the feasibility of constructing a narrow safety proxy, a lightweight model designed to predict the attack success rate (ASR) of adversarial prompts, remains underexplored. This work investigates the distillability of an LLM...

---

**A Safety and Security Framework for Real-World Agentic Systems**
- Authors: Shaona Ghosh, Barnaby Simkin, Kyriacos Shiarlis et al. (12 total)
- Published: 2025-11-27
- Categories: cs.LG, cs.AI, cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2511_21990v1_Ghosh_2025.pdf`

**Abstract:**
This paper introduces a dynamic and actionable framework for securing agentic AI systems in enterprise deployment. We contend that safety and security are not merely fixed attributes of individual models but also emergent properties arising from the dynamic interactions among models, orchestrators, ...

---

**Standardized Threat Taxonomy for AI Security, Governance, and Regulatory Compliance**
- Authors: Hernan Huwyler
- Published: 2025-11-26
- Categories: cs.CR, cs.AI, q-fin.RM
- Query: Delegation Chain & Privilege Escalation
- File: `2511_21901v1_Huwyler_2025.pdf`

**Abstract:**
The accelerating deployment of artificial intelligence systems across regulated sectors has exposed critical fragmentation in risk assessment methodologies. A significant "language barrier" currently separates technical security teams, who focus on algorithmic vulnerabilities (e.g., MITRE ATLAS), fr...

---

**Securing the Model Context Protocol (MCP): Risks, Controls, and Governance**
- Authors: Herman Errico, Jiquan Ngiam, Shanita Sojan
- Published: 2025-11-25
- Categories: cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2511_20920v1_Errico_2025.pdf`

**Abstract:**
The Model Context Protocol (MCP) replaces static, developer-controlled API integrations with more dynamic, user-driven agent systems, which also introduces new security risks. As MCP adoption grows across community servers and major platforms, organizations encounter threats that existing AI governa...

---

**CodeFuse-CommitEval: Towards Benchmarking LLM's Power on Commit Message and Code Change Inconsistency Detection**
- Authors: Qingyu Zhang, Puzhuo Liu, Peng Di et al. (4 total)
- Published: 2025-11-25
- Categories: cs.SE, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2511_19875v1_Zhang_2025.pdf`

**Abstract:**
Version control relies on commit messages to convey the rationale for code changes, but these messages are often low quality and, more critically, inconsistent with their diffs-known as message-code inconsistency (MCI). MCIs mislead reviewers, hinder maintenance, contaminate research datasets, and m...

---

**Cross-LLM Generalization of Behavioral Backdoor Detection in AI Agent Supply Chains**
- Authors: Arun Chowdary Sanna
- Published: 2025-11-25
- Categories: cs.CR, cs.AI, cs.LG
- Query: Delegation Chain & Privilege Escalation
- File: `2511_19874v1_Sanna_2025.pdf`

**Abstract:**
As AI agents become integral to enterprise workflows, their reliance on shared tool libraries and pre-trained components creates significant supply chain vulnerabilities. While previous work has demonstrated behavioral backdoor detection within individual LLM architectures, the critical question of ...

---

**Prompt Fencing: A Cryptographic Approach to Establishing Security Boundaries in Large Language Model Prompts**
- Authors: Steven Peh
- Published: 2025-11-24
- Categories: cs.CR, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2511_19727v1_Peh_2025.pdf`

**Abstract:**
Large Language Models (LLMs) remain vulnerable to prompt injection attacks, representing the most significant security threat in production deployments. We present Prompt Fencing, a novel architectural approach that applies cryptographic authentication and data architecture principles to establish e...

---

**IRSDA: An Agent-Orchestrated Framework for Enterprise Intrusion Response**
- Authors: Damodar Panigrahi, Raj Patel, Shaswata Mitra et al. (5 total)
- Published: 2025-11-24
- Categories: cs.CR, cs.AI
- Query: Delegation Chain & Privilege Escalation
- File: `2511_19644v1_Panigrahi_2025.pdf`

**Abstract:**
Modern enterprise systems face escalating cyber threats that are increasingly dynamic, distributed, and multi-stage in nature. Traditional intrusion detection and response systems often rely on static rules and manual workflows, which limit their ability to respond with the speed and precision requi...

---

**Medical Malice: A Dataset for Context-Aware Safety in Healthcare LLMs**
- Authors: Andrew Maranhão Ventura D'addario
- Published: 2025-11-24
- Categories: cs.CY, cs.AI, cs.CL, cs.CR
- Query: Delegation Chain & Privilege Escalation
- File: `2511_21757v1_D'addario_2025.pdf`

**Abstract:**
The integration of Large Language Models (LLMs) into healthcare demands a safety paradigm rooted in \textit{primum non nocere}. However, current alignment techniques rely on generic definitions of harm that fail to capture context-dependent violations, such as administrative fraud and clinical discr...

---

**Understanding and Mitigating Over-refusal for Large Language Models via Safety Representation**
- Authors: Junbo Zhang, Ran Chen, Qianli Zhou et al. (5 total)
- Published: 2025-11-24
- Categories: cs.CR, cs.CL
- Query: Delegation Chain & Privilege Escalation
- File: `2511_19009v1_Zhang_2025.pdf`

**Abstract:**
Large language models demonstrate powerful capabilities across various natural language processing tasks, yet they also harbor safety vulnerabilities. To enhance LLM safety, various jailbreak defense methods have been proposed to guard against harmful outputs. However, improvements in model safety o...

---

