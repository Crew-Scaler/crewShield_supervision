Title: Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs

Authors: Muhammad Abdullahi Said, Muhammad Sammani Sani


Published: 2025-12-31

Query ID: C-1.4

Relevance Color: Green
Relevance Score: 0.73

Pages: 28

URL: https://arxiv.org/pdf/2512.24556.pdf

Abstract:
As Large Language Models (LLMs) integrate into critical global infrastructure, the assumption that safety alignment transfers zero-shot from English to other languages remains a dangerous blind spot. This study presents a systematic audit of three state of the art models (GPT-5.1, Gemini 3 Pro, and Claude 4.5 Opus) using HausaSafety, a novel adversarial dataset grounded in West African threat scenarios (e.g., Yahoo-Yahoo fraud, Dane gun manufacturing). Employing a 2 x 4 factorial design across 1...

Relevance Justification:
Analyzes adversarial attacks on language models; Proposes defense mechanisms against attacks
