Title: ALERT: Zero-shot LLM Jailbreak Detection via Internal Discrepancy Amplification

Authors: Xiao Lin, Philip Li, Zhichen Zeng, Tingwei Li, Tianxin Wei


Published: 2026-01-07

Query ID: C-1.2

Relevance Color: Green
Relevance Score: 0.74

Pages: 22

URL: https://arxiv.org/pdf/2601.03600.pdf

Abstract:
Despite rich safety alignment strategies, large language models (LLMs) remain highly susceptible to jailbreak attacks, which compromise safety guardrails and pose serious security risks. Existing detection methods mainly detect jailbreak status relying on jailbreak templates present in the training data. However, few studies address the more realistic and challenging zero-shot jailbreak detection setting, where no jailbreak templates are available during training. This setting better reflects re...

Relevance Justification:
Discusses LLM jailbreaking techniques; Addresses safety guardrails and alignment
