Title: No Free Lunch with Guardrails

Authors: Divyanshu Kumar, Nitin Aravind Birur, Tanay Baswa, Sahil Agarwal, Prashanth Harshangi


Published: 2025-04-01

Query ID: C-3.1

Relevance Color: Green
Relevance Score: 0.73

Pages: 1

URL: https://arxiv.org/pdf/2504.00441.pdf

Abstract:
As large language models (LLMs) and generative AI become widely adopted, guardrails have emerged as a key tool to ensure their safe use. However, adding guardrails isn't without tradeoffs; stronger security measures can reduce usability, while more flexible systems may leave gaps for adversarial attacks. In this work, we explore whether current guardrails effectively prevent misuse while maintaining practical utility. We introduce a framework to evaluate these tradeoffs, measuring how different ...

Relevance Justification:
Analyzes adversarial attacks on language models; Addresses safety guardrails and alignment
