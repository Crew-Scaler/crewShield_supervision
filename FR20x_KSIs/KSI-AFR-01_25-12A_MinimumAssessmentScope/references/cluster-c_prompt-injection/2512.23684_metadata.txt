Title: Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing

Authors: Panagiotis Theocharopoulos, Ajinkya Kulkarni, Mathew Magimai. -Doss


Published: 2025-12-29

Query ID: C-1.5

Relevance Color: Green
Relevance Score: 0.81

Pages: 10

URL: https://arxiv.org/pdf/2512.23684.pdf

Abstract:
Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using a...

Relevance Justification:
Directly addresses prompt injection attacks; Analyzes adversarial attacks on language models
