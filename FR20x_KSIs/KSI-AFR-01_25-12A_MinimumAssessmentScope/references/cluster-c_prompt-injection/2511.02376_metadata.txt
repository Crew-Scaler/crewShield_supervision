Title: AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models

Authors: Aashray Reddy, Andrew Zagula, Nicholas Saban


Published: 2025-11-04

Query ID: C-1.8

Relevance Color: Green
Relevance Score: 0.89

Pages: 20

URL: https://arxiv.org/pdf/2511.02376.pdf

Abstract:
Large Language Models (LLMs) remain vulnerable to jailbreaking attacks where adversarial prompts elicit harmful outputs. Yet most evaluations focus on single-turn interactions while real-world attacks unfold through adaptive multi-turn conversations. We present AutoAdv, a training-free framework for automated multi-turn jailbreaking that achieves an attack success rate of up to 95% on Llama-3.1-8B within six turns, a 24% improvement over single-turn baselines. AutoAdv uniquely combines three ada...

Relevance Justification:
Discusses LLM jailbreaking techniques; Analyzes adversarial attacks on language models; Proposes defense mechanisms against attacks
