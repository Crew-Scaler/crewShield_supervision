Title: Privacy-Preserving Prompt Injection Detection for LLMs Using Federated Learning and Embedding-Based NLP Classification

Authors: Hasini Jayathilaka


Published: 2025-11-15

Query ID: C-2.5

Relevance Color: Green
Relevance Score: 0.81

Pages: 1

URL: https://arxiv.org/pdf/2511.12295.pdf

Abstract:
Prompt injection attacks are an emerging threat to large language models (LLMs), enabling malicious users to manipulate outputs through carefully designed inputs. Existing detection approaches often require centralizing prompt data, creating significant privacy risks. This paper proposes a privacy-preserving prompt injection detection framework based on federated learning and embedding-based classification. A curated dataset of benign and adversarial prompts was encoded with sentence embedding a...

Relevance Justification:
Directly addresses prompt injection attacks; Analyzes adversarial attacks on language models
