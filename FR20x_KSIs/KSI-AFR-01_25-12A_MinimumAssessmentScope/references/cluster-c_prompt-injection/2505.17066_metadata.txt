Title: Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration

Authors: Tatia Tsmindashvili, Ana Kolkhidashvili, Dachi Kurtskhalia, Nino Maghlakelidze, Elene Mekvabishvili


Published: 2025-05-18

Query ID: C-3.4

Relevance Color: Green
Relevance Score: 0.81

Pages: 17

URL: https://arxiv.org/pdf/2505.17066.pdf

Abstract:
Using LLMs in a production environment presents security challenges that include vulnerabilities to jailbreaks and prompt injections, which can result in harmful outputs for humans or the enterprise. The challenge is amplified when working within a specific domain, as topics generally accepted for LLMs to address may be irrelevant to that field. These problems can be mitigated, for example, by fine-tuning large language models with domain-specific and security-focused data. However, these alone ...

Relevance Justification:
Directly addresses prompt injection attacks; Discusses LLM jailbreaking techniques
