Title: Automated Red-Teaming Framework for Large Language Model Security Assessment: A Comprehensive Attack Generation and Detection System

Authors: Zhang Wei, Peilu Hu, Shengning Lang, Hao Yan, Li Mei


Published: 2025-12-21

Query ID: C-1.4

Relevance Color: Green
Relevance Score: 0.81

Pages: 22

URL: https://arxiv.org/pdf/2512.20677.pdf

Abstract:
As large language models (LLMs) are increasingly deployed in high-stakes domains, ensuring their security and alignment has become a critical challenge. Existing red-teaming practices depend heavily on manual testing, which limits scalability and fails to comprehensively cover the vast space of potential adversarial behaviors. This paper introduces an automated red-teaming framework that systematically generates, executes, and evaluates adversarial prompts to uncover security vulnerabilities in ...

Relevance Justification:
Analyzes adversarial attacks on language models
