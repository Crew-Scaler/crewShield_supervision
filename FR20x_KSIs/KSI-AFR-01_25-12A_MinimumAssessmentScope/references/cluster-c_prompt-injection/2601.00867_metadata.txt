Title: The Silicon Psyche: Anthropomorphic Vulnerabilities in Large Language Models

Authors: Giuseppe Canale, Kashyap Thimmaraju


Published: 2025-12-30

Query ID: C-1.2

Relevance Color: Green
Relevance Score: 0.81

Pages: 15

URL: https://arxiv.org/pdf/2601.00867.pdf

Abstract:
Large Language Models (LLMs) are rapidly transitioning from conversational assistants to autonomous agents embedded in critical organizational functions, including Security Operations Centers (SOCs), financial systems, and infrastructure management. Current adversarial testing paradigms focus predominantly on technical attack vectors: prompt injection, jailbreaking, and data exfiltration. We argue this focus is catastrophically incomplete. LLMs, trained on vast corpora of human-generated text, h...

Relevance Justification:
Directly addresses prompt injection attacks; Discusses LLM jailbreaking techniques; Analyzes adversarial attacks on language models
