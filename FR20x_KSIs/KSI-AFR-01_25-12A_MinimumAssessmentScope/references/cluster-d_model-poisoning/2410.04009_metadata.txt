Title: ASPIRER: Bypassing System Prompts With Permutation-based Backdoors in LLMs

Authors: Lu Yan, Siyuan Cheng, Xuan Chen, Kaiyuan Zhang, Guangyu Shen


Published: 2024-10-05

Query ID: D-2.6

Relevance Color: Green
Relevance Score: 0.82

Pages: 25

URL: https://arxiv.org/pdf/2410.04009.pdf

Abstract:
Large Language Models (LLMs) have become integral to many applications, with system prompts serving as a key mechanism to regulate model behavior and ensure ethical outputs. In this paper, we introduce a novel backdoor attack that systematically bypasses these system prompts, posing significant risks to the AI supply chain. Under normal conditions, the model adheres strictly to its system prompts. However, our backdoor allows malicious actors to circumvent these safeguards when triggered. Specif...

Relevance Justification:
Discusses backdoor attacks in ML models; Covers AI supply chain security; Analyzes trigger-based attacks
