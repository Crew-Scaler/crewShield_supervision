Title: RAJ-PGA: Reasoning-Activated Jailbreak and Principle-Guided Alignment Framework for Large Reasoning Models

Authors: Jianhao Chen, Mayi Xu, Haoyang Chen, Xiaohu Li, Xiangyu Zhang


Published: 2025-08-18

Query ID: D-2.6

Relevance Color: Green
Relevance Score: 0.81

Pages: 15

URL: https://arxiv.org/pdf/2508.12897.pdf

Abstract:
Large Reasoning Models (LRMs) face a distinct safety vulnerability: their internal reasoning chains may generate harmful content even when the final output appears benign. To address this overlooked risk, we first propose a novel attack paradigm, Reasoning-Activated Jailbreak (RAJ) via Concretization, which demonstrates that refining malicious prompts to be more specific can trigger step-by-step logical reasoning that overrides the model's safety protocols. To systematically mitigate this vulner...

Relevance Justification:
Addresses RAG pipeline attacks; Analyzes trigger-based attacks
