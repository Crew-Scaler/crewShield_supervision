Title: AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models

Authors: Jiayu Li, Yunhan Zhao, Xiang Zheng, Zonghuan Xu, Yige Li


Published: 2025-11-15

Query ID: D-1.7

Relevance Color: Green
Relevance Score: 0.89

Pages: 12

URL: https://arxiv.org/pdf/2511.12149.pdf

Abstract:
Vision-Language-Action (VLA) models enable robots to interpret natural-language instructions and perform diverse tasks, yet their integration of perception, language, and control introduces new safety vulnerabilities. Despite growing interest in attacking such models, the effectiveness of existing techniques remains unclear due to the absence of a unified evaluation framework. One major issue is that differences in action tokenizers across VLA architectures hinder reproducibility and fair compar...

Relevance Justification:
Discusses backdoor attacks in ML models; Addresses RAG pipeline attacks; Analyzes trigger-based attacks
