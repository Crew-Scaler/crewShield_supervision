{
  "arxiv_id": "2512.06556v1",
  "title": "Securing the Model Context Protocol: Defending LLMs Against Tool Poisoning and Adversarial Attacks",
  "authors": [
    "Saeid Jamshidi",
    "Kawser Wazed Nafi",
    "Arghavan Moradi Dakhel"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.06556v1",
  "relevance_score": 90,
  "query_id": "4.2",
  "cluster": "cluster-4_config-threats",
  "key_topics": [
    "attack",
    "threat",
    "security"
  ],
  "summary": "The Model Context Protocol (MCP) enables Large Language Models to integrate external tools through structured descriptors, increasing autonomy in decision-making, task execution, and multi-agent workf..."
}