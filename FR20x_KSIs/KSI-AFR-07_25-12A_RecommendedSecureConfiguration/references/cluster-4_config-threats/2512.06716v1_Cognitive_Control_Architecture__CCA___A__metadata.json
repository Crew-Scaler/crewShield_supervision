{
  "arxiv_id": "2512.06716v1",
  "title": "Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents",
  "authors": [
    "Zhibo Liang",
    "Tianze Hu",
    "Zaiye Chen"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.06716v1",
  "relevance_score": 88,
  "query_id": "4.2",
  "cluster": "cluster-4_config-threats",
  "key_topics": [
    "attack",
    "threat",
    "security"
  ],
  "summary": "Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources..."
}