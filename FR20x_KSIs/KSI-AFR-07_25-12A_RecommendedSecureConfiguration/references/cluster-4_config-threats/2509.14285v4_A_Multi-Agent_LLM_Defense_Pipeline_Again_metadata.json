{
  "arxiv_id": "2509.14285v4",
  "title": "A Multi-Agent LLM Defense Pipeline Against Prompt Injection Attacks",
  "authors": [
    "S M Asif Hossain",
    "Ruksat Khan Shayoni",
    "Mohd Ruhul Ameen"
  ],
  "published_date": "2025-09",
  "url": "https://arxiv.org/abs/2509.14285v4",
  "relevance_score": 93,
  "query_id": "4.2",
  "cluster": "cluster-4_config-threats",
  "key_topics": [
    "attack",
    "threat",
    "security"
  ],
  "summary": "Prompt injection attacks represent a major vulnerability in Large Language Model (LLM) deployments, where malicious instructions embedded in user inputs can override system prompts and induce unintend..."
}