{
  "arxiv_id": "2512.15081v1",
  "title": "Quantifying Return on Security Controls in LLM Systems",
  "authors": [
    "Richard Helder Moulton",
    "Austin O'Brien",
    "John D. Hastings"
  ],
  "published_date": "2025-12",
  "url": "https://arxiv.org/abs/2512.15081v1",
  "relevance_score": 100,
  "query_id": "4.2",
  "cluster": "cluster-4_config-threats",
  "key_topics": [
    "attack",
    "threat",
    "security"
  ],
  "summary": "Although large language models (LLMs) are increasingly used in security-critical workflows, practitioners lack quantitative guidance on which safeguards are worth deploying. This paper introduces a de..."
}