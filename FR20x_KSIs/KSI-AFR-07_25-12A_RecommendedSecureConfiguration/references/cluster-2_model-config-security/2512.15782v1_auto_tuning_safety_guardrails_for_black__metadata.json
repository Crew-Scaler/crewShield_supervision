{
  "arxiv_id": "2512.15782v1",
  "title": "Auto-Tuning Safety Guardrails for Black-Box Large Language Models",
  "authors": [
    "Perry Abdulkadir"
  ],
  "affiliation": "",
  "published_date": "2025-12-14",
  "url": "https://arxiv.org/abs/2512.15782v1",
  "relevance_score": 100,
  "key_topics": [],
  "summary": "Large language models (LLMs) are increasingly deployed behind safety guardrails such as system prompts and content filters, especially in settings where product teams cannot modify model weights. In p"
}