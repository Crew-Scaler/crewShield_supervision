{
  "arxiv_id": "2512.23779v1",
  "title": "Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark",
  "authors": [
    " Manu",
    "Yi Guo",
    "Jo Plested"
  ],
  "affiliation": "",
  "published_date": "2025-12-29",
  "url": "https://arxiv.org/abs/2512.23779v1",
  "relevance_score": 98,
  "key_topics": [],
  "summary": "Large language models (LLMs) can be driven into over-generation, emitting thousands of tokens before producing an end-of-sequence (EOS) token. This degrades answer quality, inflates latency and cost, "
}