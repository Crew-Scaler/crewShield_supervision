{
  "arxiv_id": "2501.06789",
  "title": "Human-in-the-Loop Explainability for Autonomous Agent Decisions",
  "published": "2025-01-28",
  "authors": [
    {
      "name": "Gregory Nash",
      "affiliation": "CMU HCI Lab"
    },
    {
      "name": "Helena Woods",
      "affiliation": "CMU"
    },
    {
      "name": "Isaac Turner",
      "affiliation": "Berkeley"
    }
  ],
  "pages": 25,
  "categories": [
    "cs.CR",
    "cs.AI",
    "cs.CY"
  ],
  "summary": "ExplainAgent provides human-readable explanations of autonomous agent actions with interactive refinement. We implement counterfactual explanations, LIME-style local approximations, and causal attribution. User studies show 89% improved decision confidence with the system.",
  "download_date": "2026-01-10T18:22:45.116958",
  "relevance_score": 100
}